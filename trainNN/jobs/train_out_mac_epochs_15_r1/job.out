Selected network (train.py) = bimodal
bimodal selected
Training seq
DEVICE = mps
####################
Total Parameters = 605185
Total Trainable Parameters = 605185
bichrom_seq(
  (conv1d): Conv1d(4, 256, kernel_size=(24,), stride=(1,))
  (relu): ReLU()
  (batchNorm1d): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (maxPool1d): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=True)
  (lstm): LSTM(256, 32, batch_first=True)
  (tanh): Tanh()
  (model_dense_repeat): Sequential(
    (0): Linear(in_features=32, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=512, out_features=512, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.5, inplace=False)
  )
  (linear): Linear(in_features=512, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
####################
Epochs = 15
EPOCH 1:
  batch 1 loss: 0.691869854927063
  batch 2 loss: 0.6917758882045746
  batch 3 loss: 0.6934128403663635
  batch 4 loss: 0.693450540304184
  batch 5 loss: 0.6934274673461914
  batch 6 loss: 0.6932846109072367
  batch 7 loss: 0.6931938784463065
  batch 8 loss: 0.6934704929590225
  batch 9 loss: 0.6937353875901964
  batch 10 loss: 0.6938183069229126
  batch 11 loss: 0.6936545263637196
  batch 12 loss: 0.6936713258425394
  batch 13 loss: 0.6935808154252859
  batch 14 loss: 0.6935789840562003
  batch 15 loss: 0.6935435771942139
  batch 16 loss: 0.6933188997209072
  batch 17 loss: 0.6930466995519751
  batch 18 loss: 0.6930355197853513
  batch 19 loss: 0.6929485452802557
  batch 20 loss: 0.6929671972990036
  batch 21 loss: 0.6929505467414856
  batch 22 loss: 0.6929058920253407
  batch 23 loss: 0.6928756755331288
  batch 24 loss: 0.6928359195590019
  batch 25 loss: 0.6929281735420227
  batch 26 loss: 0.6928232380977044
  batch 27 loss: 0.6927123400900099
  batch 28 loss: 0.6924029205526624
  batch 29 loss: 0.6927045357638392
  batch 30 loss: 0.6925450444221497
  batch 31 loss: 0.6924021340185597
  batch 32 loss: 0.6923991832882166
  batch 33 loss: 0.6922564813584993
  batch 34 loss: 0.6921504858662101
  batch 35 loss: 0.6921880262238639
  batch 36 loss: 0.6920298635959625
  batch 37 loss: 0.6917896464064315
  batch 38 loss: 0.6916572420220626
  batch 39 loss: 0.6913087016496903
  batch 40 loss: 0.6910864412784576
  batch 41 loss: 0.6907224684226804
  batch 42 loss: 0.6905580517791566
  batch 43 loss: 0.6905399949051613
  batch 44 loss: 0.6899561854926023
  batch 45 loss: 0.6896069579654269
  batch 46 loss: 0.6893652029659437
  batch 47 loss: 0.6895016989809402
  batch 48 loss: 0.689434410383304
  batch 49 loss: 0.6894033514723485
  batch 50 loss: 0.6892096948623657
  batch 51 loss: 0.6890159564859727
  batch 52 loss: 0.6888916102739481
  batch 53 loss: 0.6887946421245359
  batch 54 loss: 0.6885211754728247
  batch 55 loss: 0.688285925171592
  batch 56 loss: 0.6877650554691043
  batch 57 loss: 0.6876603448600099
  batch 58 loss: 0.6875080877336962
  batch 59 loss: 0.6873649075879888
  batch 60 loss: 0.6872015684843064
  batch 61 loss: 0.6867771783813101
  batch 62 loss: 0.6865320792121272
  batch 63 loss: 0.6862822685922895
  batch 64 loss: 0.685850047506392
  batch 65 loss: 0.6856283765572768
  batch 66 loss: 0.6852444581913225
  batch 67 loss: 0.6847928459964582
  batch 68 loss: 0.6847239960642422
  batch 69 loss: 0.6845581393310989
  batch 70 loss: 0.6842214567320687
  batch 71 loss: 0.6841301599019011
  batch 72 loss: 0.6839149188664224
  batch 73 loss: 0.6836819885528251
  batch 74 loss: 0.683421949277053
  batch 75 loss: 0.683362139860789
  batch 76 loss: 0.6832542411590877
  batch 77 loss: 0.6832394855363029
  batch 78 loss: 0.6829326206292862
  batch 79 loss: 0.6827066148383708
  batch 80 loss: 0.6822445437312126
  batch 81 loss: 0.6820130112730427
  batch 82 loss: 0.6818170838239717
  batch 83 loss: 0.6814837807632355
  batch 84 loss: 0.6814767320950826
  batch 85 loss: 0.6812477855121388
  batch 86 loss: 0.6817092853923177
  batch 87 loss: 0.6815057047482195
  batch 88 loss: 0.6812744797630743
  batch 89 loss: 0.6810538373636396
  batch 90 loss: 0.6809716052479214
  batch 91 loss: 0.6807960651733063
  batch 92 loss: 0.6807987715886987
  batch 93 loss: 0.6806354253522812
  batch 94 loss: 0.680517612619603
  batch 95 loss: 0.6805984597457083
  batch 96 loss: 0.6804337507734696
  batch 97 loss: 0.6801220184748935
  batch 98 loss: 0.679991757383152
  batch 99 loss: 0.6798091873978124
  batch 100 loss: 0.6796287262439727
  batch 101 loss: 0.6794620268415696
  batch 102 loss: 0.6793549551683313
  batch 103 loss: 0.679200652154904
  batch 104 loss: 0.6792478739069059
  batch 105 loss: 0.6790888587633769
  batch 106 loss: 0.679025522380505
  batch 107 loss: 0.67900834462353
  batch 108 loss: 0.6787969089216657
  batch 109 loss: 0.6787123488723685
  batch 110 loss: 0.6787867464802482
  batch 111 loss: 0.6787001952394709
  batch 112 loss: 0.678401993321521
  batch 113 loss: 0.6781954707297604
  batch 114 loss: 0.6782424434235221
  batch 115 loss: 0.6780608218649159
  batch 116 loss: 0.6780156297930355
  batch 117 loss: 0.6778739476815249
  batch 118 loss: 0.6777931305311494
  batch 119 loss: 0.6775775050916591
  batch 120 loss: 0.6773802921175957
  batch 121 loss: 0.6771408196323174
  batch 122 loss: 0.6769292144501795
  batch 123 loss: 0.6767862371312894
  batch 124 loss: 0.6766349144520298
  batch 125 loss: 0.6765280933380127
  batch 126 loss: 0.6762580696552519
  batch 127 loss: 0.676041336979453
  batch 128 loss: 0.6758780544623733
  batch 129 loss: 0.6756064771681793
  batch 130 loss: 0.675309340770428
  batch 131 loss: 0.6755029932233213
  batch 132 loss: 0.6754127311887164
  batch 133 loss: 0.6753149570379042
  batch 134 loss: 0.6751493544720891
  batch 135 loss: 0.6750068187713623
  batch 136 loss: 0.6749430566149599
  batch 137 loss: 0.6749220264219019
  batch 138 loss: 0.674751534410145
  batch 139 loss: 0.6747155283852447
  batch 140 loss: 0.6745289977107729
  batch 141 loss: 0.6743838334759922
  batch 142 loss: 0.6742710282265301
  batch 143 loss: 0.6741262882739514
  batch 144 loss: 0.6740028601553705
  batch 145 loss: 0.6738788386871075
  batch 146 loss: 0.6738661437818448
  batch 147 loss: 0.6738230557668776
  batch 148 loss: 0.6737194854665447
  batch 149 loss: 0.673638953858574
  batch 150 loss: 0.6735271382331848
  batch 151 loss: 0.6737033827415365
  batch 152 loss: 0.6736359835455292
  batch 153 loss: 0.6736282558223001
  batch 154 loss: 0.6734928012668312
  batch 155 loss: 0.6733944973637981
  batch 156 loss: 0.673325878687394
  batch 157 loss: 0.673232502618413
  batch 158 loss: 0.6732323475276367
  batch 159 loss: 0.6730781519937815
  batch 160 loss: 0.6730774406343698
  batch 161 loss: 0.6730431410836877
  batch 162 loss: 0.6730229431464348
  batch 163 loss: 0.6729511490628763
  batch 164 loss: 0.672871627458712
  batch 165 loss: 0.6727508328177713
  batch 166 loss: 0.6727323761905533
  batch 167 loss: 0.6726633802859369
  batch 168 loss: 0.6726633636724382
  batch 169 loss: 0.6726368849094098
  batch 170 loss: 0.6726007587769453
  batch 171 loss: 0.6724813894221657
  batch 172 loss: 0.6722984019407007
  batch 173 loss: 0.6722270270992565
  batch 174 loss: 0.6721829895315499
  batch 175 loss: 0.6721535083225795
  batch 176 loss: 0.672048956155777
  batch 177 loss: 0.671903486305711
  batch 178 loss: 0.6718483671043696
  batch 179 loss: 0.6717323660850525
  batch 180 loss: 0.6716965248187383
  batch 181 loss: 0.67165699716431
  batch 182 loss: 0.6715733946024717
  batch 183 loss: 0.6715221978276154
  batch 184 loss: 0.6714260519846625
  batch 185 loss: 0.671341626708572
  batch 186 loss: 0.6712531479456092
  batch 187 loss: 0.6712477175309697
  batch 188 loss: 0.6712365626020634
  batch 189 loss: 0.6711705494179296
  batch 190 loss: 0.6710571430231396
  batch 191 loss: 0.6710055642103026
  batch 192 loss: 0.6708338400349021
  batch 193 loss: 0.6707422140348761
  batch 194 loss: 0.6706412084323844
  batch 195 loss: 0.6706037814800556
  batch 196 loss: 0.6704838543522115
  batch 197 loss: 0.670522688911651
  batch 198 loss: 0.6705139414830641
  batch 199 loss: 0.6704345441343796
  batch 200 loss: 0.6703751549124718
  batch 201 loss: 0.6703137719809119
  batch 202 loss: 0.6703626433811566
  batch 203 loss: 0.6702189562943182
  batch 204 loss: 0.6702140154791814
  batch 205 loss: 0.6701820318291827
  batch 206 loss: 0.6701693474089058
  batch 207 loss: 0.6701913093023254
  batch 208 loss: 0.6701381401373789
  batch 209 loss: 0.6700592505874816
  batch 210 loss: 0.6699717093081702
  batch 211 loss: 0.6700195339618701
  batch 212 loss: 0.6698957808175177
  batch 213 loss: 0.6698611356283017
  batch 214 loss: 0.6697992941486501
  batch 215 loss: 0.6697268181068953
  batch 216 loss: 0.6695861303144031
  batch 217 loss: 0.6694959555902789
  batch 218 loss: 0.6694413645005007
  batch 219 loss: 0.6694202872171794
  batch 220 loss: 0.6694035706194964
  batch 221 loss: 0.6694174214725581
  batch 222 loss: 0.6693504012382783
  batch 223 loss: 0.6693383230756751
  batch 224 loss: 0.6692672888083118
  batch 225 loss: 0.6691378598743015
  batch 226 loss: 0.6689787997608692
  batch 227 loss: 0.6688481438002397
  batch 228 loss: 0.6687380713328981
  batch 229 loss: 0.6687049392008886
  batch 230 loss: 0.6687062802522079
  batch 231 loss: 0.6686534747416839
  batch 232 loss: 0.6686403247816809
  batch 233 loss: 0.6686103177684571
  batch 234 loss: 0.6685615500323793
  batch 235 loss: 0.6685071798081094
  batch 236 loss: 0.6683639366242845
  batch 237 loss: 0.6683057986734285
  batch 238 loss: 0.6682395426666036
  batch 239 loss: 0.6681972659781388
  batch 240 loss: 0.6681444756686687
  batch 241 loss: 0.668084586062372
  batch 242 loss: 0.6679665167962224
  batch 243 loss: 0.6679265584965302
  batch 244 loss: 0.6679670178010816
  batch 245 loss: 0.667876118786481
  batch 246 loss: 0.6678455692481219
  batch 247 loss: 0.6677502388896247
  batch 248 loss: 0.6677135741037707
  batch 249 loss: 0.6676778743065983
  batch 250 loss: 0.667624951839447
  batch 251 loss: 0.6676407867218869
  batch 252 loss: 0.6675538013851832
  batch 253 loss: 0.6674927534322023
  batch 254 loss: 0.6674376336608346
  batch 255 loss: 0.6674102848651362
  batch 256 loss: 0.6672771796584129
  batch 257 loss: 0.6672523364946537
  batch 258 loss: 0.6671452695547149
  batch 259 loss: 0.6670098748906699
  batch 260 loss: 0.6669467405630992
  batch 261 loss: 0.6668663746552449
  batch 262 loss: 0.6667607688266812
  batch 263 loss: 0.6666321428103139
  batch 264 loss: 0.6665146233457507
  batch 265 loss: 0.666444733232822
  batch 266 loss: 0.6663168834564381
  batch 267 loss: 0.6661703863393947
  batch 268 loss: 0.6661204927003206
  batch 269 loss: 0.6660649450738191
  batch 270 loss: 0.6659586999151442
  batch 271 loss: 0.6658878212045479
  batch 272 loss: 0.6657807583756307
  batch 273 loss: 0.6656175723006
  batch 274 loss: 0.6655964122636475
  batch 275 loss: 0.6655182747407393
  batch 276 loss: 0.6655018549898396
  batch 277 loss: 0.6654589156811849
  batch 278 loss: 0.6653687312877435
  batch 279 loss: 0.6653391159136236
  batch 280 loss: 0.6652271558131491
  batch 281 loss: 0.6651052187770287
  batch 282 loss: 0.6649694394135306
  batch 283 loss: 0.6648840483001601
  batch 284 loss: 0.6648525280851714
  batch 285 loss: 0.6646607089460942
  batch 286 loss: 0.664538602312128
  batch 287 loss: 0.664450337662514
  batch 288 loss: 0.6642350115709834
  batch 289 loss: 0.6642667459369118
  batch 290 loss: 0.664109309788408
  batch 291 loss: 0.6640251760220609
  batch 292 loss: 0.6640280178964955
  batch 293 loss: 0.6639792679112926
  batch 294 loss: 0.663881183076067
  batch 295 loss: 0.6638222445875911
  batch 296 loss: 0.663731570380765
  batch 297 loss: 0.6636323059849466
  batch 298 loss: 0.6634983458374971
  batch 299 loss: 0.6634600168486503
  batch 300 loss: 0.6634548683961232
  batch 301 loss: 0.6634041965997892
  batch 302 loss: 0.6633595928845816
  batch 303 loss: 0.663279143300387
  batch 304 loss: 0.6631944926553651
  batch 305 loss: 0.6630349739653165
  batch 306 loss: 0.6629853254439784
  batch 307 loss: 0.6628834741123336
  batch 308 loss: 0.6627741581820822
  batch 309 loss: 0.6627128913178799
  batch 310 loss: 0.6626651556261124
  batch 311 loss: 0.6626047095301834
  batch 312 loss: 0.662616355678974
  batch 313 loss: 0.6626434270947125
  batch 314 loss: 0.6626030743881396
  batch 315 loss: 0.6625371866756016
  batch 316 loss: 0.6624493585734428
  batch 317 loss: 0.6623702833329089
  batch 318 loss: 0.6623036300986068
  batch 319 loss: 0.6622050412022582
  batch 320 loss: 0.6621189808472991
  batch 321 loss: 0.6620370344580891
  batch 322 loss: 0.6619713000999474
  batch 323 loss: 0.6618574763599195
  batch 324 loss: 0.6617097937398486
  batch 325 loss: 0.6616252033527081
  batch 326 loss: 0.6615120267575504
  batch 327 loss: 0.6614246178839914
  batch 328 loss: 0.661315233242221
  batch 329 loss: 0.6613071348891795
  batch 330 loss: 0.6612080335617065
  batch 331 loss: 0.6610890255953971
  batch 332 loss: 0.6610217090830746
  batch 333 loss: 0.6609562413470523
  batch 334 loss: 0.6608424736354166
  batch 335 loss: 0.6606890568092688
  batch 336 loss: 0.6606150684612138
  batch 337 loss: 0.6605066736657117
  batch 338 loss: 0.6604630160613878
  batch 339 loss: 0.6604109819659792
  batch 340 loss: 0.6603148975793053
  batch 341 loss: 0.6602123524786091
  batch 342 loss: 0.6601100508232562
  batch 343 loss: 0.6600232942806389
  batch 344 loss: 0.6599697354574536
  batch 345 loss: 0.6599136825920879
  batch 346 loss: 0.6597962055592178
  batch 347 loss: 0.6597555375923685
  batch 348 loss: 0.6597401479194904
  batch 349 loss: 0.6596511137861235
  batch 350 loss: 0.6595654882703509
  batch 351 loss: 0.6594964006008246
  batch 352 loss: 0.6594187798486515
  batch 353 loss: 0.6593461062009882
  batch 354 loss: 0.6592243830699706
  batch 355 loss: 0.6592140229654984
  batch 356 loss: 0.6591437912723991
  batch 357 loss: 0.6590839881522983
  batch 358 loss: 0.6590397331301726
  batch 359 loss: 0.6589462149442072
  batch 360 loss: 0.6588684469461441
  batch 361 loss: 0.6587362769898285
  batch 362 loss: 0.6586414745170108
  batch 363 loss: 0.6586257892535081
  batch 364 loss: 0.6584811389118761
  batch 365 loss: 0.658392468217301
  batch 366 loss: 0.6583189974065686
  batch 367 loss: 0.6582788790928895
  batch 368 loss: 0.6581782355256702
  batch 369 loss: 0.6581041528603572
  batch 370 loss: 0.6580603229032981
  batch 371 loss: 0.6580856530814158
  batch 372 loss: 0.6579563002432546
  batch 373 loss: 0.6578805505750007
  batch 374 loss: 0.6578048199893319
  batch 375 loss: 0.657768632888794
  batch 376 loss: 0.6577132613734996
  batch 377 loss: 0.6576652684957974
  batch 378 loss: 0.6575386666116261
  batch 379 loss: 0.6574642835946699
  batch 380 loss: 0.6574426520811884
  batch 381 loss: 0.6573252885986188
  batch 382 loss: 0.6571782148633328
  batch 383 loss: 0.6570781968903604
  batch 384 loss: 0.6569810057990253
  batch 385 loss: 0.6569770545154423
  batch 386 loss: 0.6568562181502426
  batch 387 loss: 0.6567940137491054
  batch 388 loss: 0.6567886313519526
  batch 389 loss: 0.6567296687618932
  batch 390 loss: 0.6566485848182287
  batch 391 loss: 0.6565718248372188
  batch 392 loss: 0.6564975000765859
  batch 393 loss: 0.6564675960831969
  batch 394 loss: 0.656426104343482
  batch 395 loss: 0.6563822302637221
  batch 396 loss: 0.6563648885548717
  batch 397 loss: 0.6563027995059112
  batch 398 loss: 0.6561765961311571
  batch 399 loss: 0.6561348474115357
  batch 400 loss: 0.6560064977407456
  batch 401 loss: 0.6559354601952798
  batch 402 loss: 0.6558869835452654
  batch 403 loss: 0.6558108591560099
  batch 404 loss: 0.6557173798284909
  batch 405 loss: 0.6556599762704637
  batch 406 loss: 0.6555819992948635
  batch 407 loss: 0.6554889384593073
  batch 408 loss: 0.6554479035092335
  batch 409 loss: 0.655381028401531
  batch 410 loss: 0.6552862035065162
  batch 411 loss: 0.6551863287197123
  batch 412 loss: 0.6550946390455209
  batch 413 loss: 0.6549799296526875
  batch 414 loss: 0.6548780965920232
  batch 415 loss: 0.6547563561473985
  batch 416 loss: 0.6546314865923845
  batch 417 loss: 0.6545698226784631
  batch 418 loss: 0.654481780728655
  batch 419 loss: 0.6544527926422247
  batch 420 loss: 0.6544651630378905
  batch 421 loss: 0.6543892277957708
  batch 422 loss: 0.654354118764118
  batch 423 loss: 0.6542558498134567
  batch 424 loss: 0.6541827602206536
  batch 425 loss: 0.6541191448884852
  batch 426 loss: 0.6540720535555916
  batch 427 loss: 0.653999859890279
  batch 428 loss: 0.6538982623926947
  batch 429 loss: 0.6538076730041237
  batch 430 loss: 0.6537446770557137
  batch 431 loss: 0.6537025146307359
  batch 432 loss: 0.6536118459922297
  batch 433 loss: 0.6535257622771671
  batch 434 loss: 0.6535227872808957
  batch 435 loss: 0.6534075794548824
  batch 436 loss: 0.6533438437575594
  batch 437 loss: 0.6533582382398557
  batch 438 loss: 0.6533034230203933
  batch 439 loss: 0.6532077904714267
  batch 440 loss: 0.6531607271595434
  batch 441 loss: 0.653174821616841
  batch 442 loss: 0.6530398985379422
  batch 443 loss: 0.65297837747139
  batch 444 loss: 0.6528972595393121
  batch 445 loss: 0.6528569474648893
  batch 446 loss: 0.6528238619389556
  batch 447 loss: 0.6526907986442515
  batch 448 loss: 0.6526222311492477
  batch 449 loss: 0.6526148886085884
  batch 450 loss: 0.652548437250985
  batch 451 loss: 0.6524454113385101
  batch 452 loss: 0.6523404478763057
  batch 453 loss: 0.6522925236893542
  batch 454 loss: 0.6521993956901954
  batch 455 loss: 0.6521652296349243
  batch 456 loss: 0.6520682012564257
  batch 457 loss: 0.6520062339384133
  batch 458 loss: 0.651969134156881
  batch 459 loss: 0.6520090348580304
  batch 460 loss: 0.652022420193838
  batch 461 loss: 0.6519264020268157
  batch 462 loss: 0.6518882889768262
  batch 463 loss: 0.6518688140111145
  batch 464 loss: 0.6518791939677864
  batch 465 loss: 0.6517768213825841
  batch 466 loss: 0.6516950892788146
  batch 467 loss: 0.6516327671626906
  batch 468 loss: 0.6515675439284399
  batch 469 loss: 0.6514632994178008
  batch 470 loss: 0.6513906964596282
  batch 471 loss: 0.6514038701725614
  batch 472 loss: 0.6513160780324774
LOSS train 0.6513160780324774 valid 0.5308128595352173
LOSS train 0.6513160780324774 valid 0.523405134677887
LOSS train 0.6513160780324774 valid 0.5313394467035929
LOSS train 0.6513160780324774 valid 0.5298998653888702
LOSS train 0.6513160780324774 valid 0.5246465921401977
LOSS train 0.6513160780324774 valid 0.5283173024654388
LOSS train 0.6513160780324774 valid 0.5313364011900765
LOSS train 0.6513160780324774 valid 0.5352429747581482
LOSS train 0.6513160780324774 valid 0.5328353179825677
LOSS train 0.6513160780324774 valid 0.5324353039264679
LOSS train 0.6513160780324774 valid 0.5335794416340914
LOSS train 0.6513160780324774 valid 0.5320604195197424
LOSS train 0.6513160780324774 valid 0.5346432007276095
LOSS train 0.6513160780324774 valid 0.5351701889719281
LOSS train 0.6513160780324774 valid 0.5348342974980672
LOSS train 0.6513160780324774 valid 0.5353889390826225
LOSS train 0.6513160780324774 valid 0.5377688337774837
LOSS train 0.6513160780324774 valid 0.5384800963931613
LOSS train 0.6513160780324774 valid 0.5386149820528532
LOSS train 0.6513160780324774 valid 0.5398436725139618
LOSS train 0.6513160780324774 valid 0.5394780011404128
LOSS train 0.6513160780324774 valid 0.5385078571059487
LOSS train 0.6513160780324774 valid 0.5398720632428708
LOSS train 0.6513160780324774 valid 0.5399976397554079
LOSS train 0.6513160780324774 valid 0.5395863938331604
LOSS train 0.6513160780324774 valid 0.539221866772725
LOSS train 0.6513160780324774 valid 0.5395384475036904
LOSS train 0.6513160780324774 valid 0.539786098258836
LOSS train 0.6513160780324774 valid 0.539882925050012
LOSS train 0.6513160780324774 valid 0.5401561399300893
LOSS train 0.6513160780324774 valid 0.5409060985811295
LOSS train 0.6513160780324774 valid 0.5404135324060917
LOSS train 0.6513160780324774 valid 0.5404800501736727
LOSS train 0.6513160780324774 valid 0.5405575966133791
LOSS train 0.6513160780324774 valid 0.5414575798170908
LOSS train 0.6513160780324774 valid 0.5418812069627974
LOSS train 0.6513160780324774 valid 0.5417800980645258
LOSS train 0.6513160780324774 valid 0.5427404861701163
LOSS train 0.6513160780324774 valid 0.5424594986133087
LOSS train 0.6513160780324774 valid 0.542805577814579
LOSS train 0.6513160780324774 valid 0.5428382870627613
LOSS train 0.6513160780324774 valid 0.5433170752865928
LOSS train 0.6513160780324774 valid 0.542780036150023
LOSS train 0.6513160780324774 valid 0.5430701578205283
LOSS train 0.6513160780324774 valid 0.5431334760453966
LOSS train 0.6513160780324774 valid 0.5430915550045345
LOSS train 0.6513160780324774 valid 0.5426596770895288
LOSS train 0.6513160780324774 valid 0.5426607256134351
LOSS train 0.6513160780324774 valid 0.5430346435430099
LOSS train 0.6513160780324774 valid 0.542680059671402
LOSS train 0.6513160780324774 valid 0.5430861618004593
LOSS train 0.6513160780324774 valid 0.5429042692367847
LOSS train 0.6513160780324774 valid 0.5432939282003438
LOSS train 0.6513160780324774 valid 0.5433854615246808
LOSS train 0.6513160780324774 valid 0.5429759935899214
LOSS train 0.6513160780324774 valid 0.542908920773438
LOSS train 0.6513160780324774 valid 0.542848923750091
LOSS train 0.6513160780324774 valid 0.5427303499188917
LOSS train 0.6513160780324774 valid 0.5432833069461888
LOSS train 0.6513160780324774 valid 0.5432273368040721
LOSS train 0.6513160780324774 valid 0.5426916704803216
LOSS train 0.6513160780324774 valid 0.5429281823096737
LOSS train 0.6513160780324774 valid 0.5429268678029379
LOSS train 0.6513160780324774 valid 0.5434266403317451
LOSS train 0.6513160780324774 valid 0.5437122656748845
LOSS train 0.6513160780324774 valid 0.5437096041260343
LOSS train 0.6513160780324774 valid 0.5433597199952425
LOSS train 0.6513160780324774 valid 0.5433758909211439
LOSS train 0.6513160780324774 valid 0.5432160911352738
LOSS train 0.6513160780324774 valid 0.5429168701171875
LOSS train 0.6513160780324774 valid 0.5425452631963811
LOSS train 0.6513160780324774 valid 0.5422392007377412
LOSS train 0.6513160780324774 valid 0.542323746093332
LOSS train 0.6513160780324774 valid 0.542018076858005
LOSS train 0.6513160780324774 valid 0.5419058990478516
LOSS train 0.6513160780324774 valid 0.5419102169965443
LOSS train 0.6513160780324774 valid 0.5417498373366022
LOSS train 0.6513160780324774 valid 0.5415990146306845
LOSS train 0.6513160780324774 valid 0.5414134678961355
LOSS train 0.6513160780324774 valid 0.5411990471184254
LOSS train 0.6513160780324774 valid 0.5410941000337954
LOSS train 0.6513160780324774 valid 0.5411028527631992
LOSS train 0.6513160780324774 valid 0.541031665830727
LOSS train 0.6513160780324774 valid 0.5412386343592689
LOSS train 0.6513160780324774 valid 0.5409864951582516
LOSS train 0.6513160780324774 valid 0.5406365768854008
LOSS train 0.6513160780324774 valid 0.5405960918843061
LOSS train 0.6513160780324774 valid 0.5401814552870664
LOSS train 0.6513160780324774 valid 0.5404612448778046
LOSS train 0.6513160780324774 valid 0.540316234032313
LOSS train 0.6513160780324774 valid 0.5402302283507127
LOSS train 0.6513160780324774 valid 0.54027786332628
LOSS train 0.6513160780324774 valid 0.5400465848625348
LOSS train 0.6513160780324774 valid 0.5399624806769351
LOSS train 0.6513160780324774 valid 0.5399180249163978
LOSS train 0.6513160780324774 valid 0.5397097300738096
LOSS train 0.6513160780324774 valid 0.5397168133676666
LOSS train 0.6513160780324774 valid 0.5396382522826292
LOSS train 0.6513160780324774 valid 0.5399795698397087
LOSS train 0.6513160780324774 valid 0.540252286195755
LOSS train 0.6513160780324774 valid 0.5403615938554897
LOSS train 0.6513160780324774 valid 0.5401906476301306
LOSS train 0.6513160780324774 valid 0.5403629471954791
LOSS train 0.6513160780324774 valid 0.5403292265075904
LOSS train 0.6513160780324774 valid 0.540404068288349
LOSS train 0.6513160780324774 valid 0.5403962939415338
LOSS train 0.6513160780324774 valid 0.5403352123554622
LOSS train 0.6513160780324774 valid 0.5405257669863878
LOSS train 0.6513160780324774 valid 0.54053381659569
LOSS train 0.6513160780324774 valid 0.5407102769071406
LOSS train 0.6513160780324774 valid 0.5406653462229548
LOSS train 0.6513160780324774 valid 0.5405048483184406
LOSS train 0.6513160780324774 valid 0.5405786185137993
LOSS train 0.6513160780324774 valid 0.5404683351516724
LOSS train 0.6513160780324774 valid 0.5405471620352372
LOSS train 0.6513160780324774 valid 0.5406152898895329
LOSS train 0.6513160780324774 valid 0.5406219974542276
LOSS train 0.6513160780324774 valid 0.5406340345487757
LOSS train 0.6513160780324774 valid 0.5405449661887994
LOSS train 0.6513160780324774 valid 0.5404600217938423
LOSS train 0.6513160780324774 valid 0.5403231549854121
LOSS train 0.6513160780324774 valid 0.5402292247678413
LOSS train 0.6513160780324774 valid 0.5402248424243151
LOSS train 0.6513160780324774 valid 0.5403489100356256
LOSS train 0.6513160780324774 valid 0.5403182406425476
LOSS train 0.6513160780324774 valid 0.5401890263670966
LOSS train 0.6513160780324774 valid 0.540311633601902
LOSS train 0.6513160780324774 valid 0.5404416671954095
LOSS train 0.6513160780324774 valid 0.5406793508418771
LOSS train 0.6513160780324774 valid 0.5406630245538858
LOSS train 0.6513160780324774 valid 0.5408061101236417
LOSS train 0.6513160780324774 valid 0.5407802241318154
LOSS train 0.6513160780324774 valid 0.5407143432394903
LOSS train 0.6513160780324774 valid 0.5406349287993872
LOSS train 0.6513160780324774 valid 0.540690545241038
LOSS train 0.6513160780324774 valid 0.5407887872527627
LOSS train 0.6513160780324774 valid 0.540764238277491
LOSS train 0.6513160780324774 valid 0.5406472151694091
LOSS train 0.6513160780324774 valid 0.5404658484801972
LOSS train 0.6513160780324774 valid 0.5404778203793934
LOSS train 0.6513160780324774 valid 0.5405213942764499
LOSS train 0.6513160780324774 valid 0.5406806527728766
LOSS train 0.6513160780324774 valid 0.5406695279208097
LOSS train 0.6513160780324774 valid 0.5407047718763351
LOSS train 0.6513160780324774 valid 0.5405903277726009
LOSS train 0.6513160780324774 valid 0.5407575079023021
LOSS train 0.6513160780324774 valid 0.540566657270704
LOSS train 0.6513160780324774 valid 0.5408319033480979
LOSS train 0.6513160780324774 valid 0.5408812605294605
LOSS train 0.6513160780324774 valid 0.540744012594223
LOSS train 0.6513160780324774 valid 0.5408933194267829
LOSS train 0.6513160780324774 valid 0.5407278259333811
LOSS train 0.6513160780324774 valid 0.5406993514572094
LOSS train 0.6513160780324774 valid 0.5407033628457553
LOSS train 0.6513160780324774 valid 0.5407601760279748
LOSS train 0.6513160780324774 valid 0.5409200913630999
LOSS train 0.6513160780324774 valid 0.5409070944330495
LOSS train 0.6513160780324774 valid 0.5408696200274214
LOSS train 0.6513160780324774 valid 0.5406900171963673
LOSS train 0.6513160780324774 valid 0.5407280195504427
LOSS train 0.6513160780324774 valid 0.5406535941621532
LOSS train 0.6513160780324774 valid 0.5404488841692606
LOSS train 0.6513160780324774 valid 0.5404128655334192
LOSS train 0.6513160780324774 valid 0.5403749226796918
LOSS train 0.6513160780324774 valid 0.540328594048818
LOSS train 0.6513160780324774 valid 0.5401924169925322
LOSS train 0.6513160780324774 valid 0.5402741664184068
LOSS train 0.6513160780324774 valid 0.5404294087063699
LOSS train 0.6513160780324774 valid 0.5404932883364209
LOSS train 0.6513160780324774 valid 0.5407034071052775
LOSS train 0.6513160780324774 valid 0.5407459523245605
LOSS train 0.6513160780324774 valid 0.5406846916952799
LOSS train 0.6513160780324774 valid 0.5407304805138208
LOSS train 0.6513160780324774 valid 0.540656945143623
LOSS train 0.6513160780324774 valid 0.5406911809103829
LOSS train 0.6513160780324774 valid 0.5406328656456687
LOSS train 0.6513160780324774 valid 0.540799720812652
LOSS train 0.6513160780324774 valid 0.540866549095411
LOSS train 0.6513160780324774 valid 0.5407773392826485
LOSS train 0.6513160780324774 valid 0.5407001561588711
LOSS train 0.6513160780324774 valid 0.5406417487734589
LOSS train 0.6513160780324774 valid 0.5407176741531917
LOSS train 0.6513160780324774 valid 0.540780018261873
LOSS train 0.6513160780324774 valid 0.5409092022025067
LOSS train 0.6513160780324774 valid 0.5408381706959492
LOSS train 0.6513160780324774 valid 0.5408363012216424
LOSS train 0.6513160780324774 valid 0.5407970834543361
LOSS train 0.6513160780324774 valid 0.5408484317520832
LOSS train 0.6513160780324774 valid 0.5407293104620837
LOSS train 0.6513160780324774 valid 0.5406635635777524
LOSS train 0.6513160780324774 valid 0.5408267787613794
LOSS train 0.6513160780324774 valid 0.5408130455762148
LOSS train 0.6513160780324774 valid 0.5408450043880878
LOSS train 0.6513160780324774 valid 0.5407632067031467
LOSS train 0.6513160780324774 valid 0.5407295242334024
LOSS train 0.6513160780324774 valid 0.5409034578775873
LOSS train 0.6513160780324774 valid 0.5410475352693935
LOSS train 0.6513160780324774 valid 0.5410884278591233
LOSS train 0.6513160780324774 valid 0.5410312171557441
LOSS train 0.6513160780324774 valid 0.5411099997162819
LOSS train 0.6513160780324774 valid 0.5410599978409003
LOSS train 0.6513160780324774 valid 0.5411088687948661
LOSS train 0.6513160780324774 valid 0.5410021646269436
LOSS train 0.6513160780324774 valid 0.5410061718202105
LOSS train 0.6513160780324774 valid 0.5410259043298117
LOSS train 0.6513160780324774 valid 0.5409744946123327
LOSS train 0.6513160780324774 valid 0.5409924664359161
LOSS train 0.6513160780324774 valid 0.5410270567696828
LOSS train 0.6513160780324774 valid 0.5409698511995197
LOSS train 0.6513160780324774 valid 0.5410052370457422
LOSS train 0.6513160780324774 valid 0.5409096504839676
LOSS train 0.6513160780324774 valid 0.5409838059600794
LOSS train 0.6513160780324774 valid 0.5409344471116581
LOSS train 0.6513160780324774 valid 0.5408170705086717
LOSS train 0.6513160780324774 valid 0.5408062183579733
LOSS train 0.6513160780324774 valid 0.5407747584912512
LOSS train 0.6513160780324774 valid 0.5408378974083932
LOSS train 0.6513160780324774 valid 0.5407416784982069
LOSS train 0.6513160780324774 valid 0.5407335390783337
LOSS train 0.6513160780324774 valid 0.5407357088544152
LOSS train 0.6513160780324774 valid 0.5408651782916143
LOSS train 0.6513160780324774 valid 0.5408632964701265
LOSS train 0.6513160780324774 valid 0.5410080137808762
LOSS train 0.6513160780324774 valid 0.5410166451973575
LOSS train 0.6513160780324774 valid 0.5410762892829047
LOSS train 0.6513160780324774 valid 0.5409653273831426
LOSS train 0.6513160780324774 valid 0.5410458224985568
LOSS train 0.6513160780324774 valid 0.5411273583508375
LOSS train 0.6513160780324774 valid 0.5410682043654429
LOSS train 0.6513160780324774 valid 0.5410001187220864
LOSS train 0.6513160780324774 valid 0.5410599798867197
LOSS train 0.6513160780324774 valid 0.5410554812386118
LOSS train 0.6513160780324774 valid 0.5409452477749837
LOSS train 0.6513160780324774 valid 0.5409058263668647
LOSS train 0.6513160780324774 valid 0.5409926678272003
LOSS train 0.6513160780324774 valid 0.540873795747757
LOSS train 0.6513160780324774 valid 0.5408149137778624
LOSS train 0.6513160780324774 valid 0.5408403097080583
LOSS train 0.6513160780324774 valid 0.5408154568911596
LOSS train 0.6513160780324774 valid 0.5407382421195507
LOSS train 0.6513160780324774 valid 0.5408057417117709
LOSS train 0.6513160780324774 valid 0.5407883088943387
LOSS train 0.6513160780324774 valid 0.5407881734302505
LOSS train 0.6513160780324774 valid 0.5408023165874793
LOSS train 0.6513160780324774 valid 0.5407880559259531
LOSS train 0.6513160780324774 valid 0.54082279064791
LOSS train 0.6513160780324774 valid 0.5408899325590867
LOSS train 0.6513160780324774 valid 0.5408410511670574
LOSS train 0.6513160780324774 valid 0.5409010634364853
LOSS train 0.6513160780324774 valid 0.5409277658462525
LOSS train 0.6513160780324774 valid 0.540951772752511
LOSS train 0.6513160780324774 valid 0.5411124144281659
LOSS train 0.6513160780324774 valid 0.5411192084489603
LOSS train 0.6513160780324774 valid 0.5412116107039564
LOSS train 0.6513160780324774 valid 0.5411493668369218
LOSS train 0.6513160780324774 valid 0.5411607881542295
LOSS train 0.6513160780324774 valid 0.541084586182457
LOSS train 0.6513160780324774 valid 0.541130372951197
LOSS train 0.6513160780324774 valid 0.541198100592639
LOSS train 0.6513160780324774 valid 0.5412266834424092
LOSS train 0.6513160780324774 valid 0.5412600778071817
LOSS train 0.6513160780324774 valid 0.5412941076828324
LOSS train 0.6513160780324774 valid 0.5413439330492636
LOSS train 0.6513160780324774 valid 0.541353532084913
LOSS train 0.6513160780324774 valid 0.5414052551647403
LOSS train 0.6513160780324774 valid 0.5414457500429082
LOSS train 0.6513160780324774 valid 0.5414302384808716
LOSS train 0.6513160780324774 valid 0.5413939512487668
LOSS train 0.6513160780324774 valid 0.5414744070471441
LOSS train 0.6513160780324774 valid 0.5414615953410113
LOSS train 0.6513160780324774 valid 0.5415010234526603
LOSS train 0.6513160780324774 valid 0.5415731815292555
LOSS train 0.6513160780324774 valid 0.5416457821161319
LOSS train 0.6513160780324774 valid 0.5416549596473248
LOSS train 0.6513160780324774 valid 0.5415753438256004
LOSS train 0.6513160780324774 valid 0.541620712781298
LOSS train 0.6513160780324774 valid 0.5416223073263892
LOSS train 0.6513160780324774 valid 0.5415564762602607
LOSS train 0.6513160780324774 valid 0.5416495607745263
LOSS train 0.6513160780324774 valid 0.541545393211501
LOSS train 0.6513160780324774 valid 0.5415108706603271
LOSS train 0.6513160780324774 valid 0.5413998815607517
LOSS train 0.6513160780324774 valid 0.5413663140876555
LOSS train 0.6513160780324774 valid 0.5413784869539906
LOSS train 0.6513160780324774 valid 0.5413937254955894
LOSS train 0.6513160780324774 valid 0.5413831493237635
LOSS train 0.6513160780324774 valid 0.5413477034518943
LOSS train 0.6513160780324774 valid 0.5413129946423901
LOSS train 0.6513160780324774 valid 0.5412826637083271
LOSS train 0.6513160780324774 valid 0.5412330580168757
LOSS train 0.6513160780324774 valid 0.5411085248812777
LOSS train 0.6513160780324774 valid 0.541165312471455
LOSS train 0.6513160780324774 valid 0.5411369916522055
LOSS train 0.6513160780324774 valid 0.5411751941353286
LOSS train 0.6513160780324774 valid 0.5411833449945611
LOSS train 0.6513160780324774 valid 0.541115948678674
LOSS train 0.6513160780324774 valid 0.5410955042550059
LOSS train 0.6513160780324774 valid 0.5411059214364762
LOSS train 0.6513160780324774 valid 0.5411792020733939
LOSS train 0.6513160780324774 valid 0.5411884133021037
LOSS train 0.6513160780324774 valid 0.5411939898202586
LOSS train 0.6513160780324774 valid 0.5411689226201039
LOSS train 0.6513160780324774 valid 0.5411413311958313
LOSS train 0.6513160780324774 valid 0.5410699675741949
LOSS train 0.6513160780324774 valid 0.5409811127381247
LOSS train 0.6513160780324774 valid 0.5409588659900466
LOSS train 0.6513160780324774 valid 0.5409763758267953
LOSS train 0.6513160780324774 valid 0.540935154278557
LOSS train 0.6513160780324774 valid 0.5409870697456656
LOSS train 0.6513160780324774 valid 0.5409636534029437
LOSS train 0.6513160780324774 valid 0.5408772107489239
LOSS train 0.6513160780324774 valid 0.5408838120026466
LOSS train 0.6513160780324774 valid 0.5409650598852017
LOSS train 0.6513160780324774 valid 0.5410357614991012
LOSS train 0.6513160780324774 valid 0.5410178801370046
LOSS train 0.6513160780324774 valid 0.5409550802617134
LOSS train 0.6513160780324774 valid 0.5409439499445894
LOSS train 0.6513160780324774 valid 0.5409506784295136
LOSS train 0.6513160780324774 valid 0.5408661879342178
LOSS train 0.6513160780324774 valid 0.5408559819683433
LOSS train 0.6513160780324774 valid 0.5408111981513716
LOSS train 0.6513160780324774 valid 0.5408045775401666
LOSS train 0.6513160780324774 valid 0.5407421457878208
LOSS train 0.6513160780324774 valid 0.5406880577405294
LOSS train 0.6513160780324774 valid 0.5406652008570157
LOSS train 0.6513160780324774 valid 0.5406680609916616
LOSS train 0.6513160780324774 valid 0.5407282567899162
LOSS train 0.6513160780324774 valid 0.5407109193322135
LOSS train 0.6513160780324774 valid 0.5407361332044051
LOSS train 0.6513160780324774 valid 0.5407045512488394
LOSS train 0.6513160780324774 valid 0.5406829423054468
LOSS train 0.6513160780324774 valid 0.5406162306127777
LOSS train 0.6513160780324774 valid 0.5406210574659858
LOSS train 0.6513160780324774 valid 0.5406161880421781
LOSS train 0.6513160780324774 valid 0.5405823534993983
LOSS train 0.6513160780324774 valid 0.5406476695622716
LOSS train 0.6513160780324774 valid 0.5406300731511781
LOSS train 0.6513160780324774 valid 0.5406531277140216
LOSS train 0.6513160780324774 valid 0.5406174759949203
LOSS train 0.6513160780324774 valid 0.5405834634514416
LOSS train 0.6513160780324774 valid 0.5405797295905977
LOSS train 0.6513160780324774 valid 0.5405438951930107
LOSS train 0.6513160780324774 valid 0.5405236400946236
LOSS train 0.6513160780324774 valid 0.5406057446501976
LOSS train 0.6513160780324774 valid 0.5405969868535581
LOSS train 0.6513160780324774 valid 0.540576049013634
LOSS train 0.6513160780324774 valid 0.5405933166443443
LOSS train 0.6513160780324774 valid 0.5406058180606228
LOSS train 0.6513160780324774 valid 0.5406443678205539
LOSS train 0.6513160780324774 valid 0.5406734423977988
LOSS train 0.6513160780324774 valid 0.5406738361741743
LOSS train 0.6513160780324774 valid 0.5407344216311519
LOSS train 0.6513160780324774 valid 0.540751117653617
LOSS train 0.6513160780324774 valid 0.5407577306874054
LOSS train 0.6513160780324774 valid 0.5407806885074562
LOSS train 0.6513160780324774 valid 0.5408018638243836
LOSS train 0.6513160780324774 valid 0.5408096548889866
LOSS train 0.6513160780324774 valid 0.5406932895742981
LOSS train 0.6513160780324774 valid 0.5406944175616613
LOSS train 0.6513160780324774 valid 0.5407139905624919
LOSS train 0.6513160780324774 valid 0.5407431561530792
LOSS train 0.6513160780324774 valid 0.5407044648794838
LOSS train 0.6513160780324774 valid 0.5407223772083104
LOSS train 0.6513160780324774 valid 0.540696416418631
LOSS train 0.6513160780324774 valid 0.5407271135343265
LOSS train 0.6513160780324774 valid 0.5406884217197127
LOSS train 0.6513160780324774 valid 0.5406469951208671
LOSS train 0.6513160780324774 valid 0.5406103754497092
LOSS train 0.6513160780324774 valid 0.5405908966775186
EPOCH 2:
  batch 1 loss: 0.6417978405952454
  batch 2 loss: 0.6163370013237
  batch 3 loss: 0.6220603982607523
  batch 4 loss: 0.6276739090681076
  batch 5 loss: 0.6254813075065613
  batch 6 loss: 0.6242851515611013
  batch 7 loss: 0.6256008403641837
  batch 8 loss: 0.6249300315976143
  batch 9 loss: 0.6261506742901273
  batch 10 loss: 0.6281788766384124
  batch 11 loss: 0.6280499588359486
  batch 12 loss: 0.62800732254982
  batch 13 loss: 0.629161706337562
  batch 14 loss: 0.630537245954786
  batch 15 loss: 0.6323812484741211
  batch 16 loss: 0.6318384334445
  batch 17 loss: 0.632512134664199
  batch 18 loss: 0.6334522763888041
  batch 19 loss: 0.6344091139341655
  batch 20 loss: 0.634183257818222
  batch 21 loss: 0.6346522399357387
  batch 22 loss: 0.6351203539154746
  batch 23 loss: 0.63564816246862
  batch 24 loss: 0.6352135439713796
  batch 25 loss: 0.6356683206558228
  batch 26 loss: 0.6365111332673293
  batch 27 loss: 0.6358701255586412
  batch 28 loss: 0.6352947184017727
  batch 29 loss: 0.6361873889791554
  batch 30 loss: 0.6367583195368449
  batch 31 loss: 0.6367415189743042
  batch 32 loss: 0.6370144076645374
  batch 33 loss: 0.6369118238940383
  batch 34 loss: 0.6370251546887791
  batch 35 loss: 0.6379108718463353
  batch 36 loss: 0.638287741276953
  batch 37 loss: 0.6380344484303448
  batch 38 loss: 0.6379628510851609
  batch 39 loss: 0.6376561125119528
  batch 40 loss: 0.6371132895350456
  batch 41 loss: 0.6375089389521901
  batch 42 loss: 0.6381044387817383
  batch 43 loss: 0.6385726291079854
  batch 44 loss: 0.6379869769920002
  batch 45 loss: 0.638663853539361
  batch 46 loss: 0.6388138921364493
  batch 47 loss: 0.6387578350432376
  batch 48 loss: 0.6386310930053393
  batch 49 loss: 0.6388208574178268
  batch 50 loss: 0.6383274376392365
  batch 51 loss: 0.6385039254730823
  batch 52 loss: 0.6387845747745954
  batch 53 loss: 0.6386040572850209
  batch 54 loss: 0.6379446221722497
  batch 55 loss: 0.6375756816430526
  batch 56 loss: 0.636934087744781
  batch 57 loss: 0.6370634666660375
  batch 58 loss: 0.6374616838734726
  batch 59 loss: 0.6374056834285542
  batch 60 loss: 0.6373312542835872
  batch 61 loss: 0.637135989353305
  batch 62 loss: 0.6369512321487549
  batch 63 loss: 0.6370667152934604
  batch 64 loss: 0.6369455521926284
  batch 65 loss: 0.6363013056608346
  batch 66 loss: 0.6363520631284425
  batch 67 loss: 0.636439533375982
  batch 68 loss: 0.6366788937765009
  batch 69 loss: 0.6366549609363943
  batch 70 loss: 0.6364390560558864
  batch 71 loss: 0.6363299178405547
  batch 72 loss: 0.6361157670617104
  batch 73 loss: 0.6361763093569507
  batch 74 loss: 0.6361086102756294
  batch 75 loss: 0.6360559233029683
  batch 76 loss: 0.6360792745100824
  batch 77 loss: 0.6361770219617076
  batch 78 loss: 0.6358286753678933
  batch 79 loss: 0.6356414028360874
  batch 80 loss: 0.6352467380464077
  batch 81 loss: 0.6355110576123367
  batch 82 loss: 0.6355941433732103
  batch 83 loss: 0.6355780054287739
  batch 84 loss: 0.6358483000880196
  batch 85 loss: 0.6357339220888475
  batch 86 loss: 0.6361503587212674
  batch 87 loss: 0.6358910840133141
  batch 88 loss: 0.6358707398176193
  batch 89 loss: 0.6357550935798817
  batch 90 loss: 0.6358123885260688
  batch 91 loss: 0.636071679356334
  batch 92 loss: 0.6360956022272939
  batch 93 loss: 0.6361289120489552
  batch 94 loss: 0.6361214042978084
  batch 95 loss: 0.6363276676127785
  batch 96 loss: 0.6364614870399237
  batch 97 loss: 0.6365057979662394
  batch 98 loss: 0.63642325449963
  batch 99 loss: 0.6363210280736288
  batch 100 loss: 0.6362681818008423
  batch 101 loss: 0.6363910843830297
  batch 102 loss: 0.6363825698693594
  batch 103 loss: 0.6362778671736856
  batch 104 loss: 0.6361617847130849
  batch 105 loss: 0.6361978899864923
  batch 106 loss: 0.6362229596893743
  batch 107 loss: 0.6364562166071384
  batch 108 loss: 0.636185661510185
  batch 109 loss: 0.6362385771690159
  batch 110 loss: 0.6364672476595098
  batch 111 loss: 0.6366851856042673
  batch 112 loss: 0.6366229562887123
  batch 113 loss: 0.6365049528864632
  batch 114 loss: 0.6366663339890932
  batch 115 loss: 0.6365912525550179
  batch 116 loss: 0.6367455952126404
  batch 117 loss: 0.6367052003868625
  batch 118 loss: 0.6365486812793603
  batch 119 loss: 0.6362968738339528
  batch 120 loss: 0.6363037839531899
  batch 121 loss: 0.6360507001561567
  batch 122 loss: 0.6359632083627044
  batch 123 loss: 0.635774025102941
  batch 124 loss: 0.6357681443614345
  batch 125 loss: 0.6355788164138794
  batch 126 loss: 0.6353123689454699
  batch 127 loss: 0.6352432956845742
  batch 128 loss: 0.6350169396027923
  batch 129 loss: 0.6346456463946852
  batch 130 loss: 0.6344996337707226
  batch 131 loss: 0.6345234258484295
  batch 132 loss: 0.6346166070663568
  batch 133 loss: 0.6346359826568374
  batch 134 loss: 0.6343592716686761
  batch 135 loss: 0.634297047721015
  batch 136 loss: 0.6342568940976087
  batch 137 loss: 0.6342639827380215
  batch 138 loss: 0.6342024915460227
  batch 139 loss: 0.6342249422622241
  batch 140 loss: 0.6340636985642569
  batch 141 loss: 0.6340586496583114
  batch 142 loss: 0.6341858254352086
  batch 143 loss: 0.6339864901729397
  batch 144 loss: 0.633853299336301
  batch 145 loss: 0.63388189940617
  batch 146 loss: 0.6338311209254068
  batch 147 loss: 0.6338678123999615
  batch 148 loss: 0.6337974876970858
  batch 149 loss: 0.6338221314769463
  batch 150 loss: 0.6336558159192404
  batch 151 loss: 0.6336045245461116
  batch 152 loss: 0.6336181297114021
  batch 153 loss: 0.6335085638208326
  batch 154 loss: 0.6334791044136147
  batch 155 loss: 0.6333457839104437
  batch 156 loss: 0.633207551179788
  batch 157 loss: 0.6331214821262724
  batch 158 loss: 0.633206314301189
  batch 159 loss: 0.6330062124714162
  batch 160 loss: 0.6329952757805586
  batch 161 loss: 0.6329353703475147
  batch 162 loss: 0.6330059836676092
  batch 163 loss: 0.6330291643464492
  batch 164 loss: 0.6328930665807027
  batch 165 loss: 0.6327966700900685
  batch 166 loss: 0.6327365166451557
  batch 167 loss: 0.6326378030691319
  batch 168 loss: 0.6326431656877199
  batch 169 loss: 0.6325693253934737
  batch 170 loss: 0.6325798802516039
  batch 171 loss: 0.6326173847181755
  batch 172 loss: 0.6325701000385506
  batch 173 loss: 0.6325929264801775
  batch 174 loss: 0.63246767171498
  batch 175 loss: 0.6323689225741795
  batch 176 loss: 0.6322716450826689
  batch 177 loss: 0.6321234612141625
  batch 178 loss: 0.6320149222116792
  batch 179 loss: 0.6319799116869879
  batch 180 loss: 0.6320412900712755
  batch 181 loss: 0.6321553189451523
  batch 182 loss: 0.6320222815969488
  batch 183 loss: 0.6319944979063149
  batch 184 loss: 0.6319376583332601
  batch 185 loss: 0.631869004545985
  batch 186 loss: 0.6318420082010249
  batch 187 loss: 0.6317297162856648
  batch 188 loss: 0.6316450149454969
  batch 189 loss: 0.6314974234848426
  batch 190 loss: 0.6313444865377326
  batch 191 loss: 0.6312724773172309
  batch 192 loss: 0.631195116477708
  batch 193 loss: 0.6310676728505544
  batch 194 loss: 0.630906677430438
  batch 195 loss: 0.6309977577282833
  batch 196 loss: 0.6309464199810612
  batch 197 loss: 0.6310834821105609
  batch 198 loss: 0.6310582212125412
  batch 199 loss: 0.6311834760047682
  batch 200 loss: 0.6312304255366326
  batch 201 loss: 0.6311851129009949
  batch 202 loss: 0.6311673439375245
  batch 203 loss: 0.6312695060457502
  batch 204 loss: 0.6311927978314605
  batch 205 loss: 0.6311193733680539
  batch 206 loss: 0.6311944621859245
  batch 207 loss: 0.6312593981839608
  batch 208 loss: 0.6311363809956954
  batch 209 loss: 0.6311180115316473
  batch 210 loss: 0.6310148591086978
  batch 211 loss: 0.6310542324707972
  batch 212 loss: 0.6309750735197427
  batch 213 loss: 0.630935379317109
  batch 214 loss: 0.6309104940601599
  batch 215 loss: 0.6308696885441625
  batch 216 loss: 0.6307111255548619
  batch 217 loss: 0.630625706389203
  batch 218 loss: 0.6306517416730933
  batch 219 loss: 0.6307096124784043
  batch 220 loss: 0.6306746252558448
  batch 221 loss: 0.6306908850756167
  batch 222 loss: 0.630635864294327
  batch 223 loss: 0.6307282854088754
  batch 224 loss: 0.6306078716048172
  batch 225 loss: 0.6305230440033807
  batch 226 loss: 0.6303992790985952
  batch 227 loss: 0.6302781664327378
  batch 228 loss: 0.630249051932703
  batch 229 loss: 0.6301481617069661
  batch 230 loss: 0.6301159985687421
  batch 231 loss: 0.6301420042009065
  batch 232 loss: 0.6300897133247606
  batch 233 loss: 0.6300139061371144
  batch 234 loss: 0.6299910191287342
  batch 235 loss: 0.6299330500846213
  batch 236 loss: 0.6298747560230352
  batch 237 loss: 0.6298540136482143
  batch 238 loss: 0.6298858791339297
  batch 239 loss: 0.6297832719950497
  batch 240 loss: 0.6297318530579408
  batch 241 loss: 0.6296251628903432
  batch 242 loss: 0.6295096950590118
  batch 243 loss: 0.6294990392869392
  batch 244 loss: 0.629563493318245
  batch 245 loss: 0.6294984158204526
  batch 246 loss: 0.6294370974467053
  batch 247 loss: 0.6294155955797265
  batch 248 loss: 0.629463346254441
  batch 249 loss: 0.6294348302136463
  batch 250 loss: 0.6294012656211853
  batch 251 loss: 0.629417585424218
  batch 252 loss: 0.6293287203898505
  batch 253 loss: 0.6292997523258798
  batch 254 loss: 0.6292497588424232
  batch 255 loss: 0.629298210144043
  batch 256 loss: 0.6292433009948581
  batch 257 loss: 0.6292924697760942
  batch 258 loss: 0.6291768183541853
  batch 259 loss: 0.6290510888265367
  batch 260 loss: 0.6290039841945355
  batch 261 loss: 0.6289995945276429
  batch 262 loss: 0.6289285562420619
  batch 263 loss: 0.6289141205327139
  batch 264 loss: 0.6288514349496725
  batch 265 loss: 0.6288268404186896
  batch 266 loss: 0.6287788287141269
  batch 267 loss: 0.6286896833319789
  batch 268 loss: 0.628618125817669
  batch 269 loss: 0.6285830680765627
  batch 270 loss: 0.6284772307784469
  batch 271 loss: 0.6283971713477835
  batch 272 loss: 0.6283689303433194
  batch 273 loss: 0.6282344309838264
  batch 274 loss: 0.6281601643040232
  batch 275 loss: 0.6281362347169356
  batch 276 loss: 0.6281191607316335
  batch 277 loss: 0.6281232478816586
  batch 278 loss: 0.6280311386791064
  batch 279 loss: 0.6280756417568439
  batch 280 loss: 0.6280127885086196
  batch 281 loss: 0.6279149464865172
  batch 282 loss: 0.6277555948030864
  batch 283 loss: 0.627692026931911
  batch 284 loss: 0.6276717536466222
  batch 285 loss: 0.6275136343219824
  batch 286 loss: 0.6274194832031543
  batch 287 loss: 0.6274279204395175
  batch 288 loss: 0.6272417586296797
  batch 289 loss: 0.627231177780455
  batch 290 loss: 0.6270820373091205
  batch 291 loss: 0.62696179880719
  batch 292 loss: 0.6269978280753306
  batch 293 loss: 0.6270125652742874
  batch 294 loss: 0.6269253790378571
  batch 295 loss: 0.6269539358252186
  batch 296 loss: 0.6268858500831836
  batch 297 loss: 0.6268412111584185
  batch 298 loss: 0.6267855543418218
  batch 299 loss: 0.6266844396208441
  batch 300 loss: 0.6267574548721313
  batch 301 loss: 0.6267831192856215
  batch 302 loss: 0.6267359775817947
  batch 303 loss: 0.62672624709976
  batch 304 loss: 0.6266708015219161
  batch 305 loss: 0.6265402238877094
  batch 306 loss: 0.6265101654856813
  batch 307 loss: 0.6264013236431035
  batch 308 loss: 0.6263974047713465
  batch 309 loss: 0.62632373525101
  batch 310 loss: 0.626369152146001
  batch 311 loss: 0.6263511297787118
  batch 312 loss: 0.6263965570773834
  batch 313 loss: 0.626433475329853
  batch 314 loss: 0.6264429656183643
  batch 315 loss: 0.6264213448479062
  batch 316 loss: 0.6264478262466721
  batch 317 loss: 0.6264204198629698
  batch 318 loss: 0.6263687981749481
  batch 319 loss: 0.6263521640652026
  batch 320 loss: 0.626306002959609
  batch 321 loss: 0.6262565431565139
  batch 322 loss: 0.6262452095191672
  batch 323 loss: 0.6262258985094241
  batch 324 loss: 0.6261095941802601
  batch 325 loss: 0.6261099797028762
  batch 326 loss: 0.6259744858449222
  batch 327 loss: 0.6258907762871605
  batch 328 loss: 0.6258607735721077
  batch 329 loss: 0.6258620456721645
  batch 330 loss: 0.6257598192402811
  batch 331 loss: 0.6256533540627748
  batch 332 loss: 0.625654726502407
  batch 333 loss: 0.6255846803968733
  batch 334 loss: 0.6254470003936106
  batch 335 loss: 0.6253944432557519
  batch 336 loss: 0.6253539199630419
  batch 337 loss: 0.6253502027571024
  batch 338 loss: 0.6253967586706376
  batch 339 loss: 0.6253434780073025
  batch 340 loss: 0.6253077045959585
  batch 341 loss: 0.6252569867369017
  batch 342 loss: 0.6252232885848709
  batch 343 loss: 0.6251491059714782
  batch 344 loss: 0.6251258089445358
  batch 345 loss: 0.625171364908633
  batch 346 loss: 0.62512143292179
  batch 347 loss: 0.6251221239051489
  batch 348 loss: 0.6251348572215815
  batch 349 loss: 0.6250544222856319
  batch 350 loss: 0.6249974373408727
  batch 351 loss: 0.6249685858049964
  batch 352 loss: 0.6249510893090204
  batch 353 loss: 0.6249219429053936
  batch 354 loss: 0.6248727939223165
  batch 355 loss: 0.6249059406804367
  batch 356 loss: 0.624882993738303
  batch 357 loss: 0.6248803602881124
  batch 358 loss: 0.6248891057248888
  batch 359 loss: 0.6248285338739167
  batch 360 loss: 0.6247937801811431
  batch 361 loss: 0.6247308673620885
  batch 362 loss: 0.6246672816039449
  batch 363 loss: 0.6246325219301482
  batch 364 loss: 0.6245158804314477
  batch 365 loss: 0.624522656120666
  batch 366 loss: 0.6244421772292403
  batch 367 loss: 0.6245075873523057
  batch 368 loss: 0.624432384967804
  batch 369 loss: 0.6244304545203522
  batch 370 loss: 0.624434917681926
  batch 371 loss: 0.6244899664285049
  batch 372 loss: 0.6244031024235551
  batch 373 loss: 0.6243819375460014
  batch 374 loss: 0.624304715643592
  batch 375 loss: 0.6242924346923828
  batch 376 loss: 0.6242679360699146
  batch 377 loss: 0.6242236921894772
  batch 378 loss: 0.6241549228234266
  batch 379 loss: 0.6241068413830055
  batch 380 loss: 0.6241058940950193
  batch 381 loss: 0.6240512775623892
  batch 382 loss: 0.623900964466065
  batch 383 loss: 0.623849246582848
  batch 384 loss: 0.6238357840726773
  batch 385 loss: 0.6238711059867562
  batch 386 loss: 0.6238004336703009
  batch 387 loss: 0.6237847654086367
  batch 388 loss: 0.6238225097816015
  batch 389 loss: 0.6238030576767223
  batch 390 loss: 0.6238432532701736
  batch 391 loss: 0.6237822056121534
  batch 392 loss: 0.6237385688083512
  batch 393 loss: 0.6237353147137863
  batch 394 loss: 0.623714387114278
  batch 395 loss: 0.6237039059023314
  batch 396 loss: 0.6236959837301813
  batch 397 loss: 0.6236717715972017
  batch 398 loss: 0.6235802218542627
  batch 399 loss: 0.6235451504102626
  batch 400 loss: 0.6234803119301796
  batch 401 loss: 0.6234497670223588
  batch 402 loss: 0.623443948837062
  batch 403 loss: 0.6234270601947017
  batch 404 loss: 0.6233509508985104
  batch 405 loss: 0.6233049779762456
  batch 406 loss: 0.623260637075443
  batch 407 loss: 0.6231894377408508
  batch 408 loss: 0.6232057752854684
  batch 409 loss: 0.6231480411329013
  batch 410 loss: 0.6231142257771841
  batch 411 loss: 0.6230695106977384
  batch 412 loss: 0.623022737578281
  batch 413 loss: 0.6229424362609808
  batch 414 loss: 0.6229044587715812
  batch 415 loss: 0.6228135562804809
  batch 416 loss: 0.6227602528838011
  batch 417 loss: 0.6226912725457756
  batch 418 loss: 0.6226432081044576
  batch 419 loss: 0.6226368408499015
  batch 420 loss: 0.6226346827688671
  batch 421 loss: 0.6226118633129818
  batch 422 loss: 0.6226776288866431
  batch 423 loss: 0.6226358713833153
  batch 424 loss: 0.6225822025312567
  batch 425 loss: 0.6225726520313936
  batch 426 loss: 0.6225170038395644
  batch 427 loss: 0.6224224899635941
  batch 428 loss: 0.6223552022303376
  batch 429 loss: 0.6223015311436776
  batch 430 loss: 0.6222933365855106
  batch 431 loss: 0.6222881417539999
  batch 432 loss: 0.622231292227904
  batch 433 loss: 0.6221821944102404
  batch 434 loss: 0.6221949426534539
  batch 435 loss: 0.6221067684820328
  batch 436 loss: 0.6220510880881494
  batch 437 loss: 0.6221052931975446
  batch 438 loss: 0.6221520228473019
  batch 439 loss: 0.6221214164905504
  batch 440 loss: 0.6220927527005022
  batch 441 loss: 0.6220809806501514
  batch 442 loss: 0.6219952453045824
  batch 443 loss: 0.6219837327843056
  batch 444 loss: 0.621919645113988
  batch 445 loss: 0.6218747472495175
  batch 446 loss: 0.6218583836416492
  batch 447 loss: 0.6217839315166943
  batch 448 loss: 0.6217549839722258
  batch 449 loss: 0.6217763585874392
  batch 450 loss: 0.6217079732153151
  batch 451 loss: 0.621685375924121
  batch 452 loss: 0.6216429719882729
  batch 453 loss: 0.6216330371681954
  batch 454 loss: 0.6215830995385342
  batch 455 loss: 0.6215352571927584
  batch 456 loss: 0.6214896392142564
  batch 457 loss: 0.6214628306989858
  batch 458 loss: 0.6214243777454159
  batch 459 loss: 0.6214252340248207
  batch 460 loss: 0.6214627267225928
  batch 461 loss: 0.6214023682403979
  batch 462 loss: 0.6213891199140837
  batch 463 loss: 0.62136198506242
  batch 464 loss: 0.6213723911807455
  batch 465 loss: 0.6212849986168646
  batch 466 loss: 0.6212068711739241
  batch 467 loss: 0.6211772725719966
  batch 468 loss: 0.6211238702138265
  batch 469 loss: 0.6210645866800727
  batch 470 loss: 0.6209919095039368
  batch 471 loss: 0.6210017118231252
  batch 472 loss: 0.6209224351381851
LOSS train 0.6209224351381851 valid 0.49337899684906006
LOSS train 0.6209224351381851 valid 0.47611381113529205
LOSS train 0.6209224351381851 valid 0.4856044550736745
LOSS train 0.6209224351381851 valid 0.484109066426754
LOSS train 0.6209224351381851 valid 0.48046706318855287
LOSS train 0.6209224351381851 valid 0.4834786007801692
LOSS train 0.6209224351381851 valid 0.48488740410123554
LOSS train 0.6209224351381851 valid 0.48743685334920883
LOSS train 0.6209224351381851 valid 0.4848094715012444
LOSS train 0.6209224351381851 valid 0.4854028344154358
LOSS train 0.6209224351381851 valid 0.4877165339209817
LOSS train 0.6209224351381851 valid 0.4856875389814377
LOSS train 0.6209224351381851 valid 0.4881312709588271
LOSS train 0.6209224351381851 valid 0.48828211213861195
LOSS train 0.6209224351381851 valid 0.48723284602165223
LOSS train 0.6209224351381851 valid 0.48758811317384243
LOSS train 0.6209224351381851 valid 0.4898129403591156
LOSS train 0.6209224351381851 valid 0.4906256314780977
LOSS train 0.6209224351381851 valid 0.49046246315303604
LOSS train 0.6209224351381851 valid 0.4913287192583084
LOSS train 0.6209224351381851 valid 0.4906293551127116
LOSS train 0.6209224351381851 valid 0.4890233169902455
LOSS train 0.6209224351381851 valid 0.4900361532750337
LOSS train 0.6209224351381851 valid 0.48983168601989746
LOSS train 0.6209224351381851 valid 0.4897788166999817
LOSS train 0.6209224351381851 valid 0.4894218353124765
LOSS train 0.6209224351381851 valid 0.48959947405038057
LOSS train 0.6209224351381851 valid 0.4898191509502275
LOSS train 0.6209224351381851 valid 0.48986775813431577
LOSS train 0.6209224351381851 valid 0.4899507244427999
LOSS train 0.6209224351381851 valid 0.49074922261699555
LOSS train 0.6209224351381851 valid 0.49010516982525587
LOSS train 0.6209224351381851 valid 0.4898974471019976
LOSS train 0.6209224351381851 valid 0.489932920126354
LOSS train 0.6209224351381851 valid 0.49054938299315315
LOSS train 0.6209224351381851 valid 0.49089029017421937
LOSS train 0.6209224351381851 valid 0.4912925870031924
LOSS train 0.6209224351381851 valid 0.49224458321144704
LOSS train 0.6209224351381851 valid 0.4919746594551282
LOSS train 0.6209224351381851 valid 0.4927676498889923
LOSS train 0.6209224351381851 valid 0.4929342269897461
LOSS train 0.6209224351381851 valid 0.4935379099278223
LOSS train 0.6209224351381851 valid 0.49289644249649933
LOSS train 0.6209224351381851 valid 0.4933165819807486
LOSS train 0.6209224351381851 valid 0.49349620673391553
LOSS train 0.6209224351381851 valid 0.4933721319488857
LOSS train 0.6209224351381851 valid 0.49306481823008114
LOSS train 0.6209224351381851 valid 0.49317918966213864
LOSS train 0.6209224351381851 valid 0.49355571002376325
LOSS train 0.6209224351381851 valid 0.4931876116991043
LOSS train 0.6209224351381851 valid 0.4934410785927492
LOSS train 0.6209224351381851 valid 0.4928742687289531
LOSS train 0.6209224351381851 valid 0.49303150458155937
LOSS train 0.6209224351381851 valid 0.492856345794819
LOSS train 0.6209224351381851 valid 0.49218696030703457
LOSS train 0.6209224351381851 valid 0.4921431083764349
LOSS train 0.6209224351381851 valid 0.49206734958447906
LOSS train 0.6209224351381851 valid 0.49189726545892914
LOSS train 0.6209224351381851 valid 0.49269760665247
LOSS train 0.6209224351381851 valid 0.4927978639801343
LOSS train 0.6209224351381851 valid 0.4923358007532651
LOSS train 0.6209224351381851 valid 0.49276576743971917
LOSS train 0.6209224351381851 valid 0.49297450411887395
LOSS train 0.6209224351381851 valid 0.49350309232249856
LOSS train 0.6209224351381851 valid 0.4938358824986678
LOSS train 0.6209224351381851 valid 0.4940946711735292
LOSS train 0.6209224351381851 valid 0.4938190325872222
LOSS train 0.6209224351381851 valid 0.49365150314920087
LOSS train 0.6209224351381851 valid 0.4935384764187578
LOSS train 0.6209224351381851 valid 0.4932258056742804
LOSS train 0.6209224351381851 valid 0.49281180534564273
LOSS train 0.6209224351381851 valid 0.49256252207689816
LOSS train 0.6209224351381851 valid 0.49280498574857845
LOSS train 0.6209224351381851 valid 0.492566126021179
LOSS train 0.6209224351381851 valid 0.49243739326794944
LOSS train 0.6209224351381851 valid 0.49253529976857335
LOSS train 0.6209224351381851 valid 0.49219008738344366
LOSS train 0.6209224351381851 valid 0.49196865199468076
LOSS train 0.6209224351381851 valid 0.4918108348604999
LOSS train 0.6209224351381851 valid 0.49160465747118
LOSS train 0.6209224351381851 valid 0.4915609300872426
LOSS train 0.6209224351381851 valid 0.4915397138130374
LOSS train 0.6209224351381851 valid 0.49144863938710776
LOSS train 0.6209224351381851 valid 0.49169908392997014
LOSS train 0.6209224351381851 valid 0.49166394682491527
LOSS train 0.6209224351381851 valid 0.4913356383872587
LOSS train 0.6209224351381851 valid 0.49137830905530644
LOSS train 0.6209224351381851 valid 0.490963012996045
LOSS train 0.6209224351381851 valid 0.4912555669800619
LOSS train 0.6209224351381851 valid 0.49093742337491775
LOSS train 0.6209224351381851 valid 0.4908685621979472
LOSS train 0.6209224351381851 valid 0.49086144663717435
LOSS train 0.6209224351381851 valid 0.49070323250627007
LOSS train 0.6209224351381851 valid 0.49049372844239497
LOSS train 0.6209224351381851 valid 0.4905359606993826
LOSS train 0.6209224351381851 valid 0.49042169004678726
LOSS train 0.6209224351381851 valid 0.49043709408376635
LOSS train 0.6209224351381851 valid 0.49032927106837837
LOSS train 0.6209224351381851 valid 0.49068006421580457
LOSS train 0.6209224351381851 valid 0.4909809416532516
LOSS train 0.6209224351381851 valid 0.4910776414493523
LOSS train 0.6209224351381851 valid 0.490977942943573
LOSS train 0.6209224351381851 valid 0.49104693618792933
LOSS train 0.6209224351381851 valid 0.4910856130031439
LOSS train 0.6209224351381851 valid 0.4909907349518367
LOSS train 0.6209224351381851 valid 0.49100068801978847
LOSS train 0.6209224351381851 valid 0.4909037120431383
LOSS train 0.6209224351381851 valid 0.4911177359797336
LOSS train 0.6209224351381851 valid 0.491139139604131
LOSS train 0.6209224351381851 valid 0.4912408763712103
LOSS train 0.6209224351381851 valid 0.4911067555616568
LOSS train 0.6209224351381851 valid 0.49107628634997774
LOSS train 0.6209224351381851 valid 0.49105871752300095
LOSS train 0.6209224351381851 valid 0.49088670208788754
LOSS train 0.6209224351381851 valid 0.49095802047978276
LOSS train 0.6209224351381851 valid 0.4908875250096979
LOSS train 0.6209224351381851 valid 0.4907726928209647
LOSS train 0.6209224351381851 valid 0.4907396660517838
LOSS train 0.6209224351381851 valid 0.49062164315656454
LOSS train 0.6209224351381851 valid 0.4906393180290858
LOSS train 0.6209224351381851 valid 0.4906217313009845
LOSS train 0.6209224351381851 valid 0.4905090732652633
LOSS train 0.6209224351381851 valid 0.4906149278811323
LOSS train 0.6209224351381851 valid 0.49064362121205174
LOSS train 0.6209224351381851 valid 0.49055279469490054
LOSS train 0.6209224351381851 valid 0.4903408918115828
LOSS train 0.6209224351381851 valid 0.49059214789097705
LOSS train 0.6209224351381851 valid 0.49061094783246517
LOSS train 0.6209224351381851 valid 0.49077634247698526
LOSS train 0.6209224351381851 valid 0.4907268423300523
LOSS train 0.6209224351381851 valid 0.4907525987115525
LOSS train 0.6209224351381851 valid 0.49069857958591345
LOSS train 0.6209224351381851 valid 0.4906257874983594
LOSS train 0.6209224351381851 valid 0.49058644206666235
LOSS train 0.6209224351381851 valid 0.4905850871845528
LOSS train 0.6209224351381851 valid 0.4906085648519151
LOSS train 0.6209224351381851 valid 0.4905788274141994
LOSS train 0.6209224351381851 valid 0.4904748080433279
LOSS train 0.6209224351381851 valid 0.49031347122123775
LOSS train 0.6209224351381851 valid 0.4904090195894241
LOSS train 0.6209224351381851 valid 0.49046109521642645
LOSS train 0.6209224351381851 valid 0.4907113576019314
LOSS train 0.6209224351381851 valid 0.4907435547638606
LOSS train 0.6209224351381851 valid 0.4908557254821062
LOSS train 0.6209224351381851 valid 0.4908695971143657
LOSS train 0.6209224351381851 valid 0.49106080993397594
LOSS train 0.6209224351381851 valid 0.49088167211636397
LOSS train 0.6209224351381851 valid 0.4911050027286684
LOSS train 0.6209224351381851 valid 0.4911735469862919
LOSS train 0.6209224351381851 valid 0.4910660580794017
LOSS train 0.6209224351381851 valid 0.49114165716613367
LOSS train 0.6209224351381851 valid 0.4909782452802909
LOSS train 0.6209224351381851 valid 0.49106281216627634
LOSS train 0.6209224351381851 valid 0.4911161157991979
LOSS train 0.6209224351381851 valid 0.49114699555981545
LOSS train 0.6209224351381851 valid 0.49139104057580996
LOSS train 0.6209224351381851 valid 0.4913962063895669
LOSS train 0.6209224351381851 valid 0.4913341093666946
LOSS train 0.6209224351381851 valid 0.491143747508151
LOSS train 0.6209224351381851 valid 0.4911695424467325
LOSS train 0.6209224351381851 valid 0.4910629252839533
LOSS train 0.6209224351381851 valid 0.49086068349855916
LOSS train 0.6209224351381851 valid 0.4909228713600182
LOSS train 0.6209224351381851 valid 0.4908915480099073
LOSS train 0.6209224351381851 valid 0.4907779554526011
LOSS train 0.6209224351381851 valid 0.49063305682446584
LOSS train 0.6209224351381851 valid 0.4906871889879604
LOSS train 0.6209224351381851 valid 0.4908946582249233
LOSS train 0.6209224351381851 valid 0.4910624175382084
LOSS train 0.6209224351381851 valid 0.49116652011871337
LOSS train 0.6209224351381851 valid 0.4911243540850299
LOSS train 0.6209224351381851 valid 0.4911547005176544
LOSS train 0.6209224351381851 valid 0.49133436459337354
LOSS train 0.6209224351381851 valid 0.4913468074867095
LOSS train 0.6209224351381851 valid 0.49139666097504753
LOSS train 0.6209224351381851 valid 0.49135122092610056
LOSS train 0.6209224351381851 valid 0.4914741874751398
LOSS train 0.6209224351381851 valid 0.4915939745273483
LOSS train 0.6209224351381851 valid 0.4915110380622928
LOSS train 0.6209224351381851 valid 0.4914815364612473
LOSS train 0.6209224351381851 valid 0.49148181821759895
LOSS train 0.6209224351381851 valid 0.49156512532915386
LOSS train 0.6209224351381851 valid 0.49165414233025306
LOSS train 0.6209224351381851 valid 0.4917708146183387
LOSS train 0.6209224351381851 valid 0.49169853265221053
LOSS train 0.6209224351381851 valid 0.49167205377291606
LOSS train 0.6209224351381851 valid 0.49161025180536155
LOSS train 0.6209224351381851 valid 0.4917763485870463
LOSS train 0.6209224351381851 valid 0.49162951206404065
LOSS train 0.6209224351381851 valid 0.49156486925325893
LOSS train 0.6209224351381851 valid 0.49176924110083053
LOSS train 0.6209224351381851 valid 0.4917904566973448
LOSS train 0.6209224351381851 valid 0.4918446509949284
LOSS train 0.6209224351381851 valid 0.49172204763618943
LOSS train 0.6209224351381851 valid 0.491605572669934
LOSS train 0.6209224351381851 valid 0.4917429997300615
LOSS train 0.6209224351381851 valid 0.49187509193638257
LOSS train 0.6209224351381851 valid 0.4919091147003752
LOSS train 0.6209224351381851 valid 0.4918731976693599
LOSS train 0.6209224351381851 valid 0.4918793830275536
LOSS train 0.6209224351381851 valid 0.4918349969446363
LOSS train 0.6209224351381851 valid 0.49192619943382715
LOSS train 0.6209224351381851 valid 0.4917976421675659
LOSS train 0.6209224351381851 valid 0.4917837078956997
LOSS train 0.6209224351381851 valid 0.4917911443768478
LOSS train 0.6209224351381851 valid 0.49179556546280684
LOSS train 0.6209224351381851 valid 0.49178775842638983
LOSS train 0.6209224351381851 valid 0.491825668571087
LOSS train 0.6209224351381851 valid 0.49170015174806403
LOSS train 0.6209224351381851 valid 0.4917743091072355
LOSS train 0.6209224351381851 valid 0.49163847017627194
LOSS train 0.6209224351381851 valid 0.4916284167260494
LOSS train 0.6209224351381851 valid 0.4915922906756961
LOSS train 0.6209224351381851 valid 0.49152956499117556
LOSS train 0.6209224351381851 valid 0.4915423606717309
LOSS train 0.6209224351381851 valid 0.49153325237609724
LOSS train 0.6209224351381851 valid 0.4916391570447227
LOSS train 0.6209224351381851 valid 0.49147493549443166
LOSS train 0.6209224351381851 valid 0.49153359241137223
LOSS train 0.6209224351381851 valid 0.4915137049826709
LOSS train 0.6209224351381851 valid 0.49166669052650486
LOSS train 0.6209224351381851 valid 0.4916617564252905
LOSS train 0.6209224351381851 valid 0.49179079660920283
LOSS train 0.6209224351381851 valid 0.4917428826114961
LOSS train 0.6209224351381851 valid 0.49178843471739025
LOSS train 0.6209224351381851 valid 0.4917090635384079
LOSS train 0.6209224351381851 valid 0.49176185771757286
LOSS train 0.6209224351381851 valid 0.4918318231377685
LOSS train 0.6209224351381851 valid 0.4917504628672871
LOSS train 0.6209224351381851 valid 0.49170020261536473
LOSS train 0.6209224351381851 valid 0.4917562984542929
LOSS train 0.6209224351381851 valid 0.49179318971161184
LOSS train 0.6209224351381851 valid 0.4916331137454561
LOSS train 0.6209224351381851 valid 0.49157668038820607
LOSS train 0.6209224351381851 valid 0.49167221619727763
LOSS train 0.6209224351381851 valid 0.49162529295278806
LOSS train 0.6209224351381851 valid 0.4915808017998305
LOSS train 0.6209224351381851 valid 0.4915594249462881
LOSS train 0.6209224351381851 valid 0.4915934363419042
LOSS train 0.6209224351381851 valid 0.49152160808444023
LOSS train 0.6209224351381851 valid 0.49163315726513684
LOSS train 0.6209224351381851 valid 0.4916599342399392
LOSS train 0.6209224351381851 valid 0.491696106430925
LOSS train 0.6209224351381851 valid 0.4917375065508436
LOSS train 0.6209224351381851 valid 0.4916732837959212
LOSS train 0.6209224351381851 valid 0.491682154860923
LOSS train 0.6209224351381851 valid 0.49178165897184056
LOSS train 0.6209224351381851 valid 0.49172382236969087
LOSS train 0.6209224351381851 valid 0.491752180588772
LOSS train 0.6209224351381851 valid 0.4918052371740341
LOSS train 0.6209224351381851 valid 0.4918569139987824
LOSS train 0.6209224351381851 valid 0.4920426802266212
LOSS train 0.6209224351381851 valid 0.4920366525414433
LOSS train 0.6209224351381851 valid 0.49216009441792496
LOSS train 0.6209224351381851 valid 0.4920868605959649
LOSS train 0.6209224351381851 valid 0.4921208774903789
LOSS train 0.6209224351381851 valid 0.4920472002910733
LOSS train 0.6209224351381851 valid 0.49209176928035975
LOSS train 0.6209224351381851 valid 0.4921687976043657
LOSS train 0.6209224351381851 valid 0.4921797708823131
LOSS train 0.6209224351381851 valid 0.49217753369232703
LOSS train 0.6209224351381851 valid 0.4922160285574789
LOSS train 0.6209224351381851 valid 0.4922308294038809
LOSS train 0.6209224351381851 valid 0.4922151835353086
LOSS train 0.6209224351381851 valid 0.4922493092294009
LOSS train 0.6209224351381851 valid 0.49228874890875995
LOSS train 0.6209224351381851 valid 0.4923111734988538
LOSS train 0.6209224351381851 valid 0.49231353902549885
LOSS train 0.6209224351381851 valid 0.49241548300232585
LOSS train 0.6209224351381851 valid 0.49236871478734195
LOSS train 0.6209224351381851 valid 0.49247314514269247
LOSS train 0.6209224351381851 valid 0.4925671030274209
LOSS train 0.6209224351381851 valid 0.49261551604166137
LOSS train 0.6209224351381851 valid 0.4926023573553475
LOSS train 0.6209224351381851 valid 0.4925316281752153
LOSS train 0.6209224351381851 valid 0.4925396225374678
LOSS train 0.6209224351381851 valid 0.4925222778793707
LOSS train 0.6209224351381851 valid 0.49246398954511544
LOSS train 0.6209224351381851 valid 0.49249484515531944
LOSS train 0.6209224351381851 valid 0.49240908420511653
LOSS train 0.6209224351381851 valid 0.49236618825549333
LOSS train 0.6209224351381851 valid 0.49223707943943373
LOSS train 0.6209224351381851 valid 0.4921718725256701
LOSS train 0.6209224351381851 valid 0.492172568931546
LOSS train 0.6209224351381851 valid 0.4921418283069343
LOSS train 0.6209224351381851 valid 0.4921090303809493
LOSS train 0.6209224351381851 valid 0.4920861381479257
LOSS train 0.6209224351381851 valid 0.4920438193819589
LOSS train 0.6209224351381851 valid 0.4920674518111668
LOSS train 0.6209224351381851 valid 0.492022770437701
LOSS train 0.6209224351381851 valid 0.49189646813468013
LOSS train 0.6209224351381851 valid 0.4918966061652523
LOSS train 0.6209224351381851 valid 0.49188262041111447
LOSS train 0.6209224351381851 valid 0.4919303104180057
LOSS train 0.6209224351381851 valid 0.4919551432132721
LOSS train 0.6209224351381851 valid 0.4918972063507583
LOSS train 0.6209224351381851 valid 0.49187410409603055
LOSS train 0.6209224351381851 valid 0.4918779672792294
LOSS train 0.6209224351381851 valid 0.4919550528494411
LOSS train 0.6209224351381851 valid 0.4920076584815979
LOSS train 0.6209224351381851 valid 0.49199724900366065
LOSS train 0.6209224351381851 valid 0.4919713692159842
LOSS train 0.6209224351381851 valid 0.49188485141634547
LOSS train 0.6209224351381851 valid 0.4918072558939457
LOSS train 0.6209224351381851 valid 0.4917216953684072
LOSS train 0.6209224351381851 valid 0.49173207668697133
LOSS train 0.6209224351381851 valid 0.491745325369633
LOSS train 0.6209224351381851 valid 0.4916653814060347
LOSS train 0.6209224351381851 valid 0.49173027479532855
LOSS train 0.6209224351381851 valid 0.49166172444820405
LOSS train 0.6209224351381851 valid 0.4916149477483375
LOSS train 0.6209224351381851 valid 0.4916522372991611
LOSS train 0.6209224351381851 valid 0.4918038997406396
LOSS train 0.6209224351381851 valid 0.4918687924457963
LOSS train 0.6209224351381851 valid 0.49185274820479136
LOSS train 0.6209224351381851 valid 0.4917874704056148
LOSS train 0.6209224351381851 valid 0.4917840476291789
LOSS train 0.6209224351381851 valid 0.49181974477737955
LOSS train 0.6209224351381851 valid 0.4917133880259475
LOSS train 0.6209224351381851 valid 0.49167994521558284
LOSS train 0.6209224351381851 valid 0.49158340878204393
LOSS train 0.6209224351381851 valid 0.491595943522009
LOSS train 0.6209224351381851 valid 0.49152929439633253
LOSS train 0.6209224351381851 valid 0.4915168395748845
LOSS train 0.6209224351381851 valid 0.4915008717316848
LOSS train 0.6209224351381851 valid 0.49152154114348756
LOSS train 0.6209224351381851 valid 0.49161384904056515
LOSS train 0.6209224351381851 valid 0.4916079846642366
LOSS train 0.6209224351381851 valid 0.49161559606033256
LOSS train 0.6209224351381851 valid 0.49161287780964014
LOSS train 0.6209224351381851 valid 0.49156902978067313
LOSS train 0.6209224351381851 valid 0.49147928739527624
LOSS train 0.6209224351381851 valid 0.4914861069964217
LOSS train 0.6209224351381851 valid 0.49153427511989
LOSS train 0.6209224351381851 valid 0.4915001190420407
LOSS train 0.6209224351381851 valid 0.4915446325959194
LOSS train 0.6209224351381851 valid 0.4915891690317884
LOSS train 0.6209224351381851 valid 0.491635661417916
LOSS train 0.6209224351381851 valid 0.49161659959143245
LOSS train 0.6209224351381851 valid 0.4916210007141618
LOSS train 0.6209224351381851 valid 0.49160608317145854
LOSS train 0.6209224351381851 valid 0.4914873681570354
LOSS train 0.6209224351381851 valid 0.4914160261348802
LOSS train 0.6209224351381851 valid 0.49149464140104693
LOSS train 0.6209224351381851 valid 0.4915122535781584
LOSS train 0.6209224351381851 valid 0.49147980957362003
LOSS train 0.6209224351381851 valid 0.491519242954529
LOSS train 0.6209224351381851 valid 0.4915382928889373
LOSS train 0.6209224351381851 valid 0.49157801518126
LOSS train 0.6209224351381851 valid 0.4915690766062055
LOSS train 0.6209224351381851 valid 0.49151628912344275
LOSS train 0.6209224351381851 valid 0.49159403136846697
LOSS train 0.6209224351381851 valid 0.49164837489047064
LOSS train 0.6209224351381851 valid 0.49169895717989925
LOSS train 0.6209224351381851 valid 0.4917268948655733
LOSS train 0.6209224351381851 valid 0.49171690843748245
LOSS train 0.6209224351381851 valid 0.49169746909488815
LOSS train 0.6209224351381851 valid 0.4915807997214728
LOSS train 0.6209224351381851 valid 0.4915903837401887
LOSS train 0.6209224351381851 valid 0.4915270040432612
LOSS train 0.6209224351381851 valid 0.49155733658005984
LOSS train 0.6209224351381851 valid 0.4915343883617148
LOSS train 0.6209224351381851 valid 0.4915427616476684
LOSS train 0.6209224351381851 valid 0.49151857361033724
LOSS train 0.6209224351381851 valid 0.4915253417949154
LOSS train 0.6209224351381851 valid 0.4915015911632548
LOSS train 0.6209224351381851 valid 0.4914895605488759
LOSS train 0.6209224351381851 valid 0.4914213193013616
LOSS train 0.6209224351381851 valid 0.4913743374147389
EPOCH 3:
  batch 1 loss: 0.5916091203689575
  batch 2 loss: 0.5851403772830963
  batch 3 loss: 0.5910231073697408
  batch 4 loss: 0.6027065366506577
  batch 5 loss: 0.6004331111907959
  batch 6 loss: 0.5996358195940653
  batch 7 loss: 0.602648207119533
  batch 8 loss: 0.6027618944644928
  batch 9 loss: 0.6031492087576125
  batch 10 loss: 0.6045079708099366
  batch 11 loss: 0.6038242795250632
  batch 12 loss: 0.6041824370622635
  batch 13 loss: 0.6046009843166058
  batch 14 loss: 0.6056702733039856
  batch 15 loss: 0.6059828519821167
  batch 16 loss: 0.6051080450415611
  batch 17 loss: 0.6050868665470797
  batch 18 loss: 0.6048461927307976
  batch 19 loss: 0.6054630624620538
  batch 20 loss: 0.6043007284402847
  batch 21 loss: 0.6059353323209853
  batch 22 loss: 0.6059714962135662
  batch 23 loss: 0.6059114647948224
  batch 24 loss: 0.6054419502615929
  batch 25 loss: 0.6045391297340393
  batch 26 loss: 0.6046942701706519
  batch 27 loss: 0.6041557281105606
  batch 28 loss: 0.6030730903148651
  batch 29 loss: 0.6033466067807428
  batch 30 loss: 0.6031181732813518
  batch 31 loss: 0.6028440421627413
  batch 32 loss: 0.6033360194414854
  batch 33 loss: 0.6029283801714579
  batch 34 loss: 0.6030348556883195
  batch 35 loss: 0.6038073062896728
  batch 36 loss: 0.6037768589125739
  batch 37 loss: 0.6035322820818102
  batch 38 loss: 0.6034235734688608
  batch 39 loss: 0.6038323946488209
  batch 40 loss: 0.6034935399889946
  batch 41 loss: 0.6034735746499968
  batch 42 loss: 0.6041599497908637
  batch 43 loss: 0.6046326049538546
  batch 44 loss: 0.6044599210674112
  batch 45 loss: 0.6050622648662991
  batch 46 loss: 0.6048758859219758
  batch 47 loss: 0.6047616600990295
  batch 48 loss: 0.6049500467876593
  batch 49 loss: 0.6049561464056676
  batch 50 loss: 0.6046598899364471
  batch 51 loss: 0.6044483839296827
  batch 52 loss: 0.6047919530134934
  batch 53 loss: 0.604626864757178
  batch 54 loss: 0.6041845955230571
  batch 55 loss: 0.6038855888626792
  batch 56 loss: 0.6030374339648655
  batch 57 loss: 0.6031359800121241
  batch 58 loss: 0.603577164740398
  batch 59 loss: 0.6032956969940056
  batch 60 loss: 0.6033474038044612
  batch 61 loss: 0.6031469966544479
  batch 62 loss: 0.6034646909083089
  batch 63 loss: 0.6035838297435215
  batch 64 loss: 0.6034640744328499
  batch 65 loss: 0.6027370434540968
  batch 66 loss: 0.6027311556267015
  batch 67 loss: 0.6027264105739878
  batch 68 loss: 0.6031845799263786
  batch 69 loss: 0.6032846552738245
  batch 70 loss: 0.6031523704528808
  batch 71 loss: 0.6030738026323453
  batch 72 loss: 0.6028192796640925
  batch 73 loss: 0.6028756409475248
  batch 74 loss: 0.602941100661819
  batch 75 loss: 0.6028793255488077
  batch 76 loss: 0.602886795213348
  batch 77 loss: 0.6028185657092503
  batch 78 loss: 0.6024482532953604
  batch 79 loss: 0.6024671468553664
  batch 80 loss: 0.6020184017717838
  batch 81 loss: 0.6021706991725497
  batch 82 loss: 0.6023246878530921
  batch 83 loss: 0.6022731597165027
  batch 84 loss: 0.6024204130683627
  batch 85 loss: 0.6022851712563458
  batch 86 loss: 0.6027270153511403
  batch 87 loss: 0.6024025918423445
  batch 88 loss: 0.602234763855284
  batch 89 loss: 0.6022640895307734
  batch 90 loss: 0.6022485885355208
  batch 91 loss: 0.6023425990408593
  batch 92 loss: 0.6022401659385018
  batch 93 loss: 0.6022479482876357
  batch 94 loss: 0.6022650618502434
  batch 95 loss: 0.6025593889387031
  batch 96 loss: 0.6025874093174934
  batch 97 loss: 0.6028122729861859
  batch 98 loss: 0.6029649924258796
  batch 99 loss: 0.6028034711124921
  batch 100 loss: 0.6026839566230774
  batch 101 loss: 0.6027803603965457
  batch 102 loss: 0.6025349632197735
  batch 103 loss: 0.6025360544908394
  batch 104 loss: 0.6025239607462516
  batch 105 loss: 0.6023815728369213
  batch 106 loss: 0.6024438272107322
  batch 107 loss: 0.6025096523427518
  batch 108 loss: 0.6022649495689957
  batch 109 loss: 0.6023168049821066
  batch 110 loss: 0.6024922500957143
  batch 111 loss: 0.6025081631299611
  batch 112 loss: 0.6022797136434487
  batch 113 loss: 0.602397681865017
  batch 114 loss: 0.6026800525815863
  batch 115 loss: 0.6026387152464493
  batch 116 loss: 0.6027634071892706
  batch 117 loss: 0.6028492552602392
  batch 118 loss: 0.6026887898727998
  batch 119 loss: 0.6025093328051206
  batch 120 loss: 0.6028267368674278
  batch 121 loss: 0.602723693552096
  batch 122 loss: 0.6024253256008273
  batch 123 loss: 0.6021522409547635
  batch 124 loss: 0.6021471177378008
  batch 125 loss: 0.6021297235488892
  batch 126 loss: 0.6020035327426971
  batch 127 loss: 0.6021698825941311
  batch 128 loss: 0.6019165450707078
  batch 129 loss: 0.6017567076424296
  batch 130 loss: 0.6016415192530705
  batch 131 loss: 0.601595188825185
  batch 132 loss: 0.6019314956484418
  batch 133 loss: 0.6021450735572585
  batch 134 loss: 0.6019834747065359
  batch 135 loss: 0.602015863524543
  batch 136 loss: 0.6020465966533212
  batch 137 loss: 0.602096186067066
  batch 138 loss: 0.6021680654822916
  batch 139 loss: 0.6021661025157078
  batch 140 loss: 0.6020176764045443
  batch 141 loss: 0.6020336214532244
  batch 142 loss: 0.6020584173605475
  batch 143 loss: 0.6019521547364188
  batch 144 loss: 0.601826910343435
  batch 145 loss: 0.6017583805939247
  batch 146 loss: 0.6018073354681878
  batch 147 loss: 0.6017946819869839
  batch 148 loss: 0.6016909033060074
  batch 149 loss: 0.6016736850642518
  batch 150 loss: 0.6014747448762258
  batch 151 loss: 0.6014529146895503
  batch 152 loss: 0.6015680585252611
  batch 153 loss: 0.601527659332051
  batch 154 loss: 0.601480680239665
  batch 155 loss: 0.6013649475189947
  batch 156 loss: 0.6011185099681219
  batch 157 loss: 0.6011135562969621
  batch 158 loss: 0.601132324979275
  batch 159 loss: 0.601008727865399
  batch 160 loss: 0.601093377172947
  batch 161 loss: 0.6011180481555299
  batch 162 loss: 0.601234351043348
  batch 163 loss: 0.6012657814962001
  batch 164 loss: 0.6011939194144272
  batch 165 loss: 0.6011381019245494
  batch 166 loss: 0.6010446429970753
  batch 167 loss: 0.6009677327321675
  batch 168 loss: 0.6010421940258571
  batch 169 loss: 0.6010336995830198
  batch 170 loss: 0.6010111559839809
  batch 171 loss: 0.601113141977299
  batch 172 loss: 0.6012699836215307
  batch 173 loss: 0.6012930143086207
  batch 174 loss: 0.6013468031225533
  batch 175 loss: 0.6012855052947998
  batch 176 loss: 0.6012693745168772
  batch 177 loss: 0.6011944985659109
  batch 178 loss: 0.6012197629119573
  batch 179 loss: 0.6012919645069698
  batch 180 loss: 0.6012568218840493
  batch 181 loss: 0.601321069245839
  batch 182 loss: 0.6012848081824543
  batch 183 loss: 0.6013659333270756
  batch 184 loss: 0.6013194235122722
  batch 185 loss: 0.6012909119193618
  batch 186 loss: 0.601164246438652
  batch 187 loss: 0.6010621221945247
  batch 188 loss: 0.6011248988674042
  batch 189 loss: 0.6009440898264526
  batch 190 loss: 0.6007963525621515
  batch 191 loss: 0.600846983999482
  batch 192 loss: 0.6006832420825958
  batch 193 loss: 0.6005482349371045
  batch 194 loss: 0.6004519815911952
  batch 195 loss: 0.6005933727973547
  batch 196 loss: 0.600587511853296
  batch 197 loss: 0.6007496269826357
  batch 198 loss: 0.6006604728072581
  batch 199 loss: 0.6007489499135233
  batch 200 loss: 0.6007507038116455
  batch 201 loss: 0.6007566398649073
  batch 202 loss: 0.600877983440267
  batch 203 loss: 0.6010632494400288
  batch 204 loss: 0.6010518906747594
  batch 205 loss: 0.601062076266219
  batch 206 loss: 0.6010773853190894
  batch 207 loss: 0.601159570009812
  batch 208 loss: 0.6010325871981107
  batch 209 loss: 0.6010195541609987
  batch 210 loss: 0.6009427073455992
  batch 211 loss: 0.6009268899099521
  batch 212 loss: 0.6009729383689053
  batch 213 loss: 0.6010252869744815
  batch 214 loss: 0.601029459561143
  batch 215 loss: 0.6009268810582715
  batch 216 loss: 0.6008552884062132
  batch 217 loss: 0.6009306671432636
  batch 218 loss: 0.6009345749102601
  batch 219 loss: 0.6009695116243406
  batch 220 loss: 0.6009720929644324
  batch 221 loss: 0.6011602805750402
  batch 222 loss: 0.6012325388891203
  batch 223 loss: 0.6012840230903284
  batch 224 loss: 0.6012167398418699
  batch 225 loss: 0.601229752699534
  batch 226 loss: 0.6011809551082881
  batch 227 loss: 0.601115112525251
  batch 228 loss: 0.6010925537138655
  batch 229 loss: 0.6010199990855555
  batch 230 loss: 0.6009863231493079
  batch 231 loss: 0.6010252774019778
  batch 232 loss: 0.6009518683984362
  batch 233 loss: 0.6009016021638469
  batch 234 loss: 0.600831325747009
  batch 235 loss: 0.600770231003457
  batch 236 loss: 0.60070132653592
  batch 237 loss: 0.6006950293412189
  batch 238 loss: 0.6007560644330097
  batch 239 loss: 0.600618013278211
  batch 240 loss: 0.6006454765796662
  batch 241 loss: 0.6005480066869269
  batch 242 loss: 0.60046332138629
  batch 243 loss: 0.6004638838669891
  batch 244 loss: 0.6004920775284532
  batch 245 loss: 0.60045309383042
  batch 246 loss: 0.6004945318388745
  batch 247 loss: 0.6004897590108246
  batch 248 loss: 0.6005416988365112
  batch 249 loss: 0.6005447109540304
  batch 250 loss: 0.6005219964981079
  batch 251 loss: 0.6005486948081696
  batch 252 loss: 0.6005099434701223
  batch 253 loss: 0.6004861263418386
  batch 254 loss: 0.6004944629087223
  batch 255 loss: 0.600652687923581
  batch 256 loss: 0.6005277133081108
  batch 257 loss: 0.6005766544824445
  batch 258 loss: 0.6005375394525454
  batch 259 loss: 0.6004227169692287
  batch 260 loss: 0.6003636293686353
  batch 261 loss: 0.6004316062306079
  batch 262 loss: 0.6003476877248924
  batch 263 loss: 0.6002934192070036
  batch 264 loss: 0.600264145795143
  batch 265 loss: 0.6001295476589563
  batch 266 loss: 0.6000744588393018
  batch 267 loss: 0.6000155491775341
  batch 268 loss: 0.5999560160423393
  batch 269 loss: 0.5999638272040838
  batch 270 loss: 0.5998248011977584
  batch 271 loss: 0.5997906094107681
  batch 272 loss: 0.599751327844227
  batch 273 loss: 0.5996724775422624
  batch 274 loss: 0.5996170868403721
  batch 275 loss: 0.5996894474463029
  batch 276 loss: 0.5996863628211229
  batch 277 loss: 0.5997715837688653
  batch 278 loss: 0.5997176043850054
  batch 279 loss: 0.5997797622475572
  batch 280 loss: 0.5996687776276044
  batch 281 loss: 0.599583977694189
  batch 282 loss: 0.5994068208738421
  batch 283 loss: 0.599360266549006
  batch 284 loss: 0.5993531138544351
  batch 285 loss: 0.5992617715869033
  batch 286 loss: 0.5991723516604284
  batch 287 loss: 0.5991863899114656
  batch 288 loss: 0.5990091686447462
  batch 289 loss: 0.5990871199274558
  batch 290 loss: 0.5989699026633953
  batch 291 loss: 0.5988982461162449
  batch 292 loss: 0.5989598123586342
  batch 293 loss: 0.5990150135531768
  batch 294 loss: 0.5988840397928847
  batch 295 loss: 0.5990134784730814
  batch 296 loss: 0.598982395352544
  batch 297 loss: 0.5989558431837294
  batch 298 loss: 0.5988935268165281
  batch 299 loss: 0.5988115847708788
  batch 300 loss: 0.5988849880297978
  batch 301 loss: 0.5989585253487394
  batch 302 loss: 0.5989362161285829
  batch 303 loss: 0.5989264263571685
  batch 304 loss: 0.5988978039669363
  batch 305 loss: 0.5987139252365613
  batch 306 loss: 0.5986974734106875
  batch 307 loss: 0.5986068472023507
  batch 308 loss: 0.5985769532717667
  batch 309 loss: 0.5985547552988367
  batch 310 loss: 0.5986439279971584
  batch 311 loss: 0.5986132307451254
  batch 312 loss: 0.598706471423308
  batch 313 loss: 0.598699222167079
  batch 314 loss: 0.5986943303779432
  batch 315 loss: 0.5986556828968108
  batch 316 loss: 0.5986692609289025
  batch 317 loss: 0.5986515168887959
  batch 318 loss: 0.5985594341215098
  batch 319 loss: 0.5985240386944953
  batch 320 loss: 0.5984816687181592
  batch 321 loss: 0.5984015500062723
  batch 322 loss: 0.5983674753896938
  batch 323 loss: 0.5983687212961746
  batch 324 loss: 0.5982400265372829
  batch 325 loss: 0.5982034696065462
  batch 326 loss: 0.5980463031610829
  batch 327 loss: 0.5979757132151076
  batch 328 loss: 0.5979336827266507
  batch 329 loss: 0.5979013037174306
  batch 330 loss: 0.597767931764776
  batch 331 loss: 0.5976934209691074
  batch 332 loss: 0.5977136356284819
  batch 333 loss: 0.5976044299366238
  batch 334 loss: 0.5974230032838034
  batch 335 loss: 0.5974002727821691
  batch 336 loss: 0.5973576654990514
  batch 337 loss: 0.5973577656802509
  batch 338 loss: 0.5974052007029043
  batch 339 loss: 0.5973832598478042
  batch 340 loss: 0.597368614638553
  batch 341 loss: 0.5973262339393415
  batch 342 loss: 0.5972928153841119
  batch 343 loss: 0.597215884107195
  batch 344 loss: 0.5972216543416644
  batch 345 loss: 0.5972623308499654
  batch 346 loss: 0.5972179541353545
  batch 347 loss: 0.5972245139759624
  batch 348 loss: 0.5972117810756311
  batch 349 loss: 0.5971112761934713
  batch 350 loss: 0.5970480964865004
  batch 351 loss: 0.5970575121732858
  batch 352 loss: 0.5970336095514622
  batch 353 loss: 0.5969487828843655
  batch 354 loss: 0.5969818096376408
  batch 355 loss: 0.597049382706763
  batch 356 loss: 0.597015996997276
  batch 357 loss: 0.596976487242541
  batch 358 loss: 0.5969788125773382
  batch 359 loss: 0.5968902710420507
  batch 360 loss: 0.5968972257441945
  batch 361 loss: 0.5968773069474176
  batch 362 loss: 0.5967920687646497
  batch 363 loss: 0.596719669737435
  batch 364 loss: 0.5965736080984493
  batch 365 loss: 0.5965728251901391
  batch 366 loss: 0.5964671593220507
  batch 367 loss: 0.5964525121109362
  batch 368 loss: 0.5963706628459952
  batch 369 loss: 0.596359128228371
  batch 370 loss: 0.5964222505285933
  batch 371 loss: 0.5965310166466911
  batch 372 loss: 0.5964788544562555
  batch 373 loss: 0.5964041612742733
  batch 374 loss: 0.5963681745019188
  batch 375 loss: 0.5963486261367797
  batch 376 loss: 0.5963720290901813
  batch 377 loss: 0.5963072027388555
  batch 378 loss: 0.5962436134537692
  batch 379 loss: 0.5961701522401895
  batch 380 loss: 0.5962065331245724
  batch 381 loss: 0.5961307809734595
  batch 382 loss: 0.595980803691904
  batch 383 loss: 0.5959724096031787
  batch 384 loss: 0.5960115580819547
  batch 385 loss: 0.596066034149814
  batch 386 loss: 0.5960215479907595
  batch 387 loss: 0.5960096257909632
  batch 388 loss: 0.596017305230357
  batch 389 loss: 0.5959965592791305
  batch 390 loss: 0.5959772227666317
  batch 391 loss: 0.5959190909210068
  batch 392 loss: 0.5958602058948302
  batch 393 loss: 0.5958811194842099
  batch 394 loss: 0.5958839251002684
  batch 395 loss: 0.5959096095230006
  batch 396 loss: 0.5959008156952231
  batch 397 loss: 0.595882760337378
  batch 398 loss: 0.595793253962119
  batch 399 loss: 0.5957932237694437
  batch 400 loss: 0.5957212789356708
  batch 401 loss: 0.5957018929229413
  batch 402 loss: 0.5956939994102687
  batch 403 loss: 0.5956508094264615
  batch 404 loss: 0.5955763761654939
  batch 405 loss: 0.595539790318336
  batch 406 loss: 0.5955132918404829
  batch 407 loss: 0.5954484514873796
  batch 408 loss: 0.5954448180455788
  batch 409 loss: 0.5954140060396824
  batch 410 loss: 0.595390301652071
  batch 411 loss: 0.5953142397885195
  batch 412 loss: 0.5952603989145131
  batch 413 loss: 0.5951825435167364
  batch 414 loss: 0.5951279894165371
  batch 415 loss: 0.5950729153242456
  batch 416 loss: 0.5950407243978518
  batch 417 loss: 0.5950112964609544
  batch 418 loss: 0.5949408036955236
  batch 419 loss: 0.5949367286197326
  batch 420 loss: 0.5949427902698516
  batch 421 loss: 0.5949876002631108
  batch 422 loss: 0.5950373463438585
  batch 423 loss: 0.5950623256094912
  batch 424 loss: 0.5950353544838024
  batch 425 loss: 0.5950357981289134
  batch 426 loss: 0.5949989463521841
  batch 427 loss: 0.5949544811695465
  batch 428 loss: 0.5948647841393391
  batch 429 loss: 0.5948374834094015
  batch 430 loss: 0.5948318305403687
  batch 431 loss: 0.5948131431559676
  batch 432 loss: 0.5948007566233476
  batch 433 loss: 0.5947481022145401
  batch 434 loss: 0.5947864915368744
  batch 435 loss: 0.5947010963812641
  batch 436 loss: 0.594611242276813
  batch 437 loss: 0.5946404802990178
  batch 438 loss: 0.5947243424311076
  batch 439 loss: 0.5946915274600505
  batch 440 loss: 0.5946659611030058
  batch 441 loss: 0.5946560706140773
  batch 442 loss: 0.594586789877706
  batch 443 loss: 0.5945919635064446
  batch 444 loss: 0.5945244126760207
  batch 445 loss: 0.5944761329822326
  batch 446 loss: 0.5944527633521589
  batch 447 loss: 0.5943859748925672
  batch 448 loss: 0.5944232348618763
  batch 449 loss: 0.5944866346888128
  batch 450 loss: 0.594481701321072
  batch 451 loss: 0.5944072280384749
  batch 452 loss: 0.5943971901340822
  batch 453 loss: 0.5944096869717107
  batch 454 loss: 0.5943688402354455
  batch 455 loss: 0.5943506036485945
  batch 456 loss: 0.5942910195965516
  batch 457 loss: 0.5942786515932897
  batch 458 loss: 0.59423810178536
  batch 459 loss: 0.5942678084041039
  batch 460 loss: 0.5943160518355991
  batch 461 loss: 0.5942582565636542
  batch 462 loss: 0.5942108903354381
  batch 463 loss: 0.5942345580838412
  batch 464 loss: 0.5942626666149189
  batch 465 loss: 0.5941536813653926
  batch 466 loss: 0.5940624859200015
  batch 467 loss: 0.5940507765245131
  batch 468 loss: 0.5940318610678371
  batch 469 loss: 0.5939785440339208
  batch 470 loss: 0.5938982628761453
  batch 471 loss: 0.5939157646932419
  batch 472 loss: 0.5938398407424911
LOSS train 0.5938398407424911 valid 0.47633248567581177
LOSS train 0.5938398407424911 valid 0.45720916986465454
LOSS train 0.5938398407424911 valid 0.471333642800649
LOSS train 0.5938398407424911 valid 0.4698035642504692
LOSS train 0.5938398407424911 valid 0.4670377910137177
LOSS train 0.5938398407424911 valid 0.47109836836655933
LOSS train 0.5938398407424911 valid 0.47227959973471506
LOSS train 0.5938398407424911 valid 0.47512003779411316
LOSS train 0.5938398407424911 valid 0.47181710600852966
LOSS train 0.5938398407424911 valid 0.4715475499629974
LOSS train 0.5938398407424911 valid 0.47399958155371924
LOSS train 0.5938398407424911 valid 0.47309741377830505
LOSS train 0.5938398407424911 valid 0.4767164633824275
LOSS train 0.5938398407424911 valid 0.4768686422279903
LOSS train 0.5938398407424911 valid 0.47611395915349325
LOSS train 0.5938398407424911 valid 0.4765055514872074
LOSS train 0.5938398407424911 valid 0.4786960622843574
LOSS train 0.5938398407424911 valid 0.4797726256979836
LOSS train 0.5938398407424911 valid 0.47966146939679194
LOSS train 0.5938398407424911 valid 0.48096149116754533
LOSS train 0.5938398407424911 valid 0.4802067407539913
LOSS train 0.5938398407424911 valid 0.47826107117262756
LOSS train 0.5938398407424911 valid 0.47919473959052045
LOSS train 0.5938398407424911 valid 0.4791002770264943
LOSS train 0.5938398407424911 valid 0.47922358036041257
LOSS train 0.5938398407424911 valid 0.4792459561274602
LOSS train 0.5938398407424911 valid 0.47943489750226337
LOSS train 0.5938398407424911 valid 0.47935138642787933
LOSS train 0.5938398407424911 valid 0.4793875351034362
LOSS train 0.5938398407424911 valid 0.47951025466124214
LOSS train 0.5938398407424911 valid 0.48051795555699256
LOSS train 0.5938398407424911 valid 0.47963403537869453
LOSS train 0.5938398407424911 valid 0.4795729635339795
LOSS train 0.5938398407424911 valid 0.4795193786130232
LOSS train 0.5938398407424911 valid 0.47994234476770675
LOSS train 0.5938398407424911 valid 0.480228706366486
LOSS train 0.5938398407424911 valid 0.4806697038379875
LOSS train 0.5938398407424911 valid 0.48188336193561554
LOSS train 0.5938398407424911 valid 0.48166042413467014
LOSS train 0.5938398407424911 valid 0.48259741365909575
LOSS train 0.5938398407424911 valid 0.48281334667671016
LOSS train 0.5938398407424911 valid 0.48369072448639644
LOSS train 0.5938398407424911 valid 0.48315211506777034
LOSS train 0.5938398407424911 valid 0.4834458631548015
LOSS train 0.5938398407424911 valid 0.4837750772635142
LOSS train 0.5938398407424911 valid 0.48380173354045203
LOSS train 0.5938398407424911 valid 0.4836412439955042
LOSS train 0.5938398407424911 valid 0.4837389836708705
LOSS train 0.5938398407424911 valid 0.4842518811323205
LOSS train 0.5938398407424911 valid 0.48385226547718047
LOSS train 0.5938398407424911 valid 0.48407968177514915
LOSS train 0.5938398407424911 valid 0.4838676360937265
LOSS train 0.5938398407424911 valid 0.4841272785978497
LOSS train 0.5938398407424911 valid 0.48396552271313137
LOSS train 0.5938398407424911 valid 0.48337331901897085
LOSS train 0.5938398407424911 valid 0.48339337536266874
LOSS train 0.5938398407424911 valid 0.4831101340160035
LOSS train 0.5938398407424911 valid 0.48289530133378916
LOSS train 0.5938398407424911 valid 0.4836071608430248
LOSS train 0.5938398407424911 valid 0.4835057506958644
LOSS train 0.5938398407424911 valid 0.4829652123763913
LOSS train 0.5938398407424911 valid 0.483757592978016
LOSS train 0.5938398407424911 valid 0.48417340006147114
LOSS train 0.5938398407424911 valid 0.48475251719355583
LOSS train 0.5938398407424911 valid 0.4851883301368127
LOSS train 0.5938398407424911 valid 0.4853339610677777
LOSS train 0.5938398407424911 valid 0.48503948547946873
LOSS train 0.5938398407424911 valid 0.48464257007136063
LOSS train 0.5938398407424911 valid 0.48444831155348517
LOSS train 0.5938398407424911 valid 0.48416828342846463
LOSS train 0.5938398407424911 valid 0.4838235550363299
LOSS train 0.5938398407424911 valid 0.4836917432645957
LOSS train 0.5938398407424911 valid 0.48400902625632614
LOSS train 0.5938398407424911 valid 0.48383964759272496
LOSS train 0.5938398407424911 valid 0.48363057255744935
LOSS train 0.5938398407424911 valid 0.483708418905735
LOSS train 0.5938398407424911 valid 0.48332887268685676
LOSS train 0.5938398407424911 valid 0.4831629357276819
LOSS train 0.5938398407424911 valid 0.48308898602859884
LOSS train 0.5938398407424911 valid 0.48277159705758094
LOSS train 0.5938398407424911 valid 0.4827244921966835
LOSS train 0.5938398407424911 valid 0.4827005964953725
LOSS train 0.5938398407424911 valid 0.482552704322769
LOSS train 0.5938398407424911 valid 0.48280744822252364
LOSS train 0.5938398407424911 valid 0.48271703720092773
LOSS train 0.5938398407424911 valid 0.482435864418052
LOSS train 0.5938398407424911 valid 0.48250288148035947
LOSS train 0.5938398407424911 valid 0.48203856802799483
LOSS train 0.5938398407424911 valid 0.4822079535950436
LOSS train 0.5938398407424911 valid 0.4817807409498427
LOSS train 0.5938398407424911 valid 0.4815112489920396
LOSS train 0.5938398407424911 valid 0.4816200992335444
LOSS train 0.5938398407424911 valid 0.48145147228753693
LOSS train 0.5938398407424911 valid 0.48119449171614137
LOSS train 0.5938398407424911 valid 0.4811552157527522
LOSS train 0.5938398407424911 valid 0.4811505439380805
LOSS train 0.5938398407424911 valid 0.48128888164598915
LOSS train 0.5938398407424911 valid 0.48117542753414233
LOSS train 0.5938398407424911 valid 0.4814543338737102
LOSS train 0.5938398407424911 valid 0.4816797024011612
LOSS train 0.5938398407424911 valid 0.4816443884726798
LOSS train 0.5938398407424911 valid 0.4816337715761334
LOSS train 0.5938398407424911 valid 0.4817919120626542
LOSS train 0.5938398407424911 valid 0.4817876864511233
LOSS train 0.5938398407424911 valid 0.48168746885799224
LOSS train 0.5938398407424911 valid 0.48170707726253653
LOSS train 0.5938398407424911 valid 0.4815533553885522
LOSS train 0.5938398407424911 valid 0.4817139729857445
LOSS train 0.5938398407424911 valid 0.48169811384393535
LOSS train 0.5938398407424911 valid 0.4817855228077282
LOSS train 0.5938398407424911 valid 0.48172989836684216
LOSS train 0.5938398407424911 valid 0.4818336559193475
LOSS train 0.5938398407424911 valid 0.48179409619981206
LOSS train 0.5938398407424911 valid 0.4815588745108822
LOSS train 0.5938398407424911 valid 0.4817054779633232
LOSS train 0.5938398407424911 valid 0.48166564826307623
LOSS train 0.5938398407424911 valid 0.4816157698121845
LOSS train 0.5938398407424911 valid 0.4814907772056127
LOSS train 0.5938398407424911 valid 0.48141140121371806
LOSS train 0.5938398407424911 valid 0.4814022240539392
LOSS train 0.5938398407424911 valid 0.48136030543934216
LOSS train 0.5938398407424911 valid 0.48129310886390875
LOSS train 0.5938398407424911 valid 0.48135860203727476
LOSS train 0.5938398407424911 valid 0.48148157303371736
LOSS train 0.5938398407424911 valid 0.48134881591796874
LOSS train 0.5938398407424911 valid 0.48117261699267794
LOSS train 0.5938398407424911 valid 0.4814640950030229
LOSS train 0.5938398407424911 valid 0.4815593508537859
LOSS train 0.5938398407424911 valid 0.4817780808422917
LOSS train 0.5938398407424911 valid 0.48164406281251176
LOSS train 0.5938398407424911 valid 0.48156840928638256
LOSS train 0.5938398407424911 valid 0.48147038867076236
LOSS train 0.5938398407424911 valid 0.48127769594801995
LOSS train 0.5938398407424911 valid 0.4813231694609372
LOSS train 0.5938398407424911 valid 0.4814372678597768
LOSS train 0.5938398407424911 valid 0.4814182193401982
LOSS train 0.5938398407424911 valid 0.48127727895757577
LOSS train 0.5938398407424911 valid 0.481179423738217
LOSS train 0.5938398407424911 valid 0.48101796156210863
LOSS train 0.5938398407424911 valid 0.4811349621840886
LOSS train 0.5938398407424911 valid 0.4811710159406594
LOSS train 0.5938398407424911 valid 0.4814641708639306
LOSS train 0.5938398407424911 valid 0.481460806373116
LOSS train 0.5938398407424911 valid 0.4816203336748812
LOSS train 0.5938398407424911 valid 0.4816419630215086
LOSS train 0.5938398407424911 valid 0.4818008105232291
LOSS train 0.5938398407424911 valid 0.48162022597935733
LOSS train 0.5938398407424911 valid 0.481765716663889
LOSS train 0.5938398407424911 valid 0.4819151909159334
LOSS train 0.5938398407424911 valid 0.4818535083532333
LOSS train 0.5938398407424911 valid 0.4819521704651662
LOSS train 0.5938398407424911 valid 0.4817718379199505
LOSS train 0.5938398407424911 valid 0.4819064566902086
LOSS train 0.5938398407424911 valid 0.48190403468423076
LOSS train 0.5938398407424911 valid 0.48191040619727105
LOSS train 0.5938398407424911 valid 0.48217643281588185
LOSS train 0.5938398407424911 valid 0.48225582784907833
LOSS train 0.5938398407424911 valid 0.48221366616744027
LOSS train 0.5938398407424911 valid 0.48195011210891436
LOSS train 0.5938398407424911 valid 0.481968954205513
LOSS train 0.5938398407424911 valid 0.4818196355926324
LOSS train 0.5938398407424911 valid 0.4815793405344457
LOSS train 0.5938398407424911 valid 0.4816657798421895
LOSS train 0.5938398407424911 valid 0.48161925829765273
LOSS train 0.5938398407424911 valid 0.48148776202490834
LOSS train 0.5938398407424911 valid 0.48129126232072533
LOSS train 0.5938398407424911 valid 0.4813393418660421
LOSS train 0.5938398407424911 valid 0.4815273582935333
LOSS train 0.5938398407424911 valid 0.4816075507000353
LOSS train 0.5938398407424911 valid 0.4817673500846414
LOSS train 0.5938398407424911 valid 0.4817318749009517
LOSS train 0.5938398407424911 valid 0.48170622420865433
LOSS train 0.5938398407424911 valid 0.48189912331586626
LOSS train 0.5938398407424911 valid 0.4818912943204244
LOSS train 0.5938398407424911 valid 0.4819681305544717
LOSS train 0.5938398407424911 valid 0.48186519589613785
LOSS train 0.5938398407424911 valid 0.4819633147474063
LOSS train 0.5938398407424911 valid 0.48206502852145205
LOSS train 0.5938398407424911 valid 0.4819996818150888
LOSS train 0.5938398407424911 valid 0.4820322250326475
LOSS train 0.5938398407424911 valid 0.4820778949484641
LOSS train 0.5938398407424911 valid 0.4821251745407398
LOSS train 0.5938398407424911 valid 0.4821712254175072
LOSS train 0.5938398407424911 valid 0.4822687286397685
LOSS train 0.5938398407424911 valid 0.4821550172728461
LOSS train 0.5938398407424911 valid 0.4821547942776834
LOSS train 0.5938398407424911 valid 0.4820903149199358
LOSS train 0.5938398407424911 valid 0.4822562607996007
LOSS train 0.5938398407424911 valid 0.4821281172926464
LOSS train 0.5938398407424911 valid 0.4820748076627129
LOSS train 0.5938398407424911 valid 0.48231261516116675
LOSS train 0.5938398407424911 valid 0.4823154166030387
LOSS train 0.5938398407424911 valid 0.48237227081017175
LOSS train 0.5938398407424911 valid 0.4822343403531104
LOSS train 0.5938398407424911 valid 0.48207791783870796
LOSS train 0.5938398407424911 valid 0.4821867704087374
LOSS train 0.5938398407424911 valid 0.4823193149215679
LOSS train 0.5938398407424911 valid 0.4824225979320931
LOSS train 0.5938398407424911 valid 0.4824035434267629
LOSS train 0.5938398407424911 valid 0.4823392924666405
LOSS train 0.5938398407424911 valid 0.4822862032634109
LOSS train 0.5938398407424911 valid 0.4823812582705281
LOSS train 0.5938398407424911 valid 0.4822303206462578
LOSS train 0.5938398407424911 valid 0.48220788570595724
LOSS train 0.5938398407424911 valid 0.4822460485667717
LOSS train 0.5938398407424911 valid 0.48229505034905035
LOSS train 0.5938398407424911 valid 0.482320681574264
LOSS train 0.5938398407424911 valid 0.4823001656108178
LOSS train 0.5938398407424911 valid 0.48219832407230395
LOSS train 0.5938398407424911 valid 0.4822416934229079
LOSS train 0.5938398407424911 valid 0.4821248972585416
LOSS train 0.5938398407424911 valid 0.48212932556305294
LOSS train 0.5938398407424911 valid 0.48214926434234834
LOSS train 0.5938398407424911 valid 0.4820762706972728
LOSS train 0.5938398407424911 valid 0.4820568402146184
LOSS train 0.5938398407424911 valid 0.4820639594561524
LOSS train 0.5938398407424911 valid 0.48216243754334165
LOSS train 0.5938398407424911 valid 0.48200943806302654
LOSS train 0.5938398407424911 valid 0.4820774963729458
LOSS train 0.5938398407424911 valid 0.48208954429084605
LOSS train 0.5938398407424911 valid 0.48221052839205814
LOSS train 0.5938398407424911 valid 0.4822136723511928
LOSS train 0.5938398407424911 valid 0.48228203435115213
LOSS train 0.5938398407424911 valid 0.4822201817961676
LOSS train 0.5938398407424911 valid 0.48223310708999634
LOSS train 0.5938398407424911 valid 0.48218104625697683
LOSS train 0.5938398407424911 valid 0.4822907457005085
LOSS train 0.5938398407424911 valid 0.48232893802617727
LOSS train 0.5938398407424911 valid 0.4822571129257502
LOSS train 0.5938398407424911 valid 0.4822666004947994
LOSS train 0.5938398407424911 valid 0.4822995384018143
LOSS train 0.5938398407424911 valid 0.4823025941591838
LOSS train 0.5938398407424911 valid 0.48217481297996423
LOSS train 0.5938398407424911 valid 0.4821252452257352
LOSS train 0.5938398407424911 valid 0.4821640652544955
LOSS train 0.5938398407424911 valid 0.4821518473958565
LOSS train 0.5938398407424911 valid 0.4821459124108407
LOSS train 0.5938398407424911 valid 0.48208187808509634
LOSS train 0.5938398407424911 valid 0.48209518742860613
LOSS train 0.5938398407424911 valid 0.48199999928474424
LOSS train 0.5938398407424911 valid 0.48212633835329555
LOSS train 0.5938398407424911 valid 0.48206208030546993
LOSS train 0.5938398407424911 valid 0.4820821474118488
LOSS train 0.5938398407424911 valid 0.48215556462280085
LOSS train 0.5938398407424911 valid 0.4821075556229572
LOSS train 0.5938398407424911 valid 0.48210012307011985
LOSS train 0.5938398407424911 valid 0.4822081759391043
LOSS train 0.5938398407424911 valid 0.4821846834834545
LOSS train 0.5938398407424911 valid 0.48224486536290273
LOSS train 0.5938398407424911 valid 0.4823161245584488
LOSS train 0.5938398407424911 valid 0.4823826439827087
LOSS train 0.5938398407424911 valid 0.48254674223680344
LOSS train 0.5938398407424911 valid 0.4825283345497644
LOSS train 0.5938398407424911 valid 0.4826649849809061
LOSS train 0.5938398407424911 valid 0.4825789280966216
LOSS train 0.5938398407424911 valid 0.4826030482072383
LOSS train 0.5938398407424911 valid 0.48255449614636164
LOSS train 0.5938398407424911 valid 0.4826090624628141
LOSS train 0.5938398407424911 valid 0.48266745258022
LOSS train 0.5938398407424911 valid 0.48267800097282115
LOSS train 0.5938398407424911 valid 0.4826482488734512
LOSS train 0.5938398407424911 valid 0.4826737400002152
LOSS train 0.5938398407424911 valid 0.48265709498535997
LOSS train 0.5938398407424911 valid 0.48266470928986865
LOSS train 0.5938398407424911 valid 0.48271106728967633
LOSS train 0.5938398407424911 valid 0.48273899030864686
LOSS train 0.5938398407424911 valid 0.48281578937273345
LOSS train 0.5938398407424911 valid 0.4828013110516676
LOSS train 0.5938398407424911 valid 0.4829557857105723
LOSS train 0.5938398407424911 valid 0.48291182120641074
LOSS train 0.5938398407424911 valid 0.48299754941595435
LOSS train 0.5938398407424911 valid 0.4830101625446011
LOSS train 0.5938398407424911 valid 0.48305521310467425
LOSS train 0.5938398407424911 valid 0.483034230387994
LOSS train 0.5938398407424911 valid 0.4829477345943451
LOSS train 0.5938398407424911 valid 0.4829593088099922
LOSS train 0.5938398407424911 valid 0.4829478866356805
LOSS train 0.5938398407424911 valid 0.48290144175076655
LOSS train 0.5938398407424911 valid 0.48295605930376223
LOSS train 0.5938398407424911 valid 0.48288199699350765
LOSS train 0.5938398407424911 valid 0.48282014114576727
LOSS train 0.5938398407424911 valid 0.482734518693694
LOSS train 0.5938398407424911 valid 0.4826672550014388
LOSS train 0.5938398407424911 valid 0.48270043426416287
LOSS train 0.5938398407424911 valid 0.48269238440614
LOSS train 0.5938398407424911 valid 0.482678350347739
LOSS train 0.5938398407424911 valid 0.4826749850856302
LOSS train 0.5938398407424911 valid 0.4826372078516417
LOSS train 0.5938398407424911 valid 0.4826315060825084
LOSS train 0.5938398407424911 valid 0.4825856994965981
LOSS train 0.5938398407424911 valid 0.4824688562617679
LOSS train 0.5938398407424911 valid 0.4824922583895187
LOSS train 0.5938398407424911 valid 0.4824606552465784
LOSS train 0.5938398407424911 valid 0.482535944098518
LOSS train 0.5938398407424911 valid 0.4826110476154392
LOSS train 0.5938398407424911 valid 0.48260194586740957
LOSS train 0.5938398407424911 valid 0.4825769228365285
LOSS train 0.5938398407424911 valid 0.4825726144465824
LOSS train 0.5938398407424911 valid 0.48262906164229913
LOSS train 0.5938398407424911 valid 0.48268721769253414
LOSS train 0.5938398407424911 valid 0.48265912000127015
LOSS train 0.5938398407424911 valid 0.48262493677486645
LOSS train 0.5938398407424911 valid 0.4825514956276015
LOSS train 0.5938398407424911 valid 0.4824946850146118
LOSS train 0.5938398407424911 valid 0.4823900330262106
LOSS train 0.5938398407424911 valid 0.4824123717601003
LOSS train 0.5938398407424911 valid 0.48241835560783114
LOSS train 0.5938398407424911 valid 0.48238022064233754
LOSS train 0.5938398407424911 valid 0.4824660435849409
LOSS train 0.5938398407424911 valid 0.4823982048419214
LOSS train 0.5938398407424911 valid 0.48238665727940405
LOSS train 0.5938398407424911 valid 0.4823919693246866
LOSS train 0.5938398407424911 valid 0.48251265135055155
LOSS train 0.5938398407424911 valid 0.4825801152712221
LOSS train 0.5938398407424911 valid 0.4825602439660875
LOSS train 0.5938398407424911 valid 0.48251468725974045
LOSS train 0.5938398407424911 valid 0.4825075249002559
LOSS train 0.5938398407424911 valid 0.4825413041519669
LOSS train 0.5938398407424911 valid 0.48243447045173765
LOSS train 0.5938398407424911 valid 0.4824030861258507
LOSS train 0.5938398407424911 valid 0.48235446084696926
LOSS train 0.5938398407424911 valid 0.4823418477122088
LOSS train 0.5938398407424911 valid 0.482265781691938
LOSS train 0.5938398407424911 valid 0.4822745441838547
LOSS train 0.5938398407424911 valid 0.48228569214160627
LOSS train 0.5938398407424911 valid 0.4823294323097709
LOSS train 0.5938398407424911 valid 0.4824131345347892
LOSS train 0.5938398407424911 valid 0.48242489094050917
LOSS train 0.5938398407424911 valid 0.48244761723153134
LOSS train 0.5938398407424911 valid 0.48244353794690337
LOSS train 0.5938398407424911 valid 0.48240423445615166
LOSS train 0.5938398407424911 valid 0.48232897451843126
LOSS train 0.5938398407424911 valid 0.4823285133631022
LOSS train 0.5938398407424911 valid 0.4823692273237034
LOSS train 0.5938398407424911 valid 0.48234907264140114
LOSS train 0.5938398407424911 valid 0.4823693892075902
LOSS train 0.5938398407424911 valid 0.4823913575987434
LOSS train 0.5938398407424911 valid 0.4824080490148984
LOSS train 0.5938398407424911 valid 0.48237858163220343
LOSS train 0.5938398407424911 valid 0.482373379696818
LOSS train 0.5938398407424911 valid 0.48231917890635406
LOSS train 0.5938398407424911 valid 0.48219351531469334
LOSS train 0.5938398407424911 valid 0.48215353228260405
LOSS train 0.5938398407424911 valid 0.4821890383785547
LOSS train 0.5938398407424911 valid 0.48224402018215345
LOSS train 0.5938398407424911 valid 0.4822137756326984
LOSS train 0.5938398407424911 valid 0.4822396177379817
LOSS train 0.5938398407424911 valid 0.4822177830441245
LOSS train 0.5938398407424911 valid 0.4822457772612913
LOSS train 0.5938398407424911 valid 0.4822311280454908
LOSS train 0.5938398407424911 valid 0.48220981882508324
LOSS train 0.5938398407424911 valid 0.4822652311148969
LOSS train 0.5938398407424911 valid 0.4823639519491547
LOSS train 0.5938398407424911 valid 0.48241792290897695
LOSS train 0.5938398407424911 valid 0.48242302646099683
LOSS train 0.5938398407424911 valid 0.48239015319039313
LOSS train 0.5938398407424911 valid 0.4823716850507827
LOSS train 0.5938398407424911 valid 0.48224886960490454
LOSS train 0.5938398407424911 valid 0.4822851582988059
LOSS train 0.5938398407424911 valid 0.48222413667374187
LOSS train 0.5938398407424911 valid 0.48224220406315665
LOSS train 0.5938398407424911 valid 0.48227247711044646
LOSS train 0.5938398407424911 valid 0.48228047915398253
LOSS train 0.5938398407424911 valid 0.4822460791239372
LOSS train 0.5938398407424911 valid 0.48227749050480045
LOSS train 0.5938398407424911 valid 0.4822581293152981
LOSS train 0.5938398407424911 valid 0.48223604793769465
LOSS train 0.5938398407424911 valid 0.48216566986039927
LOSS train 0.5938398407424911 valid 0.48216714065895494
EPOCH 4:
  batch 1 loss: 0.5712435245513916
  batch 2 loss: 0.5630489587783813
  batch 3 loss: 0.5671042601267496
  batch 4 loss: 0.5753762125968933
  batch 5 loss: 0.5750925540924072
  batch 6 loss: 0.5749380191167196
  batch 7 loss: 0.5774433101926532
  batch 8 loss: 0.5775846093893051
  batch 9 loss: 0.5790626340442233
  batch 10 loss: 0.5811789035797119
  batch 11 loss: 0.5802775350483981
  batch 12 loss: 0.5798337211211523
  batch 13 loss: 0.5804994197992178
  batch 14 loss: 0.581168362072536
  batch 15 loss: 0.580867342154185
  batch 16 loss: 0.5807609260082245
  batch 17 loss: 0.5805705855874455
  batch 18 loss: 0.5788877142800225
  batch 19 loss: 0.5788416799746061
  batch 20 loss: 0.5779584109783172
  batch 21 loss: 0.5792851561591739
  batch 22 loss: 0.57845477624373
  batch 23 loss: 0.5790769224581511
  batch 24 loss: 0.5784850567579269
  batch 25 loss: 0.5784509778022766
  batch 26 loss: 0.5782670218210954
  batch 27 loss: 0.5774379107687209
  batch 28 loss: 0.5760096460580826
  batch 29 loss: 0.576187252998352
  batch 30 loss: 0.5756485184033712
  batch 31 loss: 0.5751488593316847
  batch 32 loss: 0.5755232274532318
  batch 33 loss: 0.5756556445902045
  batch 34 loss: 0.5756061638102812
  batch 35 loss: 0.5758908237729754
  batch 36 loss: 0.5760240521695879
  batch 37 loss: 0.5762898776982281
  batch 38 loss: 0.5758848864781229
  batch 39 loss: 0.5762219062218299
  batch 40 loss: 0.5753730773925781
  batch 41 loss: 0.5753794966674433
  batch 42 loss: 0.5758192964962551
  batch 43 loss: 0.5759612959484721
  batch 44 loss: 0.5758410610935905
  batch 45 loss: 0.5764643417464362
  batch 46 loss: 0.5758549752442733
  batch 47 loss: 0.5756635069847107
  batch 48 loss: 0.5751944792767366
  batch 49 loss: 0.5751725082494774
  batch 50 loss: 0.5751043736934662
  batch 51 loss: 0.5747001100988949
  batch 52 loss: 0.575290668469209
  batch 53 loss: 0.5756619628870262
  batch 54 loss: 0.5753449621023955
  batch 55 loss: 0.5748301852833141
  batch 56 loss: 0.5740619216646466
  batch 57 loss: 0.5742040412467823
  batch 58 loss: 0.5745943558627161
  batch 59 loss: 0.5743109644469568
  batch 60 loss: 0.5741198003292084
  batch 61 loss: 0.5740792340919619
  batch 62 loss: 0.5744517570541751
  batch 63 loss: 0.5747473202054463
  batch 64 loss: 0.5749739613384008
  batch 65 loss: 0.5743122192529532
  batch 66 loss: 0.5745617160291383
  batch 67 loss: 0.5745729163511476
  batch 68 loss: 0.5746274476542192
  batch 69 loss: 0.5746499187704446
  batch 70 loss: 0.5746726078646524
  batch 71 loss: 0.5747736868724017
  batch 72 loss: 0.5744742527604103
  batch 73 loss: 0.574561402405778
  batch 74 loss: 0.5746280687886316
  batch 75 loss: 0.5744405277570088
  batch 76 loss: 0.5745952678354163
  batch 77 loss: 0.5745676717200836
  batch 78 loss: 0.5741547896311834
  batch 79 loss: 0.574331949783277
  batch 80 loss: 0.5740188740193843
  batch 81 loss: 0.5743539333343506
  batch 82 loss: 0.5746413636498335
  batch 83 loss: 0.5745939727289131
  batch 84 loss: 0.5748119929007122
  batch 85 loss: 0.5745536530719084
  batch 86 loss: 0.575032499640487
  batch 87 loss: 0.5747865616590128
  batch 88 loss: 0.5744589038870551
  batch 89 loss: 0.5745058916927723
  batch 90 loss: 0.5746164931191339
  batch 91 loss: 0.5748383343874753
  batch 92 loss: 0.5749110009359277
  batch 93 loss: 0.5749492702945587
  batch 94 loss: 0.5751010008314823
  batch 95 loss: 0.5756329266648543
  batch 96 loss: 0.5758217287560304
  batch 97 loss: 0.5760889354440355
  batch 98 loss: 0.5763372657250385
  batch 99 loss: 0.5763841807240188
  batch 100 loss: 0.5764189630746841
  batch 101 loss: 0.5765527280250399
  batch 102 loss: 0.5765505018187504
  batch 103 loss: 0.5765407079631842
  batch 104 loss: 0.5765781494287344
  batch 105 loss: 0.5764063795407613
  batch 106 loss: 0.5764880416528234
  batch 107 loss: 0.5764844261597251
  batch 108 loss: 0.5761524427820135
  batch 109 loss: 0.5762205080154839
  batch 110 loss: 0.5763158299706199
  batch 111 loss: 0.5764769229803
  batch 112 loss: 0.5762776796306882
  batch 113 loss: 0.5762124958291518
  batch 114 loss: 0.5765735527925324
  batch 115 loss: 0.576760022536568
  batch 116 loss: 0.5769071373446234
  batch 117 loss: 0.57682775788837
  batch 118 loss: 0.5767640597739462
  batch 119 loss: 0.5768503486609259
  batch 120 loss: 0.5770945593714714
  batch 121 loss: 0.5770942588483007
  batch 122 loss: 0.5770185242910855
  batch 123 loss: 0.5768125914945835
  batch 124 loss: 0.5769416713906873
  batch 125 loss: 0.5768584399223328
  batch 126 loss: 0.5768058900795285
  batch 127 loss: 0.5770022864416828
  batch 128 loss: 0.5767211024649441
  batch 129 loss: 0.5765737318253332
  batch 130 loss: 0.5765262965972607
  batch 131 loss: 0.5765708489272431
  batch 132 loss: 0.5768126190611811
  batch 133 loss: 0.5770693277954159
  batch 134 loss: 0.5769741441776504
  batch 135 loss: 0.5771771051265575
  batch 136 loss: 0.5771581740940318
  batch 137 loss: 0.5771591419721172
  batch 138 loss: 0.5773654126602671
  batch 139 loss: 0.5773298358745712
  batch 140 loss: 0.5771416787590299
  batch 141 loss: 0.5771199752252998
  batch 142 loss: 0.5771642125828166
  batch 143 loss: 0.5770809275287014
  batch 144 loss: 0.5769794744749864
  batch 145 loss: 0.5769411744742557
  batch 146 loss: 0.5768588532323706
  batch 147 loss: 0.5767551384815554
  batch 148 loss: 0.5766450923842352
  batch 149 loss: 0.5767456981159697
  batch 150 loss: 0.576590043703715
  batch 151 loss: 0.5764237018610467
  batch 152 loss: 0.5767129040078113
  batch 153 loss: 0.5766994041555068
  batch 154 loss: 0.5767541419376027
  batch 155 loss: 0.5767863792757835
  batch 156 loss: 0.5766507803629606
  batch 157 loss: 0.5767474011251121
  batch 158 loss: 0.5767573672759382
  batch 159 loss: 0.5767061901542375
  batch 160 loss: 0.5768963072448969
  batch 161 loss: 0.5768982205331695
  batch 162 loss: 0.5769888243557494
  batch 163 loss: 0.5770867412075674
  batch 164 loss: 0.5771776793933496
  batch 165 loss: 0.5771485393697565
  batch 166 loss: 0.577108512441796
  batch 167 loss: 0.5770262850972707
  batch 168 loss: 0.5771163975199064
  batch 169 loss: 0.5770759519035294
  batch 170 loss: 0.5770422770696528
  batch 171 loss: 0.5770051489796555
  batch 172 loss: 0.5770405617564224
  batch 173 loss: 0.577002665555546
  batch 174 loss: 0.5770218273003896
  batch 175 loss: 0.5769251564570835
  batch 176 loss: 0.5769292153418064
  batch 177 loss: 0.5769042702717969
  batch 178 loss: 0.5769438385293725
  batch 179 loss: 0.5769520681663598
  batch 180 loss: 0.5769409202867084
  batch 181 loss: 0.577023999137773
  batch 182 loss: 0.5769622250572666
  batch 183 loss: 0.5768689588119423
  batch 184 loss: 0.5768021856961043
  batch 185 loss: 0.5767830249425527
  batch 186 loss: 0.5766812486033286
  batch 187 loss: 0.57664328622308
  batch 188 loss: 0.5766271850530137
  batch 189 loss: 0.5763818098123742
  batch 190 loss: 0.5761487615735907
  batch 191 loss: 0.5760665654511976
  batch 192 loss: 0.5758831504111489
  batch 193 loss: 0.5758344043104142
  batch 194 loss: 0.5757472754753742
  batch 195 loss: 0.5758733052473802
  batch 196 loss: 0.5758096694338078
  batch 197 loss: 0.5760033859819325
  batch 198 loss: 0.5759518212742276
  batch 199 loss: 0.5759126463128095
  batch 200 loss: 0.5758405467867851
  batch 201 loss: 0.5757919167404744
  batch 202 loss: 0.5759194761809736
  batch 203 loss: 0.5761157004116791
  batch 204 loss: 0.576058007922827
  batch 205 loss: 0.5760013327365968
  batch 206 loss: 0.5760995806420891
  batch 207 loss: 0.5761670956865025
  batch 208 loss: 0.5760342309681269
  batch 209 loss: 0.5759481585196902
  batch 210 loss: 0.5758602028801327
  batch 211 loss: 0.5759093851839762
  batch 212 loss: 0.5759471272522548
  batch 213 loss: 0.5759810931246045
  batch 214 loss: 0.5759565303815859
  batch 215 loss: 0.5757579362669657
  batch 216 loss: 0.5756102863837171
  batch 217 loss: 0.5757221601525759
  batch 218 loss: 0.575702300585738
  batch 219 loss: 0.5757294841552978
  batch 220 loss: 0.5757496218789707
  batch 221 loss: 0.5757982283156382
  batch 222 loss: 0.5757756888329446
  batch 223 loss: 0.575837901889476
  batch 224 loss: 0.5757831848625626
  batch 225 loss: 0.5756953888469272
  batch 226 loss: 0.5756005657985147
  batch 227 loss: 0.5754715579721896
  batch 228 loss: 0.5754163069160361
  batch 229 loss: 0.5752737863095047
  batch 230 loss: 0.5752601812715116
  batch 231 loss: 0.5751753743592795
  batch 232 loss: 0.5750064690565241
  batch 233 loss: 0.5749977745211687
  batch 234 loss: 0.5749820789210817
  batch 235 loss: 0.5749951971338151
  batch 236 loss: 0.5749924304121632
  batch 237 loss: 0.5749552259968302
  batch 238 loss: 0.5749670983362598
  batch 239 loss: 0.5747414503137437
  batch 240 loss: 0.5747395997246106
  batch 241 loss: 0.5747091134554123
  batch 242 loss: 0.5745628008172532
  batch 243 loss: 0.5746335473080231
  batch 244 loss: 0.5747027353185122
  batch 245 loss: 0.5746510744094848
  batch 246 loss: 0.5746179756110277
  batch 247 loss: 0.5746711774876243
  batch 248 loss: 0.5747184361661634
  batch 249 loss: 0.5746646358306149
  batch 250 loss: 0.5745968220233917
  batch 251 loss: 0.5746743826277227
  batch 252 loss: 0.5746951486383166
  batch 253 loss: 0.5746723686753525
  batch 254 loss: 0.5747012812790908
  batch 255 loss: 0.5748273868186801
  batch 256 loss: 0.5747473847586662
  batch 257 loss: 0.5748150940071284
  batch 258 loss: 0.5748023938300998
  batch 259 loss: 0.5747241271968974
  batch 260 loss: 0.5746713766684899
  batch 261 loss: 0.5748135280791827
  batch 262 loss: 0.5747805108095854
  batch 263 loss: 0.5747309388316629
  batch 264 loss: 0.5747619465445027
  batch 265 loss: 0.5746555701741632
  batch 266 loss: 0.5746169507055354
  batch 267 loss: 0.5745704441927793
  batch 268 loss: 0.5744861297643007
  batch 269 loss: 0.5744909664068967
  batch 270 loss: 0.5743752265418017
  batch 271 loss: 0.5743371674935316
  batch 272 loss: 0.5743005814797738
  batch 273 loss: 0.5742654200001951
  batch 274 loss: 0.5742469332078948
  batch 275 loss: 0.5743171661550348
  batch 276 loss: 0.574333190486051
  batch 277 loss: 0.5744182116718499
  batch 278 loss: 0.5743839772913953
  batch 279 loss: 0.5744317496549272
  batch 280 loss: 0.5743191972374916
  batch 281 loss: 0.5742953307263792
  batch 282 loss: 0.5741463358520617
  batch 283 loss: 0.5741343011704435
  batch 284 loss: 0.5741398710180337
  batch 285 loss: 0.5740320396005062
  batch 286 loss: 0.5739870119344938
  batch 287 loss: 0.5739765227464018
  batch 288 loss: 0.5737229281415542
  batch 289 loss: 0.5738726897635674
  batch 290 loss: 0.5737327487304293
  batch 291 loss: 0.5736704341734398
  batch 292 loss: 0.5737691062362227
  batch 293 loss: 0.5738281062438626
  batch 294 loss: 0.5736628596474524
  batch 295 loss: 0.5738015706256284
  batch 296 loss: 0.5737769174817446
  batch 297 loss: 0.5737825650157351
  batch 298 loss: 0.5737399572894077
  batch 299 loss: 0.5736435314883357
  batch 300 loss: 0.5736934806903203
  batch 301 loss: 0.5738058262489166
  batch 302 loss: 0.573744830903628
  batch 303 loss: 0.5736847441188573
  batch 304 loss: 0.5736337780560318
  batch 305 loss: 0.5734404831636147
  batch 306 loss: 0.5734264194186217
  batch 307 loss: 0.5733867819612112
  batch 308 loss: 0.5733112795399381
  batch 309 loss: 0.5732768056462112
  batch 310 loss: 0.5732643523523885
  batch 311 loss: 0.5732185181314156
  batch 312 loss: 0.5732797667002066
  batch 313 loss: 0.5732901941853971
  batch 314 loss: 0.5732912861617507
  batch 315 loss: 0.5732524680712866
  batch 316 loss: 0.5732541229528717
  batch 317 loss: 0.5732753218536497
  batch 318 loss: 0.5731834615551451
  batch 319 loss: 0.5730983024480575
  batch 320 loss: 0.5730378108099103
  batch 321 loss: 0.5729464921995858
  batch 322 loss: 0.5728981500456792
  batch 323 loss: 0.5729144309696398
  batch 324 loss: 0.5727943384353026
  batch 325 loss: 0.5727374406961294
  batch 326 loss: 0.5726155528992963
  batch 327 loss: 0.5725816355203635
  batch 328 loss: 0.5724861738158435
  batch 329 loss: 0.5724890248391403
  batch 330 loss: 0.5723181888912663
  batch 331 loss: 0.5722286706604627
  batch 332 loss: 0.5722683364727411
  batch 333 loss: 0.57222826720716
  batch 334 loss: 0.5720389544250009
  batch 335 loss: 0.5719749740700224
  batch 336 loss: 0.5718997853497664
  batch 337 loss: 0.571807132807259
  batch 338 loss: 0.5717866859845155
  batch 339 loss: 0.5717690536054538
  batch 340 loss: 0.571746784098008
  batch 341 loss: 0.5717121495529354
  batch 342 loss: 0.5716451793386225
  batch 343 loss: 0.5716083810906368
  batch 344 loss: 0.571596042707909
  batch 345 loss: 0.5716253747110781
  batch 346 loss: 0.5715830315744257
  batch 347 loss: 0.5715538232402086
  batch 348 loss: 0.5715318971324241
  batch 349 loss: 0.571444449759486
  batch 350 loss: 0.5714295164176396
  batch 351 loss: 0.5714280781922517
  batch 352 loss: 0.571430142968893
  batch 353 loss: 0.5713125237662123
  batch 354 loss: 0.57131205760153
  batch 355 loss: 0.5714185964893287
  batch 356 loss: 0.5714308359984601
  batch 357 loss: 0.571400933572892
  batch 358 loss: 0.5713958590390296
  batch 359 loss: 0.5713360571927679
  batch 360 loss: 0.5713368538353178
  batch 361 loss: 0.5713496457506745
  batch 362 loss: 0.5712452812418753
  batch 363 loss: 0.5711593728091763
  batch 364 loss: 0.5710293328041559
  batch 365 loss: 0.5710254878213961
  batch 366 loss: 0.5709020710382305
  batch 367 loss: 0.5708812611629268
  batch 368 loss: 0.5708110497697539
  batch 369 loss: 0.5707869487726268
  batch 370 loss: 0.5708445858311009
  batch 371 loss: 0.5709954591774233
  batch 372 loss: 0.5709858147367355
  batch 373 loss: 0.5709233931178382
  batch 374 loss: 0.5708945793582794
  batch 375 loss: 0.5708643695513408
  batch 376 loss: 0.5708981216587918
  batch 377 loss: 0.5708282806512848
  batch 378 loss: 0.5707728783920328
  batch 379 loss: 0.570773779716844
  batch 380 loss: 0.5708113439773258
  batch 381 loss: 0.5707184156094949
  batch 382 loss: 0.5705731926164078
  batch 383 loss: 0.570601416007657
  batch 384 loss: 0.5705915568396449
  batch 385 loss: 0.5706633349517723
  batch 386 loss: 0.5706189511044656
  batch 387 loss: 0.5706205805450755
  batch 388 loss: 0.5706273667591134
  batch 389 loss: 0.5706672184265058
  batch 390 loss: 0.570718187552232
  batch 391 loss: 0.5706344605101954
  batch 392 loss: 0.5706228537827122
  batch 393 loss: 0.5707016179276483
  batch 394 loss: 0.5707050746467512
  batch 395 loss: 0.570696273936501
  batch 396 loss: 0.5707754035188695
  batch 397 loss: 0.5707045804042961
  batch 398 loss: 0.5706433924897831
  batch 399 loss: 0.5706060104501576
  batch 400 loss: 0.5705148826539517
  batch 401 loss: 0.5704547270872349
  batch 402 loss: 0.5704214756761617
  batch 403 loss: 0.5703774828177232
  batch 404 loss: 0.5703007037391757
  batch 405 loss: 0.5702922095487147
  batch 406 loss: 0.5703144773767499
  batch 407 loss: 0.5702824321660128
  batch 408 loss: 0.5703165813111791
  batch 409 loss: 0.5702731733217216
  batch 410 loss: 0.5702306193549459
  batch 411 loss: 0.5701501710281465
  batch 412 loss: 0.5700659513184168
  batch 413 loss: 0.5700156874864499
  batch 414 loss: 0.5699436948207266
  batch 415 loss: 0.5699165897197034
  batch 416 loss: 0.5698260013014078
  batch 417 loss: 0.5697854244165855
  batch 418 loss: 0.5697184671340376
  batch 419 loss: 0.5697073949265309
  batch 420 loss: 0.5697093527941477
  batch 421 loss: 0.5697432950386808
  batch 422 loss: 0.5698687969508329
  batch 423 loss: 0.5698943438259423
  batch 424 loss: 0.5698733581405766
  batch 425 loss: 0.5699011639987721
  batch 426 loss: 0.5699051047714663
  batch 427 loss: 0.5698848202021954
  batch 428 loss: 0.5698038243523268
  batch 429 loss: 0.5698180566856633
  batch 430 loss: 0.5698101998761643
  batch 431 loss: 0.5698222498606087
  batch 432 loss: 0.5698423552568312
  batch 433 loss: 0.5697808148679226
  batch 434 loss: 0.5697953232697078
  batch 435 loss: 0.5697165665955379
  batch 436 loss: 0.5696533080361305
  batch 437 loss: 0.5696598947457372
  batch 438 loss: 0.5697713352773832
  batch 439 loss: 0.5697119040478335
  batch 440 loss: 0.5696925380013206
  batch 441 loss: 0.5696512603976018
  batch 442 loss: 0.569616253559406
  batch 443 loss: 0.5696141536833201
  batch 444 loss: 0.5695566859868195
  batch 445 loss: 0.56951032327802
  batch 446 loss: 0.5694858014850873
  batch 447 loss: 0.5694290660905091
  batch 448 loss: 0.5694833419152668
  batch 449 loss: 0.5695529703573554
  batch 450 loss: 0.5695658678478664
  batch 451 loss: 0.5695204155936738
  batch 452 loss: 0.5695180552723134
  batch 453 loss: 0.5695199029598278
  batch 454 loss: 0.5695012301075301
  batch 455 loss: 0.5694858794683938
  batch 456 loss: 0.5694520115329508
  batch 457 loss: 0.5694252765152595
  batch 458 loss: 0.5693684148736395
  batch 459 loss: 0.5693803323120333
  batch 460 loss: 0.5694420849499495
  batch 461 loss: 0.5694040850031143
  batch 462 loss: 0.5693606763949126
  batch 463 loss: 0.5693471605525419
  batch 464 loss: 0.5693825579665858
  batch 465 loss: 0.5692579451427665
  batch 466 loss: 0.5691767397612462
  batch 467 loss: 0.5691697416264699
  batch 468 loss: 0.5691203654576571
  batch 469 loss: 0.5690548581355162
  batch 470 loss: 0.5689628084923358
  batch 471 loss: 0.5689716393527459
  batch 472 loss: 0.5689407353431492
LOSS train 0.5689407353431492 valid 0.4822964668273926
LOSS train 0.5689407353431492 valid 0.45786842703819275
LOSS train 0.5689407353431492 valid 0.4712054332097371
LOSS train 0.5689407353431492 valid 0.46779555082321167
LOSS train 0.5689407353431492 valid 0.46807174682617186
LOSS train 0.5689407353431492 valid 0.47121947010358173
LOSS train 0.5689407353431492 valid 0.4708931233201708
LOSS train 0.5689407353431492 valid 0.47295456752181053
LOSS train 0.5689407353431492 valid 0.46928462386131287
LOSS train 0.5689407353431492 valid 0.4700347423553467
LOSS train 0.5689407353431492 valid 0.4735667109489441
LOSS train 0.5689407353431492 valid 0.473309854666392
LOSS train 0.5689407353431492 valid 0.4773326837099515
LOSS train 0.5689407353431492 valid 0.47814806018556866
LOSS train 0.5689407353431492 valid 0.476531453927358
LOSS train 0.5689407353431492 valid 0.4768169466406107
LOSS train 0.5689407353431492 valid 0.47971324534977183
LOSS train 0.5689407353431492 valid 0.48080793188677895
LOSS train 0.5689407353431492 valid 0.48073724853365046
LOSS train 0.5689407353431492 valid 0.4827708020806313
LOSS train 0.5689407353431492 valid 0.48237416999680655
LOSS train 0.5689407353431492 valid 0.48044179379940033
LOSS train 0.5689407353431492 valid 0.4814495535000511
LOSS train 0.5689407353431492 valid 0.4809233744939168
LOSS train 0.5689407353431492 valid 0.4809688699245453
LOSS train 0.5689407353431492 valid 0.4813980058981822
LOSS train 0.5689407353431492 valid 0.4815984743612784
LOSS train 0.5689407353431492 valid 0.4817738596882139
LOSS train 0.5689407353431492 valid 0.4817116507168474
LOSS train 0.5689407353431492 valid 0.48212707539399463
LOSS train 0.5689407353431492 valid 0.48319347539255697
LOSS train 0.5689407353431492 valid 0.48229019064456224
LOSS train 0.5689407353431492 valid 0.48233784780357825
LOSS train 0.5689407353431492 valid 0.4819854208651711
LOSS train 0.5689407353431492 valid 0.48248868584632876
LOSS train 0.5689407353431492 valid 0.4823851626780298
LOSS train 0.5689407353431492 valid 0.48304784378489934
LOSS train 0.5689407353431492 valid 0.48423379581225545
LOSS train 0.5689407353431492 valid 0.48382784464420414
LOSS train 0.5689407353431492 valid 0.4850490868091583
LOSS train 0.5689407353431492 valid 0.48515099577787446
LOSS train 0.5689407353431492 valid 0.48601764298620675
LOSS train 0.5689407353431492 valid 0.4858415307000626
LOSS train 0.5689407353431492 valid 0.4861555736173283
LOSS train 0.5689407353431492 valid 0.48646634022394813
LOSS train 0.5689407353431492 valid 0.4866892974013868
LOSS train 0.5689407353431492 valid 0.4865155061508747
LOSS train 0.5689407353431492 valid 0.48665853030979633
LOSS train 0.5689407353431492 valid 0.48736853198129304
LOSS train 0.5689407353431492 valid 0.48698524236679075
LOSS train 0.5689407353431492 valid 0.48729457107244756
LOSS train 0.5689407353431492 valid 0.48707494884729385
LOSS train 0.5689407353431492 valid 0.4872103980127371
LOSS train 0.5689407353431492 valid 0.48704887485062637
LOSS train 0.5689407353431492 valid 0.48652196201411163
LOSS train 0.5689407353431492 valid 0.4864572824112007
LOSS train 0.5689407353431492 valid 0.4860356538964991
LOSS train 0.5689407353431492 valid 0.485916196272291
LOSS train 0.5689407353431492 valid 0.4864411687446853
LOSS train 0.5689407353431492 valid 0.4861209362745285
LOSS train 0.5689407353431492 valid 0.4853919177758889
LOSS train 0.5689407353431492 valid 0.4863300035076757
LOSS train 0.5689407353431492 valid 0.48697028557459515
LOSS train 0.5689407353431492 valid 0.48758933041244745
LOSS train 0.5689407353431492 valid 0.4880109245960529
LOSS train 0.5689407353431492 valid 0.48804253249457386
LOSS train 0.5689407353431492 valid 0.4877207710671781
LOSS train 0.5689407353431492 valid 0.4871409048928934
LOSS train 0.5689407353431492 valid 0.48684373973072437
LOSS train 0.5689407353431492 valid 0.4865972936153412
LOSS train 0.5689407353431492 valid 0.4862793566475452
LOSS train 0.5689407353431492 valid 0.48619578033685684
LOSS train 0.5689407353431492 valid 0.4864946620105064
LOSS train 0.5689407353431492 valid 0.48642615692035573
LOSS train 0.5689407353431492 valid 0.4860606455802918
LOSS train 0.5689407353431492 valid 0.4860629211915167
LOSS train 0.5689407353431492 valid 0.48561783812262793
LOSS train 0.5689407353431492 valid 0.4855024841351387
LOSS train 0.5689407353431492 valid 0.48557649194439756
LOSS train 0.5689407353431492 valid 0.48530215620994566
LOSS train 0.5689407353431492 valid 0.4850790331393112
LOSS train 0.5689407353431492 valid 0.4851444727037011
LOSS train 0.5689407353431492 valid 0.4849993205932249
LOSS train 0.5689407353431492 valid 0.48525352208387285
LOSS train 0.5689407353431492 valid 0.48531478082432467
LOSS train 0.5689407353431492 valid 0.48497720270655875
LOSS train 0.5689407353431492 valid 0.4850343030759658
LOSS train 0.5689407353431492 valid 0.4845607243478298
LOSS train 0.5689407353431492 valid 0.48473154192560175
LOSS train 0.5689407353431492 valid 0.48427407609091866
LOSS train 0.5689407353431492 valid 0.48399878104964456
LOSS train 0.5689407353431492 valid 0.48409655269073404
LOSS train 0.5689407353431492 valid 0.48385426466182996
LOSS train 0.5689407353431492 valid 0.48348574911026243
LOSS train 0.5689407353431492 valid 0.4834310010859841
LOSS train 0.5689407353431492 valid 0.48335998225957155
LOSS train 0.5689407353431492 valid 0.4835854747246221
LOSS train 0.5689407353431492 valid 0.4835493862628937
LOSS train 0.5689407353431492 valid 0.48377745500718705
LOSS train 0.5689407353431492 valid 0.48397873222827914
LOSS train 0.5689407353431492 valid 0.48389849804415563
LOSS train 0.5689407353431492 valid 0.48397864898045856
LOSS train 0.5689407353431492 valid 0.48418293010841296
LOSS train 0.5689407353431492 valid 0.4841224213059132
LOSS train 0.5689407353431492 valid 0.48399926480792815
LOSS train 0.5689407353431492 valid 0.48399607190546
LOSS train 0.5689407353431492 valid 0.4837466099551905
LOSS train 0.5689407353431492 valid 0.48392999172210693
LOSS train 0.5689407353431492 valid 0.48394736264823773
LOSS train 0.5689407353431492 valid 0.4840949196707119
LOSS train 0.5689407353431492 valid 0.4840158656373754
LOSS train 0.5689407353431492 valid 0.48411606225584236
LOSS train 0.5689407353431492 valid 0.484083018207972
LOSS train 0.5689407353431492 valid 0.4838232452932157
LOSS train 0.5689407353431492 valid 0.4839828524900519
LOSS train 0.5689407353431492 valid 0.48387348112361184
LOSS train 0.5689407353431492 valid 0.4838307983854897
LOSS train 0.5689407353431492 valid 0.4837127966901003
LOSS train 0.5689407353431492 valid 0.48369899492303864
LOSS train 0.5689407353431492 valid 0.48364077135920525
LOSS train 0.5689407353431492 valid 0.4835583900124574
LOSS train 0.5689407353431492 valid 0.4835062102704752
LOSS train 0.5689407353431492 valid 0.4835973815704749
LOSS train 0.5689407353431492 valid 0.4837704822421074
LOSS train 0.5689407353431492 valid 0.4836349833011627
LOSS train 0.5689407353431492 valid 0.4834613816605674
LOSS train 0.5689407353431492 valid 0.4838161250268381
LOSS train 0.5689407353431492 valid 0.4839245385956019
LOSS train 0.5689407353431492 valid 0.48413734265076097
LOSS train 0.5689407353431492 valid 0.4839812844991684
LOSS train 0.5689407353431492 valid 0.48393342808912726
LOSS train 0.5689407353431492 valid 0.48384123340700613
LOSS train 0.5689407353431492 valid 0.48367237574175787
LOSS train 0.5689407353431492 valid 0.48380908837069325
LOSS train 0.5689407353431492 valid 0.4839466075102488
LOSS train 0.5689407353431492 valid 0.48387709807823687
LOSS train 0.5689407353431492 valid 0.4836924991903514
LOSS train 0.5689407353431492 valid 0.48354365125946375
LOSS train 0.5689407353431492 valid 0.4832977326653844
LOSS train 0.5689407353431492 valid 0.4834573571171079
LOSS train 0.5689407353431492 valid 0.48350176384263005
LOSS train 0.5689407353431492 valid 0.48383203715505735
LOSS train 0.5689407353431492 valid 0.48384619696990594
LOSS train 0.5689407353431492 valid 0.484079098328948
LOSS train 0.5689407353431492 valid 0.48413695528589445
LOSS train 0.5689407353431492 valid 0.48431879179934934
LOSS train 0.5689407353431492 valid 0.4840655989792882
LOSS train 0.5689407353431492 valid 0.4841899531515869
LOSS train 0.5689407353431492 valid 0.48435851531540786
LOSS train 0.5689407353431492 valid 0.4843393792708715
LOSS train 0.5689407353431492 valid 0.48438888768486627
LOSS train 0.5689407353431492 valid 0.4841827514924501
LOSS train 0.5689407353431492 valid 0.4843211696038838
LOSS train 0.5689407353431492 valid 0.4843576496297663
LOSS train 0.5689407353431492 valid 0.4843316555023193
LOSS train 0.5689407353431492 valid 0.48464565934279025
LOSS train 0.5689407353431492 valid 0.4847397360072774
LOSS train 0.5689407353431492 valid 0.48469481777541246
LOSS train 0.5689407353431492 valid 0.4843821589301967
LOSS train 0.5689407353431492 valid 0.4843589052557945
LOSS train 0.5689407353431492 valid 0.48423849388679363
LOSS train 0.5689407353431492 valid 0.48397222970738824
LOSS train 0.5689407353431492 valid 0.4840728790482129
LOSS train 0.5689407353431492 valid 0.48404687025198123
LOSS train 0.5689407353431492 valid 0.48391050714435
LOSS train 0.5689407353431492 valid 0.48370542170771635
LOSS train 0.5689407353431492 valid 0.4838076988737026
LOSS train 0.5689407353431492 valid 0.48402334802917074
LOSS train 0.5689407353431492 valid 0.484108378724939
LOSS train 0.5689407353431492 valid 0.4842786594348795
LOSS train 0.5689407353431492 valid 0.48425431802258856
LOSS train 0.5689407353431492 valid 0.4842169224176296
LOSS train 0.5689407353431492 valid 0.484430189594368
LOSS train 0.5689407353431492 valid 0.48443181093396814
LOSS train 0.5689407353431492 valid 0.4844935212816511
LOSS train 0.5689407353431492 valid 0.4843304878608747
LOSS train 0.5689407353431492 valid 0.48448180344145175
LOSS train 0.5689407353431492 valid 0.48456792148311484
LOSS train 0.5689407353431492 valid 0.4845017717537267
LOSS train 0.5689407353431492 valid 0.4845542381207148
LOSS train 0.5689407353431492 valid 0.48459590436345307
LOSS train 0.5689407353431492 valid 0.4846340462074175
LOSS train 0.5689407353431492 valid 0.4846283677822905
LOSS train 0.5689407353431492 valid 0.48470454711628996
LOSS train 0.5689407353431492 valid 0.4846246182918549
LOSS train 0.5689407353431492 valid 0.4846040335714176
LOSS train 0.5689407353431492 valid 0.4845544600231762
LOSS train 0.5689407353431492 valid 0.4847210322288757
LOSS train 0.5689407353431492 valid 0.48462627836005395
LOSS train 0.5689407353431492 valid 0.48457978838368465
LOSS train 0.5689407353431492 valid 0.4848758793626156
LOSS train 0.5689407353431492 valid 0.48488266253843904
LOSS train 0.5689407353431492 valid 0.4849172597413236
LOSS train 0.5689407353431492 valid 0.48473711603695585
LOSS train 0.5689407353431492 valid 0.4845959165157416
LOSS train 0.5689407353431492 valid 0.4846877601681923
LOSS train 0.5689407353431492 valid 0.4847903959642207
LOSS train 0.5689407353431492 valid 0.4848703115877479
LOSS train 0.5689407353431492 valid 0.48485557607669927
LOSS train 0.5689407353431492 valid 0.48482839345932005
LOSS train 0.5689407353431492 valid 0.484730249168861
LOSS train 0.5689407353431492 valid 0.4848110004521833
LOSS train 0.5689407353431492 valid 0.4846347909549187
LOSS train 0.5689407353431492 valid 0.4846020465095838
LOSS train 0.5689407353431492 valid 0.4846299604671757
LOSS train 0.5689407353431492 valid 0.48469261752748954
LOSS train 0.5689407353431492 valid 0.48478019007162193
LOSS train 0.5689407353431492 valid 0.48475365856519115
LOSS train 0.5689407353431492 valid 0.4846714046298032
LOSS train 0.5689407353431492 valid 0.48470311945392974
LOSS train 0.5689407353431492 valid 0.48456125519286963
LOSS train 0.5689407353431492 valid 0.4845739189746245
LOSS train 0.5689407353431492 valid 0.48462158973228203
LOSS train 0.5689407353431492 valid 0.4845578710888034
LOSS train 0.5689407353431492 valid 0.48455801162608836
LOSS train 0.5689407353431492 valid 0.4845940977059029
LOSS train 0.5689407353431492 valid 0.48468266063571525
LOSS train 0.5689407353431492 valid 0.4846029913206713
LOSS train 0.5689407353431492 valid 0.48465258291322894
LOSS train 0.5689407353431492 valid 0.4847011734138836
LOSS train 0.5689407353431492 valid 0.4848577552791095
LOSS train 0.5689407353431492 valid 0.4848679419573363
LOSS train 0.5689407353431492 valid 0.4849347970678133
LOSS train 0.5689407353431492 valid 0.48488498306167976
LOSS train 0.5689407353431492 valid 0.484877712726593
LOSS train 0.5689407353431492 valid 0.48483435334885017
LOSS train 0.5689407353431492 valid 0.48499598889098816
LOSS train 0.5689407353431492 valid 0.485023501280107
LOSS train 0.5689407353431492 valid 0.4849811543804069
LOSS train 0.5689407353431492 valid 0.48505069496838943
LOSS train 0.5689407353431492 valid 0.4850558316036736
LOSS train 0.5689407353431492 valid 0.48506779583363696
LOSS train 0.5689407353431492 valid 0.4849139503143376
LOSS train 0.5689407353431492 valid 0.4848830665533359
LOSS train 0.5689407353431492 valid 0.4849484361232595
LOSS train 0.5689407353431492 valid 0.4849699527277785
LOSS train 0.5689407353431492 valid 0.48495873016647145
LOSS train 0.5689407353431492 valid 0.4848977908366868
LOSS train 0.5689407353431492 valid 0.48493351671985
LOSS train 0.5689407353431492 valid 0.48485416745146115
LOSS train 0.5689407353431492 valid 0.48498984862165334
LOSS train 0.5689407353431492 valid 0.48491574688391254
LOSS train 0.5689407353431492 valid 0.4849353103971285
LOSS train 0.5689407353431492 valid 0.4850033687763527
LOSS train 0.5689407353431492 valid 0.4849589119152147
LOSS train 0.5689407353431492 valid 0.4849441170207853
LOSS train 0.5689407353431492 valid 0.4850732609327988
LOSS train 0.5689407353431492 valid 0.48503889131449884
LOSS train 0.5689407353431492 valid 0.485096734810067
LOSS train 0.5689407353431492 valid 0.4851956902742386
LOSS train 0.5689407353431492 valid 0.4852750449779024
LOSS train 0.5689407353431492 valid 0.4854772707063054
LOSS train 0.5689407353431492 valid 0.4854674439420813
LOSS train 0.5689407353431492 valid 0.48563028848546697
LOSS train 0.5689407353431492 valid 0.48555672098608577
LOSS train 0.5689407353431492 valid 0.4855695365695283
LOSS train 0.5689407353431492 valid 0.4855497858635646
LOSS train 0.5689407353431492 valid 0.4855815735898277
LOSS train 0.5689407353431492 valid 0.48565212248835327
LOSS train 0.5689407353431492 valid 0.4856646268413617
LOSS train 0.5689407353431492 valid 0.4856436041351479
LOSS train 0.5689407353431492 valid 0.4856584828546029
LOSS train 0.5689407353431492 valid 0.4856173333786286
LOSS train 0.5689407353431492 valid 0.4856034441653526
LOSS train 0.5689407353431492 valid 0.48561858793474594
LOSS train 0.5689407353431492 valid 0.4857028978211539
LOSS train 0.5689407353431492 valid 0.4858206845401378
LOSS train 0.5689407353431492 valid 0.4858187437057495
LOSS train 0.5689407353431492 valid 0.48599267626340503
LOSS train 0.5689407353431492 valid 0.4859599647698579
LOSS train 0.5689407353431492 valid 0.48604843559300326
LOSS train 0.5689407353431492 valid 0.4860580808976117
LOSS train 0.5689407353431492 valid 0.48604319514809075
LOSS train 0.5689407353431492 valid 0.4860258413492328
LOSS train 0.5689407353431492 valid 0.48592916098507966
LOSS train 0.5689407353431492 valid 0.48589908558389416
LOSS train 0.5689407353431492 valid 0.48590022884981726
LOSS train 0.5689407353431492 valid 0.4858621123025743
LOSS train 0.5689407353431492 valid 0.4859171674243011
LOSS train 0.5689407353431492 valid 0.4858548241002219
LOSS train 0.5689407353431492 valid 0.48579476651772063
LOSS train 0.5689407353431492 valid 0.4857298932599683
LOSS train 0.5689407353431492 valid 0.48565098358969805
LOSS train 0.5689407353431492 valid 0.48570173391154114
LOSS train 0.5689407353431492 valid 0.4856730657711364
LOSS train 0.5689407353431492 valid 0.4856402361309612
LOSS train 0.5689407353431492 valid 0.48564478973063024
LOSS train 0.5689407353431492 valid 0.48562867525551057
LOSS train 0.5689407353431492 valid 0.4855978533264675
LOSS train 0.5689407353431492 valid 0.48553591072559354
LOSS train 0.5689407353431492 valid 0.48541255249190574
LOSS train 0.5689407353431492 valid 0.48543603401886276
LOSS train 0.5689407353431492 valid 0.48538809007752065
LOSS train 0.5689407353431492 valid 0.48546611786294147
LOSS train 0.5689407353431492 valid 0.4855573657205549
LOSS train 0.5689407353431492 valid 0.48556394703887606
LOSS train 0.5689407353431492 valid 0.48556686190242315
LOSS train 0.5689407353431492 valid 0.4855318789514119
LOSS train 0.5689407353431492 valid 0.4855870417129236
LOSS train 0.5689407353431492 valid 0.4856329707304637
LOSS train 0.5689407353431492 valid 0.48561296956087663
LOSS train 0.5689407353431492 valid 0.4855566754049023
LOSS train 0.5689407353431492 valid 0.4854882071317226
LOSS train 0.5689407353431492 valid 0.48545686890812295
LOSS train 0.5689407353431492 valid 0.48537211115243006
LOSS train 0.5689407353431492 valid 0.4853765884645624
LOSS train 0.5689407353431492 valid 0.48540718528269167
LOSS train 0.5689407353431492 valid 0.4853535234541088
LOSS train 0.5689407353431492 valid 0.485444640264542
LOSS train 0.5689407353431492 valid 0.4853844456134304
LOSS train 0.5689407353431492 valid 0.48535086909291064
LOSS train 0.5689407353431492 valid 0.4853381709410594
LOSS train 0.5689407353431492 valid 0.4854775739554018
LOSS train 0.5689407353431492 valid 0.4855511904142465
LOSS train 0.5689407353431492 valid 0.4855203345654503
LOSS train 0.5689407353431492 valid 0.4854761357360248
LOSS train 0.5689407353431492 valid 0.4854759618122871
LOSS train 0.5689407353431492 valid 0.4855480729221548
LOSS train 0.5689407353431492 valid 0.48545099771508604
LOSS train 0.5689407353431492 valid 0.48541369317099453
LOSS train 0.5689407353431492 valid 0.4853815216327382
LOSS train 0.5689407353431492 valid 0.4853649853919604
LOSS train 0.5689407353431492 valid 0.48527833182745306
LOSS train 0.5689407353431492 valid 0.4853100991911358
LOSS train 0.5689407353431492 valid 0.4853263886158283
LOSS train 0.5689407353431492 valid 0.48537801196970093
LOSS train 0.5689407353431492 valid 0.4854740799384744
LOSS train 0.5689407353431492 valid 0.4854985259291602
LOSS train 0.5689407353431492 valid 0.48551064313001546
LOSS train 0.5689407353431492 valid 0.48552284403280777
LOSS train 0.5689407353431492 valid 0.4854869032194247
LOSS train 0.5689407353431492 valid 0.48541919671627415
LOSS train 0.5689407353431492 valid 0.48540839651325446
LOSS train 0.5689407353431492 valid 0.4854525159932896
LOSS train 0.5689407353431492 valid 0.4854535468478701
LOSS train 0.5689407353431492 valid 0.4854789821519738
LOSS train 0.5689407353431492 valid 0.4855125790533751
LOSS train 0.5689407353431492 valid 0.4855261111753227
LOSS train 0.5689407353431492 valid 0.4854756692166174
LOSS train 0.5689407353431492 valid 0.4854810769067091
LOSS train 0.5689407353431492 valid 0.48539878441091855
LOSS train 0.5689407353431492 valid 0.48528659274006447
LOSS train 0.5689407353431492 valid 0.4852527190575447
LOSS train 0.5689407353431492 valid 0.4853069078783656
LOSS train 0.5689407353431492 valid 0.4853653771289881
LOSS train 0.5689407353431492 valid 0.4853280322744667
LOSS train 0.5689407353431492 valid 0.4853608967247889
LOSS train 0.5689407353431492 valid 0.4853207216351882
LOSS train 0.5689407353431492 valid 0.48534825871188864
LOSS train 0.5689407353431492 valid 0.48528699270316533
LOSS train 0.5689407353431492 valid 0.4852606109064868
LOSS train 0.5689407353431492 valid 0.48530642688274384
LOSS train 0.5689407353431492 valid 0.48541409925428397
LOSS train 0.5689407353431492 valid 0.48547799994716534
LOSS train 0.5689407353431492 valid 0.4854870700500381
LOSS train 0.5689407353431492 valid 0.48542643438899113
LOSS train 0.5689407353431492 valid 0.48539966745536867
LOSS train 0.5689407353431492 valid 0.48526710255185984
LOSS train 0.5689407353431492 valid 0.4853078906416561
LOSS train 0.5689407353431492 valid 0.4852595884766844
LOSS train 0.5689407353431492 valid 0.48527905204619726
LOSS train 0.5689407353431492 valid 0.4853208875129236
LOSS train 0.5689407353431492 valid 0.48531683286031085
LOSS train 0.5689407353431492 valid 0.48528151287809834
LOSS train 0.5689407353431492 valid 0.48532465508539385
LOSS train 0.5689407353431492 valid 0.48529247125315533
LOSS train 0.5689407353431492 valid 0.4852762765553082
LOSS train 0.5689407353431492 valid 0.48521457150902436
LOSS train 0.5689407353431492 valid 0.48521582544011477
EPOCH 5:
  batch 1 loss: 0.544859766960144
  batch 2 loss: 0.5368508994579315
  batch 3 loss: 0.5459875464439392
  batch 4 loss: 0.5560609698295593
  batch 5 loss: 0.5555210113525391
  batch 6 loss: 0.5571641723314921
  batch 7 loss: 0.5601497037070138
  batch 8 loss: 0.5615823715925217
  batch 9 loss: 0.562409864531623
  batch 10 loss: 0.565554940700531
  batch 11 loss: 0.5646686662327159
  batch 12 loss: 0.5643922686576843
  batch 13 loss: 0.5655435415414664
  batch 14 loss: 0.5671130972249168
  batch 15 loss: 0.5672121167182922
  batch 16 loss: 0.5660497136414051
  batch 17 loss: 0.5652174844461328
  batch 18 loss: 0.5646029015382131
  batch 19 loss: 0.5636702242650484
  batch 20 loss: 0.5634318053722381
  batch 21 loss: 0.5649095177650452
  batch 22 loss: 0.5644084431908347
  batch 23 loss: 0.5638932404310807
  batch 24 loss: 0.5630500738819441
  batch 25 loss: 0.5630388832092286
  batch 26 loss: 0.5620285731095535
  batch 27 loss: 0.561188417452353
  batch 28 loss: 0.5595452125583377
  batch 29 loss: 0.559818802208736
  batch 30 loss: 0.5593408465385437
  batch 31 loss: 0.5588041966961276
  batch 32 loss: 0.5587094016373158
  batch 33 loss: 0.5586629365429734
  batch 34 loss: 0.5585059365805458
  batch 35 loss: 0.5590058786528451
  batch 36 loss: 0.5590687261687385
  batch 37 loss: 0.5591991753191561
  batch 38 loss: 0.5586124517415699
  batch 39 loss: 0.5590745317630279
  batch 40 loss: 0.5583649024367332
  batch 41 loss: 0.5582055158731414
  batch 42 loss: 0.558537388131732
  batch 43 loss: 0.5582851296247437
  batch 44 loss: 0.5580755092880942
  batch 45 loss: 0.5586057821909587
  batch 46 loss: 0.5582833626995916
  batch 47 loss: 0.5583745050937572
  batch 48 loss: 0.5576205849647522
  batch 49 loss: 0.5573139506943372
  batch 50 loss: 0.5571017801761627
  batch 51 loss: 0.5567091387860915
  batch 52 loss: 0.5569760719170938
  batch 53 loss: 0.5572885972148968
  batch 54 loss: 0.557114596720095
  batch 55 loss: 0.5565670403567228
  batch 56 loss: 0.5554810836911201
  batch 57 loss: 0.5553639855301171
  batch 58 loss: 0.5556503112973838
  batch 59 loss: 0.5554067310640367
  batch 60 loss: 0.5552401572465897
  batch 61 loss: 0.5551167814458002
  batch 62 loss: 0.5556081639182183
  batch 63 loss: 0.5558106624890887
  batch 64 loss: 0.5560379093512893
  batch 65 loss: 0.5552968254456153
  batch 66 loss: 0.5553263380671992
  batch 67 loss: 0.5555350308987632
  batch 68 loss: 0.5558373305727454
  batch 69 loss: 0.5558072907337244
  batch 70 loss: 0.5556304020541055
  batch 71 loss: 0.5558000198552306
  batch 72 loss: 0.5555440617932214
  batch 73 loss: 0.5556360189228842
  batch 74 loss: 0.5555882276715459
  batch 75 loss: 0.5554180367787679
  batch 76 loss: 0.5556361408610093
  batch 77 loss: 0.5555420525662311
  batch 78 loss: 0.5550348070951608
  batch 79 loss: 0.5552160589000846
  batch 80 loss: 0.5550183326005935
  batch 81 loss: 0.5553107923931546
  batch 82 loss: 0.5556007405606712
  batch 83 loss: 0.5556970648018711
  batch 84 loss: 0.5558910057658241
  batch 85 loss: 0.5556486613610212
  batch 86 loss: 0.5562428880569547
  batch 87 loss: 0.5558791756629944
  batch 88 loss: 0.5553337227214467
  batch 89 loss: 0.5552983953711692
  batch 90 loss: 0.5554216629929013
  batch 91 loss: 0.5557219268201472
  batch 92 loss: 0.5555234208055164
  batch 93 loss: 0.5555047585118201
  batch 94 loss: 0.5559359960099484
  batch 95 loss: 0.5562395051905983
  batch 96 loss: 0.5563882117470106
  batch 97 loss: 0.5567303097125181
  batch 98 loss: 0.5570415842289828
  batch 99 loss: 0.5567937415055554
  batch 100 loss: 0.5568035888671875
  batch 101 loss: 0.5569596538449278
  batch 102 loss: 0.5569844602369795
  batch 103 loss: 0.557042320376461
  batch 104 loss: 0.5569756323328385
  batch 105 loss: 0.5568377080417815
  batch 106 loss: 0.5570790413415657
  batch 107 loss: 0.5569936766802708
  batch 108 loss: 0.5567404004158797
  batch 109 loss: 0.556848052444808
  batch 110 loss: 0.5569501876831054
  batch 111 loss: 0.5571003115928925
  batch 112 loss: 0.5568807098482337
  batch 113 loss: 0.5570382053873181
  batch 114 loss: 0.5574004257980146
  batch 115 loss: 0.5577164649963379
  batch 116 loss: 0.5577841534696776
  batch 117 loss: 0.5577710866928101
  batch 118 loss: 0.5578876198348353
  batch 119 loss: 0.5578649054054453
  batch 120 loss: 0.5580199370781581
  batch 121 loss: 0.5579057468855677
  batch 122 loss: 0.5578108122114276
  batch 123 loss: 0.557547731612756
  batch 124 loss: 0.5576804621565726
  batch 125 loss: 0.5575519351959228
  batch 126 loss: 0.5574357973204719
  batch 127 loss: 0.5577099388978612
  batch 128 loss: 0.557391531765461
  batch 129 loss: 0.557222419930983
  batch 130 loss: 0.5571618428597084
  batch 131 loss: 0.5573849177542534
  batch 132 loss: 0.5574399548949618
  batch 133 loss: 0.5577132531574794
  batch 134 loss: 0.5576386598508749
  batch 135 loss: 0.5577179577615526
  batch 136 loss: 0.5575755015015602
  batch 137 loss: 0.5576208468771329
  batch 138 loss: 0.5578979949156443
  batch 139 loss: 0.5577609294610057
  batch 140 loss: 0.5575892337730952
  batch 141 loss: 0.5575566355218279
  batch 142 loss: 0.5575719081180196
  batch 143 loss: 0.5574900503758784
  batch 144 loss: 0.5574231503738297
  batch 145 loss: 0.557372315998735
  batch 146 loss: 0.5573076079153034
  batch 147 loss: 0.5571295679831991
  batch 148 loss: 0.5571701252782667
  batch 149 loss: 0.5571363064266691
  batch 150 loss: 0.5568808551629384
  batch 151 loss: 0.5566216600651772
  batch 152 loss: 0.5569019948965624
  batch 153 loss: 0.5568126093328388
  batch 154 loss: 0.55693073164333
  batch 155 loss: 0.5570589534697994
  batch 156 loss: 0.5569021533697079
  batch 157 loss: 0.557061383678655
  batch 158 loss: 0.5569889394542838
  batch 159 loss: 0.5569786733051516
  batch 160 loss: 0.5570526845753193
  batch 161 loss: 0.557105753362549
  batch 162 loss: 0.5571578038327488
  batch 163 loss: 0.5571841363526561
  batch 164 loss: 0.5572584536744327
  batch 165 loss: 0.5572292512113398
  batch 166 loss: 0.5573348410158272
  batch 167 loss: 0.5571980576315326
  batch 168 loss: 0.5573521618332181
  batch 169 loss: 0.5573306559810977
  batch 170 loss: 0.5573393853271709
  batch 171 loss: 0.5572577289670532
  batch 172 loss: 0.557501022552335
  batch 173 loss: 0.5574533915244086
  batch 174 loss: 0.557637383197916
  batch 175 loss: 0.5575122424534389
  batch 176 loss: 0.5576145706528967
  batch 177 loss: 0.5575259583818037
  batch 178 loss: 0.5576365804404355
  batch 179 loss: 0.5577190311927369
  batch 180 loss: 0.5577851331896252
  batch 181 loss: 0.5579055109735351
  batch 182 loss: 0.5578881079679007
  batch 183 loss: 0.5578693350156149
  batch 184 loss: 0.5578312264836353
  batch 185 loss: 0.5578718649374472
  batch 186 loss: 0.5577287279790447
  batch 187 loss: 0.5575757893649015
  batch 188 loss: 0.5575385442439545
  batch 189 loss: 0.5573438405990601
  batch 190 loss: 0.5571947386390285
  batch 191 loss: 0.5571916190741574
  batch 192 loss: 0.5570589806884527
  batch 193 loss: 0.55706472162138
  batch 194 loss: 0.5570746918314511
  batch 195 loss: 0.5572068972465319
  batch 196 loss: 0.5570502500144803
  batch 197 loss: 0.5572526500309785
  batch 198 loss: 0.5572222823446448
  batch 199 loss: 0.5571380970466077
  batch 200 loss: 0.5571156638860703
  batch 201 loss: 0.557118282982366
  batch 202 loss: 0.5572452471397891
  batch 203 loss: 0.5573658121043238
  batch 204 loss: 0.5573501791439804
  batch 205 loss: 0.5573186476056169
  batch 206 loss: 0.5574135450483526
  batch 207 loss: 0.5575031854104304
  batch 208 loss: 0.5573540496138426
  batch 209 loss: 0.5572840311880888
  batch 210 loss: 0.5572250303767976
  batch 211 loss: 0.5572407946202427
  batch 212 loss: 0.5572768314829413
  batch 213 loss: 0.5572901096702182
  batch 214 loss: 0.5572416364589584
  batch 215 loss: 0.5570378331250923
  batch 216 loss: 0.5568606522348192
  batch 217 loss: 0.556902127881204
  batch 218 loss: 0.5567883165604478
  batch 219 loss: 0.5567246604727828
  batch 220 loss: 0.5567532666704872
  batch 221 loss: 0.5567921853173372
  batch 222 loss: 0.5567735712807458
  batch 223 loss: 0.5568637008624227
  batch 224 loss: 0.5567326910261597
  batch 225 loss: 0.5566850497987536
  batch 226 loss: 0.5566961791663043
  batch 227 loss: 0.5566210731010605
  batch 228 loss: 0.556618578078454
  batch 229 loss: 0.5564974132583651
  batch 230 loss: 0.5564923117990079
  batch 231 loss: 0.5564196997390681
  batch 232 loss: 0.5562387596944283
  batch 233 loss: 0.5562452374609754
  batch 234 loss: 0.5561888054904774
  batch 235 loss: 0.5561523665773108
  batch 236 loss: 0.5560960292311038
  batch 237 loss: 0.5560877833688309
  batch 238 loss: 0.5561389615054891
  batch 239 loss: 0.5559661183895925
  batch 240 loss: 0.5560489090780417
  batch 241 loss: 0.556057549858489
  batch 242 loss: 0.555921463188061
  batch 243 loss: 0.5559510959028707
  batch 244 loss: 0.5559897926010069
  batch 245 loss: 0.5559890931966354
  batch 246 loss: 0.555995031343243
  batch 247 loss: 0.5560050732211063
  batch 248 loss: 0.5560217007033287
  batch 249 loss: 0.5559881396561741
  batch 250 loss: 0.5559801962375641
  batch 251 loss: 0.5559867855562157
  batch 252 loss: 0.5559822006358041
  batch 253 loss: 0.5559542044820521
  batch 254 loss: 0.5559194038702747
  batch 255 loss: 0.5560282770325156
  batch 256 loss: 0.5559309991076589
  batch 257 loss: 0.5559781128794302
  batch 258 loss: 0.5559116417123365
  batch 259 loss: 0.5558207016653997
  batch 260 loss: 0.5557707667350769
  batch 261 loss: 0.5558410686551383
  batch 262 loss: 0.5557744143573382
  batch 263 loss: 0.5557830113875095
  batch 264 loss: 0.555812684875546
  batch 265 loss: 0.5556819326472733
  batch 266 loss: 0.5556996119649786
  batch 267 loss: 0.5556747145420603
  batch 268 loss: 0.5555073923584241
  batch 269 loss: 0.5555183499719131
  batch 270 loss: 0.5554120456730878
  batch 271 loss: 0.5553744899390808
  batch 272 loss: 0.5553822523969061
  batch 273 loss: 0.5553119444585108
  batch 274 loss: 0.5552255315502195
  batch 275 loss: 0.5553659250519493
  batch 276 loss: 0.5553999612296837
  batch 277 loss: 0.5554431461685401
  batch 278 loss: 0.5554002536286553
  batch 279 loss: 0.5554429010678363
  batch 280 loss: 0.5553031412618501
  batch 281 loss: 0.555259835677639
  batch 282 loss: 0.5551272279827307
  batch 283 loss: 0.5551121744587227
  batch 284 loss: 0.5551348324392883
  batch 285 loss: 0.5550219468903124
  batch 286 loss: 0.5549395728361356
  batch 287 loss: 0.5549306260999487
  batch 288 loss: 0.5547192890403999
  batch 289 loss: 0.5548359826980578
  batch 290 loss: 0.5546929140543115
  batch 291 loss: 0.5546470996235654
  batch 292 loss: 0.5547505154797475
  batch 293 loss: 0.5548032704270334
  batch 294 loss: 0.5546802447563937
  batch 295 loss: 0.5548262956788984
  batch 296 loss: 0.5548092353384237
  batch 297 loss: 0.5548813988263358
  batch 298 loss: 0.5549053212740277
  batch 299 loss: 0.5548412288511079
  batch 300 loss: 0.5549042660991351
  batch 301 loss: 0.5550362999455081
  batch 302 loss: 0.555012016600331
  batch 303 loss: 0.5549796561006666
  batch 304 loss: 0.5549437147810271
  batch 305 loss: 0.5547476172447204
  batch 306 loss: 0.5547872772014218
  batch 307 loss: 0.5547070241129748
  batch 308 loss: 0.5546234139761368
  batch 309 loss: 0.5545909603436788
  batch 310 loss: 0.5545639816791781
  batch 311 loss: 0.5545091972090423
  batch 312 loss: 0.5545490645827391
  batch 313 loss: 0.5546330940990022
  batch 314 loss: 0.5546675825574595
  batch 315 loss: 0.5546343826112293
  batch 316 loss: 0.5546148206236996
  batch 317 loss: 0.5546394592203928
  batch 318 loss: 0.5545469303176088
  batch 319 loss: 0.5544259535107867
  batch 320 loss: 0.5543883301317691
  batch 321 loss: 0.5542937829115681
  batch 322 loss: 0.5542717463111285
  batch 323 loss: 0.5542437052210049
  batch 324 loss: 0.5541198897508928
  batch 325 loss: 0.5540895511553837
  batch 326 loss: 0.5539400250268128
  batch 327 loss: 0.5539199688019009
  batch 328 loss: 0.5538280122890705
  batch 329 loss: 0.5538027069126581
  batch 330 loss: 0.5536981178052498
  batch 331 loss: 0.5535899065772573
  batch 332 loss: 0.5536701223218298
  batch 333 loss: 0.553579544161891
  batch 334 loss: 0.5534530899481859
  batch 335 loss: 0.5534515921749286
  batch 336 loss: 0.5533923921840531
  batch 337 loss: 0.5534196168803319
  batch 338 loss: 0.5534782513711579
  batch 339 loss: 0.5535217602696039
  batch 340 loss: 0.5535561875385396
  batch 341 loss: 0.5535724136836367
  batch 342 loss: 0.5535269526013157
  batch 343 loss: 0.5535238817898942
  batch 344 loss: 0.5535145155912222
  batch 345 loss: 0.5535853997520779
  batch 346 loss: 0.5535862309739769
  batch 347 loss: 0.5535891200348692
  batch 348 loss: 0.5536032613666578
  batch 349 loss: 0.5534940814562035
  batch 350 loss: 0.5534914832455772
  batch 351 loss: 0.553529451545487
  batch 352 loss: 0.553551303900101
  batch 353 loss: 0.5535015733991736
  batch 354 loss: 0.5535357653421197
  batch 355 loss: 0.5536698482405972
  batch 356 loss: 0.553660657968414
  batch 357 loss: 0.5536646435574657
  batch 358 loss: 0.5536734328589625
  batch 359 loss: 0.5536788436363667
  batch 360 loss: 0.5537056174543169
  batch 361 loss: 0.5537320619805037
  batch 362 loss: 0.5536393483699356
  batch 363 loss: 0.5536293963755458
  batch 364 loss: 0.5535270715807821
  batch 365 loss: 0.5534960800654267
  batch 366 loss: 0.5533827955279845
  batch 367 loss: 0.5533640188157396
  batch 368 loss: 0.5532848700557066
  batch 369 loss: 0.5532970388084246
  batch 370 loss: 0.553358174820204
  batch 371 loss: 0.5534594613265477
  batch 372 loss: 0.553324974192086
  batch 373 loss: 0.5532623460721074
  batch 374 loss: 0.5531907421063612
  batch 375 loss: 0.5531938486099243
  batch 376 loss: 0.553233506514671
  batch 377 loss: 0.5531479823810669
  batch 378 loss: 0.5530585212997658
  batch 379 loss: 0.5530276564306194
  batch 380 loss: 0.553087293631152
  batch 381 loss: 0.5529848379412974
  batch 382 loss: 0.552847565000594
  batch 383 loss: 0.5528483513752412
  batch 384 loss: 0.5528600645872453
  batch 385 loss: 0.5529427622819876
  batch 386 loss: 0.5528683135855383
  batch 387 loss: 0.5528297544449798
  batch 388 loss: 0.5528209049677112
  batch 389 loss: 0.5527959148804142
  batch 390 loss: 0.5528146401429788
  batch 391 loss: 0.5527809009222728
  batch 392 loss: 0.5527644943521948
  batch 393 loss: 0.5528002087093188
  batch 394 loss: 0.5527895124733145
  batch 395 loss: 0.552809847004806
  batch 396 loss: 0.552851760327214
  batch 397 loss: 0.5527575807247114
  batch 398 loss: 0.5527208866785519
  batch 399 loss: 0.5527173672104838
  batch 400 loss: 0.5526132678985596
  batch 401 loss: 0.5525840443565958
  batch 402 loss: 0.5525942010369467
  batch 403 loss: 0.5525518318559632
  batch 404 loss: 0.5524589876727303
  batch 405 loss: 0.5524747408466575
  batch 406 loss: 0.5524757372334673
  batch 407 loss: 0.5524415357692821
  batch 408 loss: 0.5524888726718286
  batch 409 loss: 0.5524396482481642
  batch 410 loss: 0.5523948242024678
  batch 411 loss: 0.5523302475321322
  batch 412 loss: 0.5522577014652271
  batch 413 loss: 0.5521863257336559
  batch 414 loss: 0.5521122970154896
  batch 415 loss: 0.5520838491887932
  batch 416 loss: 0.5520020090043545
  batch 417 loss: 0.5519716112161998
  batch 418 loss: 0.5519016784343993
  batch 419 loss: 0.5518994433783119
  batch 420 loss: 0.5519277805373782
  batch 421 loss: 0.5519541414220089
  batch 422 loss: 0.5520546987158428
  batch 423 loss: 0.552072452315202
  batch 424 loss: 0.5520573460830832
  batch 425 loss: 0.5520579608748941
  batch 426 loss: 0.5520249712914927
  batch 427 loss: 0.5520105522466209
  batch 428 loss: 0.551929013333588
  batch 429 loss: 0.5519233056993196
  batch 430 loss: 0.5519292982511742
  batch 431 loss: 0.5519932296879053
  batch 432 loss: 0.5520038550926579
  batch 433 loss: 0.5519455473087126
  batch 434 loss: 0.5519868124465239
  batch 435 loss: 0.5519024924300183
  batch 436 loss: 0.5518486889403894
  batch 437 loss: 0.5518956193934862
  batch 438 loss: 0.5519602977794055
  batch 439 loss: 0.5519105892518115
  batch 440 loss: 0.5519156721505252
  batch 441 loss: 0.5518887843134181
  batch 442 loss: 0.5518804947715
  batch 443 loss: 0.551870792498707
  batch 444 loss: 0.5518015056580037
  batch 445 loss: 0.5517758342657196
  batch 446 loss: 0.5517392099705513
  batch 447 loss: 0.5516623498609402
  batch 448 loss: 0.5517288745780077
  batch 449 loss: 0.551795143327097
  batch 450 loss: 0.5518266741434733
  batch 451 loss: 0.5517792812736494
  batch 452 loss: 0.55180312798614
  batch 453 loss: 0.5517777550562591
  batch 454 loss: 0.551787814773652
  batch 455 loss: 0.5517637165038141
  batch 456 loss: 0.5517184377500886
  batch 457 loss: 0.5517382852619013
  batch 458 loss: 0.5517030536607884
  batch 459 loss: 0.5517000379385771
  batch 460 loss: 0.5517688104639883
  batch 461 loss: 0.5517347065849056
  batch 462 loss: 0.5517001398456045
  batch 463 loss: 0.5516722184278022
  batch 464 loss: 0.5517101955824885
  batch 465 loss: 0.5515946850340854
  batch 466 loss: 0.5515028438470906
  batch 467 loss: 0.5515565842198611
  batch 468 loss: 0.5514980669841807
  batch 469 loss: 0.5514544148816228
  batch 470 loss: 0.5514099445114744
  batch 471 loss: 0.5514240578101699
  batch 472 loss: 0.5513738210044675
LOSS train 0.5513738210044675 valid 0.5218261480331421
LOSS train 0.5513738210044675 valid 0.49760255217552185
LOSS train 0.5513738210044675 valid 0.5137240688006083
LOSS train 0.5513738210044675 valid 0.5090799480676651
LOSS train 0.5513738210044675 valid 0.5118308424949646
LOSS train 0.5513738210044675 valid 0.5142815510431925
LOSS train 0.5513738210044675 valid 0.512907189982278
LOSS train 0.5513738210044675 valid 0.5144538432359695
LOSS train 0.5513738210044675 valid 0.5105794999334548
LOSS train 0.5513738210044675 valid 0.5128468930721283
LOSS train 0.5513738210044675 valid 0.5164323882623152
LOSS train 0.5513738210044675 valid 0.5160041302442551
LOSS train 0.5513738210044675 valid 0.5211970210075378
LOSS train 0.5513738210044675 valid 0.5216910541057587
LOSS train 0.5513738210044675 valid 0.5200048685073853
LOSS train 0.5513738210044675 valid 0.5200495794415474
LOSS train 0.5513738210044675 valid 0.5233859735376695
LOSS train 0.5513738210044675 valid 0.5247298445966508
LOSS train 0.5513738210044675 valid 0.5247869962140134
LOSS train 0.5513738210044675 valid 0.5266209810972213
LOSS train 0.5513738210044675 valid 0.5260396656535921
LOSS train 0.5513738210044675 valid 0.5239261551336809
LOSS train 0.5513738210044675 valid 0.5250900439594103
LOSS train 0.5513738210044675 valid 0.5241895591219267
LOSS train 0.5513738210044675 valid 0.5239663100242615
LOSS train 0.5513738210044675 valid 0.5243585957930639
LOSS train 0.5513738210044675 valid 0.5242255285934165
LOSS train 0.5513738210044675 valid 0.5244508683681488
LOSS train 0.5513738210044675 valid 0.5243121426680992
LOSS train 0.5513738210044675 valid 0.5248532096544901
LOSS train 0.5513738210044675 valid 0.526330211470204
LOSS train 0.5513738210044675 valid 0.5253736507147551
LOSS train 0.5513738210044675 valid 0.5256422234304023
LOSS train 0.5513738210044675 valid 0.5251188523629132
LOSS train 0.5513738210044675 valid 0.5257535253252302
LOSS train 0.5513738210044675 valid 0.5256847689549128
LOSS train 0.5513738210044675 valid 0.5263194377357895
LOSS train 0.5513738210044675 valid 0.5277351156661385
LOSS train 0.5513738210044675 valid 0.5275576680134504
LOSS train 0.5513738210044675 valid 0.529164220392704
LOSS train 0.5513738210044675 valid 0.5292147281693249
LOSS train 0.5513738210044675 valid 0.5302156068029857
LOSS train 0.5513738210044675 valid 0.5301764593567959
LOSS train 0.5513738210044675 valid 0.530364529653029
LOSS train 0.5513738210044675 valid 0.5305951118469239
LOSS train 0.5513738210044675 valid 0.530830064545507
LOSS train 0.5513738210044675 valid 0.5306542541118379
LOSS train 0.5513738210044675 valid 0.5307820898791155
LOSS train 0.5513738210044675 valid 0.5313721651933632
LOSS train 0.5513738210044675 valid 0.5309212970733642
LOSS train 0.5513738210044675 valid 0.5313604263698354
LOSS train 0.5513738210044675 valid 0.5311298645459689
LOSS train 0.5513738210044675 valid 0.5309758726155983
LOSS train 0.5513738210044675 valid 0.5306510285094932
LOSS train 0.5513738210044675 valid 0.5301122817126187
LOSS train 0.5513738210044675 valid 0.5300070409263883
LOSS train 0.5513738210044675 valid 0.5295975250110292
LOSS train 0.5513738210044675 valid 0.5294659374089077
LOSS train 0.5513738210044675 valid 0.5300609085519435
LOSS train 0.5513738210044675 valid 0.5295425802469254
LOSS train 0.5513738210044675 valid 0.5286825377433026
LOSS train 0.5513738210044675 valid 0.5297520227970616
LOSS train 0.5513738210044675 valid 0.5304561692570883
LOSS train 0.5513738210044675 valid 0.5312624471262097
LOSS train 0.5513738210044675 valid 0.5316564752505376
LOSS train 0.5513738210044675 valid 0.5316191144061811
LOSS train 0.5513738210044675 valid 0.5312443793709598
LOSS train 0.5513738210044675 valid 0.5306252635577146
LOSS train 0.5513738210044675 valid 0.5303545853366023
LOSS train 0.5513738210044675 valid 0.5301085770130157
LOSS train 0.5513738210044675 valid 0.5297265783162184
LOSS train 0.5513738210044675 valid 0.5296551113327345
LOSS train 0.5513738210044675 valid 0.5300583863911563
LOSS train 0.5513738210044675 valid 0.5299324369108355
LOSS train 0.5513738210044675 valid 0.5294388592243194
LOSS train 0.5513738210044675 valid 0.5294904234377962
LOSS train 0.5513738210044675 valid 0.5290183003072615
LOSS train 0.5513738210044675 valid 0.5289104676399475
LOSS train 0.5513738210044675 valid 0.5289687050294273
LOSS train 0.5513738210044675 valid 0.5287493821233511
LOSS train 0.5513738210044675 valid 0.5283768673737844
LOSS train 0.5513738210044675 valid 0.5285172262569753
LOSS train 0.5513738210044675 valid 0.5283484089087291
LOSS train 0.5513738210044675 valid 0.5285883343645504
LOSS train 0.5513738210044675 valid 0.5287814852069406
LOSS train 0.5513738210044675 valid 0.52838242712409
LOSS train 0.5513738210044675 valid 0.5284421310342592
LOSS train 0.5513738210044675 valid 0.5278863608837128
LOSS train 0.5513738210044675 valid 0.5279681829923994
LOSS train 0.5513738210044675 valid 0.527502711613973
LOSS train 0.5513738210044675 valid 0.5273131099376049
LOSS train 0.5513738210044675 valid 0.5273496858451677
LOSS train 0.5513738210044675 valid 0.5270558070111019
LOSS train 0.5513738210044675 valid 0.5265956914171259
LOSS train 0.5513738210044675 valid 0.5264917223077071
LOSS train 0.5513738210044675 valid 0.5264576443781456
LOSS train 0.5513738210044675 valid 0.5267724118281886
LOSS train 0.5513738210044675 valid 0.5267532212393624
LOSS train 0.5513738210044675 valid 0.5270172622468736
LOSS train 0.5513738210044675 valid 0.5272204756736756
LOSS train 0.5513738210044675 valid 0.5271689915420985
LOSS train 0.5513738210044675 valid 0.527347781494552
LOSS train 0.5513738210044675 valid 0.5276290936377442
LOSS train 0.5513738210044675 valid 0.5275419830129697
LOSS train 0.5513738210044675 valid 0.5273779227620079
LOSS train 0.5513738210044675 valid 0.5274168073006396
LOSS train 0.5513738210044675 valid 0.527099941378442
LOSS train 0.5513738210044675 valid 0.5273288974055538
LOSS train 0.5513738210044675 valid 0.5273228397063159
LOSS train 0.5513738210044675 valid 0.527468076619235
LOSS train 0.5513738210044675 valid 0.5273659100403657
LOSS train 0.5513738210044675 valid 0.5274536950247628
LOSS train 0.5513738210044675 valid 0.5274308708916723
LOSS train 0.5513738210044675 valid 0.5271766841934439
LOSS train 0.5513738210044675 valid 0.5272437217442886
LOSS train 0.5513738210044675 valid 0.5271312381173002
LOSS train 0.5513738210044675 valid 0.527143645235616
LOSS train 0.5513738210044675 valid 0.526972141053717
LOSS train 0.5513738210044675 valid 0.5269820106630566
LOSS train 0.5513738210044675 valid 0.5269330315291881
LOSS train 0.5513738210044675 valid 0.5268225770843916
LOSS train 0.5513738210044675 valid 0.5268154928430182
LOSS train 0.5513738210044675 valid 0.5268554089030599
LOSS train 0.5513738210044675 valid 0.527091465409725
LOSS train 0.5513738210044675 valid 0.5269673011302948
LOSS train 0.5513738210044675 valid 0.5267427374446203
LOSS train 0.5513738210044675 valid 0.5271716934489453
LOSS train 0.5513738210044675 valid 0.5272757038474083
LOSS train 0.5513738210044675 valid 0.5274647797724997
LOSS train 0.5513738210044675 valid 0.5273341985849234
LOSS train 0.5513738210044675 valid 0.5272935287643025
LOSS train 0.5513738210044675 valid 0.52724822362264
LOSS train 0.5513738210044675 valid 0.5270785478720987
LOSS train 0.5513738210044675 valid 0.5273170658011934
LOSS train 0.5513738210044675 valid 0.5275571253564623
LOSS train 0.5513738210044675 valid 0.5274423330145723
LOSS train 0.5513738210044675 valid 0.5272120474463832
LOSS train 0.5513738210044675 valid 0.5270554844451987
LOSS train 0.5513738210044675 valid 0.5268159427231164
LOSS train 0.5513738210044675 valid 0.5269986799785069
LOSS train 0.5513738210044675 valid 0.527077798302292
LOSS train 0.5513738210044675 valid 0.5274924434406657
LOSS train 0.5513738210044675 valid 0.5275367848523014
LOSS train 0.5513738210044675 valid 0.5278031254808108
LOSS train 0.5513738210044675 valid 0.5279002074537607
LOSS train 0.5513738210044675 valid 0.5280945807287137
LOSS train 0.5513738210044675 valid 0.527781851437627
LOSS train 0.5513738210044675 valid 0.5279130267130362
LOSS train 0.5513738210044675 valid 0.5280851769767352
LOSS train 0.5513738210044675 valid 0.5280815279483795
LOSS train 0.5513738210044675 valid 0.5281212456178981
LOSS train 0.5513738210044675 valid 0.5279213731226168
LOSS train 0.5513738210044675 valid 0.5280997285655901
LOSS train 0.5513738210044675 valid 0.528170538026017
LOSS train 0.5513738210044675 valid 0.5281576664217057
LOSS train 0.5513738210044675 valid 0.5284597613872626
LOSS train 0.5513738210044675 valid 0.5285049866718851
LOSS train 0.5513738210044675 valid 0.5284453026856049
LOSS train 0.5513738210044675 valid 0.5281073443544736
LOSS train 0.5513738210044675 valid 0.5280731827020645
LOSS train 0.5513738210044675 valid 0.5279890061905665
LOSS train 0.5513738210044675 valid 0.5277135133007427
LOSS train 0.5513738210044675 valid 0.5278101589050761
LOSS train 0.5513738210044675 valid 0.5277835563188646
LOSS train 0.5513738210044675 valid 0.5276529395219052
LOSS train 0.5513738210044675 valid 0.5274750773447106
LOSS train 0.5513738210044675 valid 0.5275386850277107
LOSS train 0.5513738210044675 valid 0.5277823408444723
LOSS train 0.5513738210044675 valid 0.5278560755520882
LOSS train 0.5513738210044675 valid 0.5281249838716844
LOSS train 0.5513738210044675 valid 0.5281025010939927
LOSS train 0.5513738210044675 valid 0.5281012917673865
LOSS train 0.5513738210044675 valid 0.5283601146212892
LOSS train 0.5513738210044675 valid 0.5283938502443248
LOSS train 0.5513738210044675 valid 0.528403378214155
LOSS train 0.5513738210044675 valid 0.5281795363195918
LOSS train 0.5513738210044675 valid 0.5283307108165181
LOSS train 0.5513738210044675 valid 0.5283893167637708
LOSS train 0.5513738210044675 valid 0.5282961804440568
LOSS train 0.5513738210044675 valid 0.5283803464637862
LOSS train 0.5513738210044675 valid 0.5284582285920559
LOSS train 0.5513738210044675 valid 0.5285311690071127
LOSS train 0.5513738210044675 valid 0.5285034024975991
LOSS train 0.5513738210044675 valid 0.5285530532507793
LOSS train 0.5513738210044675 valid 0.5284942309598665
LOSS train 0.5513738210044675 valid 0.5284871835541981
LOSS train 0.5513738210044675 valid 0.528489816794421
LOSS train 0.5513738210044675 valid 0.5286382910736064
LOSS train 0.5513738210044675 valid 0.528580220445754
LOSS train 0.5513738210044675 valid 0.528513742904914
LOSS train 0.5513738210044675 valid 0.5288547503698559
LOSS train 0.5513738210044675 valid 0.5288627366535366
LOSS train 0.5513738210044675 valid 0.5288678310386875
LOSS train 0.5513738210044675 valid 0.5286750619866184
LOSS train 0.5513738210044675 valid 0.5285443481726524
LOSS train 0.5513738210044675 valid 0.5285604515550087
LOSS train 0.5513738210044675 valid 0.5286788221845772
LOSS train 0.5513738210044675 valid 0.528747732139597
LOSS train 0.5513738210044675 valid 0.5287312836802784
LOSS train 0.5513738210044675 valid 0.5287217606604099
LOSS train 0.5513738210044675 valid 0.5286149191322611
LOSS train 0.5513738210044675 valid 0.5287212438807629
LOSS train 0.5513738210044675 valid 0.5285470288962566
LOSS train 0.5513738210044675 valid 0.5284737100203832
LOSS train 0.5513738210044675 valid 0.5285300147242662
LOSS train 0.5513738210044675 valid 0.5285826695775523
LOSS train 0.5513738210044675 valid 0.5286732943737564
LOSS train 0.5513738210044675 valid 0.5286445551766799
LOSS train 0.5513738210044675 valid 0.5285725676271904
LOSS train 0.5513738210044675 valid 0.5285749370143527
LOSS train 0.5513738210044675 valid 0.5284280018501372
LOSS train 0.5513738210044675 valid 0.528436079199584
LOSS train 0.5513738210044675 valid 0.5285156510525466
LOSS train 0.5513738210044675 valid 0.5284978812821558
LOSS train 0.5513738210044675 valid 0.5285129839597746
LOSS train 0.5513738210044675 valid 0.5285490473939313
LOSS train 0.5513738210044675 valid 0.5286529194649463
LOSS train 0.5513738210044675 valid 0.5286166568141465
LOSS train 0.5513738210044675 valid 0.5286541734928409
LOSS train 0.5513738210044675 valid 0.5287360894409093
LOSS train 0.5513738210044675 valid 0.5289040732437669
LOSS train 0.5513738210044675 valid 0.528912227030273
LOSS train 0.5513738210044675 valid 0.5290033794572001
LOSS train 0.5513738210044675 valid 0.5289527426606843
LOSS train 0.5513738210044675 valid 0.5289390395747291
LOSS train 0.5513738210044675 valid 0.5288982131576117
LOSS train 0.5513738210044675 valid 0.5290228156003658
LOSS train 0.5513738210044675 valid 0.5290709356205505
LOSS train 0.5513738210044675 valid 0.5290558555500997
LOSS train 0.5513738210044675 valid 0.5291372976873232
LOSS train 0.5513738210044675 valid 0.5291272392778685
LOSS train 0.5513738210044675 valid 0.5291225680246435
LOSS train 0.5513738210044675 valid 0.5289967054972833
LOSS train 0.5513738210044675 valid 0.5289554697835547
LOSS train 0.5513738210044675 valid 0.5290080126295699
LOSS train 0.5513738210044675 valid 0.5290333517527176
LOSS train 0.5513738210044675 valid 0.5290114431944577
LOSS train 0.5513738210044675 valid 0.5289600982385523
LOSS train 0.5513738210044675 valid 0.52898203004853
LOSS train 0.5513738210044675 valid 0.5288609089950721
LOSS train 0.5513738210044675 valid 0.529015242558792
LOSS train 0.5513738210044675 valid 0.5289126878434961
LOSS train 0.5513738210044675 valid 0.5289298887115447
LOSS train 0.5513738210044675 valid 0.5290312615574383
LOSS train 0.5513738210044675 valid 0.5289784893697622
LOSS train 0.5513738210044675 valid 0.5289556655457349
LOSS train 0.5513738210044675 valid 0.529068205038063
LOSS train 0.5513738210044675 valid 0.5290252998951943
LOSS train 0.5513738210044675 valid 0.5290818097122223
LOSS train 0.5513738210044675 valid 0.5291962749958038
LOSS train 0.5513738210044675 valid 0.5292364066815471
LOSS train 0.5513738210044675 valid 0.5294553606756149
LOSS train 0.5513738210044675 valid 0.529424654400867
LOSS train 0.5513738210044675 valid 0.5296224592708227
LOSS train 0.5513738210044675 valid 0.5295559936878728
LOSS train 0.5513738210044675 valid 0.5296001529786736
LOSS train 0.5513738210044675 valid 0.5295619201567386
LOSS train 0.5513738210044675 valid 0.5296400136263796
LOSS train 0.5513738210044675 valid 0.5297029260042552
LOSS train 0.5513738210044675 valid 0.5297139935768568
LOSS train 0.5513738210044675 valid 0.5297035753041849
LOSS train 0.5513738210044675 valid 0.5296932743250868
LOSS train 0.5513738210044675 valid 0.5296371307209871
LOSS train 0.5513738210044675 valid 0.5296128909244682
LOSS train 0.5513738210044675 valid 0.5296668977107641
LOSS train 0.5513738210044675 valid 0.5297652830306748
LOSS train 0.5513738210044675 valid 0.5299274532982473
LOSS train 0.5513738210044675 valid 0.5299061839260272
LOSS train 0.5513738210044675 valid 0.5300899112534789
LOSS train 0.5513738210044675 valid 0.5300543270729207
LOSS train 0.5513738210044675 valid 0.5301640027123624
LOSS train 0.5513738210044675 valid 0.5301654393620351
LOSS train 0.5513738210044675 valid 0.5301232123986269
LOSS train 0.5513738210044675 valid 0.5301198922369602
LOSS train 0.5513738210044675 valid 0.5300263545729897
LOSS train 0.5513738210044675 valid 0.5299705208643622
LOSS train 0.5513738210044675 valid 0.5299777123902248
LOSS train 0.5513738210044675 valid 0.5299453550963094
LOSS train 0.5513738210044675 valid 0.5300029828129703
LOSS train 0.5513738210044675 valid 0.5299713888338634
LOSS train 0.5513738210044675 valid 0.529895034549075
LOSS train 0.5513738210044675 valid 0.5298774827879371
LOSS train 0.5513738210044675 valid 0.5298104810630475
LOSS train 0.5513738210044675 valid 0.5298719976989317
LOSS train 0.5513738210044675 valid 0.5298259530151099
LOSS train 0.5513738210044675 valid 0.5297826574398921
LOSS train 0.5513738210044675 valid 0.5297947681739356
LOSS train 0.5513738210044675 valid 0.5297993274612559
LOSS train 0.5513738210044675 valid 0.5297893339374898
LOSS train 0.5513738210044675 valid 0.5297267206783952
LOSS train 0.5513738210044675 valid 0.5295942154332125
LOSS train 0.5513738210044675 valid 0.5296188816428185
LOSS train 0.5513738210044675 valid 0.529566337325874
LOSS train 0.5513738210044675 valid 0.5296713623668061
LOSS train 0.5513738210044675 valid 0.5297733839285576
LOSS train 0.5513738210044675 valid 0.5297597071810348
LOSS train 0.5513738210044675 valid 0.5297695694347022
LOSS train 0.5513738210044675 valid 0.5296865222638085
LOSS train 0.5513738210044675 valid 0.5296965625174468
LOSS train 0.5513738210044675 valid 0.5297490512331327
LOSS train 0.5513738210044675 valid 0.5297073645647182
LOSS train 0.5513738210044675 valid 0.5296483407944244
LOSS train 0.5513738210044675 valid 0.5295635028050678
LOSS train 0.5513738210044675 valid 0.5295186547660514
LOSS train 0.5513738210044675 valid 0.5294520818796314
LOSS train 0.5513738210044675 valid 0.5294833996521882
LOSS train 0.5513738210044675 valid 0.5295131819061814
LOSS train 0.5513738210044675 valid 0.529484708878127
LOSS train 0.5513738210044675 valid 0.5295489163267574
LOSS train 0.5513738210044675 valid 0.529489692276524
LOSS train 0.5513738210044675 valid 0.5294207078659267
LOSS train 0.5513738210044675 valid 0.5294077175741012
LOSS train 0.5513738210044675 valid 0.5295436394671662
LOSS train 0.5513738210044675 valid 0.5296024753219762
LOSS train 0.5513738210044675 valid 0.5295596661075713
LOSS train 0.5513738210044675 valid 0.5295086990617499
LOSS train 0.5513738210044675 valid 0.5295245964256371
LOSS train 0.5513738210044675 valid 0.5295849002944598
LOSS train 0.5513738210044675 valid 0.5294561655170118
LOSS train 0.5513738210044675 valid 0.5294097658246756
LOSS train 0.5513738210044675 valid 0.5294070704332393
LOSS train 0.5513738210044675 valid 0.529393421381897
LOSS train 0.5513738210044675 valid 0.5293037136641818
LOSS train 0.5513738210044675 valid 0.5293550088449761
LOSS train 0.5513738210044675 valid 0.5293307161331177
LOSS train 0.5513738210044675 valid 0.5293937628985914
LOSS train 0.5513738210044675 valid 0.5294953664872989
LOSS train 0.5513738210044675 valid 0.5295282093490042
LOSS train 0.5513738210044675 valid 0.5295269123326681
LOSS train 0.5513738210044675 valid 0.5295217131123399
LOSS train 0.5513738210044675 valid 0.5294727591229349
LOSS train 0.5513738210044675 valid 0.5293938440371708
LOSS train 0.5513738210044675 valid 0.5293737782372369
LOSS train 0.5513738210044675 valid 0.5294417312402211
LOSS train 0.5513738210044675 valid 0.5294533163753908
LOSS train 0.5513738210044675 valid 0.529489735939673
LOSS train 0.5513738210044675 valid 0.5294966221916924
LOSS train 0.5513738210044675 valid 0.5295229430734758
LOSS train 0.5513738210044675 valid 0.529489649432247
LOSS train 0.5513738210044675 valid 0.5294823057511273
LOSS train 0.5513738210044675 valid 0.5293967865429317
LOSS train 0.5513738210044675 valid 0.5292805839351743
LOSS train 0.5513738210044675 valid 0.5292506450814339
LOSS train 0.5513738210044675 valid 0.5293134312297023
LOSS train 0.5513738210044675 valid 0.5293719692506652
LOSS train 0.5513738210044675 valid 0.5293345084424653
LOSS train 0.5513738210044675 valid 0.5293409427579611
LOSS train 0.5513738210044675 valid 0.5292838388818434
LOSS train 0.5513738210044675 valid 0.5293200873372207
LOSS train 0.5513738210044675 valid 0.5292589221681867
LOSS train 0.5513738210044675 valid 0.5292388599822324
LOSS train 0.5513738210044675 valid 0.5292824322188442
LOSS train 0.5513738210044675 valid 0.5293970450801146
LOSS train 0.5513738210044675 valid 0.5294822868654283
LOSS train 0.5513738210044675 valid 0.5294885232414998
LOSS train 0.5513738210044675 valid 0.529418207286449
LOSS train 0.5513738210044675 valid 0.5293927227749544
LOSS train 0.5513738210044675 valid 0.5292637556291825
LOSS train 0.5513738210044675 valid 0.5292911082921254
LOSS train 0.5513738210044675 valid 0.5292379453778266
LOSS train 0.5513738210044675 valid 0.5292562072957322
LOSS train 0.5513738210044675 valid 0.5293133174846185
LOSS train 0.5513738210044675 valid 0.5292880313455566
LOSS train 0.5513738210044675 valid 0.5292522342322947
LOSS train 0.5513738210044675 valid 0.5292734262061446
LOSS train 0.5513738210044675 valid 0.5292142033576965
LOSS train 0.5513738210044675 valid 0.5291917155159267
LOSS train 0.5513738210044675 valid 0.5291639655504538
LOSS train 0.5513738210044675 valid 0.5291600170820386
EPOCH 6:
  batch 1 loss: 0.5520951747894287
  batch 2 loss: 0.5322504639625549
  batch 3 loss: 0.5435904264450073
  batch 4 loss: 0.5529176890850067
  batch 5 loss: 0.5517744898796082
  batch 6 loss: 0.5494552751382192
  batch 7 loss: 0.5497414895466396
  batch 8 loss: 0.5513156056404114
  batch 9 loss: 0.5499027305179172
  batch 10 loss: 0.5526848077774048
  batch 11 loss: 0.5538724335757169
  batch 12 loss: 0.5527486304442087
  batch 13 loss: 0.5515010677851163
  batch 14 loss: 0.5519554189273289
  batch 15 loss: 0.5516974290211996
  batch 16 loss: 0.5492931008338928
  batch 17 loss: 0.5478638515752905
  batch 18 loss: 0.5474782056278653
  batch 19 loss: 0.5479107342268291
  batch 20 loss: 0.5472090542316437
  batch 21 loss: 0.5484921875454131
  batch 22 loss: 0.5480351393873041
  batch 23 loss: 0.5480247165845789
  batch 24 loss: 0.5468640824158987
  batch 25 loss: 0.5467875671386718
  batch 26 loss: 0.5459366073975196
  batch 27 loss: 0.5448339581489563
  batch 28 loss: 0.5433990976640156
  batch 29 loss: 0.5432242668908218
  batch 30 loss: 0.5420451502005259
  batch 31 loss: 0.5414411771682001
  batch 32 loss: 0.5416286028921604
  batch 33 loss: 0.5412461992466089
  batch 34 loss: 0.5411687966655282
  batch 35 loss: 0.5421335169247219
  batch 36 loss: 0.5421001977390714
  batch 37 loss: 0.5424676456966916
  batch 38 loss: 0.5422308899854359
  batch 39 loss: 0.5423088455811526
  batch 40 loss: 0.5415653496980667
  batch 41 loss: 0.5412694143085945
  batch 42 loss: 0.5415774342559633
  batch 43 loss: 0.5415024466292803
  batch 44 loss: 0.5413088757883419
  batch 45 loss: 0.5416682177119785
  batch 46 loss: 0.5413230217021444
  batch 47 loss: 0.5414465741908296
  batch 48 loss: 0.5409595879415671
  batch 49 loss: 0.540680010708011
  batch 50 loss: 0.5404957735538483
  batch 51 loss: 0.5401123493325477
  batch 52 loss: 0.5405510102327054
  batch 53 loss: 0.5409789793896225
  batch 54 loss: 0.5411743102250276
  batch 55 loss: 0.5404543313113126
  batch 56 loss: 0.5396309888788632
  batch 57 loss: 0.5394129732198882
  batch 58 loss: 0.5398515771175253
  batch 59 loss: 0.539294327719737
  batch 60 loss: 0.5389907081921895
  batch 61 loss: 0.5389337910980475
  batch 62 loss: 0.5396390403470686
  batch 63 loss: 0.5395278202162849
  batch 64 loss: 0.5399365955963731
  batch 65 loss: 0.539503026008606
  batch 66 loss: 0.5395784585764913
  batch 67 loss: 0.5398026197703917
  batch 68 loss: 0.5401682213825338
  batch 69 loss: 0.5402260042619014
  batch 70 loss: 0.5400562950542995
  batch 71 loss: 0.5402532295441963
  batch 72 loss: 0.5398508956034979
  batch 73 loss: 0.5398101235089237
  batch 74 loss: 0.5394991297979612
  batch 75 loss: 0.5392495965957642
  batch 76 loss: 0.5393702230955425
  batch 77 loss: 0.5396634541548692
  batch 78 loss: 0.5391440112621356
  batch 79 loss: 0.5394792145566095
  batch 80 loss: 0.5391361143440008
  batch 81 loss: 0.5393662919968735
  batch 82 loss: 0.5397262126207352
  batch 83 loss: 0.5397929315825543
  batch 84 loss: 0.5401094587785857
  batch 85 loss: 0.5400052740293391
  batch 86 loss: 0.5405131824487863
  batch 87 loss: 0.5403497434895614
  batch 88 loss: 0.5399051698094065
  batch 89 loss: 0.539802869719066
  batch 90 loss: 0.5398876392179065
  batch 91 loss: 0.5402961304554572
  batch 92 loss: 0.5401071909329166
  batch 93 loss: 0.5399415092442625
  batch 94 loss: 0.5402115897295323
  batch 95 loss: 0.5405698829575589
  batch 96 loss: 0.5408275285735726
  batch 97 loss: 0.5412142501049435
  batch 98 loss: 0.5415299112091259
  batch 99 loss: 0.5412938772427915
  batch 100 loss: 0.541357818543911
  batch 101 loss: 0.5415761031136654
  batch 102 loss: 0.541655072686719
  batch 103 loss: 0.5417014172354948
  batch 104 loss: 0.5417123617461095
  batch 105 loss: 0.5415134268147604
  batch 106 loss: 0.5419284338658711
  batch 107 loss: 0.5419406988353372
  batch 108 loss: 0.5417362625400225
  batch 109 loss: 0.5419483280509984
  batch 110 loss: 0.5420981707898054
  batch 111 loss: 0.5421739255522823
  batch 112 loss: 0.5419594600264516
  batch 113 loss: 0.5420266782815477
  batch 114 loss: 0.54232571130259
  batch 115 loss: 0.5424629996652188
  batch 116 loss: 0.5424302068763766
  batch 117 loss: 0.5424870336667086
  batch 118 loss: 0.5426137343806735
  batch 119 loss: 0.5425631010732731
  batch 120 loss: 0.5426212516923745
  batch 121 loss: 0.542406743469317
  batch 122 loss: 0.5423023341620554
  batch 123 loss: 0.5420865399566123
  batch 124 loss: 0.5422017942032507
  batch 125 loss: 0.5421318204402924
  batch 126 loss: 0.5421038064218703
  batch 127 loss: 0.5423627080410485
  batch 128 loss: 0.5420646315906197
  batch 129 loss: 0.5419373412926992
  batch 130 loss: 0.5418240806231132
  batch 131 loss: 0.5420725930283088
  batch 132 loss: 0.5421521151156137
  batch 133 loss: 0.542331168750175
  batch 134 loss: 0.5423032981691076
  batch 135 loss: 0.5422973511395631
  batch 136 loss: 0.5421505638343447
  batch 137 loss: 0.5422551464425386
  batch 138 loss: 0.5425570717324382
  batch 139 loss: 0.5424544200193968
  batch 140 loss: 0.5423166421907288
  batch 141 loss: 0.5423715260434658
  batch 142 loss: 0.5423533515611165
  batch 143 loss: 0.5421836324088223
  batch 144 loss: 0.5420927800652053
  batch 145 loss: 0.5421450514217903
  batch 146 loss: 0.5420483258897311
  batch 147 loss: 0.5419094653762117
  batch 148 loss: 0.5419205541949015
  batch 149 loss: 0.5419642311214601
  batch 150 loss: 0.54179525633653
  batch 151 loss: 0.5415370276826896
  batch 152 loss: 0.5417569705138081
  batch 153 loss: 0.5417629871882644
  batch 154 loss: 0.5418762589816923
  batch 155 loss: 0.5419226248418131
  batch 156 loss: 0.5417777603635421
  batch 157 loss: 0.5419197877880874
  batch 158 loss: 0.5418984077022045
  batch 159 loss: 0.5418722710144595
  batch 160 loss: 0.5420096008107066
  batch 161 loss: 0.5420637517612173
  batch 162 loss: 0.5420798753146772
  batch 163 loss: 0.5420845233223921
  batch 164 loss: 0.5421086228111895
  batch 165 loss: 0.5419605271382766
  batch 166 loss: 0.5419822530933174
  batch 167 loss: 0.5417775923977355
  batch 168 loss: 0.5419361089311895
  batch 169 loss: 0.541877012457368
  batch 170 loss: 0.5418492844876122
  batch 171 loss: 0.5417252909718898
  batch 172 loss: 0.541899460519469
  batch 173 loss: 0.5418597361600468
  batch 174 loss: 0.5419929974723137
  batch 175 loss: 0.5418860164710454
  batch 176 loss: 0.541982785036618
  batch 177 loss: 0.5418461889533673
  batch 178 loss: 0.5419610261582257
  batch 179 loss: 0.5420015865531047
  batch 180 loss: 0.5419771533873347
  batch 181 loss: 0.5420224661655848
  batch 182 loss: 0.5420370758562297
  batch 183 loss: 0.5420300675545885
  batch 184 loss: 0.5420035034742045
  batch 185 loss: 0.5420689523220062
  batch 186 loss: 0.5419615678569322
  batch 187 loss: 0.5418614832793965
  batch 188 loss: 0.5418108798404957
  batch 189 loss: 0.5415967739132977
  batch 190 loss: 0.5414353143227728
  batch 191 loss: 0.5415029979813162
  batch 192 loss: 0.5413705413229764
  batch 193 loss: 0.5412367395477592
  batch 194 loss: 0.541160149826217
  batch 195 loss: 0.5412063447328714
  batch 196 loss: 0.5410709726263065
  batch 197 loss: 0.5411687972884492
  batch 198 loss: 0.5411621508273211
  batch 199 loss: 0.5411523468230837
  batch 200 loss: 0.541094145923853
  batch 201 loss: 0.5410105798078414
  batch 202 loss: 0.5411190350752065
  batch 203 loss: 0.5413014115077521
  batch 204 loss: 0.5412078664875498
  batch 205 loss: 0.5411403645829457
  batch 206 loss: 0.5411887598558537
  batch 207 loss: 0.5412241895705605
  batch 208 loss: 0.5410618218951501
  batch 209 loss: 0.5409716115328684
  batch 210 loss: 0.5409456064303716
  batch 211 loss: 0.5409752496328399
  batch 212 loss: 0.5410775962584423
  batch 213 loss: 0.5410310227266499
  batch 214 loss: 0.5410021166099566
  batch 215 loss: 0.5407440256240756
  batch 216 loss: 0.5406255461275578
  batch 217 loss: 0.5406054572850328
  batch 218 loss: 0.5404818655427442
  batch 219 loss: 0.5403609761636551
  batch 220 loss: 0.5404491507194259
  batch 221 loss: 0.5405121204270497
  batch 222 loss: 0.540539127615121
  batch 223 loss: 0.5405882993888428
  batch 224 loss: 0.5405666108376214
  batch 225 loss: 0.540571880473031
  batch 226 loss: 0.5405850667605357
  batch 227 loss: 0.5403981333524646
  batch 228 loss: 0.5404509618355516
  batch 229 loss: 0.5403655276808677
  batch 230 loss: 0.5404218654269758
  batch 231 loss: 0.5403744935731352
  batch 232 loss: 0.5402003867102081
  batch 233 loss: 0.5401814417521841
  batch 234 loss: 0.5401054257765795
  batch 235 loss: 0.5401243051315876
  batch 236 loss: 0.5400713617771359
  batch 237 loss: 0.5400539871761064
  batch 238 loss: 0.5400621153476859
  batch 239 loss: 0.5398635899172667
  batch 240 loss: 0.5399317900339763
  batch 241 loss: 0.5398702581888413
  batch 242 loss: 0.5397006636562426
  batch 243 loss: 0.5397489996849264
  batch 244 loss: 0.5397644642679418
  batch 245 loss: 0.5397767014649449
  batch 246 loss: 0.5397533601134773
  batch 247 loss: 0.5397342893517452
  batch 248 loss: 0.5397832844286196
  batch 249 loss: 0.539744140512972
  batch 250 loss: 0.539730300784111
  batch 251 loss: 0.5397006117727652
  batch 252 loss: 0.5397149330330273
  batch 253 loss: 0.5396708088665612
  batch 254 loss: 0.5396604377219058
  batch 255 loss: 0.5398059383326885
  batch 256 loss: 0.5396794598782435
  batch 257 loss: 0.5397206801152878
  batch 258 loss: 0.5396777364865754
  batch 259 loss: 0.539564208289371
  batch 260 loss: 0.5394794125969593
  batch 261 loss: 0.5396045938533841
  batch 262 loss: 0.5395731515329303
  batch 263 loss: 0.5395264676541883
  batch 264 loss: 0.5395269535030379
  batch 265 loss: 0.5394670975658129
  batch 266 loss: 0.5395029302602424
  batch 267 loss: 0.5395052445292027
  batch 268 loss: 0.5393977717899564
  batch 269 loss: 0.5394226703723567
  batch 270 loss: 0.5393995835825249
  batch 271 loss: 0.5393376454875918
  batch 272 loss: 0.539335253812811
  batch 273 loss: 0.5392787632269737
  batch 274 loss: 0.5391439526838108
  batch 275 loss: 0.5392972054264762
  batch 276 loss: 0.5393547555026801
  batch 277 loss: 0.5393489484107021
  batch 278 loss: 0.5392788849074206
  batch 279 loss: 0.5393487128519243
  batch 280 loss: 0.5391792552811759
  batch 281 loss: 0.539132702817272
  batch 282 loss: 0.5389492909113566
  batch 283 loss: 0.5388953736308607
  batch 284 loss: 0.5389111638069153
  batch 285 loss: 0.5388245252140781
  batch 286 loss: 0.5387371843094593
  batch 287 loss: 0.538667156305878
  batch 288 loss: 0.5384950413265162
  batch 289 loss: 0.5386110068811265
  batch 290 loss: 0.5384701345501275
  batch 291 loss: 0.5384136144443066
  batch 292 loss: 0.5385106600923081
  batch 293 loss: 0.5385703404812275
  batch 294 loss: 0.5384555374886714
  batch 295 loss: 0.5385911229303327
  batch 296 loss: 0.5386097180480892
  batch 297 loss: 0.5386978683848975
  batch 298 loss: 0.5387049360363275
  batch 299 loss: 0.5386866968012972
  batch 300 loss: 0.538760825296243
  batch 301 loss: 0.5388147877498323
  batch 302 loss: 0.5387640657606504
  batch 303 loss: 0.5387304689821237
  batch 304 loss: 0.5386934169617138
  batch 305 loss: 0.5384843875150211
  batch 306 loss: 0.5385555704824285
  batch 307 loss: 0.5384582799498344
  batch 308 loss: 0.5383714242027952
  batch 309 loss: 0.5383391050459112
  batch 310 loss: 0.5383254353077181
  batch 311 loss: 0.5382790030773813
  batch 312 loss: 0.538326169244754
  batch 313 loss: 0.5383732612140644
  batch 314 loss: 0.5384054142198745
  batch 315 loss: 0.5383695415088109
  batch 316 loss: 0.5383117532805551
  batch 317 loss: 0.5383103503037703
  batch 318 loss: 0.5381989715234289
  batch 319 loss: 0.5380368866143181
  batch 320 loss: 0.5379733230918646
  batch 321 loss: 0.5379328746290594
  batch 322 loss: 0.5378708454392711
  batch 323 loss: 0.5378217641783204
  batch 324 loss: 0.5376936551413418
  batch 325 loss: 0.5376865908732781
  batch 326 loss: 0.5375975623635426
  batch 327 loss: 0.5375855268870654
  batch 328 loss: 0.5374795877170272
  batch 329 loss: 0.5374859255316772
  batch 330 loss: 0.5374068736126929
  batch 331 loss: 0.5373279741343414
  batch 332 loss: 0.5373461654925921
  batch 333 loss: 0.5372543214140711
  batch 334 loss: 0.5371214278086931
  batch 335 loss: 0.5371045302988878
  batch 336 loss: 0.5370228329584712
  batch 337 loss: 0.5369504446091921
  batch 338 loss: 0.5369338763536081
  batch 339 loss: 0.5370040634388769
  batch 340 loss: 0.5370455324649811
  batch 341 loss: 0.5370807694899372
  batch 342 loss: 0.5369781365520075
  batch 343 loss: 0.5369467790898359
  batch 344 loss: 0.5369414214131444
  batch 345 loss: 0.5370092079259348
  batch 346 loss: 0.5369650461425671
  batch 347 loss: 0.5369923405070126
  batch 348 loss: 0.5370115755960859
  batch 349 loss: 0.5369388076842344
  batch 350 loss: 0.5370128905773163
  batch 351 loss: 0.537007556172178
  batch 352 loss: 0.5370076689869165
  batch 353 loss: 0.5368440705048126
  batch 354 loss: 0.5368746621797313
  batch 355 loss: 0.5370123868257227
  batch 356 loss: 0.5370033617769734
  batch 357 loss: 0.5370274925766205
  batch 358 loss: 0.536999130715205
  batch 359 loss: 0.5370058604933757
  batch 360 loss: 0.5370290729734633
  batch 361 loss: 0.5370310832258737
  batch 362 loss: 0.5369128777506602
  batch 363 loss: 0.5368559537840284
  batch 364 loss: 0.5367275124395287
  batch 365 loss: 0.5367266240185254
  batch 366 loss: 0.5366294980049133
  batch 367 loss: 0.5366202404453579
  batch 368 loss: 0.5365444748945858
  batch 369 loss: 0.5365962785110887
  batch 370 loss: 0.5366937089610744
  batch 371 loss: 0.5368126248413662
  batch 372 loss: 0.5367127306038334
  batch 373 loss: 0.536661044841797
  batch 374 loss: 0.5365959106282117
  batch 375 loss: 0.5365934019088745
  batch 376 loss: 0.5366225876706712
  batch 377 loss: 0.53654643521701
  batch 378 loss: 0.5365080836588744
  batch 379 loss: 0.5364920086470631
  batch 380 loss: 0.5365752599741284
  batch 381 loss: 0.536468250544991
  batch 382 loss: 0.5363026273812299
  batch 383 loss: 0.5362926732466675
  batch 384 loss: 0.5363032061917087
  batch 385 loss: 0.5363440700939723
  batch 386 loss: 0.536263154115084
  batch 387 loss: 0.536218186835602
  batch 388 loss: 0.5362148134364295
  batch 389 loss: 0.5362173565555661
  batch 390 loss: 0.5362588295569787
  batch 391 loss: 0.536213954696265
  batch 392 loss: 0.5361975229212216
  batch 393 loss: 0.5362612599028279
  batch 394 loss: 0.5362708193396554
  batch 395 loss: 0.536256190493137
  batch 396 loss: 0.5363175503232263
  batch 397 loss: 0.5362252002999525
  batch 398 loss: 0.5361744047109805
  batch 399 loss: 0.5361717905018264
  batch 400 loss: 0.53608940705657
  batch 401 loss: 0.536022924128316
  batch 402 loss: 0.5360575300544056
  batch 403 loss: 0.5360123208971237
  batch 404 loss: 0.535939836708626
  batch 405 loss: 0.5359276324142644
  batch 406 loss: 0.5359525683478181
  batch 407 loss: 0.5359303497272276
  batch 408 loss: 0.5359694499011133
  batch 409 loss: 0.5359505208022437
  batch 410 loss: 0.5359408486180189
  batch 411 loss: 0.5359047912333134
  batch 412 loss: 0.5358427117750483
  batch 413 loss: 0.5357890735238285
  batch 414 loss: 0.5357332783908659
  batch 415 loss: 0.5357088054519101
  batch 416 loss: 0.5356477811359442
  batch 417 loss: 0.535640809461653
  batch 418 loss: 0.5356028430769888
  batch 419 loss: 0.5356126739187855
  batch 420 loss: 0.5356177853686469
  batch 421 loss: 0.5356174570081353
  batch 422 loss: 0.5357190979318032
  batch 423 loss: 0.535753657490931
  batch 424 loss: 0.5357228435997693
  batch 425 loss: 0.5357352310068467
  batch 426 loss: 0.5357282129531735
  batch 427 loss: 0.5357070732730892
  batch 428 loss: 0.5356097128068176
  batch 429 loss: 0.5355927645465433
  batch 430 loss: 0.5356076807476754
  batch 431 loss: 0.5356902675119741
  batch 432 loss: 0.535725218002443
  batch 433 loss: 0.535679879282143
  batch 434 loss: 0.535712933485409
  batch 435 loss: 0.5356480793021191
  batch 436 loss: 0.535604993957992
  batch 437 loss: 0.535627842222253
  batch 438 loss: 0.5356714352625146
  batch 439 loss: 0.5356355886524522
  batch 440 loss: 0.5356393268162554
  batch 441 loss: 0.535592848076031
  batch 442 loss: 0.5355526978883268
  batch 443 loss: 0.5355579736001336
  batch 444 loss: 0.5354785913819665
  batch 445 loss: 0.535434103547857
  batch 446 loss: 0.5354261490528893
  batch 447 loss: 0.5353275728172371
  batch 448 loss: 0.5354100469765919
  batch 449 loss: 0.5354880612252284
  batch 450 loss: 0.5355587413575914
  batch 451 loss: 0.5355491658007755
  batch 452 loss: 0.5355300187273363
  batch 453 loss: 0.5355569572901357
  batch 454 loss: 0.5355583365005544
  batch 455 loss: 0.5355552789929149
  batch 456 loss: 0.5355112001038435
  batch 457 loss: 0.535543691538095
  batch 458 loss: 0.5354977941148666
  batch 459 loss: 0.5355273781259076
  batch 460 loss: 0.5356019976346389
  batch 461 loss: 0.5355812224545344
  batch 462 loss: 0.5355220581545974
  batch 463 loss: 0.5355067107641414
  batch 464 loss: 0.5355631165720266
  batch 465 loss: 0.5354171595906698
  batch 466 loss: 0.5353273602898029
  batch 467 loss: 0.5353553700370502
  batch 468 loss: 0.5352967435605506
  batch 469 loss: 0.53529005143434
  batch 470 loss: 0.5352132234167546
  batch 471 loss: 0.5352102969862094
  batch 472 loss: 0.5351211004338022
LOSS train 0.5351211004338022 valid 0.4136884808540344
LOSS train 0.5351211004338022 valid 0.3883419930934906
LOSS train 0.5351211004338022 valid 0.4054187337557475
LOSS train 0.5351211004338022 valid 0.40257006138563156
LOSS train 0.5351211004338022 valid 0.4028353154659271
LOSS train 0.5351211004338022 valid 0.40527699887752533
LOSS train 0.5351211004338022 valid 0.40405411805425373
LOSS train 0.5351211004338022 valid 0.4048260487616062
LOSS train 0.5351211004338022 valid 0.401405049694909
LOSS train 0.5351211004338022 valid 0.40388067364692687
LOSS train 0.5351211004338022 valid 0.40687438574704254
LOSS train 0.5351211004338022 valid 0.40698213626941043
LOSS train 0.5351211004338022 valid 0.4116444748181563
LOSS train 0.5351211004338022 valid 0.4122540290866579
LOSS train 0.5351211004338022 valid 0.41082074840863547
LOSS train 0.5351211004338022 valid 0.4118692446500063
LOSS train 0.5351211004338022 valid 0.41475118784343495
LOSS train 0.5351211004338022 valid 0.41635694603125256
LOSS train 0.5351211004338022 valid 0.4164719958054392
LOSS train 0.5351211004338022 valid 0.4181664794683456
LOSS train 0.5351211004338022 valid 0.4179233355181558
LOSS train 0.5351211004338022 valid 0.4158361391587691
LOSS train 0.5351211004338022 valid 0.4169344487397567
LOSS train 0.5351211004338022 valid 0.4161232089002927
LOSS train 0.5351211004338022 valid 0.41619670629501343
LOSS train 0.5351211004338022 valid 0.4161391808436467
LOSS train 0.5351211004338022 valid 0.41552438780113504
LOSS train 0.5351211004338022 valid 0.41568368460450855
LOSS train 0.5351211004338022 valid 0.4155433239607975
LOSS train 0.5351211004338022 valid 0.4161231418450673
LOSS train 0.5351211004338022 valid 0.4177077239559543
LOSS train 0.5351211004338022 valid 0.41713920794427395
LOSS train 0.5351211004338022 valid 0.4177180691198869
LOSS train 0.5351211004338022 valid 0.4171515317524181
LOSS train 0.5351211004338022 valid 0.4177195199898311
LOSS train 0.5351211004338022 valid 0.41750920977857375
LOSS train 0.5351211004338022 valid 0.4180924956862991
LOSS train 0.5351211004338022 valid 0.4195037852776678
LOSS train 0.5351211004338022 valid 0.4193409169331575
LOSS train 0.5351211004338022 valid 0.42100833132863047
LOSS train 0.5351211004338022 valid 0.42102818445461554
LOSS train 0.5351211004338022 valid 0.4219842233828136
LOSS train 0.5351211004338022 valid 0.4218095541000366
LOSS train 0.5351211004338022 valid 0.42192481187256897
LOSS train 0.5351211004338022 valid 0.4221756769551171
LOSS train 0.5351211004338022 valid 0.42245916892652924
LOSS train 0.5351211004338022 valid 0.42235573492151623
LOSS train 0.5351211004338022 valid 0.42242841981351376
LOSS train 0.5351211004338022 valid 0.422930690098782
LOSS train 0.5351211004338022 valid 0.4221344047784805
LOSS train 0.5351211004338022 valid 0.42262982211860955
LOSS train 0.5351211004338022 valid 0.42238766929278004
LOSS train 0.5351211004338022 valid 0.4221706918950351
LOSS train 0.5351211004338022 valid 0.42200015319718254
LOSS train 0.5351211004338022 valid 0.42156276215206495
LOSS train 0.5351211004338022 valid 0.42160487334643093
LOSS train 0.5351211004338022 valid 0.42128021413819833
LOSS train 0.5351211004338022 valid 0.421056799333671
LOSS train 0.5351211004338022 valid 0.4216317367755761
LOSS train 0.5351211004338022 valid 0.4210443327824275
LOSS train 0.5351211004338022 valid 0.4199322569565695
LOSS train 0.5351211004338022 valid 0.42103386886658206
LOSS train 0.5351211004338022 valid 0.42172629350707647
LOSS train 0.5351211004338022 valid 0.4223807887174189
LOSS train 0.5351211004338022 valid 0.42259606352219214
LOSS train 0.5351211004338022 valid 0.42254311072103906
LOSS train 0.5351211004338022 valid 0.42214723309474206
LOSS train 0.5351211004338022 valid 0.4215198895510505
LOSS train 0.5351211004338022 valid 0.4212126040804213
LOSS train 0.5351211004338022 valid 0.4208264410495758
LOSS train 0.5351211004338022 valid 0.42038138735462244
LOSS train 0.5351211004338022 valid 0.4203963151408566
LOSS train 0.5351211004338022 valid 0.4208882802153287
LOSS train 0.5351211004338022 valid 0.42075939879224106
LOSS train 0.5351211004338022 valid 0.42025668183962506
LOSS train 0.5351211004338022 valid 0.420494886997499
LOSS train 0.5351211004338022 valid 0.42008744547893473
LOSS train 0.5351211004338022 valid 0.4200069518425526
LOSS train 0.5351211004338022 valid 0.42007832097101816
LOSS train 0.5351211004338022 valid 0.419886115193367
LOSS train 0.5351211004338022 valid 0.4195414295902959
LOSS train 0.5351211004338022 valid 0.4196554727670623
LOSS train 0.5351211004338022 valid 0.41943455388747064
LOSS train 0.5351211004338022 valid 0.4196046299877621
LOSS train 0.5351211004338022 valid 0.4198159238871406
LOSS train 0.5351211004338022 valid 0.41944137735422266
LOSS train 0.5351211004338022 valid 0.4195451698769098
LOSS train 0.5351211004338022 valid 0.41893933882767503
LOSS train 0.5351211004338022 valid 0.41899051123790526
LOSS train 0.5351211004338022 valid 0.4187001046207216
LOSS train 0.5351211004338022 valid 0.4185014619277074
LOSS train 0.5351211004338022 valid 0.41835473704597226
LOSS train 0.5351211004338022 valid 0.4180052078539325
LOSS train 0.5351211004338022 valid 0.41763605145697896
LOSS train 0.5351211004338022 valid 0.41743691908685787
LOSS train 0.5351211004338022 valid 0.4175084236388405
LOSS train 0.5351211004338022 valid 0.41781352660090654
LOSS train 0.5351211004338022 valid 0.4177517483429033
LOSS train 0.5351211004338022 valid 0.41790662510226473
LOSS train 0.5351211004338022 valid 0.41806176900863645
LOSS train 0.5351211004338022 valid 0.418038273801898
LOSS train 0.5351211004338022 valid 0.41823213766602907
LOSS train 0.5351211004338022 valid 0.41852415707504864
LOSS train 0.5351211004338022 valid 0.4184076851950242
LOSS train 0.5351211004338022 valid 0.4181934864748092
LOSS train 0.5351211004338022 valid 0.4182416029133887
LOSS train 0.5351211004338022 valid 0.41799039539889754
LOSS train 0.5351211004338022 valid 0.4182251575920317
LOSS train 0.5351211004338022 valid 0.41822990419667794
LOSS train 0.5351211004338022 valid 0.4184421571818265
LOSS train 0.5351211004338022 valid 0.4183544068186133
LOSS train 0.5351211004338022 valid 0.4183972680142948
LOSS train 0.5351211004338022 valid 0.41837179449807227
LOSS train 0.5351211004338022 valid 0.41822276303642675
LOSS train 0.5351211004338022 valid 0.4182712218035822
LOSS train 0.5351211004338022 valid 0.41814294662968865
LOSS train 0.5351211004338022 valid 0.4182464495683328
LOSS train 0.5351211004338022 valid 0.41800414303601796
LOSS train 0.5351211004338022 valid 0.4179118345765507
LOSS train 0.5351211004338022 valid 0.41780931676427524
LOSS train 0.5351211004338022 valid 0.4177189762434684
LOSS train 0.5351211004338022 valid 0.4177536256000644
LOSS train 0.5351211004338022 valid 0.41777969375858465
LOSS train 0.5351211004338022 valid 0.41802024576933156
LOSS train 0.5351211004338022 valid 0.41786365580558776
LOSS train 0.5351211004338022 valid 0.41763687252052245
LOSS train 0.5351211004338022 valid 0.4181768373241575
LOSS train 0.5351211004338022 valid 0.4183608505409211
LOSS train 0.5351211004338022 valid 0.4185580738293108
LOSS train 0.5351211004338022 valid 0.41842339291022373
LOSS train 0.5351211004338022 valid 0.4183650419457268
LOSS train 0.5351211004338022 valid 0.4183724122968587
LOSS train 0.5351211004338022 valid 0.41814368896018295
LOSS train 0.5351211004338022 valid 0.4184004751159184
LOSS train 0.5351211004338022 valid 0.41865117461593065
LOSS train 0.5351211004338022 valid 0.4185609874479911
LOSS train 0.5351211004338022 valid 0.4183785227963524
LOSS train 0.5351211004338022 valid 0.41825045969175256
LOSS train 0.5351211004338022 valid 0.41796557165735915
LOSS train 0.5351211004338022 valid 0.418153116106987
LOSS train 0.5351211004338022 valid 0.4182431399822235
LOSS train 0.5351211004338022 valid 0.4186856064578177
LOSS train 0.5351211004338022 valid 0.418685519403511
LOSS train 0.5351211004338022 valid 0.41899690301054054
LOSS train 0.5351211004338022 valid 0.41904530052481026
LOSS train 0.5351211004338022 valid 0.419276115624872
LOSS train 0.5351211004338022 valid 0.4189532575558643
LOSS train 0.5351211004338022 valid 0.41915410213373805
LOSS train 0.5351211004338022 valid 0.41933117536890424
LOSS train 0.5351211004338022 valid 0.4193453586101532
LOSS train 0.5351211004338022 valid 0.41942226018337225
LOSS train 0.5351211004338022 valid 0.4192422855841486
LOSS train 0.5351211004338022 valid 0.41942492107939877
LOSS train 0.5351211004338022 valid 0.41947450459777536
LOSS train 0.5351211004338022 valid 0.41943060794184284
LOSS train 0.5351211004338022 valid 0.4196502384849084
LOSS train 0.5351211004338022 valid 0.41969167787557954
LOSS train 0.5351211004338022 valid 0.4196570517518852
LOSS train 0.5351211004338022 valid 0.41933209322533516
LOSS train 0.5351211004338022 valid 0.419346528314054
LOSS train 0.5351211004338022 valid 0.4192469675348412
LOSS train 0.5351211004338022 valid 0.4189877637006618
LOSS train 0.5351211004338022 valid 0.4190107721126884
LOSS train 0.5351211004338022 valid 0.4189578183903927
LOSS train 0.5351211004338022 valid 0.4188322061842138
LOSS train 0.5351211004338022 valid 0.41871677267264173
LOSS train 0.5351211004338022 valid 0.4187493959586777
LOSS train 0.5351211004338022 valid 0.4189905866625763
LOSS train 0.5351211004338022 valid 0.4190368856904069
LOSS train 0.5351211004338022 valid 0.4193169390454012
LOSS train 0.5351211004338022 valid 0.41930093211040165
LOSS train 0.5351211004338022 valid 0.41932817652475
LOSS train 0.5351211004338022 valid 0.4195876600425367
LOSS train 0.5351211004338022 valid 0.4195521741077818
LOSS train 0.5351211004338022 valid 0.41952256832803997
LOSS train 0.5351211004338022 valid 0.4192922225391323
LOSS train 0.5351211004338022 valid 0.4194945581888748
LOSS train 0.5351211004338022 valid 0.4196133950118269
LOSS train 0.5351211004338022 valid 0.4195070717920804
LOSS train 0.5351211004338022 valid 0.41964118050204385
LOSS train 0.5351211004338022 valid 0.41969417900011685
LOSS train 0.5351211004338022 valid 0.41976656592809236
LOSS train 0.5351211004338022 valid 0.4197185151889676
LOSS train 0.5351211004338022 valid 0.41978812752210576
LOSS train 0.5351211004338022 valid 0.41975298346699896
LOSS train 0.5351211004338022 valid 0.41973038610591684
LOSS train 0.5351211004338022 valid 0.4197454949751257
LOSS train 0.5351211004338022 valid 0.4198192079016503
LOSS train 0.5351211004338022 valid 0.4198122368287788
LOSS train 0.5351211004338022 valid 0.4197489271038457
LOSS train 0.5351211004338022 valid 0.42008445384614757
LOSS train 0.5351211004338022 valid 0.4201196067345639
LOSS train 0.5351211004338022 valid 0.42008962424307905
LOSS train 0.5351211004338022 valid 0.4199110292589542
LOSS train 0.5351211004338022 valid 0.4197943394000714
LOSS train 0.5351211004338022 valid 0.4198119333203958
LOSS train 0.5351211004338022 valid 0.41994753192524015
LOSS train 0.5351211004338022 valid 0.42000529079726245
LOSS train 0.5351211004338022 valid 0.4199841067419579
LOSS train 0.5351211004338022 valid 0.41998860105872154
LOSS train 0.5351211004338022 valid 0.41986058585679353
LOSS train 0.5351211004338022 valid 0.41995527676426536
LOSS train 0.5351211004338022 valid 0.4197668381806078
LOSS train 0.5351211004338022 valid 0.41964610666036606
LOSS train 0.5351211004338022 valid 0.41969375319597196
LOSS train 0.5351211004338022 valid 0.4196455102522396
LOSS train 0.5351211004338022 valid 0.4197653527709021
LOSS train 0.5351211004338022 valid 0.4197405841774665
LOSS train 0.5351211004338022 valid 0.4196691508783678
LOSS train 0.5351211004338022 valid 0.4196582855213256
LOSS train 0.5351211004338022 valid 0.4195570534721935
LOSS train 0.5351211004338022 valid 0.4195465479256972
LOSS train 0.5351211004338022 valid 0.4196596878794997
LOSS train 0.5351211004338022 valid 0.41962722584465956
LOSS train 0.5351211004338022 valid 0.41968304403992585
LOSS train 0.5351211004338022 valid 0.4197014785475201
LOSS train 0.5351211004338022 valid 0.4197970415864672
LOSS train 0.5351211004338022 valid 0.4198157438717851
LOSS train 0.5351211004338022 valid 0.4198624614166887
LOSS train 0.5351211004338022 valid 0.4199713818051598
LOSS train 0.5351211004338022 valid 0.42013719691410323
LOSS train 0.5351211004338022 valid 0.4201398062276411
LOSS train 0.5351211004338022 valid 0.42021484091677475
LOSS train 0.5351211004338022 valid 0.42019690320427927
LOSS train 0.5351211004338022 valid 0.4201759217845069
LOSS train 0.5351211004338022 valid 0.4201071946758085
LOSS train 0.5351211004338022 valid 0.42023844196407806
LOSS train 0.5351211004338022 valid 0.4203025001967162
LOSS train 0.5351211004338022 valid 0.420338512377968
LOSS train 0.5351211004338022 valid 0.42039716813875283
LOSS train 0.5351211004338022 valid 0.42038032077091597
LOSS train 0.5351211004338022 valid 0.42041021688231106
LOSS train 0.5351211004338022 valid 0.4203112058885108
LOSS train 0.5351211004338022 valid 0.4202958550463375
LOSS train 0.5351211004338022 valid 0.42037884288645805
LOSS train 0.5351211004338022 valid 0.42040969683962354
LOSS train 0.5351211004338022 valid 0.42036229447473455
LOSS train 0.5351211004338022 valid 0.42031345046868845
LOSS train 0.5351211004338022 valid 0.42029596846472767
LOSS train 0.5351211004338022 valid 0.42016788199543953
LOSS train 0.5351211004338022 valid 0.42030000266197803
LOSS train 0.5351211004338022 valid 0.42020845770343274
LOSS train 0.5351211004338022 valid 0.4202287073243302
LOSS train 0.5351211004338022 valid 0.4203231585074644
LOSS train 0.5351211004338022 valid 0.4203174902468311
LOSS train 0.5351211004338022 valid 0.4202647664682652
LOSS train 0.5351211004338022 valid 0.4203486505307649
LOSS train 0.5351211004338022 valid 0.4203082524961041
LOSS train 0.5351211004338022 valid 0.42037124578732565
LOSS train 0.5351211004338022 valid 0.4205204097032547
LOSS train 0.5351211004338022 valid 0.42058770542600715
LOSS train 0.5351211004338022 valid 0.4208134225909672
LOSS train 0.5351211004338022 valid 0.4207635361686526
LOSS train 0.5351211004338022 valid 0.4209202957434917
LOSS train 0.5351211004338022 valid 0.42083098374161065
LOSS train 0.5351211004338022 valid 0.42085741029586643
LOSS train 0.5351211004338022 valid 0.42080897324743904
LOSS train 0.5351211004338022 valid 0.42087717365848926
LOSS train 0.5351211004338022 valid 0.42091097334637145
LOSS train 0.5351211004338022 valid 0.4209031799664864
LOSS train 0.5351211004338022 valid 0.4208960197437769
LOSS train 0.5351211004338022 valid 0.42085253851104326
LOSS train 0.5351211004338022 valid 0.4207846106458526
LOSS train 0.5351211004338022 valid 0.42077636289777176
LOSS train 0.5351211004338022 valid 0.4208369920838554
LOSS train 0.5351211004338022 valid 0.42095195418013664
LOSS train 0.5351211004338022 valid 0.4211209456572372
LOSS train 0.5351211004338022 valid 0.4211141845183586
LOSS train 0.5351211004338022 valid 0.42128438256043926
LOSS train 0.5351211004338022 valid 0.4212399011408841
LOSS train 0.5351211004338022 valid 0.42134222938125865
LOSS train 0.5351211004338022 valid 0.42134566868052764
LOSS train 0.5351211004338022 valid 0.421260804047078
LOSS train 0.5351211004338022 valid 0.4212723391769576
LOSS train 0.5351211004338022 valid 0.42117674827575685
LOSS train 0.5351211004338022 valid 0.42107967492462933
LOSS train 0.5351211004338022 valid 0.42107778238905896
LOSS train 0.5351211004338022 valid 0.421008655493208
LOSS train 0.5351211004338022 valid 0.4210330199810766
LOSS train 0.5351211004338022 valid 0.4209715835750103
LOSS train 0.5351211004338022 valid 0.42087252231255123
LOSS train 0.5351211004338022 valid 0.4208747646275987
LOSS train 0.5351211004338022 valid 0.4208404557654377
LOSS train 0.5351211004338022 valid 0.4209170688835668
LOSS train 0.5351211004338022 valid 0.42085648430021183
LOSS train 0.5351211004338022 valid 0.4207895372088972
LOSS train 0.5351211004338022 valid 0.4208095485948104
LOSS train 0.5351211004338022 valid 0.4208103059273627
LOSS train 0.5351211004338022 valid 0.42077045333426716
LOSS train 0.5351211004338022 valid 0.4207022899183734
LOSS train 0.5351211004338022 valid 0.420575903863022
LOSS train 0.5351211004338022 valid 0.42058913205584436
LOSS train 0.5351211004338022 valid 0.4205079328891767
LOSS train 0.5351211004338022 valid 0.4205985529487636
LOSS train 0.5351211004338022 valid 0.42071295410899795
LOSS train 0.5351211004338022 valid 0.4206922956415125
LOSS train 0.5351211004338022 valid 0.4207249468424505
LOSS train 0.5351211004338022 valid 0.4206538067368053
LOSS train 0.5351211004338022 valid 0.4206678673973849
LOSS train 0.5351211004338022 valid 0.420725093682607
LOSS train 0.5351211004338022 valid 0.42068824033404506
LOSS train 0.5351211004338022 valid 0.42058682264081687
LOSS train 0.5351211004338022 valid 0.42052061742681873
LOSS train 0.5351211004338022 valid 0.4204999965272452
LOSS train 0.5351211004338022 valid 0.42043992671810215
LOSS train 0.5351211004338022 valid 0.4204901748038585
LOSS train 0.5351211004338022 valid 0.42048162076294615
LOSS train 0.5351211004338022 valid 0.4204673897716906
LOSS train 0.5351211004338022 valid 0.42054055327350653
LOSS train 0.5351211004338022 valid 0.4204711405500289
LOSS train 0.5351211004338022 valid 0.4204004082074119
LOSS train 0.5351211004338022 valid 0.4203887741344097
LOSS train 0.5351211004338022 valid 0.4204903720095516
LOSS train 0.5351211004338022 valid 0.4205288944920157
LOSS train 0.5351211004338022 valid 0.4205200357096536
LOSS train 0.5351211004338022 valid 0.4204530462245398
LOSS train 0.5351211004338022 valid 0.4204872477129807
LOSS train 0.5351211004338022 valid 0.42052659748485255
LOSS train 0.5351211004338022 valid 0.4204515399977705
LOSS train 0.5351211004338022 valid 0.4204232493415475
LOSS train 0.5351211004338022 valid 0.4204516914031959
LOSS train 0.5351211004338022 valid 0.42042591584765393
LOSS train 0.5351211004338022 valid 0.4203286666434616
LOSS train 0.5351211004338022 valid 0.4203581143124604
LOSS train 0.5351211004338022 valid 0.4203231556598957
LOSS train 0.5351211004338022 valid 0.4203782805635885
LOSS train 0.5351211004338022 valid 0.4204956123588282
LOSS train 0.5351211004338022 valid 0.4204898171308564
LOSS train 0.5351211004338022 valid 0.42048095914005873
LOSS train 0.5351211004338022 valid 0.4204397886991501
LOSS train 0.5351211004338022 valid 0.42039294401324406
LOSS train 0.5351211004338022 valid 0.42029911854180946
LOSS train 0.5351211004338022 valid 0.42029851388644884
LOSS train 0.5351211004338022 valid 0.42036722894914136
LOSS train 0.5351211004338022 valid 0.42038529826633964
LOSS train 0.5351211004338022 valid 0.42039134513054577
LOSS train 0.5351211004338022 valid 0.4203912863391797
LOSS train 0.5351211004338022 valid 0.4204113987775949
LOSS train 0.5351211004338022 valid 0.42035891032148603
LOSS train 0.5351211004338022 valid 0.42035752640051
LOSS train 0.5351211004338022 valid 0.42027029893265444
LOSS train 0.5351211004338022 valid 0.4201520555897763
LOSS train 0.5351211004338022 valid 0.4201465828599457
LOSS train 0.5351211004338022 valid 0.4202141770443251
LOSS train 0.5351211004338022 valid 0.42027653758076655
LOSS train 0.5351211004338022 valid 0.42023135962858366
LOSS train 0.5351211004338022 valid 0.420234667035276
LOSS train 0.5351211004338022 valid 0.4201832417955344
LOSS train 0.5351211004338022 valid 0.4202053143848321
LOSS train 0.5351211004338022 valid 0.42014187344482967
LOSS train 0.5351211004338022 valid 0.4201101419592855
LOSS train 0.5351211004338022 valid 0.42015704089267686
LOSS train 0.5351211004338022 valid 0.420251327854378
LOSS train 0.5351211004338022 valid 0.4203624690824983
LOSS train 0.5351211004338022 valid 0.42035985622607486
LOSS train 0.5351211004338022 valid 0.4203010709600502
LOSS train 0.5351211004338022 valid 0.4202760735980603
LOSS train 0.5351211004338022 valid 0.4201436598873671
LOSS train 0.5351211004338022 valid 0.4201347744066403
LOSS train 0.5351211004338022 valid 0.42012216208709613
LOSS train 0.5351211004338022 valid 0.4201441206595244
LOSS train 0.5351211004338022 valid 0.4202244436543291
LOSS train 0.5351211004338022 valid 0.4201798306023779
LOSS train 0.5351211004338022 valid 0.4201647229902037
LOSS train 0.5351211004338022 valid 0.4202186352586093
LOSS train 0.5351211004338022 valid 0.42016200590980507
LOSS train 0.5351211004338022 valid 0.420112999567219
LOSS train 0.5351211004338022 valid 0.42008058832067513
LOSS train 0.5351211004338022 valid 0.4200982794690584
EPOCH 7:
  batch 1 loss: 0.5093492269515991
  batch 2 loss: 0.5043299496173859
  batch 3 loss: 0.5203073223431905
  batch 4 loss: 0.5331922471523285
  batch 5 loss: 0.5337206721305847
  batch 6 loss: 0.5322657922903696
  batch 7 loss: 0.5323277456419808
  batch 8 loss: 0.5318532064557076
  batch 9 loss: 0.5349731776449416
  batch 10 loss: 0.5362316131591797
  batch 11 loss: 0.5366033640774813
  batch 12 loss: 0.5351424217224121
  batch 13 loss: 0.5355724463096032
  batch 14 loss: 0.5352733858994075
  batch 15 loss: 0.535165258248647
  batch 16 loss: 0.533243965357542
  batch 17 loss: 0.5320798474199632
  batch 18 loss: 0.5309015545580122
  batch 19 loss: 0.530550125398134
  batch 20 loss: 0.5298066854476928
  batch 21 loss: 0.5306965282985142
  batch 22 loss: 0.5298770720308478
  batch 23 loss: 0.5300326243690823
  batch 24 loss: 0.5292143523693085
  batch 25 loss: 0.5292423415184021
  batch 26 loss: 0.5285887213853689
  batch 27 loss: 0.5279327940057825
  batch 28 loss: 0.5268462577036449
  batch 29 loss: 0.5267946452930056
  batch 30 loss: 0.525946052869161
  batch 31 loss: 0.5254469263938165
  batch 32 loss: 0.5260991491377354
  batch 33 loss: 0.5257442503264456
  batch 34 loss: 0.5258139757549062
  batch 35 loss: 0.5266035096985954
  batch 36 loss: 0.5267008493343989
  batch 37 loss: 0.5271088561496219
  batch 38 loss: 0.5269794244515268
  batch 39 loss: 0.5273147821426392
  batch 40 loss: 0.5265769936144352
  batch 41 loss: 0.5262545267256294
  batch 42 loss: 0.5264374862114588
  batch 43 loss: 0.5262617752995602
  batch 44 loss: 0.5261792344125834
  batch 45 loss: 0.5265864034493765
  batch 46 loss: 0.5261576881875163
  batch 47 loss: 0.5264357715211017
  batch 48 loss: 0.5256951488554478
  batch 49 loss: 0.5256579238541272
  batch 50 loss: 0.5252727425098419
  batch 51 loss: 0.5247866745088615
  batch 52 loss: 0.5254183067725255
  batch 53 loss: 0.5255876914510187
  batch 54 loss: 0.5261224563475009
  batch 55 loss: 0.5255169434980913
  batch 56 loss: 0.5248109102249146
  batch 57 loss: 0.5245497059403804
  batch 58 loss: 0.5249649769273298
  batch 59 loss: 0.5244524771884337
  batch 60 loss: 0.5242761751015981
  batch 61 loss: 0.5240918906008611
  batch 62 loss: 0.524690515572025
  batch 63 loss: 0.5246814896189977
  batch 64 loss: 0.5252878721803427
  batch 65 loss: 0.5248113751411438
  batch 66 loss: 0.5249756023739324
  batch 67 loss: 0.525154548794476
  batch 68 loss: 0.5251262512277154
  batch 69 loss: 0.5250354590623275
  batch 70 loss: 0.5246602484158107
  batch 71 loss: 0.5248511735822113
  batch 72 loss: 0.5245681371953752
  batch 73 loss: 0.5246712214326206
  batch 74 loss: 0.524233303762771
  batch 75 loss: 0.524136727253596
  batch 76 loss: 0.524248441191096
  batch 77 loss: 0.5242653957435063
  batch 78 loss: 0.5236985557354413
  batch 79 loss: 0.524250556019288
  batch 80 loss: 0.5240443382412195
  batch 81 loss: 0.5242616162623888
  batch 82 loss: 0.5247205593963948
  batch 83 loss: 0.5248782509062664
  batch 84 loss: 0.525157443469479
  batch 85 loss: 0.5249473182594075
  batch 86 loss: 0.5253881538330123
  batch 87 loss: 0.5250957817181774
  batch 88 loss: 0.5246207676827908
  batch 89 loss: 0.5246926067250498
  batch 90 loss: 0.5247485256857343
  batch 91 loss: 0.5250394871601691
  batch 92 loss: 0.5247120866956918
  batch 93 loss: 0.5245276917052525
  batch 94 loss: 0.5246801373172314
  batch 95 loss: 0.5250546941631719
  batch 96 loss: 0.5251892752324542
  batch 97 loss: 0.5254883013435245
  batch 98 loss: 0.5257663596041349
  batch 99 loss: 0.5256187798398914
  batch 100 loss: 0.5257529380917549
  batch 101 loss: 0.5257658648608935
  batch 102 loss: 0.5258855372667313
  batch 103 loss: 0.5259701751389549
  batch 104 loss: 0.5259717241502725
  batch 105 loss: 0.525759681349709
  batch 106 loss: 0.5261363671073374
  batch 107 loss: 0.526068886028272
  batch 108 loss: 0.5259208488795493
  batch 109 loss: 0.5260088047303191
  batch 110 loss: 0.5261447459459305
  batch 111 loss: 0.5261787377499245
  batch 112 loss: 0.5261539207505328
  batch 113 loss: 0.5262790884064362
  batch 114 loss: 0.5267261572574314
  batch 115 loss: 0.5268632741078086
  batch 116 loss: 0.5268944519860991
  batch 117 loss: 0.5270170378379333
  batch 118 loss: 0.5272785220610894
  batch 119 loss: 0.5272341413157327
  batch 120 loss: 0.527263559649388
  batch 121 loss: 0.5270086893858004
  batch 122 loss: 0.5268438197061663
  batch 123 loss: 0.5265562088508916
  batch 124 loss: 0.5266737043857574
  batch 125 loss: 0.526505063533783
  batch 126 loss: 0.526452260357993
  batch 127 loss: 0.5267189065302451
  batch 128 loss: 0.5264462367631495
  batch 129 loss: 0.5262990945069365
  batch 130 loss: 0.526316480911695
  batch 131 loss: 0.5265127561474574
  batch 132 loss: 0.5267224095084451
  batch 133 loss: 0.5268661931045073
  batch 134 loss: 0.5268489513824235
  batch 135 loss: 0.5268686365198206
  batch 136 loss: 0.5267196069745457
  batch 137 loss: 0.5268084506918914
  batch 138 loss: 0.5270601200020831
  batch 139 loss: 0.5270052213462995
  batch 140 loss: 0.5268874347209931
  batch 141 loss: 0.5270010685244351
  batch 142 loss: 0.5269173064701994
  batch 143 loss: 0.5267765563684743
  batch 144 loss: 0.5267338686519198
  batch 145 loss: 0.526683851357164
  batch 146 loss: 0.526530043311315
  batch 147 loss: 0.5264682400794256
  batch 148 loss: 0.5264957744527508
  batch 149 loss: 0.5265303782168651
  batch 150 loss: 0.5262964196999868
  batch 151 loss: 0.5260363615901265
  batch 152 loss: 0.5263275104133707
  batch 153 loss: 0.5262698410383237
  batch 154 loss: 0.5263841786941925
  batch 155 loss: 0.52643551634204
  batch 156 loss: 0.5263544271389643
  batch 157 loss: 0.5264977212924107
  batch 158 loss: 0.5264888854720925
  batch 159 loss: 0.5264291126023298
  batch 160 loss: 0.5265431866049767
  batch 161 loss: 0.5265752528765186
  batch 162 loss: 0.5265462383811856
  batch 163 loss: 0.5264758336032095
  batch 164 loss: 0.5264620210339384
  batch 165 loss: 0.5263086618799152
  batch 166 loss: 0.5264155376388366
  batch 167 loss: 0.5262743727175775
  batch 168 loss: 0.5265441536903381
  batch 169 loss: 0.5263793084043018
  batch 170 loss: 0.5263720543945537
  batch 171 loss: 0.5262589025915715
  batch 172 loss: 0.5264375230600667
  batch 173 loss: 0.5263216361145063
  batch 174 loss: 0.5264012145585028
  batch 175 loss: 0.5263174612181527
  batch 176 loss: 0.5263524824245409
  batch 177 loss: 0.5262138271062388
  batch 178 loss: 0.5263274754031321
  batch 179 loss: 0.5263172714403888
  batch 180 loss: 0.5263154645760854
  batch 181 loss: 0.5263230879662445
  batch 182 loss: 0.5263410004285666
  batch 183 loss: 0.5262868619355999
  batch 184 loss: 0.5262021483934444
  batch 185 loss: 0.5262980857410946
  batch 186 loss: 0.5262448050642526
  batch 187 loss: 0.5261645616694568
  batch 188 loss: 0.5261877648373867
  batch 189 loss: 0.5260757844914835
  batch 190 loss: 0.5259907054273706
  batch 191 loss: 0.5260787812203013
  batch 192 loss: 0.5259569619471828
  batch 193 loss: 0.5257708342273001
  batch 194 loss: 0.5257476904650324
  batch 195 loss: 0.5258501595411545
  batch 196 loss: 0.5257282547500669
  batch 197 loss: 0.5258676949793917
  batch 198 loss: 0.5259114315714499
  batch 199 loss: 0.5258422983651185
  batch 200 loss: 0.5258402569591999
  batch 201 loss: 0.5258687730155774
  batch 202 loss: 0.5259491531270566
  batch 203 loss: 0.5260659463593526
  batch 204 loss: 0.5260174541788942
  batch 205 loss: 0.5259304870919483
  batch 206 loss: 0.5259539367793833
  batch 207 loss: 0.5259695967326418
  batch 208 loss: 0.5258304068388847
  batch 209 loss: 0.5257597661189486
  batch 210 loss: 0.525762311191786
  batch 211 loss: 0.525817642985927
  batch 212 loss: 0.5258593602844004
  batch 213 loss: 0.5258374694087695
  batch 214 loss: 0.5257818313124024
  batch 215 loss: 0.5255278475062791
  batch 216 loss: 0.5254016944931613
  batch 217 loss: 0.5254329076285735
  batch 218 loss: 0.5253278576179382
  batch 219 loss: 0.5252175223609629
  batch 220 loss: 0.5252579170194539
  batch 221 loss: 0.5253114380717817
  batch 222 loss: 0.5253671239893716
  batch 223 loss: 0.5254242990850868
  batch 224 loss: 0.525351941984679
  batch 225 loss: 0.5253587453895145
  batch 226 loss: 0.5254077292912829
  batch 227 loss: 0.5252417579358895
  batch 228 loss: 0.5253404780176648
  batch 229 loss: 0.5252474805413375
  batch 230 loss: 0.5253378234479739
  batch 231 loss: 0.5252727599113018
  batch 232 loss: 0.5250865440687229
  batch 233 loss: 0.5251028347168869
  batch 234 loss: 0.5250763996289327
  batch 235 loss: 0.5251274498219186
  batch 236 loss: 0.5251040684722238
  batch 237 loss: 0.5251534622681292
  batch 238 loss: 0.5252108752977949
  batch 239 loss: 0.5250187168310876
  batch 240 loss: 0.5251068526258071
  batch 241 loss: 0.525129168236404
  batch 242 loss: 0.5249885495536584
  batch 243 loss: 0.5250054516910035
  batch 244 loss: 0.5250102310884194
  batch 245 loss: 0.525085501768151
  batch 246 loss: 0.5250788018470858
  batch 247 loss: 0.5250529772356937
  batch 248 loss: 0.5251160251998133
  batch 249 loss: 0.5251097121391909
  batch 250 loss: 0.5251167130470276
  batch 251 loss: 0.5250874389690232
  batch 252 loss: 0.5251112639430969
  batch 253 loss: 0.5250728076154535
  batch 254 loss: 0.5250653870931761
  batch 255 loss: 0.5252093144491607
  batch 256 loss: 0.5251073184190318
  batch 257 loss: 0.5251725665094323
  batch 258 loss: 0.5251847150944924
  batch 259 loss: 0.5250743324922319
  batch 260 loss: 0.5250831515743182
  batch 261 loss: 0.5251739204386642
  batch 262 loss: 0.5251012939305706
  batch 263 loss: 0.5250279709640111
  batch 264 loss: 0.5250591501367815
  batch 265 loss: 0.5250332095712985
  batch 266 loss: 0.5250870765824067
  batch 267 loss: 0.5250743883156151
  batch 268 loss: 0.5249767913969595
  batch 269 loss: 0.5249687509687416
  batch 270 loss: 0.5249650077687369
  batch 271 loss: 0.5249375279759129
  batch 272 loss: 0.5249742314438609
  batch 273 loss: 0.5249418573720115
  batch 274 loss: 0.5247801723923996
  batch 275 loss: 0.5249125904386693
  batch 276 loss: 0.5249825101615726
  batch 277 loss: 0.5250011261834995
  batch 278 loss: 0.5249334446174635
  batch 279 loss: 0.5249842534569429
  batch 280 loss: 0.5248470477759838
  batch 281 loss: 0.5247955942705432
  batch 282 loss: 0.5246298383947805
  batch 283 loss: 0.5245297739657412
  batch 284 loss: 0.5245040926924893
  batch 285 loss: 0.5244309200529467
  batch 286 loss: 0.5243776489596267
  batch 287 loss: 0.5242968750955336
  batch 288 loss: 0.5240803092925085
  batch 289 loss: 0.5242669047162607
  batch 290 loss: 0.5241497860900287
  batch 291 loss: 0.5241196377785345
  batch 292 loss: 0.5242847580819914
  batch 293 loss: 0.5243837061392163
  batch 294 loss: 0.5242657566151652
  batch 295 loss: 0.5244278695623753
  batch 296 loss: 0.5244701679896664
  batch 297 loss: 0.5245533252404595
  batch 298 loss: 0.5245861989139711
  batch 299 loss: 0.5246019273697333
  batch 300 loss: 0.5246613683303197
  batch 301 loss: 0.5247250547836785
  batch 302 loss: 0.5246833428641818
  batch 303 loss: 0.524638813714383
  batch 304 loss: 0.524615230332864
  batch 305 loss: 0.5243855851595519
  batch 306 loss: 0.5244740337328194
  batch 307 loss: 0.5244013828252736
  batch 308 loss: 0.5243456150804248
  batch 309 loss: 0.5243380033082561
  batch 310 loss: 0.5242928510712039
  batch 311 loss: 0.5242819659579605
  batch 312 loss: 0.5242993942438028
  batch 313 loss: 0.5243085980796205
  batch 314 loss: 0.5243164502131711
  batch 315 loss: 0.524276255804395
  batch 316 loss: 0.5242147909689553
  batch 317 loss: 0.5241834519413368
  batch 318 loss: 0.5240523443094589
  batch 319 loss: 0.523874666623561
  batch 320 loss: 0.5237862677313387
  batch 321 loss: 0.523748249929642
  batch 322 loss: 0.5237652904683758
  batch 323 loss: 0.52368186289681
  batch 324 loss: 0.5235371579542573
  batch 325 loss: 0.5235555844123547
  batch 326 loss: 0.5234633948356827
  batch 327 loss: 0.5234638181848263
  batch 328 loss: 0.5233169220751379
  batch 329 loss: 0.5233813965393055
  batch 330 loss: 0.5233293693174016
  batch 331 loss: 0.5232847342858502
  batch 332 loss: 0.5233298156814403
  batch 333 loss: 0.5232723343658734
  batch 334 loss: 0.5231069576240586
  batch 335 loss: 0.523092401917301
  batch 336 loss: 0.5230502679589248
  batch 337 loss: 0.5230013328419241
  batch 338 loss: 0.5229662707924138
  batch 339 loss: 0.5230773203844166
  batch 340 loss: 0.5230734216816285
  batch 341 loss: 0.5230719569491501
  batch 342 loss: 0.5230328958285483
  batch 343 loss: 0.5229980311310326
  batch 344 loss: 0.5229670760589976
  batch 345 loss: 0.5230542340140412
  batch 346 loss: 0.5229934603837184
  batch 347 loss: 0.523025017993938
  batch 348 loss: 0.5230558237125134
  batch 349 loss: 0.5229776791139455
  batch 350 loss: 0.5230095162561962
  batch 351 loss: 0.5230052590879619
  batch 352 loss: 0.5230274804105813
  batch 353 loss: 0.5228990138252464
  batch 354 loss: 0.5229532946806169
  batch 355 loss: 0.5230529639922398
  batch 356 loss: 0.523014756317219
  batch 357 loss: 0.5229929658044287
  batch 358 loss: 0.5229987687738248
  batch 359 loss: 0.5230381776861494
  batch 360 loss: 0.5230897376106844
  batch 361 loss: 0.5231083454022447
  batch 362 loss: 0.5229814468332417
  batch 363 loss: 0.5229420216122934
  batch 364 loss: 0.5228009604654469
  batch 365 loss: 0.5227737020956327
  batch 366 loss: 0.5226496321256043
  batch 367 loss: 0.5226113380463312
  batch 368 loss: 0.5225328309866397
  batch 369 loss: 0.5225519025067327
  batch 370 loss: 0.5226591270517659
  batch 371 loss: 0.5227764403884302
  batch 372 loss: 0.5226807398821718
  batch 373 loss: 0.5226178734136331
  batch 374 loss: 0.52253656567418
  batch 375 loss: 0.5225477149486542
  batch 376 loss: 0.5225438921851047
  batch 377 loss: 0.5224956374427684
  batch 378 loss: 0.5224604788753722
  batch 379 loss: 0.5224440571972436
  batch 380 loss: 0.5225346514268925
  batch 381 loss: 0.5224069974084539
  batch 382 loss: 0.5222382916829973
  batch 383 loss: 0.522224880696588
  batch 384 loss: 0.5222060037776828
  batch 385 loss: 0.5222466812505351
  batch 386 loss: 0.52217278625681
  batch 387 loss: 0.522147006150672
  batch 388 loss: 0.5221469030552304
  batch 389 loss: 0.5221457760254338
  batch 390 loss: 0.5221870556855813
  batch 391 loss: 0.522138808694337
  batch 392 loss: 0.5221602089551031
  batch 393 loss: 0.5222263506047296
  batch 394 loss: 0.522226988966695
  batch 395 loss: 0.5222381329234642
  batch 396 loss: 0.5223518122326244
  batch 397 loss: 0.5222671383273992
  batch 398 loss: 0.5222119253184927
  batch 399 loss: 0.5222322155060923
  batch 400 loss: 0.5221815767884255
  batch 401 loss: 0.5221277185509032
  batch 402 loss: 0.522208693163905
  batch 403 loss: 0.5221330292763249
  batch 404 loss: 0.5220736008469421
  batch 405 loss: 0.5220468426928108
  batch 406 loss: 0.5221004063272711
  batch 407 loss: 0.5221074419759708
  batch 408 loss: 0.5221702365898618
  batch 409 loss: 0.5221506838110664
  batch 410 loss: 0.5221478199086538
  batch 411 loss: 0.5221229186893379
  batch 412 loss: 0.5220494484438479
  batch 413 loss: 0.521984772301182
  batch 414 loss: 0.5219383876104862
  batch 415 loss: 0.5219468293419803
  batch 416 loss: 0.5219149771504678
  batch 417 loss: 0.5219014957368516
  batch 418 loss: 0.5218608889853555
  batch 419 loss: 0.5218760361250374
  batch 420 loss: 0.5218842912287939
  batch 421 loss: 0.5218883856175348
  batch 422 loss: 0.5219711703711777
  batch 423 loss: 0.5219800083349783
  batch 424 loss: 0.5219583286429351
  batch 425 loss: 0.5219900049882776
  batch 426 loss: 0.5219629935815301
  batch 427 loss: 0.5219777762471094
  batch 428 loss: 0.5219080668882788
  batch 429 loss: 0.5218876198038355
  batch 430 loss: 0.5219141686378523
  batch 431 loss: 0.5220349348753068
  batch 432 loss: 0.5220718523832383
  batch 433 loss: 0.5220321095430273
  batch 434 loss: 0.5220630488225392
  batch 435 loss: 0.5220148713424289
  batch 436 loss: 0.5219930491726333
  batch 437 loss: 0.5220260791292998
  batch 438 loss: 0.5220694282691772
  batch 439 loss: 0.5220329687508473
  batch 440 loss: 0.5220240081575784
  batch 441 loss: 0.5219561638069802
  batch 442 loss: 0.5219765049974303
  batch 443 loss: 0.5219724224733177
  batch 444 loss: 0.5218756367360149
  batch 445 loss: 0.5218873181369867
  batch 446 loss: 0.5218284052583669
  batch 447 loss: 0.521760235696831
  batch 448 loss: 0.5218631204749856
  batch 449 loss: 0.5218988022453801
  batch 450 loss: 0.5219481468200684
  batch 451 loss: 0.521942869258297
  batch 452 loss: 0.5219705869666244
  batch 453 loss: 0.5219802614342561
  batch 454 loss: 0.5219659983849211
  batch 455 loss: 0.5219567027720776
  batch 456 loss: 0.5219375079399661
  batch 457 loss: 0.5219632171958489
  batch 458 loss: 0.521906706768873
  batch 459 loss: 0.5219374928209517
  batch 460 loss: 0.5220083381170811
  batch 461 loss: 0.5219986381215284
  batch 462 loss: 0.5219541295911326
  batch 463 loss: 0.5219286938336704
  batch 464 loss: 0.5219721550699966
  batch 465 loss: 0.5218357079772539
  batch 466 loss: 0.5217550479419242
  batch 467 loss: 0.5217912570439773
  batch 468 loss: 0.5217258680580009
  batch 469 loss: 0.5217177567959849
  batch 470 loss: 0.5217032741993032
  batch 471 loss: 0.5217068766079638
  batch 472 loss: 0.5216608792543411
LOSS train 0.5216608792543411 valid 0.41209685802459717
LOSS train 0.5216608792543411 valid 0.3933892101049423
LOSS train 0.5216608792543411 valid 0.41136522094408673
LOSS train 0.5216608792543411 valid 0.40752071887254715
LOSS train 0.5216608792543411 valid 0.40764341950416566
LOSS train 0.5216608792543411 valid 0.40920892357826233
LOSS train 0.5216608792543411 valid 0.4085571893623897
LOSS train 0.5216608792543411 valid 0.4081003852188587
LOSS train 0.5216608792543411 valid 0.405377596616745
LOSS train 0.5216608792543411 valid 0.4084547281265259
LOSS train 0.5216608792543411 valid 0.4107655205509879
LOSS train 0.5216608792543411 valid 0.41080919404824573
LOSS train 0.5216608792543411 valid 0.4145795932182899
LOSS train 0.5216608792543411 valid 0.4150360311780657
LOSS train 0.5216608792543411 valid 0.41402929623921714
LOSS train 0.5216608792543411 valid 0.41510874778032303
LOSS train 0.5216608792543411 valid 0.417472746442346
LOSS train 0.5216608792543411 valid 0.4187326365047031
LOSS train 0.5216608792543411 valid 0.41897130326220866
LOSS train 0.5216608792543411 valid 0.4203714519739151
LOSS train 0.5216608792543411 valid 0.41990712994620916
LOSS train 0.5216608792543411 valid 0.41781849752772937
LOSS train 0.5216608792543411 valid 0.41890862324963446
LOSS train 0.5216608792543411 valid 0.41824022059639293
LOSS train 0.5216608792543411 valid 0.41819636344909666
LOSS train 0.5216608792543411 valid 0.4179982405442458
LOSS train 0.5216608792543411 valid 0.4176826300444426
LOSS train 0.5216608792543411 valid 0.4178121089935303
LOSS train 0.5216608792543411 valid 0.41770365114869745
LOSS train 0.5216608792543411 valid 0.4182856559753418
LOSS train 0.5216608792543411 valid 0.4197532207735123
LOSS train 0.5216608792543411 valid 0.41934361681342125
LOSS train 0.5216608792543411 valid 0.4199295260689475
LOSS train 0.5216608792543411 valid 0.41949274259455066
LOSS train 0.5216608792543411 valid 0.4202374066625323
LOSS train 0.5216608792543411 valid 0.4202244248655107
LOSS train 0.5216608792543411 valid 0.42078420439281977
LOSS train 0.5216608792543411 valid 0.4220707589074185
LOSS train 0.5216608792543411 valid 0.4219741760156093
LOSS train 0.5216608792543411 valid 0.42335104048252103
LOSS train 0.5216608792543411 valid 0.4233277774438625
LOSS train 0.5216608792543411 valid 0.42420927967344013
LOSS train 0.5216608792543411 valid 0.4241197421107181
LOSS train 0.5216608792543411 valid 0.4241977340795777
LOSS train 0.5216608792543411 valid 0.42444531122843426
LOSS train 0.5216608792543411 valid 0.4248242093169171
LOSS train 0.5216608792543411 valid 0.4245285518625949
LOSS train 0.5216608792543411 valid 0.4246404593189557
LOSS train 0.5216608792543411 valid 0.42509035674893125
LOSS train 0.5216608792543411 valid 0.4243311679363251
LOSS train 0.5216608792543411 valid 0.4248000915144004
LOSS train 0.5216608792543411 valid 0.42452128059588945
LOSS train 0.5216608792543411 valid 0.42418442188568833
LOSS train 0.5216608792543411 valid 0.4241376028016762
LOSS train 0.5216608792543411 valid 0.4237838783047416
LOSS train 0.5216608792543411 valid 0.4238291595663343
LOSS train 0.5216608792543411 valid 0.4235054113362965
LOSS train 0.5216608792543411 valid 0.42327045366681854
LOSS train 0.5216608792543411 valid 0.4237664119671967
LOSS train 0.5216608792543411 valid 0.4232627093791962
LOSS train 0.5216608792543411 valid 0.4222269561447081
LOSS train 0.5216608792543411 valid 0.42316741904904764
LOSS train 0.5216608792543411 valid 0.42372617835090276
LOSS train 0.5216608792543411 valid 0.4244197770021856
LOSS train 0.5216608792543411 valid 0.4245600654528691
LOSS train 0.5216608792543411 valid 0.42452855588811816
LOSS train 0.5216608792543411 valid 0.42409109535501965
LOSS train 0.5216608792543411 valid 0.42347975951783795
LOSS train 0.5216608792543411 valid 0.42334121033765265
LOSS train 0.5216608792543411 valid 0.42306378441197534
LOSS train 0.5216608792543411 valid 0.42260788066286437
LOSS train 0.5216608792543411 valid 0.42255907878279686
LOSS train 0.5216608792543411 valid 0.4229550006454938
LOSS train 0.5216608792543411 valid 0.4227965917136218
LOSS train 0.5216608792543411 valid 0.42232906103134155
LOSS train 0.5216608792543411 valid 0.4225918987863942
LOSS train 0.5216608792543411 valid 0.4223014743297131
LOSS train 0.5216608792543411 valid 0.4222025806323076
LOSS train 0.5216608792543411 valid 0.42228697372388235
LOSS train 0.5216608792543411 valid 0.42217973694205285
LOSS train 0.5216608792543411 valid 0.42167703678578505
LOSS train 0.5216608792543411 valid 0.4218225057532148
LOSS train 0.5216608792543411 valid 0.4216389763786132
LOSS train 0.5216608792543411 valid 0.42177958431698026
LOSS train 0.5216608792543411 valid 0.42201931757085465
LOSS train 0.5216608792543411 valid 0.4216894497011983
LOSS train 0.5216608792543411 valid 0.42175408992274055
LOSS train 0.5216608792543411 valid 0.42117533731189644
LOSS train 0.5216608792543411 valid 0.42127271750000084
LOSS train 0.5216608792543411 valid 0.4209850553009245
LOSS train 0.5216608792543411 valid 0.4208429056209522
LOSS train 0.5216608792543411 valid 0.4206836589652559
LOSS train 0.5216608792543411 valid 0.4203338555751308
LOSS train 0.5216608792543411 valid 0.419946403262463
LOSS train 0.5216608792543411 valid 0.4197712336715899
LOSS train 0.5216608792543411 valid 0.41991539516796667
LOSS train 0.5216608792543411 valid 0.42024526553055674
LOSS train 0.5216608792543411 valid 0.42018691921720697
LOSS train 0.5216608792543411 valid 0.42027591394655633
LOSS train 0.5216608792543411 valid 0.42046156883239744
LOSS train 0.5216608792543411 valid 0.42047057086878487
LOSS train 0.5216608792543411 valid 0.42067493001619977
LOSS train 0.5216608792543411 valid 0.4210382323820614
LOSS train 0.5216608792543411 valid 0.4209433157856648
LOSS train 0.5216608792543411 valid 0.42076592757588344
LOSS train 0.5216608792543411 valid 0.42085923310720696
LOSS train 0.5216608792543411 valid 0.42064127715948585
LOSS train 0.5216608792543411 valid 0.4208478682019092
LOSS train 0.5216608792543411 valid 0.4208448496433573
LOSS train 0.5216608792543411 valid 0.4209627628326416
LOSS train 0.5216608792543411 valid 0.4208641178436107
LOSS train 0.5216608792543411 valid 0.4208661323147161
LOSS train 0.5216608792543411 valid 0.4208292823977175
LOSS train 0.5216608792543411 valid 0.42069567818390696
LOSS train 0.5216608792543411 valid 0.4207292802955793
LOSS train 0.5216608792543411 valid 0.420672492220484
LOSS train 0.5216608792543411 valid 0.4207763850179493
LOSS train 0.5216608792543411 valid 0.4205560613486726
LOSS train 0.5216608792543411 valid 0.4204896022291744
LOSS train 0.5216608792543411 valid 0.4203927628695965
LOSS train 0.5216608792543411 valid 0.42036101911678786
LOSS train 0.5216608792543411 valid 0.42038150864546414
LOSS train 0.5216608792543411 valid 0.4204487412925658
LOSS train 0.5216608792543411 valid 0.42069253710008436
LOSS train 0.5216608792543411 valid 0.4205312337875366
LOSS train 0.5216608792543411 valid 0.42033926409388345
LOSS train 0.5216608792543411 valid 0.4208409187831278
LOSS train 0.5216608792543411 valid 0.42099844431504607
LOSS train 0.5216608792543411 valid 0.4211549504782802
LOSS train 0.5216608792543411 valid 0.4209832402376028
LOSS train 0.5216608792543411 valid 0.420957880620738
LOSS train 0.5216608792543411 valid 0.4209427824526122
LOSS train 0.5216608792543411 valid 0.4207072508962531
LOSS train 0.5216608792543411 valid 0.4209477349893371
LOSS train 0.5216608792543411 valid 0.4211521128813426
LOSS train 0.5216608792543411 valid 0.42099617180578847
LOSS train 0.5216608792543411 valid 0.42079653639863007
LOSS train 0.5216608792543411 valid 0.42070779485115106
LOSS train 0.5216608792543411 valid 0.4205016200062182
LOSS train 0.5216608792543411 valid 0.4206659979053906
LOSS train 0.5216608792543411 valid 0.42080616697351986
LOSS train 0.5216608792543411 valid 0.4212512856637928
LOSS train 0.5216608792543411 valid 0.42117344770398174
LOSS train 0.5216608792543411 valid 0.4214062067783541
LOSS train 0.5216608792543411 valid 0.42141037048964664
LOSS train 0.5216608792543411 valid 0.42160836637836613
LOSS train 0.5216608792543411 valid 0.42126019957925187
LOSS train 0.5216608792543411 valid 0.421457164593645
LOSS train 0.5216608792543411 valid 0.42160947130830495
LOSS train 0.5216608792543411 valid 0.4216294111808141
LOSS train 0.5216608792543411 valid 0.4216784978939208
LOSS train 0.5216608792543411 valid 0.42150986351464925
LOSS train 0.5216608792543411 valid 0.42173951163011436
LOSS train 0.5216608792543411 valid 0.4217742805357103
LOSS train 0.5216608792543411 valid 0.4217218299065867
LOSS train 0.5216608792543411 valid 0.42190327590856797
LOSS train 0.5216608792543411 valid 0.4219637623258457
LOSS train 0.5216608792543411 valid 0.42196672739861885
LOSS train 0.5216608792543411 valid 0.42164899118291504
LOSS train 0.5216608792543411 valid 0.42169574219733474
LOSS train 0.5216608792543411 valid 0.42153556654171914
LOSS train 0.5216608792543411 valid 0.4212592488821642
LOSS train 0.5216608792543411 valid 0.42127122359773134
LOSS train 0.5216608792543411 valid 0.42121742265980416
LOSS train 0.5216608792543411 valid 0.4210903156887401
LOSS train 0.5216608792543411 valid 0.42097667847053116
LOSS train 0.5216608792543411 valid 0.4210036648604684
LOSS train 0.5216608792543411 valid 0.42117429258567946
LOSS train 0.5216608792543411 valid 0.42124224996425697
LOSS train 0.5216608792543411 valid 0.4215135016862084
LOSS train 0.5216608792543411 valid 0.4214816888173421
LOSS train 0.5216608792543411 valid 0.42155230599780413
LOSS train 0.5216608792543411 valid 0.42179035554731514
LOSS train 0.5216608792543411 valid 0.42176439878584326
LOSS train 0.5216608792543411 valid 0.42175125564847676
LOSS train 0.5216608792543411 valid 0.4215414585037665
LOSS train 0.5216608792543411 valid 0.42172001580060536
LOSS train 0.5216608792543411 valid 0.42179736511760885
LOSS train 0.5216608792543411 valid 0.4216756063133645
LOSS train 0.5216608792543411 valid 0.4218361770113309
LOSS train 0.5216608792543411 valid 0.42190507877597494
LOSS train 0.5216608792543411 valid 0.42196982018240203
LOSS train 0.5216608792543411 valid 0.4218999675062836
LOSS train 0.5216608792543411 valid 0.42195871585737105
LOSS train 0.5216608792543411 valid 0.42191057640153007
LOSS train 0.5216608792543411 valid 0.42190455765493456
LOSS train 0.5216608792543411 valid 0.42194587629746627
LOSS train 0.5216608792543411 valid 0.4220157078606017
LOSS train 0.5216608792543411 valid 0.42197955190820036
LOSS train 0.5216608792543411 valid 0.42190588995030054
LOSS train 0.5216608792543411 valid 0.4221851460596654
LOSS train 0.5216608792543411 valid 0.422237624724706
LOSS train 0.5216608792543411 valid 0.42218567330602536
LOSS train 0.5216608792543411 valid 0.4220306016120714
LOSS train 0.5216608792543411 valid 0.42195217838654153
LOSS train 0.5216608792543411 valid 0.42194095025865397
LOSS train 0.5216608792543411 valid 0.42208073420573006
LOSS train 0.5216608792543411 valid 0.422097619284283
LOSS train 0.5216608792543411 valid 0.4220504220107093
LOSS train 0.5216608792543411 valid 0.422055542320013
LOSS train 0.5216608792543411 valid 0.4219187954765054
LOSS train 0.5216608792543411 valid 0.42201409097945336
LOSS train 0.5216608792543411 valid 0.42184092757737107
LOSS train 0.5216608792543411 valid 0.42172611753145856
LOSS train 0.5216608792543411 valid 0.42174625571181135
LOSS train 0.5216608792543411 valid 0.4216877320437755
LOSS train 0.5216608792543411 valid 0.42182811691565214
LOSS train 0.5216608792543411 valid 0.42180044963382757
LOSS train 0.5216608792543411 valid 0.42170461270797766
LOSS train 0.5216608792543411 valid 0.42173699750786736
LOSS train 0.5216608792543411 valid 0.4216561681851392
LOSS train 0.5216608792543411 valid 0.4216516948533508
LOSS train 0.5216608792543411 valid 0.42173914492410114
LOSS train 0.5216608792543411 valid 0.42173556760649816
LOSS train 0.5216608792543411 valid 0.4217801286730655
LOSS train 0.5216608792543411 valid 0.4217943062108976
LOSS train 0.5216608792543411 valid 0.4218665154024203
LOSS train 0.5216608792543411 valid 0.4219257037300582
LOSS train 0.5216608792543411 valid 0.4219750391838213
LOSS train 0.5216608792543411 valid 0.4220908231355927
LOSS train 0.5216608792543411 valid 0.4221881922014159
LOSS train 0.5216608792543411 valid 0.42223423558312495
LOSS train 0.5216608792543411 valid 0.42232647070435664
LOSS train 0.5216608792543411 valid 0.42234955608312574
LOSS train 0.5216608792543411 valid 0.4223450850115882
LOSS train 0.5216608792543411 valid 0.42228991848177616
LOSS train 0.5216608792543411 valid 0.42240348182585796
LOSS train 0.5216608792543411 valid 0.4224579386543809
LOSS train 0.5216608792543411 valid 0.4224983202578199
LOSS train 0.5216608792543411 valid 0.42256770017354384
LOSS train 0.5216608792543411 valid 0.42253897742275554
LOSS train 0.5216608792543411 valid 0.4225451065034702
LOSS train 0.5216608792543411 valid 0.4224756326798206
LOSS train 0.5216608792543411 valid 0.4224774139559167
LOSS train 0.5216608792543411 valid 0.42255385682937946
LOSS train 0.5216608792543411 valid 0.42256778327085204
LOSS train 0.5216608792543411 valid 0.4225225986810676
LOSS train 0.5216608792543411 valid 0.42250342491795034
LOSS train 0.5216608792543411 valid 0.4224473383885547
LOSS train 0.5216608792543411 valid 0.4223298868785302
LOSS train 0.5216608792543411 valid 0.42243379737826303
LOSS train 0.5216608792543411 valid 0.4223393725215896
LOSS train 0.5216608792543411 valid 0.42236235615157297
LOSS train 0.5216608792543411 valid 0.4224592684233775
LOSS train 0.5216608792543411 valid 0.4224353067728938
LOSS train 0.5216608792543411 valid 0.42237748956777216
LOSS train 0.5216608792543411 valid 0.42245911936528285
LOSS train 0.5216608792543411 valid 0.4224226883342189
LOSS train 0.5216608792543411 valid 0.4224579609541529
LOSS train 0.5216608792543411 valid 0.42261123383045196
LOSS train 0.5216608792543411 valid 0.42265180845659567
LOSS train 0.5216608792543411 valid 0.42283580144719474
LOSS train 0.5216608792543411 valid 0.4227834963515813
LOSS train 0.5216608792543411 valid 0.42293887004608244
LOSS train 0.5216608792543411 valid 0.42286295528505363
LOSS train 0.5216608792543411 valid 0.4228766580345109
LOSS train 0.5216608792543411 valid 0.4228500333045707
LOSS train 0.5216608792543411 valid 0.42293853734352793
LOSS train 0.5216608792543411 valid 0.4229405195556552
LOSS train 0.5216608792543411 valid 0.4229013367341115
LOSS train 0.5216608792543411 valid 0.4229204408053694
LOSS train 0.5216608792543411 valid 0.42287628273017536
LOSS train 0.5216608792543411 valid 0.42281686851733535
LOSS train 0.5216608792543411 valid 0.42278360360951134
LOSS train 0.5216608792543411 valid 0.42284062257352867
LOSS train 0.5216608792543411 valid 0.42290717027241126
LOSS train 0.5216608792543411 valid 0.42307652940464374
LOSS train 0.5216608792543411 valid 0.42306524659715483
LOSS train 0.5216608792543411 valid 0.4232006053055972
LOSS train 0.5216608792543411 valid 0.4231381840176053
LOSS train 0.5216608792543411 valid 0.4232173568648166
LOSS train 0.5216608792543411 valid 0.4232296152588199
LOSS train 0.5216608792543411 valid 0.4231672995474749
LOSS train 0.5216608792543411 valid 0.42317328803295634
LOSS train 0.5216608792543411 valid 0.4231003467603163
LOSS train 0.5216608792543411 valid 0.423000719992147
LOSS train 0.5216608792543411 valid 0.4230385854140946
LOSS train 0.5216608792543411 valid 0.4229869563802541
LOSS train 0.5216608792543411 valid 0.42301469742183617
LOSS train 0.5216608792543411 valid 0.42297133771436557
LOSS train 0.5216608792543411 valid 0.422858910522427
LOSS train 0.5216608792543411 valid 0.42287319201104184
LOSS train 0.5216608792543411 valid 0.4228579621011714
LOSS train 0.5216608792543411 valid 0.4229160717255633
LOSS train 0.5216608792543411 valid 0.4228738956284105
LOSS train 0.5216608792543411 valid 0.4227866872207268
LOSS train 0.5216608792543411 valid 0.42279065340653527
LOSS train 0.5216608792543411 valid 0.42277969720049036
LOSS train 0.5216608792543411 valid 0.4227471055662756
LOSS train 0.5216608792543411 valid 0.4226806296356793
LOSS train 0.5216608792543411 valid 0.42257926502997933
LOSS train 0.5216608792543411 valid 0.42258151671657823
LOSS train 0.5216608792543411 valid 0.42250632120887577
LOSS train 0.5216608792543411 valid 0.42259000191072216
LOSS train 0.5216608792543411 valid 0.4227054408041097
LOSS train 0.5216608792543411 valid 0.42269774043076747
LOSS train 0.5216608792543411 valid 0.42273507154349127
LOSS train 0.5216608792543411 valid 0.4226680523997185
LOSS train 0.5216608792543411 valid 0.4226771198387529
LOSS train 0.5216608792543411 valid 0.4227206746737162
LOSS train 0.5216608792543411 valid 0.42267716772532543
LOSS train 0.5216608792543411 valid 0.4225819111857193
LOSS train 0.5216608792543411 valid 0.42254794243932164
LOSS train 0.5216608792543411 valid 0.42254110710009146
LOSS train 0.5216608792543411 valid 0.4224976124333554
LOSS train 0.5216608792543411 valid 0.42254486787163353
LOSS train 0.5216608792543411 valid 0.4225280128589282
LOSS train 0.5216608792543411 valid 0.4225154033341965
LOSS train 0.5216608792543411 valid 0.4225695234479256
LOSS train 0.5216608792543411 valid 0.4224952103630189
LOSS train 0.5216608792543411 valid 0.42243948847151264
LOSS train 0.5216608792543411 valid 0.42244486634929973
LOSS train 0.5216608792543411 valid 0.4225337087346342
LOSS train 0.5216608792543411 valid 0.422578561932418
LOSS train 0.5216608792543411 valid 0.42258028019042243
LOSS train 0.5216608792543411 valid 0.42250146396175214
LOSS train 0.5216608792543411 valid 0.4225140636087592
LOSS train 0.5216608792543411 valid 0.4225670401967547
LOSS train 0.5216608792543411 valid 0.4225177167911888
LOSS train 0.5216608792543411 valid 0.4224965592846274
LOSS train 0.5216608792543411 valid 0.4225214643641796
LOSS train 0.5216608792543411 valid 0.42249205902866693
LOSS train 0.5216608792543411 valid 0.4224167385891126
LOSS train 0.5216608792543411 valid 0.42242745457240094
LOSS train 0.5216608792543411 valid 0.42237926648213314
LOSS train 0.5216608792543411 valid 0.422427247455515
LOSS train 0.5216608792543411 valid 0.42252649991155034
LOSS train 0.5216608792543411 valid 0.42251723350548165
LOSS train 0.5216608792543411 valid 0.42249835778514666
LOSS train 0.5216608792543411 valid 0.422459009921912
LOSS train 0.5216608792543411 valid 0.4224303292723941
LOSS train 0.5216608792543411 valid 0.42231016956179973
LOSS train 0.5216608792543411 valid 0.4223070940276882
LOSS train 0.5216608792543411 valid 0.422362788887081
LOSS train 0.5216608792543411 valid 0.4223744590780628
LOSS train 0.5216608792543411 valid 0.42238473191502546
LOSS train 0.5216608792543411 valid 0.42237949459772084
LOSS train 0.5216608792543411 valid 0.4224312143212945
LOSS train 0.5216608792543411 valid 0.42234534737283147
LOSS train 0.5216608792543411 valid 0.4223426939810024
LOSS train 0.5216608792543411 valid 0.4222434792350814
LOSS train 0.5216608792543411 valid 0.42213559734542466
LOSS train 0.5216608792543411 valid 0.42214718834651804
LOSS train 0.5216608792543411 valid 0.42219044683977613
LOSS train 0.5216608792543411 valid 0.422237310461376
LOSS train 0.5216608792543411 valid 0.42220259479360084
LOSS train 0.5216608792543411 valid 0.42218565502840094
LOSS train 0.5216608792543411 valid 0.42212724968277177
LOSS train 0.5216608792543411 valid 0.4221447944470326
LOSS train 0.5216608792543411 valid 0.42208120678152355
LOSS train 0.5216608792543411 valid 0.4220521301455647
LOSS train 0.5216608792543411 valid 0.42207716549323365
LOSS train 0.5216608792543411 valid 0.4221693772938704
LOSS train 0.5216608792543411 valid 0.4222671130282731
LOSS train 0.5216608792543411 valid 0.4222700707509484
LOSS train 0.5216608792543411 valid 0.42222335507695596
LOSS train 0.5216608792543411 valid 0.42220159605437635
LOSS train 0.5216608792543411 valid 0.4220957087571395
LOSS train 0.5216608792543411 valid 0.4220883705157755
LOSS train 0.5216608792543411 valid 0.4220848359167576
LOSS train 0.5216608792543411 valid 0.42211193514992984
LOSS train 0.5216608792543411 valid 0.4221767695075241
LOSS train 0.5216608792543411 valid 0.42212911865599556
LOSS train 0.5216608792543411 valid 0.4221226359297941
LOSS train 0.5216608792543411 valid 0.42217184721607054
LOSS train 0.5216608792543411 valid 0.4221153174593149
LOSS train 0.5216608792543411 valid 0.4220626381015258
LOSS train 0.5216608792543411 valid 0.4220485798204723
LOSS train 0.5216608792543411 valid 0.4220632760505366
EPOCH 8:
  batch 1 loss: 0.4952963888645172
  batch 2 loss: 0.5004528909921646
  batch 3 loss: 0.5069884757200877
  batch 4 loss: 0.5176607295870781
  batch 5 loss: 0.5158900201320649
  batch 6 loss: 0.5141699562470118
  batch 7 loss: 0.5137740416186196
  batch 8 loss: 0.5148702748119831
  batch 9 loss: 0.5154818991820017
  batch 10 loss: 0.5167966395616531
  batch 11 loss: 0.5164880508726294
  batch 12 loss: 0.5160680537422498
  batch 13 loss: 0.515186037008579
  batch 14 loss: 0.5161616738353457
  batch 15 loss: 0.5155843595663706
  batch 16 loss: 0.5145266409963369
  batch 17 loss: 0.5134467009235831
  batch 18 loss: 0.5123988538980484
  batch 19 loss: 0.5125917462926162
  batch 20 loss: 0.5125259354710578
  batch 21 loss: 0.513319323460261
  batch 22 loss: 0.512661948800087
  batch 23 loss: 0.5130936801433563
  batch 24 loss: 0.5128368251025677
  batch 25 loss: 0.5129914009571075
  batch 26 loss: 0.5125404745340347
  batch 27 loss: 0.5124450822671255
  batch 28 loss: 0.5112603966678891
  batch 29 loss: 0.511814583992136
  batch 30 loss: 0.5111723115046819
  batch 31 loss: 0.510801968074614
  batch 32 loss: 0.511282647959888
  batch 33 loss: 0.5118336921388452
  batch 34 loss: 0.5118953962536419
  batch 35 loss: 0.5129545714173999
  batch 36 loss: 0.5134072626630465
  batch 37 loss: 0.5140914167906787
  batch 38 loss: 0.5143490300366753
  batch 39 loss: 0.5147289534409841
  batch 40 loss: 0.5142911963164807
  batch 41 loss: 0.5138569786781217
  batch 42 loss: 0.5141254102899915
  batch 43 loss: 0.5141544764818147
  batch 44 loss: 0.514247751371427
  batch 45 loss: 0.5146362947093116
  batch 46 loss: 0.5144974608784136
  batch 47 loss: 0.5145117824381971
  batch 48 loss: 0.5139165930449963
  batch 49 loss: 0.5133985280990601
  batch 50 loss: 0.5132686114311218
  batch 51 loss: 0.5127054932070714
  batch 52 loss: 0.5129927866733991
  batch 53 loss: 0.5132586359977722
  batch 54 loss: 0.5135703086853027
  batch 55 loss: 0.5131444085728039
  batch 56 loss: 0.512297052357878
  batch 57 loss: 0.5121416773712426
  batch 58 loss: 0.512636149751729
  batch 59 loss: 0.5122468966548726
  batch 60 loss: 0.5118861362338066
  batch 61 loss: 0.5117339291533486
  batch 62 loss: 0.5126067443240073
  batch 63 loss: 0.512808025356323
  batch 64 loss: 0.513571445364505
  batch 65 loss: 0.5130431711673736
  batch 66 loss: 0.5132234489375894
  batch 67 loss: 0.5136041227561324
  batch 68 loss: 0.5136269291534143
  batch 69 loss: 0.513470353855603
  batch 70 loss: 0.5132743609803063
  batch 71 loss: 0.5134662973209166
  batch 72 loss: 0.5131967907978429
  batch 73 loss: 0.513274953381656
  batch 74 loss: 0.5128658280984776
  batch 75 loss: 0.5127186930179596
  batch 76 loss: 0.5128797602496649
  batch 77 loss: 0.5128375326658224
  batch 78 loss: 0.5122925918071698
  batch 79 loss: 0.5126767660243602
  batch 80 loss: 0.5125896234065295
  batch 81 loss: 0.5130460427867042
  batch 82 loss: 0.513463474264959
  batch 83 loss: 0.5135602021073721
  batch 84 loss: 0.5137340046820187
  batch 85 loss: 0.5136604256489697
  batch 86 loss: 0.5141867624465809
  batch 87 loss: 0.5140400881739868
  batch 88 loss: 0.5134366381574761
  batch 89 loss: 0.5135400191451727
  batch 90 loss: 0.5135305566920174
  batch 91 loss: 0.513973206936658
  batch 92 loss: 0.5137416445042776
  batch 93 loss: 0.513524087526465
  batch 94 loss: 0.5135960743782368
  batch 95 loss: 0.5137352868130333
  batch 96 loss: 0.5138781797140837
  batch 97 loss: 0.514231703330561
  batch 98 loss: 0.5145574777710195
  batch 99 loss: 0.5143089137896143
  batch 100 loss: 0.514399299621582
  batch 101 loss: 0.5144451225158011
  batch 102 loss: 0.5144678570476233
  batch 103 loss: 0.5145971746120638
  batch 104 loss: 0.5146608278155327
  batch 105 loss: 0.5144144478298369
  batch 106 loss: 0.514667938340385
  batch 107 loss: 0.5147293338151736
  batch 108 loss: 0.5145966471345337
  batch 109 loss: 0.5149171407069635
  batch 110 loss: 0.5152711228890853
  batch 111 loss: 0.5153564676508173
  batch 112 loss: 0.5153549467878682
  batch 113 loss: 0.5157126604983236
  batch 114 loss: 0.5161977243005184
  batch 115 loss: 0.516188074713168
  batch 116 loss: 0.5163683249004956
  batch 117 loss: 0.5165398059747158
  batch 118 loss: 0.5167538998490673
  batch 119 loss: 0.5165467695528719
  batch 120 loss: 0.5164692061642806
  batch 121 loss: 0.5161460372042065
  batch 122 loss: 0.5159052991476215
  batch 123 loss: 0.5155912836392721
  batch 124 loss: 0.5157385641528714
  batch 125 loss: 0.515512065410614
  batch 126 loss: 0.5154398883145953
  batch 127 loss: 0.5157466718531031
  batch 128 loss: 0.5154851893894374
  batch 129 loss: 0.5152758928232415
  batch 130 loss: 0.5153334397536058
  batch 131 loss: 0.5156477789842445
  batch 132 loss: 0.5158233520659533
  batch 133 loss: 0.5160087521811177
  batch 134 loss: 0.5160054017358752
  batch 135 loss: 0.5160124809653671
  batch 136 loss: 0.5159116786192445
  batch 137 loss: 0.5159777033067968
  batch 138 loss: 0.5163256564865941
  batch 139 loss: 0.516246815379575
  batch 140 loss: 0.5160667774932725
  batch 141 loss: 0.5161525571177191
  batch 142 loss: 0.5160894664660306
  batch 143 loss: 0.5159894488491379
  batch 144 loss: 0.5158804810295502
  batch 145 loss: 0.5158391979233972
  batch 146 loss: 0.5156764818789208
  batch 147 loss: 0.5156276828172256
  batch 148 loss: 0.5156749754741385
  batch 149 loss: 0.5156820502457202
  batch 150 loss: 0.5154177886247635
  batch 151 loss: 0.5151596870643413
  batch 152 loss: 0.5154275482422427
  batch 153 loss: 0.5153674413176144
  batch 154 loss: 0.5154269109298657
  batch 155 loss: 0.5154648111712548
  batch 156 loss: 0.5154520899821551
  batch 157 loss: 0.5156249962035259
  batch 158 loss: 0.5155847623378416
  batch 159 loss: 0.5155512214456714
  batch 160 loss: 0.515709824860096
  batch 161 loss: 0.5157389559360764
  batch 162 loss: 0.5158357583446267
  batch 163 loss: 0.5157136608120854
  batch 164 loss: 0.5156800963166284
  batch 165 loss: 0.5155497820088357
  batch 166 loss: 0.5157693547297673
  batch 167 loss: 0.5156760167575882
  batch 168 loss: 0.5159039690735794
  batch 169 loss: 0.5157889261753601
  batch 170 loss: 0.5157768936718211
  batch 171 loss: 0.5156570324423717
  batch 172 loss: 0.5157893258471822
  batch 173 loss: 0.5156920130197713
  batch 174 loss: 0.515762891063745
  batch 175 loss: 0.5156245570523398
  batch 176 loss: 0.515594978054816
  batch 177 loss: 0.5154786593159714
  batch 178 loss: 0.5155520206421949
  batch 179 loss: 0.5155859591241655
  batch 180 loss: 0.5155065183838209
  batch 181 loss: 0.5155504482556443
  batch 182 loss: 0.5155999213457108
  batch 183 loss: 0.5155293617417903
  batch 184 loss: 0.5154443786520025
  batch 185 loss: 0.5155073364038725
  batch 186 loss: 0.5154661787773973
  batch 187 loss: 0.5153412455543477
  batch 188 loss: 0.5154080746021676
  batch 189 loss: 0.5152452225407596
  batch 190 loss: 0.5151168355816289
  batch 191 loss: 0.5152161823517365
  batch 192 loss: 0.5151558633272847
  batch 193 loss: 0.5150429263633768
  batch 194 loss: 0.5149973335954332
  batch 195 loss: 0.5151722266123845
  batch 196 loss: 0.5151230224541256
  batch 197 loss: 0.5152244262283828
  batch 198 loss: 0.5153411641867474
  batch 199 loss: 0.5152465437524881
  batch 200 loss: 0.5153016689419746
  batch 201 loss: 0.5153768866216365
  batch 202 loss: 0.5154450904614855
  batch 203 loss: 0.5155399653124692
  batch 204 loss: 0.5154768108737235
  batch 205 loss: 0.5154274859079501
  batch 206 loss: 0.5154769137067702
  batch 207 loss: 0.5154881707712072
  batch 208 loss: 0.5153350082154458
  batch 209 loss: 0.5152633004781733
  batch 210 loss: 0.5152358435449146
  batch 211 loss: 0.5153161462449349
  batch 212 loss: 0.5154309871624101
  batch 213 loss: 0.5154487504645693
  batch 214 loss: 0.5153720693610538
  batch 215 loss: 0.5151070375775182
  batch 216 loss: 0.5150087823470434
  batch 217 loss: 0.5149222738731841
  batch 218 loss: 0.5148358813939838
  batch 219 loss: 0.5146956570344429
  batch 220 loss: 0.514751847088337
  batch 221 loss: 0.5147848381445959
  batch 222 loss: 0.5149394567753818
  batch 223 loss: 0.5150099157485192
  batch 224 loss: 0.5149232432512301
  batch 225 loss: 0.5149554190370772
  batch 226 loss: 0.5149925384110055
  batch 227 loss: 0.5148767626758189
  batch 228 loss: 0.5149659629453692
  batch 229 loss: 0.5148959051833923
  batch 230 loss: 0.5149603015702704
  batch 231 loss: 0.5149472646124951
  batch 232 loss: 0.5147896091742762
  batch 233 loss: 0.5147255762708034
  batch 234 loss: 0.5146809257248528
  batch 235 loss: 0.5147139619005487
  batch 236 loss: 0.5146464023549678
  batch 237 loss: 0.5146775648060731
  batch 238 loss: 0.5147131340844291
  batch 239 loss: 0.514528548617742
  batch 240 loss: 0.5145784561832746
  batch 241 loss: 0.5146497725451141
  batch 242 loss: 0.5145194419651977
  batch 243 loss: 0.5146062347133464
  batch 244 loss: 0.5146266981715062
  batch 245 loss: 0.5147937431627391
  batch 246 loss: 0.5147697341635944
  batch 247 loss: 0.5147693774960784
  batch 248 loss: 0.5148384573478852
  batch 249 loss: 0.5148622781397348
  batch 250 loss: 0.5148687026500702
  batch 251 loss: 0.5148850674648209
  batch 252 loss: 0.5149437028264242
  batch 253 loss: 0.5149018015314939
  batch 254 loss: 0.5148980601096717
  batch 255 loss: 0.5150319482765946
  batch 256 loss: 0.5149189879884943
  batch 257 loss: 0.5149832039723601
  batch 258 loss: 0.5150098152631937
  batch 259 loss: 0.5149032709451256
  batch 260 loss: 0.5148750432408773
  batch 261 loss: 0.5149516660820022
  batch 262 loss: 0.5148551379906312
  batch 263 loss: 0.5148063791568741
  batch 264 loss: 0.514810978688977
  batch 265 loss: 0.5147851140993946
  batch 266 loss: 0.5148186224295681
  batch 267 loss: 0.5148217354374431
  batch 268 loss: 0.5147364874606701
  batch 269 loss: 0.5147739880368613
  batch 270 loss: 0.5148153551198819
  batch 271 loss: 0.5148278317548252
  batch 272 loss: 0.5149081646300414
  batch 273 loss: 0.5148904038654579
  batch 274 loss: 0.5147577552464757
  batch 275 loss: 0.5149232060259039
  batch 276 loss: 0.5150249628485113
  batch 277 loss: 0.5150754548582359
  batch 278 loss: 0.5150529915909116
  batch 279 loss: 0.5150499501963243
  batch 280 loss: 0.5148689048630851
  batch 281 loss: 0.514811677864862
  batch 282 loss: 0.5146509635110273
  batch 283 loss: 0.5145911496435375
  batch 284 loss: 0.5146138470777324
  batch 285 loss: 0.5145190161571168
  batch 286 loss: 0.5144917754443376
  batch 287 loss: 0.5145185739321161
  batch 288 loss: 0.5143025261867378
  batch 289 loss: 0.5144856096757737
  batch 290 loss: 0.514355077414677
  batch 291 loss: 0.5143436259010813
  batch 292 loss: 0.5144700620272388
  batch 293 loss: 0.5145119927035257
  batch 294 loss: 0.5144183949953844
  batch 295 loss: 0.5146119738029221
  batch 296 loss: 0.5147081845112749
  batch 297 loss: 0.5147878997253649
  batch 298 loss: 0.5148143130260826
  batch 299 loss: 0.5148921010884951
  batch 300 loss: 0.5150002141793569
  batch 301 loss: 0.515001330462801
  batch 302 loss: 0.5149551961595649
  batch 303 loss: 0.5149345449095118
  batch 304 loss: 0.5149022030987238
  batch 305 loss: 0.5146705510186367
  batch 306 loss: 0.5147547480327631
  batch 307 loss: 0.5146847758502836
  batch 308 loss: 0.5146061945464704
  batch 309 loss: 0.514668830486563
  batch 310 loss: 0.5146364289906717
  batch 311 loss: 0.5146410109720813
  batch 312 loss: 0.5146784473879215
  batch 313 loss: 0.5147649012625027
  batch 314 loss: 0.514821160086401
  batch 315 loss: 0.5148264306878286
  batch 316 loss: 0.5147507915013954
  batch 317 loss: 0.5148248523943808
  batch 318 loss: 0.5147697741880357
  batch 319 loss: 0.5145832664540568
  batch 320 loss: 0.5145953007042408
  batch 321 loss: 0.5145579140134319
  batch 322 loss: 0.5145701203287018
  batch 323 loss: 0.5144868530909712
  batch 324 loss: 0.5143494612456839
  batch 325 loss: 0.5143396114386045
  batch 326 loss: 0.5142601665360796
  batch 327 loss: 0.5142317608408972
  batch 328 loss: 0.5140975125860877
  batch 329 loss: 0.5141917933627828
  batch 330 loss: 0.5141413727492997
  batch 331 loss: 0.5140480279382262
  batch 332 loss: 0.5140145073633596
  batch 333 loss: 0.5139472474744012
  batch 334 loss: 0.5137736455587569
  batch 335 loss: 0.513738438531534
  batch 336 loss: 0.5136865563690662
  batch 337 loss: 0.5136245976392876
  batch 338 loss: 0.5135709625729442
  batch 339 loss: 0.5136982534838989
  batch 340 loss: 0.5136893803582472
  batch 341 loss: 0.5136909769776979
  batch 342 loss: 0.513620682365713
  batch 343 loss: 0.5135670762194141
  batch 344 loss: 0.5135702668407629
  batch 345 loss: 0.51369354163391
  batch 346 loss: 0.5136476941191392
  batch 347 loss: 0.5137111917352813
  batch 348 loss: 0.5137250378899191
  batch 349 loss: 0.5136226938242215
  batch 350 loss: 0.5136707854270935
  batch 351 loss: 0.5136387524781404
  batch 352 loss: 0.5136865394359286
  batch 353 loss: 0.5135690838351804
  batch 354 loss: 0.5136159527099738
  batch 355 loss: 0.5137192794974421
  batch 356 loss: 0.5136796051866552
  batch 357 loss: 0.5136806971552659
  batch 358 loss: 0.5136937602272247
  batch 359 loss: 0.5137449502944946
  batch 360 loss: 0.5137856052981482
  batch 361 loss: 0.5138158122918612
  batch 362 loss: 0.5137028867039233
  batch 363 loss: 0.513674607946853
  batch 364 loss: 0.5135603064036631
  batch 365 loss: 0.5135788156561656
  batch 366 loss: 0.5134579159848677
  batch 367 loss: 0.5134100404844621
  batch 368 loss: 0.5133699746397526
  batch 369 loss: 0.5133946873146668
  batch 370 loss: 0.5134634566468161
  batch 371 loss: 0.513598163413873
  batch 372 loss: 0.5134790519713074
  batch 373 loss: 0.5133938630368691
  batch 374 loss: 0.5133093384338573
  batch 375 loss: 0.513323723713557
  batch 376 loss: 0.5133533299444838
  batch 377 loss: 0.51329436740129
  batch 378 loss: 0.5132348049412329
  batch 379 loss: 0.5131824982984085
  batch 380 loss: 0.5132690890054954
  batch 381 loss: 0.5131665346972899
  batch 382 loss: 0.5130213488927062
  batch 383 loss: 0.5130095658507733
  batch 384 loss: 0.5129996936302632
  batch 385 loss: 0.5130798405641085
  batch 386 loss: 0.5130023337862034
  batch 387 loss: 0.5129593593051576
  batch 388 loss: 0.5129817052139449
  batch 389 loss: 0.5129784968487707
  batch 390 loss: 0.5130309166816565
  batch 391 loss: 0.5129748949461885
  batch 392 loss: 0.5129800555201209
  batch 393 loss: 0.5130364106963305
  batch 394 loss: 0.5130429099205182
  batch 395 loss: 0.5130693373046343
  batch 396 loss: 0.5131145317596618
  batch 397 loss: 0.5130313767744251
  batch 398 loss: 0.5130020514055712
  batch 399 loss: 0.5130071209038708
  batch 400 loss: 0.5129500111937523
  batch 401 loss: 0.512918933222716
  batch 402 loss: 0.5129930043398444
  batch 403 loss: 0.5129281807478249
  batch 404 loss: 0.5128903183163983
  batch 405 loss: 0.5128386287041652
  batch 406 loss: 0.5128901288133537
  batch 407 loss: 0.5128900048480866
  batch 408 loss: 0.5129838569783697
  batch 409 loss: 0.5129802009878648
  batch 410 loss: 0.5130132225955405
  batch 411 loss: 0.5129963133456933
  batch 412 loss: 0.5129728085786394
  batch 413 loss: 0.5129508963508699
  batch 414 loss: 0.5129270432651907
  batch 415 loss: 0.5129229381860021
  batch 416 loss: 0.5128892564143126
  batch 417 loss: 0.5128508396000028
  batch 418 loss: 0.5128533426654396
  batch 419 loss: 0.5128548256252716
  batch 420 loss: 0.5128611276547114
  batch 421 loss: 0.5128488224928849
  batch 422 loss: 0.5129316039559966
  batch 423 loss: 0.5129624896861137
  batch 424 loss: 0.5129558361082707
  batch 425 loss: 0.5129722386247971
  batch 426 loss: 0.5129301217800015
  batch 427 loss: 0.5129530661558379
  batch 428 loss: 0.5128885369016746
  batch 429 loss: 0.5128511578053028
  batch 430 loss: 0.5128690532473631
  batch 431 loss: 0.5130132573663221
  batch 432 loss: 0.5130420891499078
  batch 433 loss: 0.512960494115226
  batch 434 loss: 0.5129852908822249
  batch 435 loss: 0.5129408941871818
  batch 436 loss: 0.512908768763236
  batch 437 loss: 0.5129343535861925
  batch 438 loss: 0.5129944429005662
  batch 439 loss: 0.5129770965130834
  batch 440 loss: 0.5129945287650282
  batch 441 loss: 0.5129497545241228
  batch 442 loss: 0.5129681830357642
  batch 443 loss: 0.5129344442493491
  batch 444 loss: 0.5128574927782154
  batch 445 loss: 0.5129104928354199
  batch 446 loss: 0.5128712392842288
  batch 447 loss: 0.512813523311743
  batch 448 loss: 0.5129215110625539
  batch 449 loss: 0.5129754391969711
  batch 450 loss: 0.51302463610967
  batch 451 loss: 0.5130495044450274
  batch 452 loss: 0.5130884196378488
  batch 453 loss: 0.5131149531463387
  batch 454 loss: 0.5131215791870319
  batch 455 loss: 0.5131227979293236
  batch 456 loss: 0.5131095468736532
  batch 457 loss: 0.5131413751410185
  batch 458 loss: 0.5131037017924296
  batch 459 loss: 0.5131291934088165
  batch 460 loss: 0.5132404053988664
  batch 461 loss: 0.5132523093720062
  batch 462 loss: 0.51321306644064
  batch 463 loss: 0.5131965046567485
  batch 464 loss: 0.5132383182644844
  batch 465 loss: 0.5131161630794566
  batch 466 loss: 0.5130272837667507
  batch 467 loss: 0.5130576439026336
  batch 468 loss: 0.5129805052509675
  batch 469 loss: 0.5129661506045856
  batch 470 loss: 0.5129399546283356
  batch 471 loss: 0.5129113523190695
  batch 472 loss: 0.5128449454145917
LOSS train 0.5128449454145917 valid 0.37770605087280273
LOSS train 0.5128449454145917 valid 0.3591570556163788
LOSS train 0.5128449454145917 valid 0.3775200645128886
LOSS train 0.5128449454145917 valid 0.37523147463798523
LOSS train 0.5128449454145917 valid 0.37444711923599244
LOSS train 0.5128449454145917 valid 0.37671540180842084
LOSS train 0.5128449454145917 valid 0.37587484291621615
LOSS train 0.5128449454145917 valid 0.37491778284311295
LOSS train 0.5128449454145917 valid 0.37173061238394844
LOSS train 0.5128449454145917 valid 0.37490456700325014
LOSS train 0.5128449454145917 valid 0.3772283684123646
LOSS train 0.5128449454145917 valid 0.37774524092674255
LOSS train 0.5128449454145917 valid 0.380925721847094
LOSS train 0.5128449454145917 valid 0.3812690036637442
LOSS train 0.5128449454145917 valid 0.38040255109469095
LOSS train 0.5128449454145917 valid 0.3816581107676029
LOSS train 0.5128449454145917 valid 0.384088851073209
LOSS train 0.5128449454145917 valid 0.3851715640889274
LOSS train 0.5128449454145917 valid 0.3853824985654731
LOSS train 0.5128449454145917 valid 0.3869124993681908
LOSS train 0.5128449454145917 valid 0.38671181741214933
LOSS train 0.5128449454145917 valid 0.3846296491948041
LOSS train 0.5128449454145917 valid 0.38583435053410736
LOSS train 0.5128449454145917 valid 0.3852241796751817
LOSS train 0.5128449454145917 valid 0.38513670444488524
LOSS train 0.5128449454145917 valid 0.38471785073096937
LOSS train 0.5128449454145917 valid 0.3840661953996729
LOSS train 0.5128449454145917 valid 0.3838515430688858
LOSS train 0.5128449454145917 valid 0.3839507257116252
LOSS train 0.5128449454145917 valid 0.3847131848335266
LOSS train 0.5128449454145917 valid 0.38614536773773933
LOSS train 0.5128449454145917 valid 0.38584289140999317
LOSS train 0.5128449454145917 valid 0.38663284345106647
LOSS train 0.5128449454145917 valid 0.3861394787535948
LOSS train 0.5128449454145917 valid 0.386896447624479
LOSS train 0.5128449454145917 valid 0.38675565603706574
LOSS train 0.5128449454145917 valid 0.38729305686177434
LOSS train 0.5128449454145917 valid 0.3884178682377464
LOSS train 0.5128449454145917 valid 0.38821963774852264
LOSS train 0.5128449454145917 valid 0.3897099122405052
LOSS train 0.5128449454145917 valid 0.38968608001383337
LOSS train 0.5128449454145917 valid 0.3907180187248048
LOSS train 0.5128449454145917 valid 0.3905123493006063
LOSS train 0.5128449454145917 valid 0.3906710384921594
LOSS train 0.5128449454145917 valid 0.3910293241341909
LOSS train 0.5128449454145917 valid 0.3915053541245668
LOSS train 0.5128449454145917 valid 0.3912795807452912
LOSS train 0.5128449454145917 valid 0.391514515504241
LOSS train 0.5128449454145917 valid 0.39211673213511095
LOSS train 0.5128449454145917 valid 0.39132833778858184
LOSS train 0.5128449454145917 valid 0.3918381257384431
LOSS train 0.5128449454145917 valid 0.3915056144961944
LOSS train 0.5128449454145917 valid 0.39107726879839627
LOSS train 0.5128449454145917 valid 0.3911143055668584
LOSS train 0.5128449454145917 valid 0.3908226191997528
LOSS train 0.5128449454145917 valid 0.39079974964261055
LOSS train 0.5128449454145917 valid 0.3904693811609034
LOSS train 0.5128449454145917 valid 0.3902870637589487
LOSS train 0.5128449454145917 valid 0.3908033987223092
LOSS train 0.5128449454145917 valid 0.3902599612871806
LOSS train 0.5128449454145917 valid 0.38912061980513274
LOSS train 0.5128449454145917 valid 0.3899867630773975
LOSS train 0.5128449454145917 valid 0.39051616854137844
LOSS train 0.5128449454145917 valid 0.3910939134657383
LOSS train 0.5128449454145917 valid 0.3911990069426023
LOSS train 0.5128449454145917 valid 0.39120296682372235
LOSS train 0.5128449454145917 valid 0.3908477287683914
LOSS train 0.5128449454145917 valid 0.39024461148416295
LOSS train 0.5128449454145917 valid 0.39005267965620843
LOSS train 0.5128449454145917 valid 0.38972698875835965
LOSS train 0.5128449454145917 valid 0.38928635271502215
LOSS train 0.5128449454145917 valid 0.3892899002465937
LOSS train 0.5128449454145917 valid 0.3896942134589365
LOSS train 0.5128449454145917 valid 0.3894746045808534
LOSS train 0.5128449454145917 valid 0.3889876381556193
LOSS train 0.5128449454145917 valid 0.38931691019158615
LOSS train 0.5128449454145917 valid 0.38902449298214603
LOSS train 0.5128449454145917 valid 0.3889585454494525
LOSS train 0.5128449454145917 valid 0.38897189158427564
LOSS train 0.5128449454145917 valid 0.388848002627492
LOSS train 0.5128449454145917 valid 0.38824399606681165
LOSS train 0.5128449454145917 valid 0.38837652598939293
LOSS train 0.5128449454145917 valid 0.3881063138145998
LOSS train 0.5128449454145917 valid 0.38830602381910595
LOSS train 0.5128449454145917 valid 0.3885410463108736
LOSS train 0.5128449454145917 valid 0.38822897610276247
LOSS train 0.5128449454145917 valid 0.38823003981305265
LOSS train 0.5128449454145917 valid 0.3876568387177857
LOSS train 0.5128449454145917 valid 0.38776339540320837
LOSS train 0.5128449454145917 valid 0.38755741715431213
LOSS train 0.5128449454145917 valid 0.3873299117926713
LOSS train 0.5128449454145917 valid 0.3871325277115988
LOSS train 0.5128449454145917 valid 0.3867041491052156
LOSS train 0.5128449454145917 valid 0.3863513615537197
LOSS train 0.5128449454145917 valid 0.3860467942137467
LOSS train 0.5128449454145917 valid 0.38627195979158085
LOSS train 0.5128449454145917 valid 0.38659292459487915
LOSS train 0.5128449454145917 valid 0.38649809390914686
LOSS train 0.5128449454145917 valid 0.3865505631523903
LOSS train 0.5128449454145917 valid 0.3867709523439407
LOSS train 0.5128449454145917 valid 0.3867865706434344
LOSS train 0.5128449454145917 valid 0.38692091785225213
LOSS train 0.5128449454145917 valid 0.38737495431622254
LOSS train 0.5128449454145917 valid 0.3872645686452205
LOSS train 0.5128449454145917 valid 0.3870675189154489
LOSS train 0.5128449454145917 valid 0.3870905469048698
LOSS train 0.5128449454145917 valid 0.38688100721234475
LOSS train 0.5128449454145917 valid 0.3871916088241118
LOSS train 0.5128449454145917 valid 0.3872282469491346
LOSS train 0.5128449454145917 valid 0.38737809143283153
LOSS train 0.5128449454145917 valid 0.38727977603405445
LOSS train 0.5128449454145917 valid 0.3872319281633411
LOSS train 0.5128449454145917 valid 0.38723270951119143
LOSS train 0.5128449454145917 valid 0.38718135236648094
LOSS train 0.5128449454145917 valid 0.38726715030877484
LOSS train 0.5128449454145917 valid 0.3871991552155593
LOSS train 0.5128449454145917 valid 0.38732771180633807
LOSS train 0.5128449454145917 valid 0.3870439865326477
LOSS train 0.5128449454145917 valid 0.38692204917178435
LOSS train 0.5128449454145917 valid 0.3867733674744765
LOSS train 0.5128449454145917 valid 0.38674221403342635
LOSS train 0.5128449454145917 valid 0.3867367823592952
LOSS train 0.5128449454145917 valid 0.38685556325486037
LOSS train 0.5128449454145917 valid 0.38709572173895374
LOSS train 0.5128449454145917 valid 0.38693500018119814
LOSS train 0.5128449454145917 valid 0.38672036003498805
LOSS train 0.5128449454145917 valid 0.3873022400488065
LOSS train 0.5128449454145917 valid 0.3874870219733566
LOSS train 0.5128449454145917 valid 0.38764896780945535
LOSS train 0.5128449454145917 valid 0.3874627390733132
LOSS train 0.5128449454145917 valid 0.38743313373500154
LOSS train 0.5128449454145917 valid 0.3874079506054069
LOSS train 0.5128449454145917 valid 0.3872094862443164
LOSS train 0.5128449454145917 valid 0.38747409453142934
LOSS train 0.5128449454145917 valid 0.387690931558609
LOSS train 0.5128449454145917 valid 0.3875144218258998
LOSS train 0.5128449454145917 valid 0.38733455408228573
LOSS train 0.5128449454145917 valid 0.38723690505476965
LOSS train 0.5128449454145917 valid 0.3869732026573565
LOSS train 0.5128449454145917 valid 0.38718206201280864
LOSS train 0.5128449454145917 valid 0.38729858694347086
LOSS train 0.5128449454145917 valid 0.38773199936873476
LOSS train 0.5128449454145917 valid 0.38762389717402157
LOSS train 0.5128449454145917 valid 0.3878421512328916
LOSS train 0.5128449454145917 valid 0.3878117205767796
LOSS train 0.5128449454145917 valid 0.38801328715396255
LOSS train 0.5128449454145917 valid 0.3876370438913099
LOSS train 0.5128449454145917 valid 0.387891910768844
LOSS train 0.5128449454145917 valid 0.3880564994459984
LOSS train 0.5128449454145917 valid 0.38808860977490744
LOSS train 0.5128449454145917 valid 0.38817396937616616
LOSS train 0.5128449454145917 valid 0.3880101273718633
LOSS train 0.5128449454145917 valid 0.38820821085786505
LOSS train 0.5128449454145917 valid 0.38821512789695295
LOSS train 0.5128449454145917 valid 0.3881941149311681
LOSS train 0.5128449454145917 valid 0.3884262855236347
LOSS train 0.5128449454145917 valid 0.38847721496205423
LOSS train 0.5128449454145917 valid 0.38846785961827146
LOSS train 0.5128449454145917 valid 0.3881359823844718
LOSS train 0.5128449454145917 valid 0.38821902722120283
LOSS train 0.5128449454145917 valid 0.3880880432469504
LOSS train 0.5128449454145917 valid 0.3878238508362829
LOSS train 0.5128449454145917 valid 0.38780833881325516
LOSS train 0.5128449454145917 valid 0.3877662322143229
LOSS train 0.5128449454145917 valid 0.38769088983535765
LOSS train 0.5128449454145917 valid 0.38754796066198005
LOSS train 0.5128449454145917 valid 0.38757772235099425
LOSS train 0.5128449454145917 valid 0.38773557845325696
LOSS train 0.5128449454145917 valid 0.3877849629997502
LOSS train 0.5128449454145917 valid 0.3880995503243278
LOSS train 0.5128449454145917 valid 0.38806922812210887
LOSS train 0.5128449454145917 valid 0.38814635938683223
LOSS train 0.5128449454145917 valid 0.38838595479209986
LOSS train 0.5128449454145917 valid 0.38831456382384244
LOSS train 0.5128449454145917 valid 0.38825754727636064
LOSS train 0.5128449454145917 valid 0.38804637488316407
LOSS train 0.5128449454145917 valid 0.38824119928192957
LOSS train 0.5128449454145917 valid 0.38836233652709573
LOSS train 0.5128449454145917 valid 0.38824391015415083
LOSS train 0.5128449454145917 valid 0.3884016422761811
LOSS train 0.5128449454145917 valid 0.3884469027018679
LOSS train 0.5128449454145917 valid 0.3885335663517753
LOSS train 0.5128449454145917 valid 0.3884931356529069
LOSS train 0.5128449454145917 valid 0.3885869646201963
LOSS train 0.5128449454145917 valid 0.38855140982447445
LOSS train 0.5128449454145917 valid 0.38856478051472737
LOSS train 0.5128449454145917 valid 0.3886183439729048
LOSS train 0.5128449454145917 valid 0.38864131366952936
LOSS train 0.5128449454145917 valid 0.38862219342479
LOSS train 0.5128449454145917 valid 0.3885250822493905
LOSS train 0.5128449454145917 valid 0.3887908324521249
LOSS train 0.5128449454145917 valid 0.3888336014933884
LOSS train 0.5128449454145917 valid 0.38880570518538127
LOSS train 0.5128449454145917 valid 0.3886694653132527
LOSS train 0.5128449454145917 valid 0.3885935659591968
LOSS train 0.5128449454145917 valid 0.3885845750266192
LOSS train 0.5128449454145917 valid 0.3887316687458058
LOSS train 0.5128449454145917 valid 0.38876019945048323
LOSS train 0.5128449454145917 valid 0.38875046327485513
LOSS train 0.5128449454145917 valid 0.38874908089637755
LOSS train 0.5128449454145917 valid 0.38861781447681026
LOSS train 0.5128449454145917 valid 0.3887424224083967
LOSS train 0.5128449454145917 valid 0.3885211834472976
LOSS train 0.5128449454145917 valid 0.3884273529344914
LOSS train 0.5128449454145917 valid 0.38845585919008024
LOSS train 0.5128449454145917 valid 0.388383625635823
LOSS train 0.5128449454145917 valid 0.3885293186862688
LOSS train 0.5128449454145917 valid 0.38852025024019754
LOSS train 0.5128449454145917 valid 0.3884461713179447
LOSS train 0.5128449454145917 valid 0.3884778122107188
LOSS train 0.5128449454145917 valid 0.3884161987575874
LOSS train 0.5128449454145917 valid 0.3884092887055199
LOSS train 0.5128449454145917 valid 0.38854543983656475
LOSS train 0.5128449454145917 valid 0.3885279554072942
LOSS train 0.5128449454145917 valid 0.3885998717574186
LOSS train 0.5128449454145917 valid 0.38861244544386864
LOSS train 0.5128449454145917 valid 0.3886824273568694
LOSS train 0.5128449454145917 valid 0.3887593470035343
LOSS train 0.5128449454145917 valid 0.3888125657763111
LOSS train 0.5128449454145917 valid 0.38894419819116594
LOSS train 0.5128449454145917 valid 0.38905991553181435
LOSS train 0.5128449454145917 valid 0.38910241344490565
LOSS train 0.5128449454145917 valid 0.389159740621199
LOSS train 0.5128449454145917 valid 0.38917657387043747
LOSS train 0.5128449454145917 valid 0.38920896808306377
LOSS train 0.5128449454145917 valid 0.38914662164396946
LOSS train 0.5128449454145917 valid 0.38926969160067354
LOSS train 0.5128449454145917 valid 0.3893416444199127
LOSS train 0.5128449454145917 valid 0.38942253641686586
LOSS train 0.5128449454145917 valid 0.38949516130530315
LOSS train 0.5128449454145917 valid 0.3894564809995296
LOSS train 0.5128449454145917 valid 0.389486548587166
LOSS train 0.5128449454145917 valid 0.38938290328426933
LOSS train 0.5128449454145917 valid 0.3893648591051754
LOSS train 0.5128449454145917 valid 0.38943999447721117
LOSS train 0.5128449454145917 valid 0.3894510110050945
LOSS train 0.5128449454145917 valid 0.38938419074448855
LOSS train 0.5128449454145917 valid 0.38937392004397736
LOSS train 0.5128449454145917 valid 0.38928807031160617
LOSS train 0.5128449454145917 valid 0.38918530382215977
LOSS train 0.5128449454145917 valid 0.3893351970371864
LOSS train 0.5128449454145917 valid 0.38925751477233633
LOSS train 0.5128449454145917 valid 0.3892592129148083
LOSS train 0.5128449454145917 valid 0.389371356758915
LOSS train 0.5128449454145917 valid 0.3893704491002219
LOSS train 0.5128449454145917 valid 0.3893195663283511
LOSS train 0.5128449454145917 valid 0.38938875876457585
LOSS train 0.5128449454145917 valid 0.389343278422471
LOSS train 0.5128449454145917 valid 0.38937225590748004
LOSS train 0.5128449454145917 valid 0.3895323940515518
LOSS train 0.5128449454145917 valid 0.3895841334683012
LOSS train 0.5128449454145917 valid 0.3897735611313865
LOSS train 0.5128449454145917 valid 0.38971001604800165
LOSS train 0.5128449454145917 valid 0.38986047292788195
LOSS train 0.5128449454145917 valid 0.3897713713786181
LOSS train 0.5128449454145917 valid 0.38978734181728214
LOSS train 0.5128449454145917 valid 0.38974962612534314
LOSS train 0.5128449454145917 valid 0.38984100589918536
LOSS train 0.5128449454145917 valid 0.38981410584854803
LOSS train 0.5128449454145917 valid 0.3897583666902322
LOSS train 0.5128449454145917 valid 0.3897729729555576
LOSS train 0.5128449454145917 valid 0.38970664700933993
LOSS train 0.5128449454145917 valid 0.3896462132042352
LOSS train 0.5128449454145917 valid 0.3896016334042405
LOSS train 0.5128449454145917 valid 0.3896315538658286
LOSS train 0.5128449454145917 valid 0.389717224621235
LOSS train 0.5128449454145917 valid 0.38986231749423883
LOSS train 0.5128449454145917 valid 0.38988525876358376
LOSS train 0.5128449454145917 valid 0.39004616190066566
LOSS train 0.5128449454145917 valid 0.3899761086260831
LOSS train 0.5128449454145917 valid 0.3900756325668954
LOSS train 0.5128449454145917 valid 0.3900882624747122
LOSS train 0.5128449454145917 valid 0.3900208260331835
LOSS train 0.5128449454145917 valid 0.39004249218171533
LOSS train 0.5128449454145917 valid 0.3899680834466761
LOSS train 0.5128449454145917 valid 0.38984429760687594
LOSS train 0.5128449454145917 valid 0.38990070361522994
LOSS train 0.5128449454145917 valid 0.3898119022734731
LOSS train 0.5128449454145917 valid 0.3898617147758443
LOSS train 0.5128449454145917 valid 0.3897901300873075
LOSS train 0.5128449454145917 valid 0.3896721844359225
LOSS train 0.5128449454145917 valid 0.38969794296203775
LOSS train 0.5128449454145917 valid 0.38968807953827794
LOSS train 0.5128449454145917 valid 0.3897693843488962
LOSS train 0.5128449454145917 valid 0.3897325777170951
LOSS train 0.5128449454145917 valid 0.38962369198565716
LOSS train 0.5128449454145917 valid 0.3896240677152361
LOSS train 0.5128449454145917 valid 0.3896316695544455
LOSS train 0.5128449454145917 valid 0.3896205061241005
LOSS train 0.5128449454145917 valid 0.38956069154986017
LOSS train 0.5128449454145917 valid 0.3894230046427946
LOSS train 0.5128449454145917 valid 0.3894170613525665
LOSS train 0.5128449454145917 valid 0.38931529605347953
LOSS train 0.5128449454145917 valid 0.38938823230818015
LOSS train 0.5128449454145917 valid 0.3895363869303364
LOSS train 0.5128449454145917 valid 0.38951390317162954
LOSS train 0.5128449454145917 valid 0.3895437583979533
LOSS train 0.5128449454145917 valid 0.389470954169363
LOSS train 0.5128449454145917 valid 0.38951469165425634
LOSS train 0.5128449454145917 valid 0.38955661257108054
LOSS train 0.5128449454145917 valid 0.3895173056973175
LOSS train 0.5128449454145917 valid 0.3893999510648235
LOSS train 0.5128449454145917 valid 0.3893662893732782
LOSS train 0.5128449454145917 valid 0.3893652793608214
LOSS train 0.5128449454145917 valid 0.3893186295618776
LOSS train 0.5128449454145917 valid 0.38936430254792853
LOSS train 0.5128449454145917 valid 0.38934324269186016
LOSS train 0.5128449454145917 valid 0.38930791732552766
LOSS train 0.5128449454145917 valid 0.38936858809881614
LOSS train 0.5128449454145917 valid 0.38931188871783595
LOSS train 0.5128449454145917 valid 0.3892537698485077
LOSS train 0.5128449454145917 valid 0.3892668819007201
LOSS train 0.5128449454145917 valid 0.3893535726557905
LOSS train 0.5128449454145917 valid 0.38937554171510563
LOSS train 0.5128449454145917 valid 0.389384872288931
LOSS train 0.5128449454145917 valid 0.3892949990267995
LOSS train 0.5128449454145917 valid 0.38932481737166924
LOSS train 0.5128449454145917 valid 0.3893421934273258
LOSS train 0.5128449454145917 valid 0.38931701951266084
LOSS train 0.5128449454145917 valid 0.3892760150134563
LOSS train 0.5128449454145917 valid 0.3893071430680165
LOSS train 0.5128449454145917 valid 0.3892747698733525
LOSS train 0.5128449454145917 valid 0.3892078461477262
LOSS train 0.5128449454145917 valid 0.3891912234234221
LOSS train 0.5128449454145917 valid 0.3891449384505932
LOSS train 0.5128449454145917 valid 0.3891992099080349
LOSS train 0.5128449454145917 valid 0.38931238924691436
LOSS train 0.5128449454145917 valid 0.38927766062864444
LOSS train 0.5128449454145917 valid 0.3892482943991397
LOSS train 0.5128449454145917 valid 0.38918364933042815
LOSS train 0.5128449454145917 valid 0.38915025269517006
LOSS train 0.5128449454145917 valid 0.3890202898217971
LOSS train 0.5128449454145917 valid 0.38902294143542154
LOSS train 0.5128449454145917 valid 0.38909059450654926
LOSS train 0.5128449454145917 valid 0.3891002200432678
LOSS train 0.5128449454145917 valid 0.3890857654845431
LOSS train 0.5128449454145917 valid 0.38908551681996806
LOSS train 0.5128449454145917 valid 0.38913214956162245
LOSS train 0.5128449454145917 valid 0.38905009486682296
LOSS train 0.5128449454145917 valid 0.38906431706512673
LOSS train 0.5128449454145917 valid 0.38895167301127637
LOSS train 0.5128449454145917 valid 0.38884058063141785
LOSS train 0.5128449454145917 valid 0.38886184708022514
LOSS train 0.5128449454145917 valid 0.38894061025145443
LOSS train 0.5128449454145917 valid 0.38901779271554254
LOSS train 0.5128449454145917 valid 0.38898291615392433
LOSS train 0.5128449454145917 valid 0.38895201425387466
LOSS train 0.5128449454145917 valid 0.3888849280346399
LOSS train 0.5128449454145917 valid 0.38890949941979436
LOSS train 0.5128449454145917 valid 0.3888269408260073
LOSS train 0.5128449454145917 valid 0.38879236035537174
LOSS train 0.5128449454145917 valid 0.38882934784686024
LOSS train 0.5128449454145917 valid 0.38891817059462874
LOSS train 0.5128449454145917 valid 0.38901781993733964
LOSS train 0.5128449454145917 valid 0.3890296535592684
LOSS train 0.5128449454145917 valid 0.3889860777875011
LOSS train 0.5128449454145917 valid 0.38896154004986544
LOSS train 0.5128449454145917 valid 0.38888027731266767
LOSS train 0.5128449454145917 valid 0.38887721881228904
LOSS train 0.5128449454145917 valid 0.38888634277714623
LOSS train 0.5128449454145917 valid 0.3889206578526801
LOSS train 0.5128449454145917 valid 0.388996629589829
LOSS train 0.5128449454145917 valid 0.3889357468149222
LOSS train 0.5128449454145917 valid 0.3889281743994126
LOSS train 0.5128449454145917 valid 0.38897551616577253
LOSS train 0.5128449454145917 valid 0.38890375514499476
LOSS train 0.5128449454145917 valid 0.3888394348627865
LOSS train 0.5128449454145917 valid 0.38883318476702855
LOSS train 0.5128449454145917 valid 0.38884027936271215
EPOCH 9:
  batch 1 loss: 0.4891979396343231
  batch 2 loss: 0.48696744441986084
  batch 3 loss: 0.5005712111790975
  batch 4 loss: 0.5126853287220001
  batch 5 loss: 0.5101996064186096
  batch 6 loss: 0.5074376265207926
  batch 7 loss: 0.509292551449367
  batch 8 loss: 0.5097720474004745
  batch 9 loss: 0.5114168723424276
  batch 10 loss: 0.5123417854309082
  batch 11 loss: 0.512275527824055
  batch 12 loss: 0.5099864502747854
  batch 13 loss: 0.5091814215366657
  batch 14 loss: 0.5088743141719273
  batch 15 loss: 0.507824832201004
  batch 16 loss: 0.5080752167850733
  batch 17 loss: 0.507328112335766
  batch 18 loss: 0.5055920465124978
  batch 19 loss: 0.5053670767106508
  batch 20 loss: 0.5046147793531418
  batch 21 loss: 0.5048662197022211
  batch 22 loss: 0.5046004138209603
  batch 23 loss: 0.5047594179277834
  batch 24 loss: 0.5040086085597674
  batch 25 loss: 0.5042755556106567
  batch 26 loss: 0.5035795535032566
  batch 27 loss: 0.5028939070524993
  batch 28 loss: 0.5023143099887031
  batch 29 loss: 0.5024895770796414
  batch 30 loss: 0.5017415682474772
  batch 31 loss: 0.5012346583027993
  batch 32 loss: 0.5019982699304819
  batch 33 loss: 0.5022948203664838
  batch 34 loss: 0.5021061537896886
  batch 35 loss: 0.5036270337445395
  batch 36 loss: 0.5041907702883085
  batch 37 loss: 0.5050233368938034
  batch 38 loss: 0.5054683253953332
  batch 39 loss: 0.5058037508756686
  batch 40 loss: 0.5053743980824947
  batch 41 loss: 0.5051220023050541
  batch 42 loss: 0.5056847511302858
  batch 43 loss: 0.5054945342762526
  batch 44 loss: 0.5057937834750522
  batch 45 loss: 0.5059728152222104
  batch 46 loss: 0.5059971038414084
  batch 47 loss: 0.5064342586283989
  batch 48 loss: 0.5057709844162067
  batch 49 loss: 0.505846598318645
  batch 50 loss: 0.505476171374321
  batch 51 loss: 0.504953600027982
  batch 52 loss: 0.5053805026870507
  batch 53 loss: 0.5057033958300104
  batch 54 loss: 0.5059524658653471
  batch 55 loss: 0.5053853625600988
  batch 56 loss: 0.5045689147497926
  batch 57 loss: 0.5043574524553198
  batch 58 loss: 0.5053370045176868
  batch 59 loss: 0.5051019237203113
  batch 60 loss: 0.5047546411554019
  batch 61 loss: 0.5046319077249433
  batch 62 loss: 0.5054112033497903
  batch 63 loss: 0.5056159027985164
  batch 64 loss: 0.5064541311003268
  batch 65 loss: 0.5060005774864784
  batch 66 loss: 0.5061146580811703
  batch 67 loss: 0.5064472565010413
  batch 68 loss: 0.5064197603394004
  batch 69 loss: 0.5064154500546663
  batch 70 loss: 0.5061268742595401
  batch 71 loss: 0.5063627727434669
  batch 72 loss: 0.5060990597638819
  batch 73 loss: 0.505989088995816
  batch 74 loss: 0.50565444416291
  batch 75 loss: 0.5055267814795176
  batch 76 loss: 0.5057080046910989
  batch 77 loss: 0.5054316799361984
  batch 78 loss: 0.5049133828053107
  batch 79 loss: 0.5054067637346968
  batch 80 loss: 0.5053196590393781
  batch 81 loss: 0.5055595529668125
  batch 82 loss: 0.506019123807186
  batch 83 loss: 0.5063006903033659
  batch 84 loss: 0.5064533420261883
  batch 85 loss: 0.5064135884537416
  batch 86 loss: 0.5070010732079662
  batch 87 loss: 0.5068394099843914
  batch 88 loss: 0.5062397572804581
  batch 89 loss: 0.5063931905151753
  batch 90 loss: 0.506374627020624
  batch 91 loss: 0.5067166053986811
  batch 92 loss: 0.5065260173186011
  batch 93 loss: 0.5062081406834305
  batch 94 loss: 0.5065111850804471
  batch 95 loss: 0.5065053792376267
  batch 96 loss: 0.5068113235756755
  batch 97 loss: 0.5071316272327581
  batch 98 loss: 0.5073936171069438
  batch 99 loss: 0.5072763565212789
  batch 100 loss: 0.5073677691817283
  batch 101 loss: 0.5072374010440146
  batch 102 loss: 0.5073701152030159
  batch 103 loss: 0.5074576634226493
  batch 104 loss: 0.5074714041100099
  batch 105 loss: 0.5071434415522076
  batch 106 loss: 0.5074732458254076
  batch 107 loss: 0.5075580959565171
  batch 108 loss: 0.5074449330568314
  batch 109 loss: 0.5077993656517169
  batch 110 loss: 0.5081860374320637
  batch 111 loss: 0.5082920650104145
  batch 112 loss: 0.5083293808358056
  batch 113 loss: 0.5087642279346433
  batch 114 loss: 0.5091951824071115
  batch 115 loss: 0.5091779283855272
  batch 116 loss: 0.5093216803567163
  batch 117 loss: 0.5094881511142111
  batch 118 loss: 0.5096401466151416
  batch 119 loss: 0.5094851906560048
  batch 120 loss: 0.5095021580656369
  batch 121 loss: 0.5091869402522883
  batch 122 loss: 0.5089086856021255
  batch 123 loss: 0.5085541547798529
  batch 124 loss: 0.5087780466964168
  batch 125 loss: 0.5085651576519012
  batch 126 loss: 0.5083602607723267
  batch 127 loss: 0.5086989503676497
  batch 128 loss: 0.5083780223503709
  batch 129 loss: 0.5082296562749286
  batch 130 loss: 0.5082741838235122
  batch 131 loss: 0.5086154364447557
  batch 132 loss: 0.5087683142134638
  batch 133 loss: 0.5088336696302084
  batch 134 loss: 0.5088092626920387
  batch 135 loss: 0.5087804096716422
  batch 136 loss: 0.5086579408277484
  batch 137 loss: 0.508735797918626
  batch 138 loss: 0.509096693949423
  batch 139 loss: 0.5090357800610632
  batch 140 loss: 0.5088200850146157
  batch 141 loss: 0.5089907329133216
  batch 142 loss: 0.5089097612760436
  batch 143 loss: 0.5088415033333785
  batch 144 loss: 0.508810482505295
  batch 145 loss: 0.508792981197094
  batch 146 loss: 0.5086284730940649
  batch 147 loss: 0.5086333980771149
  batch 148 loss: 0.5086863018773697
  batch 149 loss: 0.5086412159788528
  batch 150 loss: 0.5083492155869802
  batch 151 loss: 0.5081270656838323
  batch 152 loss: 0.5083276872572146
  batch 153 loss: 0.5082432286801681
  batch 154 loss: 0.5082754235376011
  batch 155 loss: 0.5083157506681257
  batch 156 loss: 0.5083971006365923
  batch 157 loss: 0.5085833260587825
  batch 158 loss: 0.5086246213958233
  batch 159 loss: 0.5085957693228932
  batch 160 loss: 0.5086956528946758
  batch 161 loss: 0.5087293917718141
  batch 162 loss: 0.5087329294578529
  batch 163 loss: 0.5085913668746597
  batch 164 loss: 0.5085284575456526
  batch 165 loss: 0.5083920980944778
  batch 166 loss: 0.5085600158536291
  batch 167 loss: 0.5085373271011306
  batch 168 loss: 0.5088217836760339
  batch 169 loss: 0.5086873074960426
  batch 170 loss: 0.5087067088660072
  batch 171 loss: 0.5086041441437794
  batch 172 loss: 0.508781429986621
  batch 173 loss: 0.5087190642522249
  batch 174 loss: 0.5087107683735332
  batch 175 loss: 0.5086259584767477
  batch 176 loss: 0.5085958342321895
  batch 177 loss: 0.5084172485575165
  batch 178 loss: 0.508553584472517
  batch 179 loss: 0.5086093759736535
  batch 180 loss: 0.5086142369442516
  batch 181 loss: 0.50861864541117
  batch 182 loss: 0.5086747592949605
  batch 183 loss: 0.5086118422570776
  batch 184 loss: 0.5085682940223942
  batch 185 loss: 0.508632705018327
  batch 186 loss: 0.5086642388374575
  batch 187 loss: 0.5085511649037427
  batch 188 loss: 0.5085567186804528
  batch 189 loss: 0.5084659001499257
  batch 190 loss: 0.5083448948044526
  batch 191 loss: 0.5084137584214435
  batch 192 loss: 0.5083762141875923
  batch 193 loss: 0.5082795562830613
  batch 194 loss: 0.5082459635648531
  batch 195 loss: 0.5084220154163165
  batch 196 loss: 0.5082873860184027
  batch 197 loss: 0.5083620384865001
  batch 198 loss: 0.5084126657909818
  batch 199 loss: 0.5082394056883289
  batch 200 loss: 0.5082365815341473
  batch 201 loss: 0.5083314623702225
  batch 202 loss: 0.5083473547555433
  batch 203 loss: 0.5084837641328427
  batch 204 loss: 0.5084707136539852
  batch 205 loss: 0.508402222976452
  batch 206 loss: 0.5084823869096423
  batch 207 loss: 0.508498086589546
  batch 208 loss: 0.5083701838381015
  batch 209 loss: 0.5083214748989452
  batch 210 loss: 0.5083237823985872
  batch 211 loss: 0.508381657408312
  batch 212 loss: 0.5084647752766339
  batch 213 loss: 0.5084332208118528
  batch 214 loss: 0.5083654850164306
  batch 215 loss: 0.508115746669991
  batch 216 loss: 0.5079605784957055
  batch 217 loss: 0.5078912544909711
  batch 218 loss: 0.5078257005149072
  batch 219 loss: 0.5077167033604836
  batch 220 loss: 0.5077303309332241
  batch 221 loss: 0.5078182700532594
  batch 222 loss: 0.5078986673741728
  batch 223 loss: 0.5079065368849066
  batch 224 loss: 0.5079010126313993
  batch 225 loss: 0.5079319249259101
  batch 226 loss: 0.5080204993750141
  batch 227 loss: 0.5078431219518973
  batch 228 loss: 0.5078854925538364
  batch 229 loss: 0.5078197289502256
  batch 230 loss: 0.507853557622951
  batch 231 loss: 0.5077698417814263
  batch 232 loss: 0.507572401828807
  batch 233 loss: 0.5075336495182545
  batch 234 loss: 0.5074399826873062
  batch 235 loss: 0.5075210124888319
  batch 236 loss: 0.507476083429183
  batch 237 loss: 0.5074744225805822
  batch 238 loss: 0.5074753477042463
  batch 239 loss: 0.5072946218017754
  batch 240 loss: 0.5073828400423129
  batch 241 loss: 0.5074342792212221
  batch 242 loss: 0.5072770498015664
  batch 243 loss: 0.5073501739972903
  batch 244 loss: 0.5073583304393486
  batch 245 loss: 0.5075382312949823
  batch 246 loss: 0.5074699860278183
  batch 247 loss: 0.507418658448617
  batch 248 loss: 0.5075647791306819
  batch 249 loss: 0.5075648035629686
  batch 250 loss: 0.5075732358694076
  batch 251 loss: 0.5075738162870901
  batch 252 loss: 0.5076383431515996
  batch 253 loss: 0.5076005813396967
  batch 254 loss: 0.5076115024606074
  batch 255 loss: 0.5077937487293692
  batch 256 loss: 0.5076962850289419
  batch 257 loss: 0.5077586868625671
  batch 258 loss: 0.5078000489824502
  batch 259 loss: 0.5076939059730662
  batch 260 loss: 0.5077481855566685
  batch 261 loss: 0.5077939692356578
  batch 262 loss: 0.5076837709159342
  batch 263 loss: 0.5076446030076466
  batch 264 loss: 0.50761446514816
  batch 265 loss: 0.5075637423767234
  batch 266 loss: 0.507635956420038
  batch 267 loss: 0.5076836463663909
  batch 268 loss: 0.5075705298292104
  batch 269 loss: 0.50764000415802
  batch 270 loss: 0.5076870640118917
  batch 271 loss: 0.5076718068650727
  batch 272 loss: 0.5077261061352842
  batch 273 loss: 0.5076910832644382
  batch 274 loss: 0.5075735274675118
  batch 275 loss: 0.5077087845585563
  batch 276 loss: 0.5078274289119071
  batch 277 loss: 0.5078992788757228
  batch 278 loss: 0.5078398541366453
  batch 279 loss: 0.5078653903631326
  batch 280 loss: 0.507711758358138
  batch 281 loss: 0.5076400355512137
  batch 282 loss: 0.507469338939545
  batch 283 loss: 0.5073609025655281
  batch 284 loss: 0.5074219951327418
  batch 285 loss: 0.5073207613668944
  batch 286 loss: 0.507293080637505
  batch 287 loss: 0.5072930321253135
  batch 288 loss: 0.5070868528758486
  batch 289 loss: 0.5072491205068608
  batch 290 loss: 0.5071122757319746
  batch 291 loss: 0.5070914200081449
  batch 292 loss: 0.5071805782922326
  batch 293 loss: 0.5072428519001593
  batch 294 loss: 0.5071990501110245
  batch 295 loss: 0.5073879511679633
  batch 296 loss: 0.5074446983635426
  batch 297 loss: 0.5075307033880793
  batch 298 loss: 0.5075980877916285
  batch 299 loss: 0.5076636427820327
  batch 300 loss: 0.5077690344055493
  batch 301 loss: 0.5078217289178475
  batch 302 loss: 0.5078048158363001
  batch 303 loss: 0.5078026179236548
  batch 304 loss: 0.5077883780590797
  batch 305 loss: 0.5075882713325688
  batch 306 loss: 0.5076700286343206
  batch 307 loss: 0.5076416650307684
  batch 308 loss: 0.507594681308641
  batch 309 loss: 0.507646333727636
  batch 310 loss: 0.5075977288907574
  batch 311 loss: 0.5076206705961197
  batch 312 loss: 0.5076700924680784
  batch 313 loss: 0.5077295126244664
  batch 314 loss: 0.5077981464802079
  batch 315 loss: 0.5077849863067506
  batch 316 loss: 0.5077323908858662
  batch 317 loss: 0.5077721375960281
  batch 318 loss: 0.5076931676587219
  batch 319 loss: 0.5075055903588717
  batch 320 loss: 0.5074666364118456
  batch 321 loss: 0.5074854639831733
  batch 322 loss: 0.5074546293627401
  batch 323 loss: 0.5073625269135454
  batch 324 loss: 0.5072432711352537
  batch 325 loss: 0.5072113542373364
  batch 326 loss: 0.5071810265443076
  batch 327 loss: 0.5071765061365355
  batch 328 loss: 0.5070632351789532
  batch 329 loss: 0.507169542975701
  batch 330 loss: 0.5071539693709576
  batch 331 loss: 0.50707456658614
  batch 332 loss: 0.5070695634706911
  batch 333 loss: 0.507021186051068
  batch 334 loss: 0.5068851587122786
  batch 335 loss: 0.5068457618578156
  batch 336 loss: 0.5067908901366449
  batch 337 loss: 0.50675715731584
  batch 338 loss: 0.5067509873026221
  batch 339 loss: 0.5069649115776242
  batch 340 loss: 0.5070054080556421
  batch 341 loss: 0.5070072585536588
  batch 342 loss: 0.5069496552323738
  batch 343 loss: 0.506958918477634
  batch 344 loss: 0.5069243155939634
  batch 345 loss: 0.5070735034735306
  batch 346 loss: 0.5070614296232345
  batch 347 loss: 0.5070633250973067
  batch 348 loss: 0.5070709923560592
  batch 349 loss: 0.5069966401616618
  batch 350 loss: 0.5070392869200026
  batch 351 loss: 0.5070678496632481
  batch 352 loss: 0.5071443673223257
  batch 353 loss: 0.5070287230669945
  batch 354 loss: 0.5070905929568124
  batch 355 loss: 0.507216223360787
  batch 356 loss: 0.5071971863508224
  batch 357 loss: 0.5072004426093328
  batch 358 loss: 0.5072132801876388
  batch 359 loss: 0.5071974215733308
  batch 360 loss: 0.5072804643048181
  batch 361 loss: 0.5073398625751612
  batch 362 loss: 0.5072107978617948
  batch 363 loss: 0.5071719765006346
  batch 364 loss: 0.5070637706053126
  batch 365 loss: 0.5070324749979255
  batch 366 loss: 0.5069380292638404
  batch 367 loss: 0.5069550671272122
  batch 368 loss: 0.5068922605689453
  batch 369 loss: 0.506889193603986
  batch 370 loss: 0.5069458918797003
  batch 371 loss: 0.5070784627748628
  batch 372 loss: 0.5069567859172821
  batch 373 loss: 0.5068376449413657
  batch 374 loss: 0.5067683946002614
  batch 375 loss: 0.5068057063420613
  batch 376 loss: 0.506842870027461
  batch 377 loss: 0.5068097634720233
  batch 378 loss: 0.5067344974903834
  batch 379 loss: 0.5067052000588037
  batch 380 loss: 0.5068060315753284
  batch 381 loss: 0.5067032908047904
  batch 382 loss: 0.5065443043777456
  batch 383 loss: 0.5065055309014282
  batch 384 loss: 0.5065303831361234
  batch 385 loss: 0.5066246634953981
  batch 386 loss: 0.5065394042378263
  batch 387 loss: 0.5065097484631748
  batch 388 loss: 0.5065143497795174
  batch 389 loss: 0.5065200864349355
  batch 390 loss: 0.5064969647389191
  batch 391 loss: 0.5064719576969781
  batch 392 loss: 0.5064994028332283
  batch 393 loss: 0.5065436385970079
  batch 394 loss: 0.5065476429946532
  batch 395 loss: 0.5066080444975745
  batch 396 loss: 0.5066208210256364
  batch 397 loss: 0.5065616587697709
  batch 398 loss: 0.5065749208981069
  batch 399 loss: 0.5065732757399853
  batch 400 loss: 0.5065153857320547
  batch 401 loss: 0.5065102692405482
  batch 402 loss: 0.5066231366858553
  batch 403 loss: 0.5065521248073199
  batch 404 loss: 0.5065411732781051
  batch 405 loss: 0.5065362985487337
  batch 406 loss: 0.50661782523975
  batch 407 loss: 0.5066127262332223
  batch 408 loss: 0.5066875740155286
  batch 409 loss: 0.506683670876953
  batch 410 loss: 0.5067038128288781
  batch 411 loss: 0.5066917608979264
  batch 412 loss: 0.5066522882835379
  batch 413 loss: 0.506610386885396
  batch 414 loss: 0.5066002457614106
  batch 415 loss: 0.5066051984407816
  batch 416 loss: 0.5065815152170566
  batch 417 loss: 0.5065669944818071
  batch 418 loss: 0.5065705689231744
  batch 419 loss: 0.5065589461804574
  batch 420 loss: 0.5065696795781454
  batch 421 loss: 0.5065629681895295
  batch 422 loss: 0.5066411880802769
  batch 423 loss: 0.5066720276859635
  batch 424 loss: 0.5066867768764496
  batch 425 loss: 0.5067147958979887
  batch 426 loss: 0.5067012280645505
  batch 427 loss: 0.5067206995269454
  batch 428 loss: 0.5066284439831137
  batch 429 loss: 0.5065799171413297
  batch 430 loss: 0.5066043121177096
  batch 431 loss: 0.5067497236684414
  batch 432 loss: 0.5067674154070793
  batch 433 loss: 0.5066960315643777
  batch 434 loss: 0.5067288225284919
  batch 435 loss: 0.5066740965706179
  batch 436 loss: 0.5066486698225003
  batch 437 loss: 0.5066753208500843
  batch 438 loss: 0.5067485004799551
  batch 439 loss: 0.506737423377591
  batch 440 loss: 0.5067647417837923
  batch 441 loss: 0.5067242690765398
  batch 442 loss: 0.5067029945990619
  batch 443 loss: 0.5067047475423017
  batch 444 loss: 0.5066141725123465
  batch 445 loss: 0.5066225871611177
  batch 446 loss: 0.506573881669964
  batch 447 loss: 0.506527045429153
  batch 448 loss: 0.5066060427842396
  batch 449 loss: 0.5066540116456676
  batch 450 loss: 0.5067178746064503
  batch 451 loss: 0.5067236366663169
  batch 452 loss: 0.5067400402199905
  batch 453 loss: 0.5067600580240716
  batch 454 loss: 0.5067772917810516
  batch 455 loss: 0.5067642460812579
  batch 456 loss: 0.506773829460144
  batch 457 loss: 0.506806303818325
  batch 458 loss: 0.5067751655542174
  batch 459 loss: 0.5067933445272882
  batch 460 loss: 0.506845686034016
  batch 461 loss: 0.5068611216260658
  batch 462 loss: 0.5068167776385427
  batch 463 loss: 0.5068151164904526
  batch 464 loss: 0.5068561991612459
  batch 465 loss: 0.5067064819156483
  batch 466 loss: 0.5065985321359061
  batch 467 loss: 0.5066035256523647
  batch 468 loss: 0.506531818363911
  batch 469 loss: 0.5065293626617521
  batch 470 loss: 0.5064927372526615
  batch 471 loss: 0.5064848686732557
  batch 472 loss: 0.5064422643538249
LOSS train 0.5064422643538249 valid 0.3577346205711365
LOSS train 0.5064422643538249 valid 0.34196892380714417
LOSS train 0.5064422643538249 valid 0.35716456174850464
LOSS train 0.5064422643538249 valid 0.35475875437259674
LOSS train 0.5064422643538249 valid 0.3540331542491913
LOSS train 0.5064422643538249 valid 0.35577492415905
LOSS train 0.5064422643538249 valid 0.35430427534239634
LOSS train 0.5064422643538249 valid 0.35374869778752327
LOSS train 0.5064422643538249 valid 0.35066306922170853
LOSS train 0.5064422643538249 valid 0.3535198479890823
LOSS train 0.5064422643538249 valid 0.35575774853879755
LOSS train 0.5064422643538249 valid 0.35649164766073227
LOSS train 0.5064422643538249 valid 0.3590329449910384
LOSS train 0.5064422643538249 valid 0.3592868468591145
LOSS train 0.5064422643538249 valid 0.35870890816052753
LOSS train 0.5064422643538249 valid 0.3600233346223831
LOSS train 0.5064422643538249 valid 0.36234599176575155
LOSS train 0.5064422643538249 valid 0.36294962134626174
LOSS train 0.5064422643538249 valid 0.36302862826146576
LOSS train 0.5064422643538249 valid 0.36435018926858903
LOSS train 0.5064422643538249 valid 0.3639986089297703
LOSS train 0.5064422643538249 valid 0.36191780458797107
LOSS train 0.5064422643538249 valid 0.36297599647356116
LOSS train 0.5064422643538249 valid 0.3624773174524307
LOSS train 0.5064422643538249 valid 0.3624573040008545
LOSS train 0.5064422643538249 valid 0.3621431566201724
LOSS train 0.5064422643538249 valid 0.36159999944545607
LOSS train 0.5064422643538249 valid 0.36147335384573254
LOSS train 0.5064422643538249 valid 0.3615886353213212
LOSS train 0.5064422643538249 valid 0.36233700315157574
LOSS train 0.5064422643538249 valid 0.36356258200060937
LOSS train 0.5064422643538249 valid 0.3634051438421011
LOSS train 0.5064422643538249 valid 0.3642494949427518
LOSS train 0.5064422643538249 valid 0.3638260171693914
LOSS train 0.5064422643538249 valid 0.36463737658091955
LOSS train 0.5064422643538249 valid 0.36461707949638367
LOSS train 0.5064422643538249 valid 0.3651610870619078
LOSS train 0.5064422643538249 valid 0.36625432340722336
LOSS train 0.5064422643538249 valid 0.36607528038513965
LOSS train 0.5064422643538249 valid 0.36742416620254514
LOSS train 0.5064422643538249 valid 0.36734703110485545
LOSS train 0.5064422643538249 valid 0.3681897222995758
LOSS train 0.5064422643538249 valid 0.36807450860045676
LOSS train 0.5064422643538249 valid 0.36820301752198825
LOSS train 0.5064422643538249 valid 0.3685501754283905
LOSS train 0.5064422643538249 valid 0.3689781032178713
LOSS train 0.5064422643538249 valid 0.36870740385765727
LOSS train 0.5064422643538249 valid 0.3689392687131961
LOSS train 0.5064422643538249 valid 0.3694550005757079
LOSS train 0.5064422643538249 valid 0.3687545657157898
LOSS train 0.5064422643538249 valid 0.3691794194427191
LOSS train 0.5064422643538249 valid 0.3688492327928543
LOSS train 0.5064422643538249 valid 0.368384025006924
LOSS train 0.5064422643538249 valid 0.3684908957393081
LOSS train 0.5064422643538249 valid 0.36821888793598523
LOSS train 0.5064422643538249 valid 0.3682479379432542
LOSS train 0.5064422643538249 valid 0.36788660810704815
LOSS train 0.5064422643538249 valid 0.3675555484048251
LOSS train 0.5064422643538249 valid 0.36799768926733634
LOSS train 0.5064422643538249 valid 0.3674266164501508
LOSS train 0.5064422643538249 valid 0.36639981924510395
LOSS train 0.5064422643538249 valid 0.3671273810248221
LOSS train 0.5064422643538249 valid 0.36762247577546137
LOSS train 0.5064422643538249 valid 0.3681101789698005
LOSS train 0.5064422643538249 valid 0.36816889139322134
LOSS train 0.5064422643538249 valid 0.3682426629644452
LOSS train 0.5064422643538249 valid 0.36786110276606543
LOSS train 0.5064422643538249 valid 0.36732212497907524
LOSS train 0.5064422643538249 valid 0.3671898936879808
LOSS train 0.5064422643538249 valid 0.36693992061274394
LOSS train 0.5064422643538249 valid 0.36659793156973075
LOSS train 0.5064422643538249 valid 0.36660580875145066
LOSS train 0.5064422643538249 valid 0.36692647697174385
LOSS train 0.5064422643538249 valid 0.36675614078302643
LOSS train 0.5064422643538249 valid 0.3662924603621165
LOSS train 0.5064422643538249 valid 0.3666338371603112
LOSS train 0.5064422643538249 valid 0.366362737757819
LOSS train 0.5064422643538249 valid 0.3662952433029811
LOSS train 0.5064422643538249 valid 0.3663152618498742
LOSS train 0.5064422643538249 valid 0.36623960100114344
LOSS train 0.5064422643538249 valid 0.3657117357224594
LOSS train 0.5064422643538249 valid 0.36585519590028903
LOSS train 0.5064422643538249 valid 0.36558493433228456
LOSS train 0.5064422643538249 valid 0.36580630391836166
LOSS train 0.5064422643538249 valid 0.3660027637201197
LOSS train 0.5064422643538249 valid 0.3657138548618139
LOSS train 0.5064422643538249 valid 0.365744285199834
LOSS train 0.5064422643538249 valid 0.36527497930960223
LOSS train 0.5064422643538249 valid 0.3653986028740915
LOSS train 0.5064422643538249 valid 0.3651837014489704
LOSS train 0.5064422643538249 valid 0.36497185092705947
LOSS train 0.5064422643538249 valid 0.36477592684652493
LOSS train 0.5064422643538249 valid 0.3643618254892288
LOSS train 0.5064422643538249 valid 0.3640092611312866
LOSS train 0.5064422643538249 valid 0.3637283525968853
LOSS train 0.5064422643538249 valid 0.36398650892078876
LOSS train 0.5064422643538249 valid 0.36428462905982106
LOSS train 0.5064422643538249 valid 0.36423231448446003
LOSS train 0.5064422643538249 valid 0.3642883643959508
LOSS train 0.5064422643538249 valid 0.3644625127315521
LOSS train 0.5064422643538249 valid 0.36450830662604605
LOSS train 0.5064422643538249 valid 0.364578936029883
LOSS train 0.5064422643538249 valid 0.3650516083518278
LOSS train 0.5064422643538249 valid 0.36489963330901587
LOSS train 0.5064422643538249 valid 0.36472309515589757
LOSS train 0.5064422643538249 valid 0.3647291320112516
LOSS train 0.5064422643538249 valid 0.3645207817866423
LOSS train 0.5064422643538249 valid 0.3647903123939479
LOSS train 0.5064422643538249 valid 0.36481466369891385
LOSS train 0.5064422643538249 valid 0.3649382374503396
LOSS train 0.5064422643538249 valid 0.364861904500841
LOSS train 0.5064422643538249 valid 0.36478800752333235
LOSS train 0.5064422643538249 valid 0.3648010909029868
LOSS train 0.5064422643538249 valid 0.3647129368363765
LOSS train 0.5064422643538249 valid 0.364745991644652
LOSS train 0.5064422643538249 valid 0.364729991246914
LOSS train 0.5064422643538249 valid 0.36485630757788307
LOSS train 0.5064422643538249 valid 0.36458901177018377
LOSS train 0.5064422643538249 valid 0.3644920116713067
LOSS train 0.5064422643538249 valid 0.3643348107735316
LOSS train 0.5064422643538249 valid 0.36429340583233794
LOSS train 0.5064422643538249 valid 0.36426624997717433
LOSS train 0.5064422643538249 valid 0.36439667218099764
LOSS train 0.5064422643538249 valid 0.3646042628153678
LOSS train 0.5064422643538249 valid 0.36444901633262633
LOSS train 0.5064422643538249 valid 0.36424329474804895
LOSS train 0.5064422643538249 valid 0.36476909574561234
LOSS train 0.5064422643538249 valid 0.3649362337309867
LOSS train 0.5064422643538249 valid 0.36504888511443323
LOSS train 0.5064422643538249 valid 0.3648693655545895
LOSS train 0.5064422643538249 valid 0.3648825048945332
LOSS train 0.5064422643538249 valid 0.36487527078751364
LOSS train 0.5064422643538249 valid 0.364689665853529
LOSS train 0.5064422643538249 valid 0.3649068875099296
LOSS train 0.5064422643538249 valid 0.36504614971302174
LOSS train 0.5064422643538249 valid 0.3648759188020931
LOSS train 0.5064422643538249 valid 0.36469494143541714
LOSS train 0.5064422643538249 valid 0.36462411046891974
LOSS train 0.5064422643538249 valid 0.36443328364289923
LOSS train 0.5064422643538249 valid 0.36462984830141065
LOSS train 0.5064422643538249 valid 0.36473769055190663
LOSS train 0.5064422643538249 valid 0.3651342956532895
LOSS train 0.5064422643538249 valid 0.3650158316522211
LOSS train 0.5064422643538249 valid 0.36515096347365117
LOSS train 0.5064422643538249 valid 0.36511471456494826
LOSS train 0.5064422643538249 valid 0.36529090673956155
LOSS train 0.5064422643538249 valid 0.36495138917650494
LOSS train 0.5064422643538249 valid 0.36514885381266876
LOSS train 0.5064422643538249 valid 0.3652659268587228
LOSS train 0.5064422643538249 valid 0.3652780646085739
LOSS train 0.5064422643538249 valid 0.36537325303286117
LOSS train 0.5064422643538249 valid 0.3652003244741967
LOSS train 0.5064422643538249 valid 0.36541053905985715
LOSS train 0.5064422643538249 valid 0.36540871471553654
LOSS train 0.5064422643538249 valid 0.3653835940745569
LOSS train 0.5064422643538249 valid 0.3656122808655103
LOSS train 0.5064422643538249 valid 0.3656477485872378
LOSS train 0.5064422643538249 valid 0.36563634608365314
LOSS train 0.5064422643538249 valid 0.3653311530749003
LOSS train 0.5064422643538249 valid 0.36539605651050805
LOSS train 0.5064422643538249 valid 0.3652801489607888
LOSS train 0.5064422643538249 valid 0.3650415543420815
LOSS train 0.5064422643538249 valid 0.364995876704257
LOSS train 0.5064422643538249 valid 0.3649610002956739
LOSS train 0.5064422643538249 valid 0.36485871130769904
LOSS train 0.5064422643538249 valid 0.3647155907139721
LOSS train 0.5064422643538249 valid 0.3647455903227458
LOSS train 0.5064422643538249 valid 0.3648744464984962
LOSS train 0.5064422643538249 valid 0.36490969033636284
LOSS train 0.5064422643538249 valid 0.365196189810248
LOSS train 0.5064422643538249 valid 0.365188736838904
LOSS train 0.5064422643538249 valid 0.3652795620782431
LOSS train 0.5064422643538249 valid 0.3654689611382567
LOSS train 0.5064422643538249 valid 0.3653829986679143
LOSS train 0.5064422643538249 valid 0.36532972727503094
LOSS train 0.5064422643538249 valid 0.36514023572883825
LOSS train 0.5064422643538249 valid 0.3653121307744818
LOSS train 0.5064422643538249 valid 0.36541427152880124
LOSS train 0.5064422643538249 valid 0.3653039725799134
LOSS train 0.5064422643538249 valid 0.36544220000505445
LOSS train 0.5064422643538249 valid 0.365469747979338
LOSS train 0.5064422643538249 valid 0.3655479640423597
LOSS train 0.5064422643538249 valid 0.3654729741844323
LOSS train 0.5064422643538249 valid 0.36555736819687096
LOSS train 0.5064422643538249 valid 0.36552246905661917
LOSS train 0.5064422643538249 valid 0.3655588771066358
LOSS train 0.5064422643538249 valid 0.36562679986902735
LOSS train 0.5064422643538249 valid 0.3656521921462201
LOSS train 0.5064422643538249 valid 0.3656290189299003
LOSS train 0.5064422643538249 valid 0.365542555482764
LOSS train 0.5064422643538249 valid 0.3657531037692624
LOSS train 0.5064422643538249 valid 0.3657956506746511
LOSS train 0.5064422643538249 valid 0.3657494934729344
LOSS train 0.5064422643538249 valid 0.36563296631439446
LOSS train 0.5064422643538249 valid 0.3655887322548108
LOSS train 0.5064422643538249 valid 0.36556413982595715
LOSS train 0.5064422643538249 valid 0.365692850750715
LOSS train 0.5064422643538249 valid 0.3656872236969495
LOSS train 0.5064422643538249 valid 0.36569434224660674
LOSS train 0.5064422643538249 valid 0.3656686624884605
LOSS train 0.5064422643538249 valid 0.36554580808278936
LOSS train 0.5064422643538249 valid 0.36564935065142
LOSS train 0.5064422643538249 valid 0.3654597752493591
LOSS train 0.5064422643538249 valid 0.3653760945387915
LOSS train 0.5064422643538249 valid 0.36538231343757815
LOSS train 0.5064422643538249 valid 0.3653361930430514
LOSS train 0.5064422643538249 valid 0.36548414380078154
LOSS train 0.5064422643538249 valid 0.36550870609398073
LOSS train 0.5064422643538249 valid 0.36543407394555194
LOSS train 0.5064422643538249 valid 0.3654677186693464
LOSS train 0.5064422643538249 valid 0.3654097769215209
LOSS train 0.5064422643538249 valid 0.36540858461609427
LOSS train 0.5064422643538249 valid 0.3655237769576865
LOSS train 0.5064422643538249 valid 0.3655169498976146
LOSS train 0.5064422643538249 valid 0.3655641493409179
LOSS train 0.5064422643538249 valid 0.3655830668630423
LOSS train 0.5064422643538249 valid 0.36564186393939957
LOSS train 0.5064422643538249 valid 0.3657451217327643
LOSS train 0.5064422643538249 valid 0.3657808992416347
LOSS train 0.5064422643538249 valid 0.3659079844301397
LOSS train 0.5064422643538249 valid 0.36598038484607887
LOSS train 0.5064422643538249 valid 0.3660067941422935
LOSS train 0.5064422643538249 valid 0.36605940217929034
LOSS train 0.5064422643538249 valid 0.36608125508895945
LOSS train 0.5064422643538249 valid 0.3661237604088253
LOSS train 0.5064422643538249 valid 0.36608607196702364
LOSS train 0.5064422643538249 valid 0.3662102680636923
LOSS train 0.5064422643538249 valid 0.3662626561627053
LOSS train 0.5064422643538249 valid 0.3663306901288345
LOSS train 0.5064422643538249 valid 0.36640731290630674
LOSS train 0.5064422643538249 valid 0.36637516132680886
LOSS train 0.5064422643538249 valid 0.36639171183623115
LOSS train 0.5064422643538249 valid 0.3663122161519374
LOSS train 0.5064422643538249 valid 0.36628665959733164
LOSS train 0.5064422643538249 valid 0.3663678596628473
LOSS train 0.5064422643538249 valid 0.3663604889633292
LOSS train 0.5064422643538249 valid 0.36630007448578683
LOSS train 0.5064422643538249 valid 0.36630589183138196
LOSS train 0.5064422643538249 valid 0.36621268760709086
LOSS train 0.5064422643538249 valid 0.3661202574769656
LOSS train 0.5064422643538249 valid 0.36626140841309957
LOSS train 0.5064422643538249 valid 0.3661913557732401
LOSS train 0.5064422643538249 valid 0.36619332923320097
LOSS train 0.5064422643538249 valid 0.3662959827018566
LOSS train 0.5064422643538249 valid 0.3662961963488131
LOSS train 0.5064422643538249 valid 0.36623609708092075
LOSS train 0.5064422643538249 valid 0.36628974340705256
LOSS train 0.5064422643538249 valid 0.36625539343203267
LOSS train 0.5064422643538249 valid 0.3662671322324669
LOSS train 0.5064422643538249 valid 0.36641709065437317
LOSS train 0.5064422643538249 valid 0.3664581160621339
LOSS train 0.5064422643538249 valid 0.3666248100381049
LOSS train 0.5064422643538249 valid 0.366554790452535
LOSS train 0.5064422643538249 valid 0.36669910376466164
LOSS train 0.5064422643538249 valid 0.3666148863586725
LOSS train 0.5064422643538249 valid 0.3665968127315864
LOSS train 0.5064422643538249 valid 0.3665837693075262
LOSS train 0.5064422643538249 valid 0.3666662435198939
LOSS train 0.5064422643538249 valid 0.3666256106958426
LOSS train 0.5064422643538249 valid 0.36655380370525215
LOSS train 0.5064422643538249 valid 0.366581695175719
LOSS train 0.5064422643538249 valid 0.36651028977095623
LOSS train 0.5064422643538249 valid 0.36646833505920584
LOSS train 0.5064422643538249 valid 0.3664225929162719
LOSS train 0.5064422643538249 valid 0.36644550089566214
LOSS train 0.5064422643538249 valid 0.3665238529219663
LOSS train 0.5064422643538249 valid 0.3666557746656825
LOSS train 0.5064422643538249 valid 0.36667189502449177
LOSS train 0.5064422643538249 valid 0.3668474212676619
LOSS train 0.5064422643538249 valid 0.3667881812210436
LOSS train 0.5064422643538249 valid 0.36686897343815034
LOSS train 0.5064422643538249 valid 0.36688076923875246
LOSS train 0.5064422643538249 valid 0.3668356142637931
LOSS train 0.5064422643538249 valid 0.3668392177698386
LOSS train 0.5064422643538249 valid 0.36677365682341834
LOSS train 0.5064422643538249 valid 0.36666914572318393
LOSS train 0.5064422643538249 valid 0.3667243111219647
LOSS train 0.5064422643538249 valid 0.36665299856405464
LOSS train 0.5064422643538249 valid 0.36669825588930466
LOSS train 0.5064422643538249 valid 0.36662166586944034
LOSS train 0.5064422643538249 valid 0.36649696788753905
LOSS train 0.5064422643538249 valid 0.3665040414384071
LOSS train 0.5064422643538249 valid 0.36650586760086223
LOSS train 0.5064422643538249 valid 0.3665710587946462
LOSS train 0.5064422643538249 valid 0.36655287596217373
LOSS train 0.5064422643538249 valid 0.36645137846886694
LOSS train 0.5064422643538249 valid 0.3664528205211985
LOSS train 0.5064422643538249 valid 0.36645401796946925
LOSS train 0.5064422643538249 valid 0.36645045257769654
LOSS train 0.5064422643538249 valid 0.3664081401866058
LOSS train 0.5064422643538249 valid 0.36630980941847835
LOSS train 0.5064422643538249 valid 0.3662958231894937
LOSS train 0.5064422643538249 valid 0.36619624770135195
LOSS train 0.5064422643538249 valid 0.3662675606961153
LOSS train 0.5064422643538249 valid 0.36641302937168185
LOSS train 0.5064422643538249 valid 0.36639133941482854
LOSS train 0.5064422643538249 valid 0.3664146860440572
LOSS train 0.5064422643538249 valid 0.36634943429255645
LOSS train 0.5064422643538249 valid 0.36638673651577236
LOSS train 0.5064422643538249 valid 0.36642805496851605
LOSS train 0.5064422643538249 valid 0.3663799106282649
LOSS train 0.5064422643538249 valid 0.36625371103649895
LOSS train 0.5064422643538249 valid 0.3662171488744591
LOSS train 0.5064422643538249 valid 0.3662165806285645
LOSS train 0.5064422643538249 valid 0.3661687993612446
LOSS train 0.5064422643538249 valid 0.3662051660757439
LOSS train 0.5064422643538249 valid 0.36619386290494316
LOSS train 0.5064422643538249 valid 0.36616593550939064
LOSS train 0.5064422643538249 valid 0.3662187726173586
LOSS train 0.5064422643538249 valid 0.3661814140696679
LOSS train 0.5064422643538249 valid 0.3661343416983675
LOSS train 0.5064422643538249 valid 0.36614354508809555
LOSS train 0.5064422643538249 valid 0.3662313306674409
LOSS train 0.5064422643538249 valid 0.3662349686121485
LOSS train 0.5064422643538249 valid 0.3662466702007112
LOSS train 0.5064422643538249 valid 0.36616140349379067
LOSS train 0.5064422643538249 valid 0.3661946738932035
LOSS train 0.5064422643538249 valid 0.36621613800525665
LOSS train 0.5064422643538249 valid 0.3661964159213637
LOSS train 0.5064422643538249 valid 0.3661418537609279
LOSS train 0.5064422643538249 valid 0.3661788176524676
LOSS train 0.5064422643538249 valid 0.36615870735660105
LOSS train 0.5064422643538249 valid 0.36612525342418684
LOSS train 0.5064422643538249 valid 0.3661089121007625
LOSS train 0.5064422643538249 valid 0.36607168527749867
LOSS train 0.5064422643538249 valid 0.36612162131107656
LOSS train 0.5064422643538249 valid 0.36622179347440736
LOSS train 0.5064422643538249 valid 0.3661875991923053
LOSS train 0.5064422643538249 valid 0.36616056242612355
LOSS train 0.5064422643538249 valid 0.36610203286012016
LOSS train 0.5064422643538249 valid 0.3660709476182828
LOSS train 0.5064422643538249 valid 0.36595403142722255
LOSS train 0.5064422643538249 valid 0.36594919918535707
LOSS train 0.5064422643538249 valid 0.3660176394585364
LOSS train 0.5064422643538249 valid 0.3660273529700379
LOSS train 0.5064422643538249 valid 0.3660023766791537
LOSS train 0.5064422643538249 valid 0.3659925378571632
LOSS train 0.5064422643538249 valid 0.36603532907878156
LOSS train 0.5064422643538249 valid 0.3659523557596854
LOSS train 0.5064422643538249 valid 0.36596350713687786
LOSS train 0.5064422643538249 valid 0.3658530073256786
LOSS train 0.5064422643538249 valid 0.3657598501583289
LOSS train 0.5064422643538249 valid 0.3657747774708028
LOSS train 0.5064422643538249 valid 0.36584759165727815
LOSS train 0.5064422643538249 valid 0.3659104634886203
LOSS train 0.5064422643538249 valid 0.36587703150476336
LOSS train 0.5064422643538249 valid 0.36584587219125597
LOSS train 0.5064422643538249 valid 0.36577974319800566
LOSS train 0.5064422643538249 valid 0.3657876759511352
LOSS train 0.5064422643538249 valid 0.36571559880461013
LOSS train 0.5064422643538249 valid 0.36569626412839973
LOSS train 0.5064422643538249 valid 0.3657303877513517
LOSS train 0.5064422643538249 valid 0.3658265691809884
LOSS train 0.5064422643538249 valid 0.3659122387568156
LOSS train 0.5064422643538249 valid 0.3659365289647814
LOSS train 0.5064422643538249 valid 0.3659027839979429
LOSS train 0.5064422643538249 valid 0.365884987746968
LOSS train 0.5064422643538249 valid 0.3658292285223913
LOSS train 0.5064422643538249 valid 0.36583183427707067
LOSS train 0.5064422643538249 valid 0.36584437232878475
LOSS train 0.5064422643538249 valid 0.36587164648021686
LOSS train 0.5064422643538249 valid 0.3659457148603313
LOSS train 0.5064422643538249 valid 0.3658935691206908
LOSS train 0.5064422643538249 valid 0.365897784111919
LOSS train 0.5064422643538249 valid 0.3659406786095606
LOSS train 0.5064422643538249 valid 0.36587954536487494
LOSS train 0.5064422643538249 valid 0.36581770478867054
LOSS train 0.5064422643538249 valid 0.365816768825702
LOSS train 0.5064422643538249 valid 0.3658180290929024
EPOCH 10:
  batch 1 loss: 0.4945557713508606
  batch 2 loss: 0.494057297706604
  batch 3 loss: 0.5032760898272196
  batch 4 loss: 0.5117041915655136
  batch 5 loss: 0.5079571902751923
  batch 6 loss: 0.5058117061853409
  batch 7 loss: 0.5060885931764331
  batch 8 loss: 0.5062038190662861
  batch 9 loss: 0.5084124240610335
  batch 10 loss: 0.5101866036653518
  batch 11 loss: 0.5094104923985221
  batch 12 loss: 0.5077966103951136
  batch 13 loss: 0.507405331501594
  batch 14 loss: 0.5080375288214002
  batch 15 loss: 0.5066806296507518
  batch 16 loss: 0.5064757782965899
  batch 17 loss: 0.5055546813151416
  batch 18 loss: 0.5052897449996736
  batch 19 loss: 0.5045121453310314
  batch 20 loss: 0.5040307566523552
  batch 21 loss: 0.5042589491321927
  batch 22 loss: 0.503409197384661
  batch 23 loss: 0.5035869595797166
  batch 24 loss: 0.5031914661327997
  batch 25 loss: 0.5032537603378295
  batch 26 loss: 0.5023230256942602
  batch 27 loss: 0.5014735294712914
  batch 28 loss: 0.50084801869733
  batch 29 loss: 0.500738668030706
  batch 30 loss: 0.4999719242254893
  batch 31 loss: 0.4998434551300541
  batch 32 loss: 0.50018778629601
  batch 33 loss: 0.49993352817766595
  batch 34 loss: 0.4998427384039935
  batch 35 loss: 0.5014430556978499
  batch 36 loss: 0.5016474392679002
  batch 37 loss: 0.5024452676644197
  batch 38 loss: 0.5025529594797837
  batch 39 loss: 0.5027125386091379
  batch 40 loss: 0.5020849213004113
  batch 41 loss: 0.5019630164634891
  batch 42 loss: 0.5023010401498704
  batch 43 loss: 0.502258321573568
  batch 44 loss: 0.5024751397696409
  batch 45 loss: 0.5025983889897664
  batch 46 loss: 0.5023491771324821
  batch 47 loss: 0.5024105868440993
  batch 48 loss: 0.5017426206419865
  batch 49 loss: 0.5017109859962853
  batch 50 loss: 0.5013717025518417
  batch 51 loss: 0.5007501437383539
  batch 52 loss: 0.5011323891006983
  batch 53 loss: 0.5013215142600941
  batch 54 loss: 0.5016769441189589
  batch 55 loss: 0.5012802432883869
  batch 56 loss: 0.5003379758979593
  batch 57 loss: 0.5000059238651342
  batch 58 loss: 0.5004586597968792
  batch 59 loss: 0.500323763338186
  batch 60 loss: 0.4999773939450582
  batch 61 loss: 0.49983274448113363
  batch 62 loss: 0.5006126761436462
  batch 63 loss: 0.5007002760493566
  batch 64 loss: 0.5014778645709157
  batch 65 loss: 0.5009756271655743
  batch 66 loss: 0.5009407699108124
  batch 67 loss: 0.50119586578056
  batch 68 loss: 0.501314598847838
  batch 69 loss: 0.5012428440909454
  batch 70 loss: 0.5010026778493609
  batch 71 loss: 0.5012568143052114
  batch 72 loss: 0.5009643700387743
  batch 73 loss: 0.5007980510796586
  batch 74 loss: 0.5006961439912384
  batch 75 loss: 0.5004847705364227
  batch 76 loss: 0.5008397169019047
  batch 77 loss: 0.5006364684600335
  batch 78 loss: 0.5001186632957214
  batch 79 loss: 0.5006253730647171
  batch 80 loss: 0.500733869895339
  batch 81 loss: 0.5009361141257815
  batch 82 loss: 0.5014511757507557
  batch 83 loss: 0.5017320969736719
  batch 84 loss: 0.5019343967239062
  batch 85 loss: 0.5018162211951087
  batch 86 loss: 0.5024821962728057
  batch 87 loss: 0.5024492435756771
  batch 88 loss: 0.501939043064009
  batch 89 loss: 0.5020371953423104
  batch 90 loss: 0.5022011674112744
  batch 91 loss: 0.5026303015567444
  batch 92 loss: 0.5022770674980205
  batch 93 loss: 0.501980310806664
  batch 94 loss: 0.5023245643428031
  batch 95 loss: 0.5026211170773757
  batch 96 loss: 0.5027323411777616
  batch 97 loss: 0.5032040227934257
  batch 98 loss: 0.5035469285687622
  batch 99 loss: 0.5032990144358741
  batch 100 loss: 0.5035831251740456
  batch 101 loss: 0.5035919721173768
  batch 102 loss: 0.5036637581446591
  batch 103 loss: 0.503731238899879
  batch 104 loss: 0.5038252854003356
  batch 105 loss: 0.5035532556828999
  batch 106 loss: 0.5039415328570132
  batch 107 loss: 0.5039678926222793
  batch 108 loss: 0.5039402326499974
  batch 109 loss: 0.5042298542797019
  batch 110 loss: 0.5045851986516606
  batch 111 loss: 0.5047584957367665
  batch 112 loss: 0.5046695909862008
  batch 113 loss: 0.5048254272051617
  batch 114 loss: 0.505236583582142
  batch 115 loss: 0.505177594008653
  batch 116 loss: 0.5052387835136776
  batch 117 loss: 0.5053096456914885
  batch 118 loss: 0.5054205542398711
  batch 119 loss: 0.5052812773139537
  batch 120 loss: 0.5052606351673603
  batch 121 loss: 0.5050064625818868
  batch 122 loss: 0.5046416020295659
  batch 123 loss: 0.5042825188578629
  batch 124 loss: 0.5044805385893391
  batch 125 loss: 0.5043019585609436
  batch 126 loss: 0.5040925686794614
  batch 127 loss: 0.5043305625596385
  batch 128 loss: 0.5040869417134672
  batch 129 loss: 0.5038948823777281
  batch 130 loss: 0.5039091043747388
  batch 131 loss: 0.5042010379656581
  batch 132 loss: 0.504262096276789
  batch 133 loss: 0.5042761194526701
  batch 134 loss: 0.5043194104931248
  batch 135 loss: 0.5043248863131912
  batch 136 loss: 0.5041680899174774
  batch 137 loss: 0.5042274731354122
  batch 138 loss: 0.5045514169378557
  batch 139 loss: 0.504618376493454
  batch 140 loss: 0.5044504238026483
  batch 141 loss: 0.5046198203208598
  batch 142 loss: 0.5045325907183366
  batch 143 loss: 0.5044258605766964
  batch 144 loss: 0.5044110742294126
  batch 145 loss: 0.504400499319208
  batch 146 loss: 0.5042937565339755
  batch 147 loss: 0.504308683531625
  batch 148 loss: 0.5043595473508578
  batch 149 loss: 0.504348046027574
  batch 150 loss: 0.5041283098856608
  batch 151 loss: 0.5039174671204675
  batch 152 loss: 0.5041517258474701
  batch 153 loss: 0.5040292511968052
  batch 154 loss: 0.5041046984396972
  batch 155 loss: 0.5041507669033543
  batch 156 loss: 0.5041571666414921
  batch 157 loss: 0.5043089870055011
  batch 158 loss: 0.5042842266303075
  batch 159 loss: 0.5043904168425866
  batch 160 loss: 0.504484354890883
  batch 161 loss: 0.5045140568884263
  batch 162 loss: 0.5045268305657823
  batch 163 loss: 0.504339870499687
  batch 164 loss: 0.5043661859704227
  batch 165 loss: 0.5042473290905808
  batch 166 loss: 0.5044388074472727
  batch 167 loss: 0.5043996802704063
  batch 168 loss: 0.5045894116518044
  batch 169 loss: 0.5044936818131328
  batch 170 loss: 0.5045044367804247
  batch 171 loss: 0.5043673834256959
  batch 172 loss: 0.5045391132318696
  batch 173 loss: 0.504423761815694
  batch 174 loss: 0.5043438537710014
  batch 175 loss: 0.504203770841871
  batch 176 loss: 0.5041822936724533
  batch 177 loss: 0.5040025736315775
  batch 178 loss: 0.5040638438436422
  batch 179 loss: 0.5040300470157708
  batch 180 loss: 0.5040197774767876
  batch 181 loss: 0.5040684686510603
  batch 182 loss: 0.5041141570596904
  batch 183 loss: 0.5040750387913543
  batch 184 loss: 0.5039890008452146
  batch 185 loss: 0.5040764797378231
  batch 186 loss: 0.5040580000608198
  batch 187 loss: 0.503918591189512
  batch 188 loss: 0.5039563554715603
  batch 189 loss: 0.5038727892454339
  batch 190 loss: 0.5037871685467268
  batch 191 loss: 0.5038665887260936
  batch 192 loss: 0.5037606684491038
  batch 193 loss: 0.5036988627416482
  batch 194 loss: 0.5037039953101542
  batch 195 loss: 0.5039082962733049
  batch 196 loss: 0.503758121661994
  batch 197 loss: 0.5037537130910128
  batch 198 loss: 0.5038687142759862
  batch 199 loss: 0.5036534954555071
  batch 200 loss: 0.5036629354953766
  batch 201 loss: 0.5037589345998432
  batch 202 loss: 0.5037634006821283
  batch 203 loss: 0.5038690616931821
  batch 204 loss: 0.5038314872220451
  batch 205 loss: 0.5037878503159778
  batch 206 loss: 0.5038278147722911
  batch 207 loss: 0.5038247780811383
  batch 208 loss: 0.5037048252729269
  batch 209 loss: 0.5037203542353433
  batch 210 loss: 0.5037553091843923
  batch 211 loss: 0.5038411761347151
  batch 212 loss: 0.503914143398123
  batch 213 loss: 0.5038860224782021
  batch 214 loss: 0.5038475853817486
  batch 215 loss: 0.5036051543646081
  batch 216 loss: 0.5034266646813463
  batch 217 loss: 0.5033914727000047
  batch 218 loss: 0.5033047037933944
  batch 219 loss: 0.5031824441260944
  batch 220 loss: 0.5032195058735934
  batch 221 loss: 0.5032909240118518
  batch 222 loss: 0.5034624117988724
  batch 223 loss: 0.5034931876734233
  batch 224 loss: 0.5034179734066129
  batch 225 loss: 0.5034847560193804
  batch 226 loss: 0.5036032385794462
  batch 227 loss: 0.503427925745296
  batch 228 loss: 0.5035019162715527
  batch 229 loss: 0.5034481752907866
  batch 230 loss: 0.5035137943599535
  batch 231 loss: 0.5034651882720717
  batch 232 loss: 0.5033027297206993
  batch 233 loss: 0.503276482032604
  batch 234 loss: 0.5032739143850457
  batch 235 loss: 0.5033846590113132
  batch 236 loss: 0.5033016785726709
  batch 237 loss: 0.5033436510633316
  batch 238 loss: 0.5033988807381702
  batch 239 loss: 0.503207431677495
  batch 240 loss: 0.5033086265126864
  batch 241 loss: 0.5033635905174794
  batch 242 loss: 0.5032096918949411
  batch 243 loss: 0.5033024851186776
  batch 244 loss: 0.5033695680684731
  batch 245 loss: 0.5035125953810555
  batch 246 loss: 0.5035014780071693
  batch 247 loss: 0.5034904909520014
  batch 248 loss: 0.5035908813438108
  batch 249 loss: 0.5035929442888283
  batch 250 loss: 0.5036398429870605
  batch 251 loss: 0.5036428506630826
  batch 252 loss: 0.5036966989910792
  batch 253 loss: 0.5036988903882476
  batch 254 loss: 0.5037094795797753
  batch 255 loss: 0.503832528404161
  batch 256 loss: 0.5037468797527254
  batch 257 loss: 0.5037783657994251
  batch 258 loss: 0.5037848940191343
  batch 259 loss: 0.5036962814772912
  batch 260 loss: 0.5036586441672766
  batch 261 loss: 0.5037357255645182
  batch 262 loss: 0.5036173307031165
  batch 263 loss: 0.5035899108127043
  batch 264 loss: 0.5035352990257017
  batch 265 loss: 0.5034831686964575
  batch 266 loss: 0.5035064248438168
  batch 267 loss: 0.5035265618272489
  batch 268 loss: 0.5034629547996308
  batch 269 loss: 0.5034949559039786
  batch 270 loss: 0.5035561668652075
  batch 271 loss: 0.5035600135467149
  batch 272 loss: 0.5036276233766008
  batch 273 loss: 0.5035999623628763
  batch 274 loss: 0.5034995657684159
  batch 275 loss: 0.5036014448512685
  batch 276 loss: 0.5036779488774313
  batch 277 loss: 0.5037554808041679
  batch 278 loss: 0.5036957890009709
  batch 279 loss: 0.5036873984080489
  batch 280 loss: 0.5035440593957901
  batch 281 loss: 0.5034783295889342
  batch 282 loss: 0.5033317648984016
  batch 283 loss: 0.5032620476328442
  batch 284 loss: 0.5033327210956896
  batch 285 loss: 0.503273073623055
  batch 286 loss: 0.5032371865077452
  batch 287 loss: 0.5032410311158941
  batch 288 loss: 0.5030366074707773
  batch 289 loss: 0.5031442652524136
  batch 290 loss: 0.502997679957028
  batch 291 loss: 0.5029550002202955
  batch 292 loss: 0.5030384045349409
  batch 293 loss: 0.5030773343079733
  batch 294 loss: 0.5030332984162026
  batch 295 loss: 0.5032001434746435
  batch 296 loss: 0.503259297158267
  batch 297 loss: 0.5033634808729794
  batch 298 loss: 0.50341952727145
  batch 299 loss: 0.5034664406824272
  batch 300 loss: 0.5035504738489787
  batch 301 loss: 0.5036323080427226
  batch 302 loss: 0.5036394088868273
  batch 303 loss: 0.5036173500243587
  batch 304 loss: 0.5036061519854947
  batch 305 loss: 0.5034258392013488
  batch 306 loss: 0.5035098762878405
  batch 307 loss: 0.5034445002917747
  batch 308 loss: 0.5034219769688396
  batch 309 loss: 0.5034323718555537
  batch 310 loss: 0.5033804274374439
  batch 311 loss: 0.5034113773579
  batch 312 loss: 0.5034515979962472
  batch 313 loss: 0.5034546492198786
  batch 314 loss: 0.5034876452509764
  batch 315 loss: 0.5034857929699005
  batch 316 loss: 0.5034039652423014
  batch 317 loss: 0.503424972577802
  batch 318 loss: 0.5033555388825495
  batch 319 loss: 0.5032025321523972
  batch 320 loss: 0.5031682545319199
  batch 321 loss: 0.5031820856893545
  batch 322 loss: 0.5032057808422894
  batch 323 loss: 0.5031100740373688
  batch 324 loss: 0.5029784333374765
  batch 325 loss: 0.5029625623959761
  batch 326 loss: 0.5029028128444052
  batch 327 loss: 0.5029289202041217
  batch 328 loss: 0.5027944232995917
  batch 329 loss: 0.5029317917794804
  batch 330 loss: 0.5029341703111475
  batch 331 loss: 0.5028448470409543
  batch 332 loss: 0.5028643850461546
  batch 333 loss: 0.5028757576469902
  batch 334 loss: 0.5027571072478494
  batch 335 loss: 0.5027007736376862
  batch 336 loss: 0.5026669438396182
  batch 337 loss: 0.5026309601630938
  batch 338 loss: 0.5026016850795971
  batch 339 loss: 0.5027155137695043
  batch 340 loss: 0.502730744375902
  batch 341 loss: 0.5027464135301428
  batch 342 loss: 0.5027031830528326
  batch 343 loss: 0.5026318406572148
  batch 344 loss: 0.5026408381933389
  batch 345 loss: 0.5027675023977307
  batch 346 loss: 0.5026944910170715
  batch 347 loss: 0.5027744440249132
  batch 348 loss: 0.502809794127256
  batch 349 loss: 0.5026937556642516
  batch 350 loss: 0.5027074072190694
  batch 351 loss: 0.5026879986466846
  batch 352 loss: 0.5027671686627648
  batch 353 loss: 0.5027176209279566
  batch 354 loss: 0.5028241621909169
  batch 355 loss: 0.5029425159306593
  batch 356 loss: 0.502882155893224
  batch 357 loss: 0.5028840067172918
  batch 358 loss: 0.5028894612742536
  batch 359 loss: 0.5029298049659782
  batch 360 loss: 0.5029948452280627
  batch 361 loss: 0.5030215716923373
  batch 362 loss: 0.5029279210126203
  batch 363 loss: 0.5029651777967605
  batch 364 loss: 0.5028959529904219
  batch 365 loss: 0.5029080066778888
  batch 366 loss: 0.502841586705114
  batch 367 loss: 0.502827572887535
  batch 368 loss: 0.5027613369343074
  batch 369 loss: 0.5027554720074827
  batch 370 loss: 0.5028702051252932
  batch 371 loss: 0.5029619169042439
  batch 372 loss: 0.5028515152072394
  batch 373 loss: 0.502816896336328
  batch 374 loss: 0.5027146245387786
  batch 375 loss: 0.5027995433807373
  batch 376 loss: 0.5028556106572456
  batch 377 loss: 0.5028239505992961
  batch 378 loss: 0.5027450495769107
  batch 379 loss: 0.5027157566792733
  batch 380 loss: 0.5028240851665798
  batch 381 loss: 0.5027310493893511
  batch 382 loss: 0.5025856564338295
  batch 383 loss: 0.5025830756746447
  batch 384 loss: 0.5025702960944424
  batch 385 loss: 0.5026202763055826
  batch 386 loss: 0.5025126230685822
  batch 387 loss: 0.5025453024594358
  batch 388 loss: 0.5025758238643715
  batch 389 loss: 0.502573654017289
  batch 390 loss: 0.5025995386716647
  batch 391 loss: 0.502562277228631
  batch 392 loss: 0.5025922006034121
  batch 393 loss: 0.5026512219553989
  batch 394 loss: 0.5026726672038209
  batch 395 loss: 0.502691639450532
  batch 396 loss: 0.502760382538492
  batch 397 loss: 0.5026602768327487
  batch 398 loss: 0.5026013362946822
  batch 399 loss: 0.5026130437253412
  batch 400 loss: 0.5025487611442805
  batch 401 loss: 0.5025067819175577
  batch 402 loss: 0.5025912483978034
  batch 403 loss: 0.5025047169577691
  batch 404 loss: 0.5024658734403035
  batch 405 loss: 0.5024394294362009
  batch 406 loss: 0.5025064821900993
  batch 407 loss: 0.5024825233499307
  batch 408 loss: 0.5025685826937357
  batch 409 loss: 0.5025576635794418
  batch 410 loss: 0.5025829573956931
  batch 411 loss: 0.5025623400135922
  batch 412 loss: 0.5025094679547745
  batch 413 loss: 0.5024784537117938
  batch 414 loss: 0.5024548789153352
  batch 415 loss: 0.5024501869477421
  batch 416 loss: 0.5024299730475132
  batch 417 loss: 0.5024051361804386
  batch 418 loss: 0.5024087391971972
  batch 419 loss: 0.502396562859096
  batch 420 loss: 0.5023896775075367
  batch 421 loss: 0.5023932809501249
  batch 422 loss: 0.5024851146749976
  batch 423 loss: 0.5025199368490395
  batch 424 loss: 0.5025369576969236
  batch 425 loss: 0.5025327549261205
  batch 426 loss: 0.5025208814183312
  batch 427 loss: 0.5025329249943726
  batch 428 loss: 0.5024539691126235
  batch 429 loss: 0.5024044035059033
  batch 430 loss: 0.5024192508569983
  batch 431 loss: 0.5025868155148633
  batch 432 loss: 0.5026240840692211
  batch 433 loss: 0.5025943065488035
  batch 434 loss: 0.5026241737988687
  batch 435 loss: 0.5025545569671982
  batch 436 loss: 0.5025520948095059
  batch 437 loss: 0.5025813514089693
  batch 438 loss: 0.5026562129525833
  batch 439 loss: 0.5026399813643349
  batch 440 loss: 0.5026572701605884
  batch 441 loss: 0.502619436538679
  batch 442 loss: 0.5025645786415938
  batch 443 loss: 0.5025621752841208
  batch 444 loss: 0.5024532032711012
  batch 445 loss: 0.5024670659826043
  batch 446 loss: 0.5024329771375442
  batch 447 loss: 0.5024264348833353
  batch 448 loss: 0.5025458196843309
  batch 449 loss: 0.502625036810448
  batch 450 loss: 0.5026807389656702
  batch 451 loss: 0.502698308546633
  batch 452 loss: 0.5027159749802235
  batch 453 loss: 0.5027786634747292
  batch 454 loss: 0.5027876344677635
  batch 455 loss: 0.5028031332807227
  batch 456 loss: 0.5028023993629113
  batch 457 loss: 0.5028470020977621
  batch 458 loss: 0.5028243645960587
  batch 459 loss: 0.50283233253265
  batch 460 loss: 0.502893447422463
  batch 461 loss: 0.5029156526748633
  batch 462 loss: 0.5028811871876449
  batch 463 loss: 0.5028595798216422
  batch 464 loss: 0.5029246634964285
  batch 465 loss: 0.5027768869553843
  batch 466 loss: 0.5026659565805878
  batch 467 loss: 0.5027189478756784
  batch 468 loss: 0.5026575069651644
  batch 469 loss: 0.5026598083439158
  batch 470 loss: 0.502588560606571
  batch 471 loss: 0.502610061705239
  batch 472 loss: 0.5025515861935534
LOSS train 0.5025515861935534 valid 0.35434290766716003
LOSS train 0.5025515861935534 valid 0.3413686007261276
LOSS train 0.5025515861935534 valid 0.35736314455668133
LOSS train 0.5025515861935534 valid 0.35310860723257065
LOSS train 0.5025515861935534 valid 0.3520049750804901
LOSS train 0.5025515861935534 valid 0.3527895261843999
LOSS train 0.5025515861935534 valid 0.35121250578335356
LOSS train 0.5025515861935534 valid 0.35102689638733864
LOSS train 0.5025515861935534 valid 0.34791208306948346
LOSS train 0.5025515861935534 valid 0.3504764407873154
LOSS train 0.5025515861935534 valid 0.35283778743310407
LOSS train 0.5025515861935534 valid 0.35282740493615466
LOSS train 0.5025515861935534 valid 0.35556957584161025
LOSS train 0.5025515861935534 valid 0.3554951995611191
LOSS train 0.5025515861935534 valid 0.35400523940722145
LOSS train 0.5025515861935534 valid 0.3551384974271059
LOSS train 0.5025515861935534 valid 0.35760900027611675
LOSS train 0.5025515861935534 valid 0.35815149876806474
LOSS train 0.5025515861935534 valid 0.3584392541333249
LOSS train 0.5025515861935534 valid 0.35967438519001005
LOSS train 0.5025515861935534 valid 0.35920578099432443
LOSS train 0.5025515861935534 valid 0.3570506938479163
LOSS train 0.5025515861935534 valid 0.35816594310428784
LOSS train 0.5025515861935534 valid 0.357614083836476
LOSS train 0.5025515861935534 valid 0.3572131633758545
LOSS train 0.5025515861935534 valid 0.356798666027876
LOSS train 0.5025515861935534 valid 0.35644705759154427
LOSS train 0.5025515861935534 valid 0.3564325581703867
LOSS train 0.5025515861935534 valid 0.35649920229254095
LOSS train 0.5025515861935534 valid 0.35723842481772106
LOSS train 0.5025515861935534 valid 0.3586400622321713
LOSS train 0.5025515861935534 valid 0.35838845651596785
LOSS train 0.5025515861935534 valid 0.3591127675591093
LOSS train 0.5025515861935534 valid 0.35865666585810047
LOSS train 0.5025515861935534 valid 0.35958813088280817
LOSS train 0.5025515861935534 valid 0.35946116513676113
LOSS train 0.5025515861935534 valid 0.3599276333241849
LOSS train 0.5025515861935534 valid 0.361029020265529
LOSS train 0.5025515861935534 valid 0.36074250095929855
LOSS train 0.5025515861935534 valid 0.36201030761003494
LOSS train 0.5025515861935534 valid 0.3619027602963331
LOSS train 0.5025515861935534 valid 0.3626446546543212
LOSS train 0.5025515861935534 valid 0.36246533795844676
LOSS train 0.5025515861935534 valid 0.3626739931377498
LOSS train 0.5025515861935534 valid 0.36298486789067586
LOSS train 0.5025515861935534 valid 0.3635282989429391
LOSS train 0.5025515861935534 valid 0.36320697753987413
LOSS train 0.5025515861935534 valid 0.3634618322054545
LOSS train 0.5025515861935534 valid 0.36395792328581517
LOSS train 0.5025515861935534 valid 0.36330758571624755
LOSS train 0.5025515861935534 valid 0.36382921303019805
LOSS train 0.5025515861935534 valid 0.36343910029301274
LOSS train 0.5025515861935534 valid 0.3629296028389121
LOSS train 0.5025515861935534 valid 0.36307485677577833
LOSS train 0.5025515861935534 valid 0.36274093877185476
LOSS train 0.5025515861935534 valid 0.3627424532813685
LOSS train 0.5025515861935534 valid 0.3623704831851156
LOSS train 0.5025515861935534 valid 0.36201530643578234
LOSS train 0.5025515861935534 valid 0.3625867245560985
LOSS train 0.5025515861935534 valid 0.3619876598318418
LOSS train 0.5025515861935534 valid 0.3609843957619589
LOSS train 0.5025515861935534 valid 0.3618491580409388
LOSS train 0.5025515861935534 valid 0.3623352930659339
LOSS train 0.5025515861935534 valid 0.3628046130761504
LOSS train 0.5025515861935534 valid 0.3628603848127218
LOSS train 0.5025515861935534 valid 0.3628650917248292
LOSS train 0.5025515861935534 valid 0.3625060511169149
LOSS train 0.5025515861935534 valid 0.36197326332330704
LOSS train 0.5025515861935534 valid 0.36185323803321173
LOSS train 0.5025515861935534 valid 0.36152883384908946
LOSS train 0.5025515861935534 valid 0.3611809397247476
LOSS train 0.5025515861935534 valid 0.3611783902678225
LOSS train 0.5025515861935534 valid 0.36147638951262384
LOSS train 0.5025515861935534 valid 0.36123119858471125
LOSS train 0.5025515861935534 valid 0.36070707599322
LOSS train 0.5025515861935534 valid 0.36101742010367543
LOSS train 0.5025515861935534 valid 0.3606816464430326
LOSS train 0.5025515861935534 valid 0.3605497093536915
LOSS train 0.5025515861935534 valid 0.36049905796594256
LOSS train 0.5025515861935534 valid 0.3604996811598539
LOSS train 0.5025515861935534 valid 0.3599475625856423
LOSS train 0.5025515861935534 valid 0.36013796380380303
LOSS train 0.5025515861935534 valid 0.35984072268727313
LOSS train 0.5025515861935534 valid 0.3600194603204727
LOSS train 0.5025515861935534 valid 0.3601990152807797
LOSS train 0.5025515861935534 valid 0.3599299805801968
LOSS train 0.5025515861935534 valid 0.35992301538072785
LOSS train 0.5025515861935534 valid 0.3593733205714009
LOSS train 0.5025515861935534 valid 0.3595899370279205
LOSS train 0.5025515861935534 valid 0.3593779765897327
LOSS train 0.5025515861935534 valid 0.359220510000711
LOSS train 0.5025515861935534 valid 0.35900547420201095
LOSS train 0.5025515861935534 valid 0.3585706446119534
LOSS train 0.5025515861935534 valid 0.3581626770344186
LOSS train 0.5025515861935534 valid 0.3578162111734089
LOSS train 0.5025515861935534 valid 0.35803056446214515
LOSS train 0.5025515861935534 valid 0.35833212456752345
LOSS train 0.5025515861935534 valid 0.35825659608354377
LOSS train 0.5025515861935534 valid 0.35829292764567366
LOSS train 0.5025515861935534 valid 0.3584601292014122
LOSS train 0.5025515861935534 valid 0.3585352871087518
LOSS train 0.5025515861935534 valid 0.35859448857167187
LOSS train 0.5025515861935534 valid 0.3591245502522848
LOSS train 0.5025515861935534 valid 0.3589272639499261
LOSS train 0.5025515861935534 valid 0.358784681558609
LOSS train 0.5025515861935534 valid 0.35878702632661136
LOSS train 0.5025515861935534 valid 0.35856328640028695
LOSS train 0.5025515861935534 valid 0.3588982006465947
LOSS train 0.5025515861935534 valid 0.35890590925829124
LOSS train 0.5025515861935534 valid 0.3590331502936103
LOSS train 0.5025515861935534 valid 0.35893963961987885
LOSS train 0.5025515861935534 valid 0.35881114644663675
LOSS train 0.5025515861935534 valid 0.35882267276797675
LOSS train 0.5025515861935534 valid 0.3586532528463163
LOSS train 0.5025515861935534 valid 0.35871562102566595
LOSS train 0.5025515861935534 valid 0.3587484739977738
LOSS train 0.5025515861935534 valid 0.3588343191350627
LOSS train 0.5025515861935534 valid 0.35858633760678565
LOSS train 0.5025515861935534 valid 0.3584676900831591
LOSS train 0.5025515861935534 valid 0.35829723079999287
LOSS train 0.5025515861935534 valid 0.35821667978586247
LOSS train 0.5025515861935534 valid 0.3581259963942356
LOSS train 0.5025515861935534 valid 0.3581976590117788
LOSS train 0.5025515861935534 valid 0.35844212914666823
LOSS train 0.5025515861935534 valid 0.35827632904052736
LOSS train 0.5025515861935534 valid 0.3580492242934212
LOSS train 0.5025515861935534 valid 0.3585580038273428
LOSS train 0.5025515861935534 valid 0.358682872261852
LOSS train 0.5025515861935534 valid 0.3588062125120976
LOSS train 0.5025515861935534 valid 0.35854312983842995
LOSS train 0.5025515861935534 valid 0.35855488354013165
LOSS train 0.5025515861935534 valid 0.3585351382692655
LOSS train 0.5025515861935534 valid 0.3583438087226753
LOSS train 0.5025515861935534 valid 0.3585801262464096
LOSS train 0.5025515861935534 valid 0.35869256522920395
LOSS train 0.5025515861935534 valid 0.3585166725165704
LOSS train 0.5025515861935534 valid 0.3583124497511091
LOSS train 0.5025515861935534 valid 0.35823486594186316
LOSS train 0.5025515861935534 valid 0.35806240044909415
LOSS train 0.5025515861935534 valid 0.35822211354970934
LOSS train 0.5025515861935534 valid 0.3583127165094335
LOSS train 0.5025515861935534 valid 0.358693443763424
LOSS train 0.5025515861935534 valid 0.358537434489577
LOSS train 0.5025515861935534 valid 0.3586995881050825
LOSS train 0.5025515861935534 valid 0.358616676618313
LOSS train 0.5025515861935534 valid 0.35879142235403194
LOSS train 0.5025515861935534 valid 0.35844296298059475
LOSS train 0.5025515861935534 valid 0.3586701045970659
LOSS train 0.5025515861935534 valid 0.358788074863037
LOSS train 0.5025515861935534 valid 0.35879096627235413
LOSS train 0.5025515861935534 valid 0.3588065276082778
LOSS train 0.5025515861935534 valid 0.358633724286368
LOSS train 0.5025515861935534 valid 0.3588095843012816
LOSS train 0.5025515861935534 valid 0.3587950959608152
LOSS train 0.5025515861935534 valid 0.3587857996263812
LOSS train 0.5025515861935534 valid 0.35899852827573436
LOSS train 0.5025515861935534 valid 0.35900663456339743
LOSS train 0.5025515861935534 valid 0.35902327431153647
LOSS train 0.5025515861935534 valid 0.3587352725319892
LOSS train 0.5025515861935534 valid 0.3587499322369695
LOSS train 0.5025515861935534 valid 0.35860531652195854
LOSS train 0.5025515861935534 valid 0.35832128793369106
LOSS train 0.5025515861935534 valid 0.35827667819210357
LOSS train 0.5025515861935534 valid 0.3582099240000655
LOSS train 0.5025515861935534 valid 0.35812996969078525
LOSS train 0.5025515861935534 valid 0.35801163585071105
LOSS train 0.5025515861935534 valid 0.358042369881076
LOSS train 0.5025515861935534 valid 0.35811621961849077
LOSS train 0.5025515861935534 valid 0.35814389269027486
LOSS train 0.5025515861935534 valid 0.3584243951474919
LOSS train 0.5025515861935534 valid 0.3583849070713534
LOSS train 0.5025515861935534 valid 0.3584288346559502
LOSS train 0.5025515861935534 valid 0.3586148617929117
LOSS train 0.5025515861935534 valid 0.35855495141840527
LOSS train 0.5025515861935534 valid 0.35850052867616927
LOSS train 0.5025515861935534 valid 0.3583198291334239
LOSS train 0.5025515861935534 valid 0.35846550451160153
LOSS train 0.5025515861935534 valid 0.35859661624672706
LOSS train 0.5025515861935534 valid 0.358474225638299
LOSS train 0.5025515861935534 valid 0.35859230326281655
LOSS train 0.5025515861935534 valid 0.3586531093766018
LOSS train 0.5025515861935534 valid 0.3587535302062611
LOSS train 0.5025515861935534 valid 0.35870685912872274
LOSS train 0.5025515861935534 valid 0.35881528663246526
LOSS train 0.5025515861935534 valid 0.35875026406468574
LOSS train 0.5025515861935534 valid 0.3588095188781779
LOSS train 0.5025515861935534 valid 0.3589073174140033
LOSS train 0.5025515861935534 valid 0.35888482122979265
LOSS train 0.5025515861935534 valid 0.3588871463896736
LOSS train 0.5025515861935534 valid 0.3587501507056387
LOSS train 0.5025515861935534 valid 0.3589649911950396
LOSS train 0.5025515861935534 valid 0.3590451351677378
LOSS train 0.5025515861935534 valid 0.3589862841398605
LOSS train 0.5025515861935534 valid 0.35884350292461437
LOSS train 0.5025515861935534 valid 0.35880568424860637
LOSS train 0.5025515861935534 valid 0.3588028790391221
LOSS train 0.5025515861935534 valid 0.35892433911410687
LOSS train 0.5025515861935534 valid 0.35895452159221725
LOSS train 0.5025515861935534 valid 0.3589461559626325
LOSS train 0.5025515861935534 valid 0.358920102417469
LOSS train 0.5025515861935534 valid 0.35878962515598506
LOSS train 0.5025515861935534 valid 0.35891054334616895
LOSS train 0.5025515861935534 valid 0.3587357917149079
LOSS train 0.5025515861935534 valid 0.358640796121429
LOSS train 0.5025515861935534 valid 0.3586334071508268
LOSS train 0.5025515861935534 valid 0.35858776847135676
LOSS train 0.5025515861935534 valid 0.35873128394573783
LOSS train 0.5025515861935534 valid 0.3587520546638049
LOSS train 0.5025515861935534 valid 0.35866072089478157
LOSS train 0.5025515861935534 valid 0.3586992400033133
LOSS train 0.5025515861935534 valid 0.3586546448169726
LOSS train 0.5025515861935534 valid 0.3586763984189843
LOSS train 0.5025515861935534 valid 0.3587761026033213
LOSS train 0.5025515861935534 valid 0.358790211727686
LOSS train 0.5025515861935534 valid 0.3588078270124835
LOSS train 0.5025515861935534 valid 0.3588170221558324
LOSS train 0.5025515861935534 valid 0.3588834646660062
LOSS train 0.5025515861935534 valid 0.35897348397368684
LOSS train 0.5025515861935534 valid 0.3590107916696975
LOSS train 0.5025515861935534 valid 0.35912004004825243
LOSS train 0.5025515861935534 valid 0.35920191620270053
LOSS train 0.5025515861935534 valid 0.3591930420549066
LOSS train 0.5025515861935534 valid 0.35926941504927495
LOSS train 0.5025515861935534 valid 0.35931482152747257
LOSS train 0.5025515861935534 valid 0.35938508298661975
LOSS train 0.5025515861935534 valid 0.3593313879935087
LOSS train 0.5025515861935534 valid 0.3594617385433634
LOSS train 0.5025515861935534 valid 0.3595175369266878
LOSS train 0.5025515861935534 valid 0.3595467730380562
LOSS train 0.5025515861935534 valid 0.3596397568350253
LOSS train 0.5025515861935534 valid 0.359607383931354
LOSS train 0.5025515861935534 valid 0.359592763385896
LOSS train 0.5025515861935534 valid 0.35950751302068323
LOSS train 0.5025515861935534 valid 0.35944163353524655
LOSS train 0.5025515861935534 valid 0.3594916809112468
LOSS train 0.5025515861935534 valid 0.3594329988552352
LOSS train 0.5025515861935534 valid 0.3593564791769921
LOSS train 0.5025515861935534 valid 0.35938298714761974
LOSS train 0.5025515861935534 valid 0.3592648082198458
LOSS train 0.5025515861935534 valid 0.35916535357634227
LOSS train 0.5025515861935534 valid 0.35932937919846214
LOSS train 0.5025515861935534 valid 0.35926829450879216
LOSS train 0.5025515861935534 valid 0.3592637216848601
LOSS train 0.5025515861935534 valid 0.35934104013149853
LOSS train 0.5025515861935534 valid 0.3593394371928001
LOSS train 0.5025515861935534 valid 0.3592901736255584
LOSS train 0.5025515861935534 valid 0.3593301520897792
LOSS train 0.5025515861935534 valid 0.3592920951064556
LOSS train 0.5025515861935534 valid 0.35928534898891984
LOSS train 0.5025515861935534 valid 0.35945533072948455
LOSS train 0.5025515861935534 valid 0.35948528628425297
LOSS train 0.5025515861935534 valid 0.35963970328134204
LOSS train 0.5025515861935534 valid 0.3595779981066587
LOSS train 0.5025515861935534 valid 0.3597344554315402
LOSS train 0.5025515861935534 valid 0.35967755481308583
LOSS train 0.5025515861935534 valid 0.35966088669374585
LOSS train 0.5025515861935534 valid 0.359617801028003
LOSS train 0.5025515861935534 valid 0.35970539663189144
LOSS train 0.5025515861935534 valid 0.3596586464224635
LOSS train 0.5025515861935534 valid 0.35954506076299225
LOSS train 0.5025515861935534 valid 0.3595890140168055
LOSS train 0.5025515861935534 valid 0.3595352942934473
LOSS train 0.5025515861935534 valid 0.35948652697606687
LOSS train 0.5025515861935534 valid 0.3594250926239924
LOSS train 0.5025515861935534 valid 0.359455521039243
LOSS train 0.5025515861935534 valid 0.35954154445264574
LOSS train 0.5025515861935534 valid 0.35967528619123307
LOSS train 0.5025515861935534 valid 0.3596939644706783
LOSS train 0.5025515861935534 valid 0.35986404204014066
LOSS train 0.5025515861935534 valid 0.35980720818042755
LOSS train 0.5025515861935534 valid 0.35991823222364444
LOSS train 0.5025515861935534 valid 0.359926646356197
LOSS train 0.5025515861935534 valid 0.35991313933452845
LOSS train 0.5025515861935534 valid 0.3598994090609307
LOSS train 0.5025515861935534 valid 0.35983831893314017
LOSS train 0.5025515861935534 valid 0.3597581957777341
LOSS train 0.5025515861935534 valid 0.3598180733863197
LOSS train 0.5025515861935534 valid 0.3597689960285914
LOSS train 0.5025515861935534 valid 0.3598074491092381
LOSS train 0.5025515861935534 valid 0.3597311240221773
LOSS train 0.5025515861935534 valid 0.35961571547908716
LOSS train 0.5025515861935534 valid 0.3596103665887887
LOSS train 0.5025515861935534 valid 0.3596049255490724
LOSS train 0.5025515861935534 valid 0.35965133731214094
LOSS train 0.5025515861935534 valid 0.359629330823296
LOSS train 0.5025515861935534 valid 0.35953059052670755
LOSS train 0.5025515861935534 valid 0.3595352789666179
LOSS train 0.5025515861935534 valid 0.35952188985215294
LOSS train 0.5025515861935534 valid 0.35951031285586244
LOSS train 0.5025515861935534 valid 0.35947781801223755
LOSS train 0.5025515861935534 valid 0.3593753085718122
LOSS train 0.5025515861935534 valid 0.35938344028306335
LOSS train 0.5025515861935534 valid 0.3592866235015335
LOSS train 0.5025515861935534 valid 0.35936889133485805
LOSS train 0.5025515861935534 valid 0.35950184767529114
LOSS train 0.5025515861935534 valid 0.35946937982697746
LOSS train 0.5025515861935534 valid 0.35947307663333133
LOSS train 0.5025515861935534 valid 0.3593864983960286
LOSS train 0.5025515861935534 valid 0.3594393871699687
LOSS train 0.5025515861935534 valid 0.3594868615269661
LOSS train 0.5025515861935534 valid 0.359433488691368
LOSS train 0.5025515861935534 valid 0.3593144203653399
LOSS train 0.5025515861935534 valid 0.35926401093848076
LOSS train 0.5025515861935534 valid 0.35925331966657387
LOSS train 0.5025515861935534 valid 0.35921447804716766
LOSS train 0.5025515861935534 valid 0.3592572088529861
LOSS train 0.5025515861935534 valid 0.3592528239717701
LOSS train 0.5025515861935534 valid 0.35920014948426904
LOSS train 0.5025515861935534 valid 0.3592375565115302
LOSS train 0.5025515861935534 valid 0.3592085694113085
LOSS train 0.5025515861935534 valid 0.3591567528976122
LOSS train 0.5025515861935534 valid 0.3591591947926925
LOSS train 0.5025515861935534 valid 0.3592466701524326
LOSS train 0.5025515861935534 valid 0.3592271147070417
LOSS train 0.5025515861935534 valid 0.35920667619932267
LOSS train 0.5025515861935534 valid 0.3591172179277939
LOSS train 0.5025515861935534 valid 0.35914382310319776
LOSS train 0.5025515861935534 valid 0.3591425653148747
LOSS train 0.5025515861935534 valid 0.3591163122915549
LOSS train 0.5025515861935534 valid 0.35904635544866326
LOSS train 0.5025515861935534 valid 0.35908415031581653
LOSS train 0.5025515861935534 valid 0.3590813360599257
LOSS train 0.5025515861935534 valid 0.3590546797488127
LOSS train 0.5025515861935534 valid 0.359038517706924
LOSS train 0.5025515861935534 valid 0.35899213075637815
LOSS train 0.5025515861935534 valid 0.3590396161825379
LOSS train 0.5025515861935534 valid 0.35914612764247694
LOSS train 0.5025515861935534 valid 0.35913026223822336
LOSS train 0.5025515861935534 valid 0.3591330946397636
LOSS train 0.5025515861935534 valid 0.3590743770202001
LOSS train 0.5025515861935534 valid 0.35905103867147625
LOSS train 0.5025515861935534 valid 0.3589295807732157
LOSS train 0.5025515861935534 valid 0.3588990417865662
LOSS train 0.5025515861935534 valid 0.3589691688379128
LOSS train 0.5025515861935534 valid 0.3589516117501615
LOSS train 0.5025515861935534 valid 0.35892148768263205
LOSS train 0.5025515861935534 valid 0.35889951252442087
LOSS train 0.5025515861935534 valid 0.35893700320339766
LOSS train 0.5025515861935534 valid 0.35887569206654146
LOSS train 0.5025515861935534 valid 0.35887688328238093
LOSS train 0.5025515861935534 valid 0.35876916484399274
LOSS train 0.5025515861935534 valid 0.3586791927180095
LOSS train 0.5025515861935534 valid 0.35869499667392873
LOSS train 0.5025515861935534 valid 0.3587766528822655
LOSS train 0.5025515861935534 valid 0.3588302391162817
LOSS train 0.5025515861935534 valid 0.3588009336263458
LOSS train 0.5025515861935534 valid 0.3587681044762691
LOSS train 0.5025515861935534 valid 0.35869784216428624
LOSS train 0.5025515861935534 valid 0.358704269017736
LOSS train 0.5025515861935534 valid 0.35861789882183076
LOSS train 0.5025515861935534 valid 0.3585991732924752
LOSS train 0.5025515861935534 valid 0.3586290664124218
LOSS train 0.5025515861935534 valid 0.3587241458994133
LOSS train 0.5025515861935534 valid 0.3588004757960637
LOSS train 0.5025515861935534 valid 0.35883414409529996
LOSS train 0.5025515861935534 valid 0.3588250344723798
LOSS train 0.5025515861935534 valid 0.35879714023165343
LOSS train 0.5025515861935534 valid 0.35874531347325395
LOSS train 0.5025515861935534 valid 0.35873032064490995
LOSS train 0.5025515861935534 valid 0.3587353906697697
LOSS train 0.5025515861935534 valid 0.35877794580446387
LOSS train 0.5025515861935534 valid 0.35886288092610585
LOSS train 0.5025515861935534 valid 0.35880096975108483
LOSS train 0.5025515861935534 valid 0.3587949969447576
LOSS train 0.5025515861935534 valid 0.35883170064181497
LOSS train 0.5025515861935534 valid 0.3587682197491328
LOSS train 0.5025515861935534 valid 0.3587025791325426
LOSS train 0.5025515861935534 valid 0.35871952650663647
LOSS train 0.5025515861935534 valid 0.35874186024110166
EPOCH 11:
  batch 1 loss: 0.4795840382575989
  batch 2 loss: 0.48635542392730713
  batch 3 loss: 0.5009718736012777
  batch 4 loss: 0.5116505026817322
  batch 5 loss: 0.5070569396018982
  batch 6 loss: 0.5043240586916605
  batch 7 loss: 0.5051781705447606
  batch 8 loss: 0.506154477596283
  batch 9 loss: 0.5073972079488966
  batch 10 loss: 0.509613960981369
  batch 11 loss: 0.5084233202717521
  batch 12 loss: 0.5069501946369807
  batch 13 loss: 0.5069060646570646
  batch 14 loss: 0.5081677947725568
  batch 15 loss: 0.5076063493887584
  batch 16 loss: 0.5066594034433365
  batch 17 loss: 0.5069316029548645
  batch 18 loss: 0.5077456831932068
  batch 19 loss: 0.5073140138073972
  batch 20 loss: 0.5064662218093872
  batch 21 loss: 0.507559427193233
  batch 22 loss: 0.5068371268835935
  batch 23 loss: 0.5065746229627858
  batch 24 loss: 0.5064880276719729
  batch 25 loss: 0.506427903175354
  batch 26 loss: 0.5052646650717809
  batch 27 loss: 0.5043668769024037
  batch 28 loss: 0.5033380932041577
  batch 29 loss: 0.5035009045025398
  batch 30 loss: 0.502775498231252
  batch 31 loss: 0.5027236957703868
  batch 32 loss: 0.5023454884067178
  batch 33 loss: 0.5016151350555997
  batch 34 loss: 0.5015567891737994
  batch 35 loss: 0.5027810794966562
  batch 36 loss: 0.502977169222302
  batch 37 loss: 0.5036231762654072
  batch 38 loss: 0.5041170120239258
  batch 39 loss: 0.5042561017549955
  batch 40 loss: 0.5036823637783527
  batch 41 loss: 0.5033422395950411
  batch 42 loss: 0.5035429717529387
  batch 43 loss: 0.5032135366007339
  batch 44 loss: 0.5035825161771341
  batch 45 loss: 0.5032979634073046
  batch 46 loss: 0.5031294259040252
  batch 47 loss: 0.5035561709961993
  batch 48 loss: 0.5029172239204248
  batch 49 loss: 0.5027055107817358
  batch 50 loss: 0.5024043953418732
  batch 51 loss: 0.5016928665778216
  batch 52 loss: 0.5019108194571275
  batch 53 loss: 0.5021751736694912
  batch 54 loss: 0.5025984722155111
  batch 55 loss: 0.502262352813374
  batch 56 loss: 0.501519361776965
  batch 57 loss: 0.5012525733102832
  batch 58 loss: 0.5019108627376885
  batch 59 loss: 0.5017200172957728
  batch 60 loss: 0.5014055977265041
  batch 61 loss: 0.5011273651826577
  batch 62 loss: 0.5017259668919348
  batch 63 loss: 0.5015976641859327
  batch 64 loss: 0.5023335642181337
  batch 65 loss: 0.5019113352665534
  batch 66 loss: 0.5019878894090652
  batch 67 loss: 0.5022844205151743
  batch 68 loss: 0.5023095173870816
  batch 69 loss: 0.5022735358148381
  batch 70 loss: 0.5021383404731751
  batch 71 loss: 0.5020472352773371
  batch 72 loss: 0.5017348060177432
  batch 73 loss: 0.5016331178684758
  batch 74 loss: 0.5013667796109174
  batch 75 loss: 0.5009477186203003
  batch 76 loss: 0.5014592613044538
  batch 77 loss: 0.5012148843183146
  batch 78 loss: 0.5006871949403714
  batch 79 loss: 0.501047965091995
  batch 80 loss: 0.5009432040154934
  batch 81 loss: 0.5010456810762853
  batch 82 loss: 0.5013841201619404
  batch 83 loss: 0.5015652919390116
  batch 84 loss: 0.5016983456554867
  batch 85 loss: 0.5016318293178783
  batch 86 loss: 0.5021534589833991
  batch 87 loss: 0.5020790658463007
  batch 88 loss: 0.5015030469406735
  batch 89 loss: 0.5014967456292571
  batch 90 loss: 0.5012679662969377
  batch 91 loss: 0.5014601022332579
  batch 92 loss: 0.5010950439002203
  batch 93 loss: 0.5008072327542049
  batch 94 loss: 0.5011920865545881
  batch 95 loss: 0.5012489770588122
  batch 96 loss: 0.5015134612719218
  batch 97 loss: 0.5019094980869097
  batch 98 loss: 0.5021670424208349
  batch 99 loss: 0.5018927340555672
  batch 100 loss: 0.502325941324234
  batch 101 loss: 0.5022293131540317
  batch 102 loss: 0.5022847480049321
  batch 103 loss: 0.5023845680130338
  batch 104 loss: 0.5024296913582545
  batch 105 loss: 0.5021677235762279
  batch 106 loss: 0.5024414891904255
  batch 107 loss: 0.5025389748756016
  batch 108 loss: 0.5024740491752271
  batch 109 loss: 0.5027011638387627
  batch 110 loss: 0.5030775823376396
  batch 111 loss: 0.5032932119326549
  batch 112 loss: 0.5030787837292466
  batch 113 loss: 0.5033095584506482
  batch 114 loss: 0.503729320931853
  batch 115 loss: 0.5035493907721146
  batch 116 loss: 0.5035454142710258
  batch 117 loss: 0.5036594725062704
  batch 118 loss: 0.5037479102611542
  batch 119 loss: 0.5035832689589813
  batch 120 loss: 0.5035312540829182
  batch 121 loss: 0.5032038464526499
  batch 122 loss: 0.5028488416163648
  batch 123 loss: 0.5024892026331367
  batch 124 loss: 0.5026372981167608
  batch 125 loss: 0.5023674988746643
  batch 126 loss: 0.5021492890895359
  batch 127 loss: 0.5025068474566843
  batch 128 loss: 0.5022390969097614
  batch 129 loss: 0.502038157725519
  batch 130 loss: 0.5021390754442948
  batch 131 loss: 0.502415991466464
  batch 132 loss: 0.5026070014996962
  batch 133 loss: 0.5026533473703197
  batch 134 loss: 0.5026794978931769
  batch 135 loss: 0.5027531486970407
  batch 136 loss: 0.5025502469609765
  batch 137 loss: 0.5025945636477783
  batch 138 loss: 0.50306216702945
  batch 139 loss: 0.502986656247283
  batch 140 loss: 0.5027659663132259
  batch 141 loss: 0.502944122814963
  batch 142 loss: 0.5027863744279029
  batch 143 loss: 0.5025502239073907
  batch 144 loss: 0.5025390961931812
  batch 145 loss: 0.5025022288848614
  batch 146 loss: 0.5024053295181222
  batch 147 loss: 0.5023589714043806
  batch 148 loss: 0.5023621751649959
  batch 149 loss: 0.5022687863983564
  batch 150 loss: 0.5019905265172323
  batch 151 loss: 0.5018462700559604
  batch 152 loss: 0.5021492427116946
  batch 153 loss: 0.5021465872627457
  batch 154 loss: 0.5021430838417698
  batch 155 loss: 0.5021734372262032
  batch 156 loss: 0.5020911823480557
  batch 157 loss: 0.5023282227242828
  batch 158 loss: 0.5023242276680621
  batch 159 loss: 0.5023544396994248
  batch 160 loss: 0.5025020468980074
  batch 161 loss: 0.5025332414585612
  batch 162 loss: 0.5024668165930996
  batch 163 loss: 0.5023095220144541
  batch 164 loss: 0.5022835239041142
  batch 165 loss: 0.502173909815875
  batch 166 loss: 0.5023362419332367
  batch 167 loss: 0.5022726624668715
  batch 168 loss: 0.502494578028009
  batch 169 loss: 0.5023552780673348
  batch 170 loss: 0.5023484947050318
  batch 171 loss: 0.5022185310634256
  batch 172 loss: 0.502294928701811
  batch 173 loss: 0.5021389149172457
  batch 174 loss: 0.502071261919778
  batch 175 loss: 0.5019675236088889
  batch 176 loss: 0.5019520612602885
  batch 177 loss: 0.501752493576815
  batch 178 loss: 0.5018208025211699
  batch 179 loss: 0.5017822566312119
  batch 180 loss: 0.501828609738085
  batch 181 loss: 0.501872344734919
  batch 182 loss: 0.5019077195243521
  batch 183 loss: 0.5018647318003607
  batch 184 loss: 0.5017022702680982
  batch 185 loss: 0.5017798689571586
  batch 186 loss: 0.5017392484731572
  batch 187 loss: 0.5016042191714527
  batch 188 loss: 0.501616914221581
  batch 189 loss: 0.5014865698007048
  batch 190 loss: 0.501360884779378
  batch 191 loss: 0.5013512819225251
  batch 192 loss: 0.5012661162763834
  batch 193 loss: 0.5011260989725281
  batch 194 loss: 0.5011612882011944
  batch 195 loss: 0.5013971831554022
  batch 196 loss: 0.5012255917702403
  batch 197 loss: 0.501252938496885
  batch 198 loss: 0.5014140372625505
  batch 199 loss: 0.5013473727295746
  batch 200 loss: 0.5013410042226315
  batch 201 loss: 0.5014325983785278
  batch 202 loss: 0.5014851794089421
  batch 203 loss: 0.5016335884632148
  batch 204 loss: 0.5015706579182663
  batch 205 loss: 0.5016130097028686
  batch 206 loss: 0.5016935492314182
  batch 207 loss: 0.5016478529010994
  batch 208 loss: 0.5015769843012094
  batch 209 loss: 0.5015565342309942
  batch 210 loss: 0.501575764020284
  batch 211 loss: 0.501568698770062
  batch 212 loss: 0.5015925843760652
  batch 213 loss: 0.5015390634256909
  batch 214 loss: 0.5015303000947026
  batch 215 loss: 0.5013198752735937
  batch 216 loss: 0.5011075580561603
  batch 217 loss: 0.5010392135738777
  batch 218 loss: 0.5009967929452931
  batch 219 loss: 0.5008795265465567
  batch 220 loss: 0.5009063432162458
  batch 221 loss: 0.5009873907220849
  batch 222 loss: 0.5011124225618603
  batch 223 loss: 0.5011069669049951
  batch 224 loss: 0.5010575554998857
  batch 225 loss: 0.5010645022657183
  batch 226 loss: 0.5011424194131278
  batch 227 loss: 0.5009731448169322
  batch 228 loss: 0.5011039535727417
  batch 229 loss: 0.5010352137307412
  batch 230 loss: 0.5011119228342306
  batch 231 loss: 0.5010525287487806
  batch 232 loss: 0.5009104933204322
  batch 233 loss: 0.5008651039886884
  batch 234 loss: 0.500845508570345
  batch 235 loss: 0.5009261561200974
  batch 236 loss: 0.5008000967613722
  batch 237 loss: 0.5008531113465627
  batch 238 loss: 0.500882188186926
  batch 239 loss: 0.5006762716810075
  batch 240 loss: 0.500815307473143
  batch 241 loss: 0.5008933001286756
  batch 242 loss: 0.5007407629539159
  batch 243 loss: 0.5007998166996755
  batch 244 loss: 0.5008603167094168
  batch 245 loss: 0.5010020337542709
  batch 246 loss: 0.5010170838454875
  batch 247 loss: 0.5009829435753919
  batch 248 loss: 0.5011015164275323
  batch 249 loss: 0.5011109793521314
  batch 250 loss: 0.5011364722251892
  batch 251 loss: 0.5011304200170524
  batch 252 loss: 0.5012164755709587
  batch 253 loss: 0.5011990966768604
  batch 254 loss: 0.5011782187411166
  batch 255 loss: 0.5013115295008117
  batch 256 loss: 0.5012263600947335
  batch 257 loss: 0.5013433505820857
  batch 258 loss: 0.5013770815706993
  batch 259 loss: 0.5013152316040054
  batch 260 loss: 0.501280559026278
  batch 261 loss: 0.501366309050856
  batch 262 loss: 0.501252088041706
  batch 263 loss: 0.5011962124150062
  batch 264 loss: 0.5011547401998983
  batch 265 loss: 0.5010921111646688
  batch 266 loss: 0.5011000718389239
  batch 267 loss: 0.5010924549138501
  batch 268 loss: 0.5010325895316565
  batch 269 loss: 0.5010994495512384
  batch 270 loss: 0.5011866128003156
  batch 271 loss: 0.5011982513089901
  batch 272 loss: 0.5013063392218422
  batch 273 loss: 0.5012733864260244
  batch 274 loss: 0.5011827340961372
  batch 275 loss: 0.5013250149380077
  batch 276 loss: 0.5014265121325202
  batch 277 loss: 0.5015738113692522
  batch 278 loss: 0.5015339692719549
  batch 279 loss: 0.5015752977795072
  batch 280 loss: 0.501416682771274
  batch 281 loss: 0.5013885207447717
  batch 282 loss: 0.501250352631224
  batch 283 loss: 0.5011604171338435
  batch 284 loss: 0.5011675615965481
  batch 285 loss: 0.5010841134347414
  batch 286 loss: 0.5010830877752571
  batch 287 loss: 0.5010646218206825
  batch 288 loss: 0.5008548945188522
  batch 289 loss: 0.5010292455811814
  batch 290 loss: 0.5008895117661049
  batch 291 loss: 0.500894590751412
  batch 292 loss: 0.5009640902280807
  batch 293 loss: 0.5010011129004963
  batch 294 loss: 0.5009317677848193
  batch 295 loss: 0.5011281068042174
  batch 296 loss: 0.5012154812748367
  batch 297 loss: 0.5013223424905077
  batch 298 loss: 0.5013829415676577
  batch 299 loss: 0.5014425137369928
  batch 300 loss: 0.5015558381875356
  batch 301 loss: 0.5015915525316004
  batch 302 loss: 0.5016243021614504
  batch 303 loss: 0.5016315738753517
  batch 304 loss: 0.501596008672526
  batch 305 loss: 0.5014023669430467
  batch 306 loss: 0.5014994212614945
  batch 307 loss: 0.5014758358560867
  batch 308 loss: 0.5014061899734782
  batch 309 loss: 0.5014307166187508
  batch 310 loss: 0.5014132567951756
  batch 311 loss: 0.5015062637076118
  batch 312 loss: 0.5015972838378869
  batch 313 loss: 0.5016008932560015
  batch 314 loss: 0.5016628759112328
  batch 315 loss: 0.5016843297178784
  batch 316 loss: 0.5016124443728712
  batch 317 loss: 0.5016359371905823
  batch 318 loss: 0.501606840382582
  batch 319 loss: 0.5014935016258383
  batch 320 loss: 0.501429114677012
  batch 321 loss: 0.5014897408515122
  batch 322 loss: 0.501453446490424
  batch 323 loss: 0.5013750192735217
  batch 324 loss: 0.501278083909441
  batch 325 loss: 0.5012492085420168
  batch 326 loss: 0.5011862095879631
  batch 327 loss: 0.5011841036857815
  batch 328 loss: 0.5010645995598014
  batch 329 loss: 0.5011902053848951
  batch 330 loss: 0.5011473718014631
  batch 331 loss: 0.5010252965000821
  batch 332 loss: 0.5009867016630001
  batch 333 loss: 0.5009753103549774
  batch 334 loss: 0.500834139967393
  batch 335 loss: 0.5007427762693434
  batch 336 loss: 0.5007147314470439
  batch 337 loss: 0.500631255105978
  batch 338 loss: 0.5005839683953122
  batch 339 loss: 0.500684208926198
  batch 340 loss: 0.500744750920464
  batch 341 loss: 0.5007499678393613
  batch 342 loss: 0.5006700225217998
  batch 343 loss: 0.5005931102673444
  batch 344 loss: 0.5006051457725292
  batch 345 loss: 0.500754150532294
  batch 346 loss: 0.5007263777745252
  batch 347 loss: 0.5007607443016613
  batch 348 loss: 0.5007631692221794
  batch 349 loss: 0.5006742272472655
  batch 350 loss: 0.5006960892677307
  batch 351 loss: 0.5006790809821539
  batch 352 loss: 0.5007436868141998
  batch 353 loss: 0.5006497420433899
  batch 354 loss: 0.5006778702392416
  batch 355 loss: 0.5007973754070174
  batch 356 loss: 0.5007342292686526
  batch 357 loss: 0.5007135560031698
  batch 358 loss: 0.5007412039867326
  batch 359 loss: 0.5007140624822016
  batch 360 loss: 0.5007601166764896
  batch 361 loss: 0.5008101993320391
  batch 362 loss: 0.5006822526290272
  batch 363 loss: 0.5006300277453809
  batch 364 loss: 0.5005005641461728
  batch 365 loss: 0.5004805657145095
  batch 366 loss: 0.5003835597162039
  batch 367 loss: 0.5003860418250841
  batch 368 loss: 0.5003521203508844
  batch 369 loss: 0.5003355970873742
  batch 370 loss: 0.5003757188449035
  batch 371 loss: 0.5004992995943341
  batch 372 loss: 0.5003979047459941
  batch 373 loss: 0.5003081213373282
  batch 374 loss: 0.5002304761804999
  batch 375 loss: 0.5003155028025309
  batch 376 loss: 0.5003314357488713
  batch 377 loss: 0.5003090156168141
  batch 378 loss: 0.5002446267655287
  batch 379 loss: 0.5001844442928687
  batch 380 loss: 0.5003168819766296
  batch 381 loss: 0.5002178433998989
  batch 382 loss: 0.5000780004793437
  batch 383 loss: 0.5000353864839121
  batch 384 loss: 0.5000160386164983
  batch 385 loss: 0.5000763660901553
  batch 386 loss: 0.49999956022272457
  batch 387 loss: 0.4999621163196958
  batch 388 loss: 0.49995479333339277
  batch 389 loss: 0.4999661127675162
  batch 390 loss: 0.4999273044940753
  batch 391 loss: 0.499864283730002
  batch 392 loss: 0.4998642300464669
  batch 393 loss: 0.4999185585186985
  batch 394 loss: 0.49992255979988176
  batch 395 loss: 0.49996490131450605
  batch 396 loss: 0.49995593899729274
  batch 397 loss: 0.4998761286363193
  batch 398 loss: 0.49981876271753456
  batch 399 loss: 0.4997832620502415
  batch 400 loss: 0.4997503191977739
  batch 401 loss: 0.49973248551016736
  batch 402 loss: 0.49981830361767193
  batch 403 loss: 0.49974755983494645
  batch 404 loss: 0.4997326609964418
  batch 405 loss: 0.49969850204609056
  batch 406 loss: 0.4997630012152817
  batch 407 loss: 0.49978036684251825
  batch 408 loss: 0.4998934339074528
  batch 409 loss: 0.49989100831645045
  batch 410 loss: 0.49992211330227737
  batch 411 loss: 0.49989851163541604
  batch 412 loss: 0.4998465699044246
  batch 413 loss: 0.4998199787468945
  batch 414 loss: 0.4998080081121933
  batch 415 loss: 0.4998036890144808
  batch 416 loss: 0.4997824254230811
  batch 417 loss: 0.49974949711518324
  batch 418 loss: 0.49974114237504713
  batch 419 loss: 0.4997325398045679
  batch 420 loss: 0.49972031861543653
  batch 421 loss: 0.4996950887586045
  batch 422 loss: 0.49977510101139827
  batch 423 loss: 0.49979149090482833
  batch 424 loss: 0.49980712281364315
  batch 425 loss: 0.4998104328968946
  batch 426 loss: 0.4998012469827849
  batch 427 loss: 0.4998090083621425
  batch 428 loss: 0.49971766052680594
  batch 429 loss: 0.49966935865528933
  batch 430 loss: 0.4996780009463776
  batch 431 loss: 0.49984095413281027
  batch 432 loss: 0.4998308347745074
  batch 433 loss: 0.4997867396742312
  batch 434 loss: 0.49982352946211117
  batch 435 loss: 0.49975237955992247
  batch 436 loss: 0.4997363648283372
  batch 437 loss: 0.49978845956942036
  batch 438 loss: 0.49985174351631234
  batch 439 loss: 0.49983731394205116
  batch 440 loss: 0.49988509917801077
  batch 441 loss: 0.4998586183232245
  batch 442 loss: 0.49981953547551083
  batch 443 loss: 0.49981509367714616
  batch 444 loss: 0.49972268207384657
  batch 445 loss: 0.49975520847888477
  batch 446 loss: 0.499703483196652
  batch 447 loss: 0.49968777326929487
  batch 448 loss: 0.49980408219354494
  batch 449 loss: 0.4998822506923718
  batch 450 loss: 0.49997594330045914
  batch 451 loss: 0.5000011644712309
  batch 452 loss: 0.5000190330026424
  batch 453 loss: 0.5000545660128394
  batch 454 loss: 0.5000737994777998
  batch 455 loss: 0.5000831245066045
  batch 456 loss: 0.5001038817460077
  batch 457 loss: 0.5001289924072749
  batch 458 loss: 0.5001077706636821
  batch 459 loss: 0.5001131400043928
  batch 460 loss: 0.5001991649036822
  batch 461 loss: 0.5002402500320153
  batch 462 loss: 0.5001897946709678
  batch 463 loss: 0.500203560482606
  batch 464 loss: 0.5002845343973102
  batch 465 loss: 0.5001237572521292
  batch 466 loss: 0.5000063251272292
  batch 467 loss: 0.5000170658181005
  batch 468 loss: 0.49995714833593774
  batch 469 loss: 0.4999794314410895
  batch 470 loss: 0.49991948033900974
  batch 471 loss: 0.49990428873434695
  batch 472 loss: 0.4998558106816421
LOSS train 0.4998558106816421 valid 0.3454321622848511
LOSS train 0.4998558106816421 valid 0.3332723528146744
LOSS train 0.4998558106816421 valid 0.345911701520284
LOSS train 0.4998558106816421 valid 0.34303368628025055
LOSS train 0.4998558106816421 valid 0.34136139154434203
LOSS train 0.4998558106816421 valid 0.342777540286382
LOSS train 0.4998558106816421 valid 0.3415610534804208
LOSS train 0.4998558106816421 valid 0.3417721651494503
LOSS train 0.4998558106816421 valid 0.33918720814916825
LOSS train 0.4998558106816421 valid 0.34139027297496793
LOSS train 0.4998558106816421 valid 0.34391991929574445
LOSS train 0.4998558106816421 valid 0.34398770332336426
LOSS train 0.4998558106816421 valid 0.3462382096510667
LOSS train 0.4998558106816421 valid 0.3464690148830414
LOSS train 0.4998558106816421 valid 0.34555018742879234
LOSS train 0.4998558106816421 valid 0.3471914306282997
LOSS train 0.4998558106816421 valid 0.349314644056208
LOSS train 0.4998558106816421 valid 0.34959089756011963
LOSS train 0.4998558106816421 valid 0.34979039587472616
LOSS train 0.4998558106816421 valid 0.3509770050644875
LOSS train 0.4998558106816421 valid 0.35054169098536175
LOSS train 0.4998558106816421 valid 0.3487742001360113
LOSS train 0.4998558106816421 valid 0.3494569516700247
LOSS train 0.4998558106816421 valid 0.34879741196831066
LOSS train 0.4998558106816421 valid 0.3486031901836395
LOSS train 0.4998558106816421 valid 0.3480503731049024
LOSS train 0.4998558106816421 valid 0.3475526096644225
LOSS train 0.4998558106816421 valid 0.34755865910223555
LOSS train 0.4998558106816421 valid 0.34758578189488115
LOSS train 0.4998558106816421 valid 0.34850252072016397
LOSS train 0.4998558106816421 valid 0.3498245516131001
LOSS train 0.4998558106816421 valid 0.34970102552324533
LOSS train 0.4998558106816421 valid 0.3506741424401601
LOSS train 0.4998558106816421 valid 0.35009974153602824
LOSS train 0.4998558106816421 valid 0.3510020077228546
LOSS train 0.4998558106816421 valid 0.3510020184848044
LOSS train 0.4998558106816421 valid 0.351477595599922
LOSS train 0.4998558106816421 valid 0.3523677265957782
LOSS train 0.4998558106816421 valid 0.35210922818917495
LOSS train 0.4998558106816421 valid 0.3533006891608238
LOSS train 0.4998558106816421 valid 0.35328406386259126
LOSS train 0.4998558106816421 valid 0.354058706334659
LOSS train 0.4998558106816421 valid 0.3539309328378633
LOSS train 0.4998558106816421 valid 0.35421482202681626
LOSS train 0.4998558106816421 valid 0.35439455774095324
LOSS train 0.4998558106816421 valid 0.3548289038564848
LOSS train 0.4998558106816421 valid 0.3544636134137499
LOSS train 0.4998558106816421 valid 0.3547076905767123
LOSS train 0.4998558106816421 valid 0.3552034740545312
LOSS train 0.4998558106816421 valid 0.35460006415843964
LOSS train 0.4998558106816421 valid 0.35510072462698994
LOSS train 0.4998558106816421 valid 0.3547880334349779
LOSS train 0.4998558106816421 valid 0.35439786708579873
LOSS train 0.4998558106816421 valid 0.3545392431594707
LOSS train 0.4998558106816421 valid 0.3542072583328594
LOSS train 0.4998558106816421 valid 0.35421992944819586
LOSS train 0.4998558106816421 valid 0.35389503784347
LOSS train 0.4998558106816421 valid 0.3536195045915143
LOSS train 0.4998558106816421 valid 0.35407782005051436
LOSS train 0.4998558106816421 valid 0.3534549539287885
LOSS train 0.4998558106816421 valid 0.3524319627245919
LOSS train 0.4998558106816421 valid 0.3532553858334018
LOSS train 0.4998558106816421 valid 0.35362524692974395
LOSS train 0.4998558106816421 valid 0.35406912211328745
LOSS train 0.4998558106816421 valid 0.3540680027925051
LOSS train 0.4998558106816421 valid 0.3541271456263282
LOSS train 0.4998558106816421 valid 0.3536992775860117
LOSS train 0.4998558106816421 valid 0.35324304156443653
LOSS train 0.4998558106816421 valid 0.3531757394472758
LOSS train 0.4998558106816421 valid 0.3528812595776149
LOSS train 0.4998558106816421 valid 0.35258431291916004
LOSS train 0.4998558106816421 valid 0.3525750964052147
LOSS train 0.4998558106816421 valid 0.35282736159350775
LOSS train 0.4998558106816421 valid 0.35262876144937566
LOSS train 0.4998558106816421 valid 0.3521446454524994
LOSS train 0.4998558106816421 valid 0.3524536384563697
LOSS train 0.4998558106816421 valid 0.3521822439385699
LOSS train 0.4998558106816421 valid 0.35210848045654786
LOSS train 0.4998558106816421 valid 0.3519867009754422
LOSS train 0.4998558106816421 valid 0.3519734025001526
LOSS train 0.4998558106816421 valid 0.3515428532788783
LOSS train 0.4998558106816421 valid 0.3517289924912336
LOSS train 0.4998558106816421 valid 0.35143932089748153
LOSS train 0.4998558106816421 valid 0.35168370817388805
LOSS train 0.4998558106816421 valid 0.35177297592163087
LOSS train 0.4998558106816421 valid 0.35145975995895473
LOSS train 0.4998558106816421 valid 0.3514453703644632
LOSS train 0.4998558106816421 valid 0.3510091890665618
LOSS train 0.4998558106816421 valid 0.3512274519111333
LOSS train 0.4998558106816421 valid 0.35107047657171886
LOSS train 0.4998558106816421 valid 0.35086884308647326
LOSS train 0.4998558106816421 valid 0.3506669538176578
LOSS train 0.4998558106816421 valid 0.35019938215132684
LOSS train 0.4998558106816421 valid 0.349836565078573
LOSS train 0.4998558106816421 valid 0.34958785646840146
LOSS train 0.4998558106816421 valid 0.3497903241465489
LOSS train 0.4998558106816421 valid 0.35003281684265924
LOSS train 0.4998558106816421 valid 0.3500186612411421
LOSS train 0.4998558106816421 valid 0.3500617745548788
LOSS train 0.4998558106816421 valid 0.3502261605858803
LOSS train 0.4998558106816421 valid 0.3502924604581134
LOSS train 0.4998558106816421 valid 0.35030374807469983
LOSS train 0.4998558106816421 valid 0.35077008576069063
LOSS train 0.4998558106816421 valid 0.35058652323025924
LOSS train 0.4998558106816421 valid 0.3504631649880182
LOSS train 0.4998558106816421 valid 0.3504275893265346
LOSS train 0.4998558106816421 valid 0.3502117517952607
LOSS train 0.4998558106816421 valid 0.3504956016937892
LOSS train 0.4998558106816421 valid 0.3505135402766936
LOSS train 0.4998558106816421 valid 0.3506229533390565
LOSS train 0.4998558106816421 valid 0.3505538753024093
LOSS train 0.4998558106816421 valid 0.3504259381443262
LOSS train 0.4998558106816421 valid 0.3504136758568013
LOSS train 0.4998558106816421 valid 0.35022832636247603
LOSS train 0.4998558106816421 valid 0.3502676766851674
LOSS train 0.4998558106816421 valid 0.3502867242385601
LOSS train 0.4998558106816421 valid 0.35040077668988806
LOSS train 0.4998558106816421 valid 0.35017953560513965
LOSS train 0.4998558106816421 valid 0.35004259382977204
LOSS train 0.4998558106816421 valid 0.34990620985627174
LOSS train 0.4998558106816421 valid 0.34986457376440694
LOSS train 0.4998558106816421 valid 0.34975795105832524
LOSS train 0.4998558106816421 valid 0.3499108499627772
LOSS train 0.4998558106816421 valid 0.3501054250424908
LOSS train 0.4998558106816421 valid 0.3499568531513214
LOSS train 0.4998558106816421 valid 0.34978671230020975
LOSS train 0.4998558106816421 valid 0.3503083434161239
LOSS train 0.4998558106816421 valid 0.3504419536329806
LOSS train 0.4998558106816421 valid 0.3505558172861735
LOSS train 0.4998558106816421 valid 0.35039226091825043
LOSS train 0.4998558106816421 valid 0.3504059803849868
LOSS train 0.4998558106816421 valid 0.35039078963525366
LOSS train 0.4998558106816421 valid 0.3501996951443808
LOSS train 0.4998558106816421 valid 0.35041829854694767
LOSS train 0.4998558106816421 valid 0.3504997831803781
LOSS train 0.4998558106816421 valid 0.35032596526777043
LOSS train 0.4998558106816421 valid 0.3501975740829523
LOSS train 0.4998558106816421 valid 0.3501076357088227
LOSS train 0.4998558106816421 valid 0.3499629010828279
LOSS train 0.4998558106816421 valid 0.35012031687157497
LOSS train 0.4998558106816421 valid 0.35017083934012877
LOSS train 0.4998558106816421 valid 0.35051126799113314
LOSS train 0.4998558106816421 valid 0.35034085424629957
LOSS train 0.4998558106816421 valid 0.3504008512116141
LOSS train 0.4998558106816421 valid 0.35034094720051207
LOSS train 0.4998558106816421 valid 0.35054928431772203
LOSS train 0.4998558106816421 valid 0.3502001604255365
LOSS train 0.4998558106816421 valid 0.350422950209798
LOSS train 0.4998558106816421 valid 0.35051945951961033
LOSS train 0.4998558106816421 valid 0.35051242748896283
LOSS train 0.4998558106816421 valid 0.35058179438508896
LOSS train 0.4998558106816421 valid 0.35038661486224126
LOSS train 0.4998558106816421 valid 0.35060520557796254
LOSS train 0.4998558106816421 valid 0.350616147572344
LOSS train 0.4998558106816421 valid 0.3506214024559144
LOSS train 0.4998558106816421 valid 0.3508352853166751
LOSS train 0.4998558106816421 valid 0.35082666832170667
LOSS train 0.4998558106816421 valid 0.3508010323666319
LOSS train 0.4998558106816421 valid 0.3505209914918216
LOSS train 0.4998558106816421 valid 0.3505778593942523
LOSS train 0.4998558106816421 valid 0.3504547722961592
LOSS train 0.4998558106816421 valid 0.3501961417036292
LOSS train 0.4998558106816421 valid 0.3501324874857452
LOSS train 0.4998558106816421 valid 0.35009214045797904
LOSS train 0.4998558106816421 valid 0.3499954048431281
LOSS train 0.4998558106816421 valid 0.34985122084617615
LOSS train 0.4998558106816421 valid 0.3498555751974711
LOSS train 0.4998558106816421 valid 0.3499519042670727
LOSS train 0.4998558106816421 valid 0.3499875070428002
LOSS train 0.4998558106816421 valid 0.3502364265568116
LOSS train 0.4998558106816421 valid 0.35024191273583305
LOSS train 0.4998558106816421 valid 0.3503018974564796
LOSS train 0.4998558106816421 valid 0.3504581904480223
LOSS train 0.4998558106816421 valid 0.35037092864513397
LOSS train 0.4998558106816421 valid 0.3503495487145015
LOSS train 0.4998558106816421 valid 0.35016930543563585
LOSS train 0.4998558106816421 valid 0.3503492200105204
LOSS train 0.4998558106816421 valid 0.35045889924081525
LOSS train 0.4998558106816421 valid 0.35035337682542855
LOSS train 0.4998558106816421 valid 0.35048847595850624
LOSS train 0.4998558106816421 valid 0.3505096919628797
LOSS train 0.4998558106816421 valid 0.35058962971299557
LOSS train 0.4998558106816421 valid 0.35051822401786764
LOSS train 0.4998558106816421 valid 0.35061448002639023
LOSS train 0.4998558106816421 valid 0.3505731995041306
LOSS train 0.4998558106816421 valid 0.350597033096898
LOSS train 0.4998558106816421 valid 0.3506611875671754
LOSS train 0.4998558106816421 valid 0.35065444352778985
LOSS train 0.4998558106816421 valid 0.35064719798703675
LOSS train 0.4998558106816421 valid 0.35052947794136247
LOSS train 0.4998558106816421 valid 0.3506960308676615
LOSS train 0.4998558106816421 valid 0.3507574435013036
LOSS train 0.4998558106816421 valid 0.35067700953681236
LOSS train 0.4998558106816421 valid 0.35053142920597313
LOSS train 0.4998558106816421 valid 0.3505155552656223
LOSS train 0.4998558106816421 valid 0.3505302658494638
LOSS train 0.4998558106816421 valid 0.35066577474477933
LOSS train 0.4998558106816421 valid 0.35067137082417804
LOSS train 0.4998558106816421 valid 0.3506648170588604
LOSS train 0.4998558106816421 valid 0.350610778927803
LOSS train 0.4998558106816421 valid 0.35047782861178195
LOSS train 0.4998558106816421 valid 0.35059353310873015
LOSS train 0.4998558106816421 valid 0.3504372804329313
LOSS train 0.4998558106816421 valid 0.3503763826162207
LOSS train 0.4998558106816421 valid 0.35036921515697383
LOSS train 0.4998558106816421 valid 0.35030653002192674
LOSS train 0.4998558106816421 valid 0.35045314238267244
LOSS train 0.4998558106816421 valid 0.3504565220612746
LOSS train 0.4998558106816421 valid 0.3503709137439728
LOSS train 0.4998558106816421 valid 0.3504325161377589
LOSS train 0.4998558106816421 valid 0.35041363826860183
LOSS train 0.4998558106816421 valid 0.35044326520753355
LOSS train 0.4998558106816421 valid 0.35053976083025684
LOSS train 0.4998558106816421 valid 0.3505236629013703
LOSS train 0.4998558106816421 valid 0.3505411046882008
LOSS train 0.4998558106816421 valid 0.3505761183246418
LOSS train 0.4998558106816421 valid 0.35062436203253433
LOSS train 0.4998558106816421 valid 0.35072305087649497
LOSS train 0.4998558106816421 valid 0.3507885399474401
LOSS train 0.4998558106816421 valid 0.35091241923245514
LOSS train 0.4998558106816421 valid 0.3509878303130827
LOSS train 0.4998558106816421 valid 0.35100146980436
LOSS train 0.4998558106816421 valid 0.3510497706887968
LOSS train 0.4998558106816421 valid 0.3510842734415616
LOSS train 0.4998558106816421 valid 0.3511424352063073
LOSS train 0.4998558106816421 valid 0.35110196405279953
LOSS train 0.4998558106816421 valid 0.3512207747556039
LOSS train 0.4998558106816421 valid 0.3512411922739263
LOSS train 0.4998558106816421 valid 0.35129003909998063
LOSS train 0.4998558106816421 valid 0.35134918508322344
LOSS train 0.4998558106816421 valid 0.35133738357783395
LOSS train 0.4998558106816421 valid 0.3513478703539947
LOSS train 0.4998558106816421 valid 0.3512606943114121
LOSS train 0.4998558106816421 valid 0.35121557676894033
LOSS train 0.4998558106816421 valid 0.3512902206562935
LOSS train 0.4998558106816421 valid 0.35125397120491936
LOSS train 0.4998558106816421 valid 0.35118554853185824
LOSS train 0.4998558106816421 valid 0.3511966500713044
LOSS train 0.4998558106816421 valid 0.35109512165001744
LOSS train 0.4998558106816421 valid 0.3509871282925208
LOSS train 0.4998558106816421 valid 0.3511627792570106
LOSS train 0.4998558106816421 valid 0.35109277709949116
LOSS train 0.4998558106816421 valid 0.3510975819311024
LOSS train 0.4998558106816421 valid 0.35119457982602664
LOSS train 0.4998558106816421 valid 0.351183896162072
LOSS train 0.4998558106816421 valid 0.35113524542591434
LOSS train 0.4998558106816421 valid 0.35117534309746284
LOSS train 0.4998558106816421 valid 0.3511405286769713
LOSS train 0.4998558106816421 valid 0.35116516083598615
LOSS train 0.4998558106816421 valid 0.35132325494289396
LOSS train 0.4998558106816421 valid 0.3513668694819112
LOSS train 0.4998558106816421 valid 0.3515146790988862
LOSS train 0.4998558106816421 valid 0.3514458506474853
LOSS train 0.4998558106816421 valid 0.3516039219428235
LOSS train 0.4998558106816421 valid 0.3515542614693735
LOSS train 0.4998558106816421 valid 0.35153554077260196
LOSS train 0.4998558106816421 valid 0.351497744771757
LOSS train 0.4998558106816421 valid 0.35160017614216765
LOSS train 0.4998558106816421 valid 0.35156336300161356
LOSS train 0.4998558106816421 valid 0.35146749363495755
LOSS train 0.4998558106816421 valid 0.35149615991617983
LOSS train 0.4998558106816421 valid 0.351445195215349
LOSS train 0.4998558106816421 valid 0.35142638270845883
LOSS train 0.4998558106816421 valid 0.3513662495622129
LOSS train 0.4998558106816421 valid 0.3513754023695892
LOSS train 0.4998558106816421 valid 0.351450144908482
LOSS train 0.4998558106816421 valid 0.3515939898928453
LOSS train 0.4998558106816421 valid 0.35160711018452
LOSS train 0.4998558106816421 valid 0.35179443020359735
LOSS train 0.4998558106816421 valid 0.3517442075190721
LOSS train 0.4998558106816421 valid 0.35184251987186305
LOSS train 0.4998558106816421 valid 0.3518631590858978
LOSS train 0.4998558106816421 valid 0.35185317602349725
LOSS train 0.4998558106816421 valid 0.3518531751023592
LOSS train 0.4998558106816421 valid 0.3517823660373688
LOSS train 0.4998558106816421 valid 0.35171653567880823
LOSS train 0.4998558106816421 valid 0.35177111152277096
LOSS train 0.4998558106816421 valid 0.3517058296598119
LOSS train 0.4998558106816421 valid 0.3517623586466663
LOSS train 0.4998558106816421 valid 0.35167971764292033
LOSS train 0.4998558106816421 valid 0.35155146041374613
LOSS train 0.4998558106816421 valid 0.3515391464985854
LOSS train 0.4998558106816421 valid 0.3515306699612958
LOSS train 0.4998558106816421 valid 0.35156857537131914
LOSS train 0.4998558106816421 valid 0.3515628895215821
LOSS train 0.4998558106816421 valid 0.3514701372885204
LOSS train 0.4998558106816421 valid 0.35147612570470216
LOSS train 0.4998558106816421 valid 0.35147337646534044
LOSS train 0.4998558106816421 valid 0.35149350019887243
LOSS train 0.4998558106816421 valid 0.351459627829749
LOSS train 0.4998558106816421 valid 0.35135959165612446
LOSS train 0.4998558106816421 valid 0.351363160634694
LOSS train 0.4998558106816421 valid 0.35126916052131524
LOSS train 0.4998558106816421 valid 0.35133607330776395
LOSS train 0.4998558106816421 valid 0.3514690380985454
LOSS train 0.4998558106816421 valid 0.35143898971177434
LOSS train 0.4998558106816421 valid 0.3514527389497468
LOSS train 0.4998558106816421 valid 0.3513949939468563
LOSS train 0.4998558106816421 valid 0.35145895477122685
LOSS train 0.4998558106816421 valid 0.35150504648685454
LOSS train 0.4998558106816421 valid 0.3514696918056653
LOSS train 0.4998558106816421 valid 0.35133118789322326
LOSS train 0.4998558106816421 valid 0.35129618949622604
LOSS train 0.4998558106816421 valid 0.35130166017303344
LOSS train 0.4998558106816421 valid 0.35125837804841215
LOSS train 0.4998558106816421 valid 0.35127943647063636
LOSS train 0.4998558106816421 valid 0.35127526531390335
LOSS train 0.4998558106816421 valid 0.3512328461586655
LOSS train 0.4998558106816421 valid 0.3512793595158166
LOSS train 0.4998558106816421 valid 0.35126822244736455
LOSS train 0.4998558106816421 valid 0.3512236446238024
LOSS train 0.4998558106816421 valid 0.3512372559843919
LOSS train 0.4998558106816421 valid 0.35131357081781944
LOSS train 0.4998558106816421 valid 0.351290169794848
LOSS train 0.4998558106816421 valid 0.35127737238293605
LOSS train 0.4998558106816421 valid 0.35117813737332065
LOSS train 0.4998558106816421 valid 0.3512179314714125
LOSS train 0.4998558106816421 valid 0.35122494661957965
LOSS train 0.4998558106816421 valid 0.35119551653772313
LOSS train 0.4998558106816421 valid 0.3511393304914236
LOSS train 0.4998558106816421 valid 0.35117672425564206
LOSS train 0.4998558106816421 valid 0.3511779452703014
LOSS train 0.4998558106816421 valid 0.35114964898156675
LOSS train 0.4998558106816421 valid 0.35112447126044166
LOSS train 0.4998558106816421 valid 0.3510830839780661
LOSS train 0.4998558106816421 valid 0.3511349091683429
LOSS train 0.4998558106816421 valid 0.3512507825634166
LOSS train 0.4998558106816421 valid 0.3512264789059395
LOSS train 0.4998558106816421 valid 0.3512029681343438
LOSS train 0.4998558106816421 valid 0.3511711453849619
LOSS train 0.4998558106816421 valid 0.35112830645368176
LOSS train 0.4998558106816421 valid 0.35101624784699403
LOSS train 0.4998558106816421 valid 0.35103116056940575
LOSS train 0.4998558106816421 valid 0.3510894100823088
LOSS train 0.4998558106816421 valid 0.35109013781618714
LOSS train 0.4998558106816421 valid 0.3510511145882663
LOSS train 0.4998558106816421 valid 0.35104093194361613
LOSS train 0.4998558106816421 valid 0.35108036534673365
LOSS train 0.4998558106816421 valid 0.3510192375970801
LOSS train 0.4998558106816421 valid 0.35104154558742745
LOSS train 0.4998558106816421 valid 0.3509243709250979
LOSS train 0.4998558106816421 valid 0.3508343881333781
LOSS train 0.4998558106816421 valid 0.3508418227597506
LOSS train 0.4998558106816421 valid 0.35091469462874325
LOSS train 0.4998558106816421 valid 0.3509868424007858
LOSS train 0.4998558106816421 valid 0.35097442222812963
LOSS train 0.4998558106816421 valid 0.35092706398592904
LOSS train 0.4998558106816421 valid 0.350857753777641
LOSS train 0.4998558106816421 valid 0.3508607268675009
LOSS train 0.4998558106816421 valid 0.3507890713214874
LOSS train 0.4998558106816421 valid 0.35078821206024907
LOSS train 0.4998558106816421 valid 0.3508195345374671
LOSS train 0.4998558106816421 valid 0.35090162691583715
LOSS train 0.4998558106816421 valid 0.3509547975608858
LOSS train 0.4998558106816421 valid 0.35098723349436906
LOSS train 0.4998558106816421 valid 0.3509555349356673
LOSS train 0.4998558106816421 valid 0.35093240519197716
LOSS train 0.4998558106816421 valid 0.35088985109462417
LOSS train 0.4998558106816421 valid 0.35089935706850545
LOSS train 0.4998558106816421 valid 0.3509142222503821
LOSS train 0.4998558106816421 valid 0.3509359932672284
LOSS train 0.4998558106816421 valid 0.3510101015231886
LOSS train 0.4998558106816421 valid 0.3509603488379602
LOSS train 0.4998558106816421 valid 0.3509583744210201
LOSS train 0.4998558106816421 valid 0.35099394737857664
LOSS train 0.4998558106816421 valid 0.35093059232000445
LOSS train 0.4998558106816421 valid 0.35088029284568184
LOSS train 0.4998558106816421 valid 0.35088786175069603
LOSS train 0.4998558106816421 valid 0.35088630129651327
EPOCH 12:
  batch 1 loss: 0.4704466462135315
  batch 2 loss: 0.48341262340545654
  batch 3 loss: 0.49109500646591187
  batch 4 loss: 0.5036764144897461
  batch 5 loss: 0.49980618357658385
  batch 6 loss: 0.49683145185311633
  batch 7 loss: 0.49756504382405964
  batch 8 loss: 0.4969720430672169
  batch 9 loss: 0.5003072188960181
  batch 10 loss: 0.5026164084672928
  batch 11 loss: 0.5003915970975702
  batch 12 loss: 0.5007180273532867
  batch 13 loss: 0.5007531505364639
  batch 14 loss: 0.5004900182996478
  batch 15 loss: 0.4987763226032257
  batch 16 loss: 0.4982587583363056
  batch 17 loss: 0.49814562061253714
  batch 18 loss: 0.49782000813219285
  batch 19 loss: 0.4976786233876881
  batch 20 loss: 0.4971971109509468
  batch 21 loss: 0.4975358091649555
  batch 22 loss: 0.49724764309146186
  batch 23 loss: 0.4976969452007957
  batch 24 loss: 0.4975917873283227
  batch 25 loss: 0.49721922755241393
  batch 26 loss: 0.49587297095702243
  batch 27 loss: 0.4953166257452082
  batch 28 loss: 0.49512102880648207
  batch 29 loss: 0.4950558830951822
  batch 30 loss: 0.4943258812030156
  batch 31 loss: 0.49418333941890347
  batch 32 loss: 0.4945913730189204
  batch 33 loss: 0.4943935320232854
  batch 34 loss: 0.4941227181869395
  batch 35 loss: 0.4956537170069558
  batch 36 loss: 0.49594450576437843
  batch 37 loss: 0.4966693496381914
  batch 38 loss: 0.49722239610395935
  batch 39 loss: 0.4973752475701846
  batch 40 loss: 0.4967742919921875
  batch 41 loss: 0.4964543137608505
  batch 42 loss: 0.496969250696046
  batch 43 loss: 0.4965962455716244
  batch 44 loss: 0.49698010967536405
  batch 45 loss: 0.4969259242216746
  batch 46 loss: 0.4969265810821367
  batch 47 loss: 0.49695773137376664
  batch 48 loss: 0.49638654726246995
  batch 49 loss: 0.49602000202451435
  batch 50 loss: 0.4959884238243103
  batch 51 loss: 0.4951557949477551
  batch 52 loss: 0.49549855864965
  batch 53 loss: 0.49599935873499457
  batch 54 loss: 0.4964422826413755
  batch 55 loss: 0.49601206616921856
  batch 56 loss: 0.495160985738039
  batch 57 loss: 0.49485131157071965
  batch 58 loss: 0.49544030479316054
  batch 59 loss: 0.49537057139105717
  batch 60 loss: 0.49501076638698577
  batch 61 loss: 0.49484320058197273
  batch 62 loss: 0.49569111197225507
  batch 63 loss: 0.49567910319282893
  batch 64 loss: 0.4964298699051142
  batch 65 loss: 0.49607120477236233
  batch 66 loss: 0.49606243995102967
  batch 67 loss: 0.4963076208064805
  batch 68 loss: 0.4962090161793372
  batch 69 loss: 0.4962594496167224
  batch 70 loss: 0.49588163154465814
  batch 71 loss: 0.4960272471669694
  batch 72 loss: 0.49569041033585864
  batch 73 loss: 0.49573010206222534
  batch 74 loss: 0.4953823903122464
  batch 75 loss: 0.4951255202293396
  batch 76 loss: 0.49576407278838913
  batch 77 loss: 0.49544648806770125
  batch 78 loss: 0.4949734146014238
  batch 79 loss: 0.49552071132237396
  batch 80 loss: 0.49554375894367697
  batch 81 loss: 0.49570338115280055
  batch 82 loss: 0.49618119546552986
  batch 83 loss: 0.49637915104268543
  batch 84 loss: 0.4965761626760165
  batch 85 loss: 0.4965722515302546
  batch 86 loss: 0.4974702163491138
  batch 87 loss: 0.49744276856553965
  batch 88 loss: 0.4969455921514468
  batch 89 loss: 0.4969209194853065
  batch 90 loss: 0.4970352361599604
  batch 91 loss: 0.4972401644502367
  batch 92 loss: 0.49702422547599545
  batch 93 loss: 0.4966670031188637
  batch 94 loss: 0.4970875642401107
  batch 95 loss: 0.497317740164305
  batch 96 loss: 0.4974539807687203
  batch 97 loss: 0.49787529780692663
  batch 98 loss: 0.4982012285261738
  batch 99 loss: 0.49792920098160254
  batch 100 loss: 0.4983362293243408
  batch 101 loss: 0.4983743606227459
  batch 102 loss: 0.4983791884254007
  batch 103 loss: 0.49859875035517426
  batch 104 loss: 0.49871909389129054
  batch 105 loss: 0.4984738151232401
  batch 106 loss: 0.4988199101304108
  batch 107 loss: 0.49883014882836385
  batch 108 loss: 0.49883169184128445
  batch 109 loss: 0.4991353129575012
  batch 110 loss: 0.4994727695530111
  batch 111 loss: 0.4996231963505616
  batch 112 loss: 0.4994601301316704
  batch 113 loss: 0.49970705345668626
  batch 114 loss: 0.5001701187146338
  batch 115 loss: 0.5000052954839623
  batch 116 loss: 0.4999667706674543
  batch 117 loss: 0.5000398609882746
  batch 118 loss: 0.5001097551341784
  batch 119 loss: 0.5000019248794106
  batch 120 loss: 0.5000092094143231
  batch 121 loss: 0.49973142393364395
  batch 122 loss: 0.4994594874929209
  batch 123 loss: 0.4990919731496795
  batch 124 loss: 0.4992952149721884
  batch 125 loss: 0.4990855288505554
  batch 126 loss: 0.49878244054695914
  batch 127 loss: 0.4991193312828935
  batch 128 loss: 0.4988830017391592
  batch 129 loss: 0.4986376577569533
  batch 130 loss: 0.4986754032281729
  batch 131 loss: 0.4989553325958834
  batch 132 loss: 0.4991809061982415
  batch 133 loss: 0.49918541939635025
  batch 134 loss: 0.4991696381302022
  batch 135 loss: 0.49925527683010806
  batch 136 loss: 0.49909229006837397
  batch 137 loss: 0.4990977216376005
  batch 138 loss: 0.49957364991955133
  batch 139 loss: 0.49952933899790264
  batch 140 loss: 0.4993692838719913
  batch 141 loss: 0.4995143453702859
  batch 142 loss: 0.49933754117556023
  batch 143 loss: 0.49908704128298725
  batch 144 loss: 0.49908447824418545
  batch 145 loss: 0.4990673772219954
  batch 146 loss: 0.49895118687250845
  batch 147 loss: 0.49896731830778573
  batch 148 loss: 0.4990022315366848
  batch 149 loss: 0.4989126864695709
  batch 150 loss: 0.49858980655670165
  batch 151 loss: 0.4983317153343302
  batch 152 loss: 0.49865290483361796
  batch 153 loss: 0.49856797678797854
  batch 154 loss: 0.4985947274155431
  batch 155 loss: 0.4985683408475691
  batch 156 loss: 0.4985595364601184
  batch 157 loss: 0.4987540719615426
  batch 158 loss: 0.4986518921354149
  batch 159 loss: 0.49867009835423165
  batch 160 loss: 0.49876858163625004
  batch 161 loss: 0.49882644137240345
  batch 162 loss: 0.49881662446775554
  batch 163 loss: 0.4986139303701787
  batch 164 loss: 0.49866388429228853
  batch 165 loss: 0.4984822224486958
  batch 166 loss: 0.4986682862761509
  batch 167 loss: 0.49861259089258614
  batch 168 loss: 0.4988362356310799
  batch 169 loss: 0.49873441246134287
  batch 170 loss: 0.4986865301342571
  batch 171 loss: 0.49854042707828056
  batch 172 loss: 0.49865029942850736
  batch 173 loss: 0.4984709084723037
  batch 174 loss: 0.49840447203866367
  batch 175 loss: 0.4983387119429452
  batch 176 loss: 0.49829826249995013
  batch 177 loss: 0.49814027665698596
  batch 178 loss: 0.4982192832767294
  batch 179 loss: 0.49827853477866957
  batch 180 loss: 0.4982058013478915
  batch 181 loss: 0.4982017347825825
  batch 182 loss: 0.49828993258895454
  batch 183 loss: 0.49826745452776633
  batch 184 loss: 0.49815986370262894
  batch 185 loss: 0.4982538406913345
  batch 186 loss: 0.49827649612580577
  batch 187 loss: 0.4981680835950821
  batch 188 loss: 0.498152309117165
  batch 189 loss: 0.4980473483681048
  batch 190 loss: 0.497925496885651
  batch 191 loss: 0.4979346539649664
  batch 192 loss: 0.4978539068251848
  batch 193 loss: 0.4977595529716867
  batch 194 loss: 0.4978069867362681
  batch 195 loss: 0.4979659772836245
  batch 196 loss: 0.4978450310169434
  batch 197 loss: 0.4979107378400522
  batch 198 loss: 0.4980477093145101
  batch 199 loss: 0.4979039135590271
  batch 200 loss: 0.4978990130126476
  batch 201 loss: 0.49795882455745144
  batch 202 loss: 0.4980037916119736
  batch 203 loss: 0.4982122662913036
  batch 204 loss: 0.49815427950199914
  batch 205 loss: 0.4981714314076959
  batch 206 loss: 0.49822154337341346
  batch 207 loss: 0.49817155999837864
  batch 208 loss: 0.498054439918353
  batch 209 loss: 0.4980487504073878
  batch 210 loss: 0.4980693854036785
  batch 211 loss: 0.4980656208020251
  batch 212 loss: 0.49810717746896566
  batch 213 loss: 0.49807108344046724
  batch 214 loss: 0.4980283495143195
  batch 215 loss: 0.4978034126204114
  batch 216 loss: 0.497654275899684
  batch 217 loss: 0.49765504903507674
  batch 218 loss: 0.4976188653926237
  batch 219 loss: 0.49757379620042563
  batch 220 loss: 0.49763051623647864
  batch 221 loss: 0.4977204786166886
  batch 222 loss: 0.4978820018403165
  batch 223 loss: 0.49788869563239574
  batch 224 loss: 0.4978152509512646
  batch 225 loss: 0.49782484862539506
  batch 226 loss: 0.4979266958162848
  batch 227 loss: 0.4977625370813361
  batch 228 loss: 0.4978698634526186
  batch 229 loss: 0.4978262447634118
  batch 230 loss: 0.4978678896375324
  batch 231 loss: 0.4978588023485043
  batch 232 loss: 0.49767538018781565
  batch 233 loss: 0.49758604757263936
  batch 234 loss: 0.4975088357161253
  batch 235 loss: 0.4976174566339939
  batch 236 loss: 0.49756276531744814
  batch 237 loss: 0.49763694569028377
  batch 238 loss: 0.49760825769240113
  batch 239 loss: 0.49746667839992
  batch 240 loss: 0.49756808827320737
  batch 241 loss: 0.49760554786539674
  batch 242 loss: 0.4974177107830678
  batch 243 loss: 0.49744668541621767
  batch 244 loss: 0.49744764837573785
  batch 245 loss: 0.4975747876021327
  batch 246 loss: 0.4975663785769687
  batch 247 loss: 0.49752983607743917
  batch 248 loss: 0.4976116070343602
  batch 249 loss: 0.49766186226802656
  batch 250 loss: 0.49770644688606264
  batch 251 loss: 0.4976985217090622
  batch 252 loss: 0.49778032799561817
  batch 253 loss: 0.49781454339800146
  batch 254 loss: 0.4978041723957212
  batch 255 loss: 0.4978944984136843
  batch 256 loss: 0.49781739118043333
  batch 257 loss: 0.4979268503792091
  batch 258 loss: 0.49790741457033527
  batch 259 loss: 0.497847751876102
  batch 260 loss: 0.4978031879434219
  batch 261 loss: 0.4978831222002534
  batch 262 loss: 0.4977600978303502
  batch 263 loss: 0.49769628648522235
  batch 264 loss: 0.4976588829674504
  batch 265 loss: 0.4975866141184321
  batch 266 loss: 0.4976014924004562
  batch 267 loss: 0.49760759959506634
  batch 268 loss: 0.49754602851262736
  batch 269 loss: 0.4975795668297098
  batch 270 loss: 0.4976343960673721
  batch 271 loss: 0.4975977888626366
  batch 272 loss: 0.49769520244615917
  batch 273 loss: 0.4976971674533117
  batch 274 loss: 0.4975913527020573
  batch 275 loss: 0.49769323468208315
  batch 276 loss: 0.4977585780231849
  batch 277 loss: 0.4978684521539117
  batch 278 loss: 0.49776907029340595
  batch 279 loss: 0.4977703915915609
  batch 280 loss: 0.49760050379804205
  batch 281 loss: 0.49759728798238406
  batch 282 loss: 0.4974331795535189
  batch 283 loss: 0.49733129817689686
  batch 284 loss: 0.4973783706065635
  batch 285 loss: 0.4973114731019003
  batch 286 loss: 0.4972801125132954
  batch 287 loss: 0.4973259287844136
  batch 288 loss: 0.49710916313860154
  batch 289 loss: 0.4971650954348818
  batch 290 loss: 0.4970662299928994
  batch 291 loss: 0.4970360717822596
  batch 292 loss: 0.4970688458583126
  batch 293 loss: 0.4971512922247929
  batch 294 loss: 0.4970847923739427
  batch 295 loss: 0.49720030113802116
  batch 296 loss: 0.49722867781246033
  batch 297 loss: 0.4973542327029938
  batch 298 loss: 0.49740742977033525
  batch 299 loss: 0.49740699282457995
  batch 300 loss: 0.4975204960505168
  batch 301 loss: 0.49763550790045347
  batch 302 loss: 0.4976802709086841
  batch 303 loss: 0.4976937676420306
  batch 304 loss: 0.497703313043243
  batch 305 loss: 0.4975396726952224
  batch 306 loss: 0.4976338948689255
  batch 307 loss: 0.49760707455659925
  batch 308 loss: 0.4975797010513095
  batch 309 loss: 0.4975944947463409
  batch 310 loss: 0.49757431630165344
  batch 311 loss: 0.4976660212519851
  batch 312 loss: 0.4977162235822433
  batch 313 loss: 0.49773643991817684
  batch 314 loss: 0.4977464005825626
  batch 315 loss: 0.4977690944595942
  batch 316 loss: 0.49767270335291003
  batch 317 loss: 0.4976864192952117
  batch 318 loss: 0.497684859910851
  batch 319 loss: 0.4975688498595665
  batch 320 loss: 0.49751669717952607
  batch 321 loss: 0.49754581338148623
  batch 322 loss: 0.497529635055465
  batch 323 loss: 0.49742880546640683
  batch 324 loss: 0.49727182605384307
  batch 325 loss: 0.4972340348133674
  batch 326 loss: 0.49718640086475324
  batch 327 loss: 0.49721045587040963
  batch 328 loss: 0.49708181928570677
  batch 329 loss: 0.49720753652346533
  batch 330 loss: 0.497158069953774
  batch 331 loss: 0.49704732545553015
  batch 332 loss: 0.4970163803502738
  batch 333 loss: 0.49696928916034755
  batch 334 loss: 0.49684370956021157
  batch 335 loss: 0.4967534913055932
  batch 336 loss: 0.4967126399278641
  batch 337 loss: 0.4966896510619438
  batch 338 loss: 0.4966114464067143
  batch 339 loss: 0.4967707065881881
  batch 340 loss: 0.49682094989454045
  batch 341 loss: 0.49684731046125685
  batch 342 loss: 0.49682276865892244
  batch 343 loss: 0.4967648916967409
  batch 344 loss: 0.496806878163371
  batch 345 loss: 0.49694066583246427
  batch 346 loss: 0.4968940186707271
  batch 347 loss: 0.4969751060180774
  batch 348 loss: 0.4969944804906845
  batch 349 loss: 0.4968967659767173
  batch 350 loss: 0.4969093489646912
  batch 351 loss: 0.496923540052865
  batch 352 loss: 0.497002110901204
  batch 353 loss: 0.4969284792797424
  batch 354 loss: 0.496993171966682
  batch 355 loss: 0.4971254399125005
  batch 356 loss: 0.4970727864276157
  batch 357 loss: 0.4970749008889292
  batch 358 loss: 0.49709485612768034
  batch 359 loss: 0.4970911166794121
  batch 360 loss: 0.49717876464128496
  batch 361 loss: 0.4972200370561383
  batch 362 loss: 0.4970854015310825
  batch 363 loss: 0.49705648627491367
  batch 364 loss: 0.49694707883255823
  batch 365 loss: 0.4969418518347283
  batch 366 loss: 0.49684629275824854
  batch 367 loss: 0.49685364133330717
  batch 368 loss: 0.4968280539564464
  batch 369 loss: 0.4968269065143616
  batch 370 loss: 0.4969194943840439
  batch 371 loss: 0.4970544565398738
  batch 372 loss: 0.49694549076018796
  batch 373 loss: 0.4968840933677019
  batch 374 loss: 0.49681107165979194
  batch 375 loss: 0.49691550874710083
  batch 376 loss: 0.49695802511686976
  batch 377 loss: 0.49689502599068597
  batch 378 loss: 0.4968262466173323
  batch 379 loss: 0.4968015180414144
  batch 380 loss: 0.49687626252048894
  batch 381 loss: 0.49679662580565204
  batch 382 loss: 0.4966225134140534
  batch 383 loss: 0.4966398253453307
  batch 384 loss: 0.49660608102567494
  batch 385 loss: 0.496672673891117
  batch 386 loss: 0.4965549580019373
  batch 387 loss: 0.49657448648790364
  batch 388 loss: 0.4965870926521488
  batch 389 loss: 0.49662539240327164
  batch 390 loss: 0.496639662140455
  batch 391 loss: 0.4965813682054925
  batch 392 loss: 0.49662983090597757
  batch 393 loss: 0.4967196810488179
  batch 394 loss: 0.4967089525334121
  batch 395 loss: 0.4967759551881235
  batch 396 loss: 0.4968710282836298
  batch 397 loss: 0.4967962532710068
  batch 398 loss: 0.49675930197814
  batch 399 loss: 0.4968022450916749
  batch 400 loss: 0.4967821151763201
  batch 401 loss: 0.4967425247826184
  batch 402 loss: 0.4968126339847176
  batch 403 loss: 0.49672658819122884
  batch 404 loss: 0.4967215577564617
  batch 405 loss: 0.49670889760241094
  batch 406 loss: 0.4968116676866127
  batch 407 loss: 0.49681282563350126
  batch 408 loss: 0.4968884633306195
  batch 409 loss: 0.4968900659410761
  batch 410 loss: 0.4969118033240481
  batch 411 loss: 0.49689558757482655
  batch 412 loss: 0.49685011601563794
  batch 413 loss: 0.49684996776661633
  batch 414 loss: 0.49683684096244224
  batch 415 loss: 0.49678833922707893
  batch 416 loss: 0.496771117600684
  batch 417 loss: 0.4967630191100873
  batch 418 loss: 0.4967960023708891
  batch 419 loss: 0.4967559261652052
  batch 420 loss: 0.4967605847687948
  batch 421 loss: 0.4967598082617173
  batch 422 loss: 0.49684334917091083
  batch 423 loss: 0.4968811615984491
  batch 424 loss: 0.49686962429363773
  batch 425 loss: 0.4969051743254942
  batch 426 loss: 0.4968687253239009
  batch 427 loss: 0.49685438950949584
  batch 428 loss: 0.49674546084949905
  batch 429 loss: 0.49670178649864555
  batch 430 loss: 0.49671305355637574
  batch 431 loss: 0.4968654328736794
  batch 432 loss: 0.4969106965732795
  batch 433 loss: 0.49684751377920633
  batch 434 loss: 0.4969048030365447
  batch 435 loss: 0.4968586776448392
  batch 436 loss: 0.49686133717998454
  batch 437 loss: 0.49689527909597486
  batch 438 loss: 0.4969839609513
  batch 439 loss: 0.4969627635218288
  batch 440 loss: 0.49700743197040126
  batch 441 loss: 0.4970035611772213
  batch 442 loss: 0.49697241638850304
  batch 443 loss: 0.4969584520056877
  batch 444 loss: 0.4968587818580705
  batch 445 loss: 0.49690050268441105
  batch 446 loss: 0.496870173400293
  batch 447 loss: 0.49684501434332573
  batch 448 loss: 0.49696677304538234
  batch 449 loss: 0.49707302384758845
  batch 450 loss: 0.4971396738290787
  batch 451 loss: 0.4971717300674075
  batch 452 loss: 0.49717736587060235
  batch 453 loss: 0.49721941358469446
  batch 454 loss: 0.49725301307728637
  batch 455 loss: 0.4972718485109099
  batch 456 loss: 0.49728413370617647
  batch 457 loss: 0.497295422679225
  batch 458 loss: 0.4972770700808696
  batch 459 loss: 0.4972948152774819
  batch 460 loss: 0.49737128796784774
  batch 461 loss: 0.49743157470045274
  batch 462 loss: 0.4974132982038316
  batch 463 loss: 0.4973825077902421
  batch 464 loss: 0.4974685660081691
  batch 465 loss: 0.4973178486029307
  batch 466 loss: 0.4972090475549002
  batch 467 loss: 0.49721977797514366
  batch 468 loss: 0.49716173672777975
  batch 469 loss: 0.49717896363374264
  batch 470 loss: 0.49711182738872284
  batch 471 loss: 0.4971240947454092
  batch 472 loss: 0.4970695065744853
LOSS train 0.4970695065744853 valid 0.36025241017341614
LOSS train 0.4970695065744853 valid 0.35403892397880554
LOSS train 0.4970695065744853 valid 0.3680921792984009
LOSS train 0.4970695065744853 valid 0.36465686559677124
LOSS train 0.4970695065744853 valid 0.3639998733997345
LOSS train 0.4970695065744853 valid 0.3639666785796483
LOSS train 0.4970695065744853 valid 0.36074600900922504
LOSS train 0.4970695065744853 valid 0.3605218157172203
LOSS train 0.4970695065744853 valid 0.3565307491355472
LOSS train 0.4970695065744853 valid 0.3586981564760208
LOSS train 0.4970695065744853 valid 0.36146102439273486
LOSS train 0.4970695065744853 valid 0.36109880606333417
LOSS train 0.4970695065744853 valid 0.36324058129237247
LOSS train 0.4970695065744853 valid 0.3633509895631245
LOSS train 0.4970695065744853 valid 0.36173283457756045
LOSS train 0.4970695065744853 valid 0.3625852707773447
LOSS train 0.4970695065744853 valid 0.3652095566777622
LOSS train 0.4970695065744853 valid 0.36522456175751156
LOSS train 0.4970695065744853 valid 0.3655053016386534
LOSS train 0.4970695065744853 valid 0.3667406961321831
LOSS train 0.4970695065744853 valid 0.36595002384412856
LOSS train 0.4970695065744853 valid 0.36381785436110065
LOSS train 0.4970695065744853 valid 0.36469939480657165
LOSS train 0.4970695065744853 valid 0.3639320470392704
LOSS train 0.4970695065744853 valid 0.3635257399082184
LOSS train 0.4970695065744853 valid 0.3630471791212375
LOSS train 0.4970695065744853 valid 0.3624643948343065
LOSS train 0.4970695065744853 valid 0.36257973526205334
LOSS train 0.4970695065744853 valid 0.36262047701868516
LOSS train 0.4970695065744853 valid 0.3634547213713328
LOSS train 0.4970695065744853 valid 0.36492644298461174
LOSS train 0.4970695065744853 valid 0.364947653375566
LOSS train 0.4970695065744853 valid 0.36568043809948547
LOSS train 0.4970695065744853 valid 0.3649684795561959
LOSS train 0.4970695065744853 valid 0.3658272615500859
LOSS train 0.4970695065744853 valid 0.3656856707400746
LOSS train 0.4970695065744853 valid 0.3663738627691527
LOSS train 0.4970695065744853 valid 0.3673183400379984
LOSS train 0.4970695065744853 valid 0.36706511943768233
LOSS train 0.4970695065744853 valid 0.36846557036042216
LOSS train 0.4970695065744853 valid 0.3683888992158378
LOSS train 0.4970695065744853 valid 0.369176216068722
LOSS train 0.4970695065744853 valid 0.3690285329208818
LOSS train 0.4970695065744853 valid 0.36940091916105966
LOSS train 0.4970695065744853 valid 0.36957598593499924
LOSS train 0.4970695065744853 valid 0.37005768845910614
LOSS train 0.4970695065744853 valid 0.36975108118767436
LOSS train 0.4970695065744853 valid 0.3702420300493638
LOSS train 0.4970695065744853 valid 0.3707139394721206
LOSS train 0.4970695065744853 valid 0.3701388746500015
LOSS train 0.4970695065744853 valid 0.3706556400832008
LOSS train 0.4970695065744853 valid 0.3701906278729439
LOSS train 0.4970695065744853 valid 0.3696210030114876
LOSS train 0.4970695065744853 valid 0.36965308752324844
LOSS train 0.4970695065744853 valid 0.36936247023669155
LOSS train 0.4970695065744853 valid 0.3692965486219951
LOSS train 0.4970695065744853 valid 0.36892310516876087
LOSS train 0.4970695065744853 valid 0.36865883089345075
LOSS train 0.4970695065744853 valid 0.3691330658177198
LOSS train 0.4970695065744853 valid 0.36851278990507125
LOSS train 0.4970695065744853 valid 0.3675992024726555
LOSS train 0.4970695065744853 valid 0.3684029997356476
LOSS train 0.4970695065744853 valid 0.36890247369569446
LOSS train 0.4970695065744853 valid 0.3693098328076303
LOSS train 0.4970695065744853 valid 0.36936422127943774
LOSS train 0.4970695065744853 valid 0.3693897444190401
LOSS train 0.4970695065744853 valid 0.3690640330314636
LOSS train 0.4970695065744853 valid 0.3686317919808276
LOSS train 0.4970695065744853 valid 0.3684225302675496
LOSS train 0.4970695065744853 valid 0.3681076249905995
LOSS train 0.4970695065744853 valid 0.3678677673910705
LOSS train 0.4970695065744853 valid 0.36780790529317325
LOSS train 0.4970695065744853 valid 0.3679729785821209
LOSS train 0.4970695065744853 valid 0.36781706721396057
LOSS train 0.4970695065744853 valid 0.3672749996185303
LOSS train 0.4970695065744853 valid 0.36743963039235067
LOSS train 0.4970695065744853 valid 0.36716628306871885
LOSS train 0.4970695065744853 valid 0.3671263395211635
LOSS train 0.4970695065744853 valid 0.3669505651238598
LOSS train 0.4970695065744853 valid 0.36697450093925
LOSS train 0.4970695065744853 valid 0.36647328624018916
LOSS train 0.4970695065744853 valid 0.3667044552361093
LOSS train 0.4970695065744853 valid 0.36645514024309367
LOSS train 0.4970695065744853 valid 0.3666330302755038
LOSS train 0.4970695065744853 valid 0.3667295424377217
LOSS train 0.4970695065744853 valid 0.3664734200682751
LOSS train 0.4970695065744853 valid 0.3664053599724824
LOSS train 0.4970695065744853 valid 0.36591383374550124
LOSS train 0.4970695065744853 valid 0.36618704742260194
LOSS train 0.4970695065744853 valid 0.3659935769107607
LOSS train 0.4970695065744853 valid 0.3658011834045033
LOSS train 0.4970695065744853 valid 0.3655764797459478
LOSS train 0.4970695065744853 valid 0.3650558837639388
LOSS train 0.4970695065744853 valid 0.36457710982637204
LOSS train 0.4970695065744853 valid 0.3642611180481158
LOSS train 0.4970695065744853 valid 0.3644695235416293
LOSS train 0.4970695065744853 valid 0.36469448380863545
LOSS train 0.4970695065744853 valid 0.3646967864158202
LOSS train 0.4970695065744853 valid 0.36477258891770337
LOSS train 0.4970695065744853 valid 0.3649578893184662
LOSS train 0.4970695065744853 valid 0.3650271712553383
LOSS train 0.4970695065744853 valid 0.3650455121316162
LOSS train 0.4970695065744853 valid 0.3655794485680108
LOSS train 0.4970695065744853 valid 0.3653570559735482
LOSS train 0.4970695065744853 valid 0.3652813074134645
LOSS train 0.4970695065744853 valid 0.36522244226257755
LOSS train 0.4970695065744853 valid 0.36501090214631265
LOSS train 0.4970695065744853 valid 0.3653897135346024
LOSS train 0.4970695065744853 valid 0.36544679775150546
LOSS train 0.4970695065744853 valid 0.3655639117414301
LOSS train 0.4970695065744853 valid 0.3655080282473349
LOSS train 0.4970695065744853 valid 0.36536398476787973
LOSS train 0.4970695065744853 valid 0.3654192933994057
LOSS train 0.4970695065744853 valid 0.36518147300209913
LOSS train 0.4970695065744853 valid 0.3652007167753966
LOSS train 0.4970695065744853 valid 0.3652423396706581
LOSS train 0.4970695065744853 valid 0.3653362716874506
LOSS train 0.4970695065744853 valid 0.3651339823411683
LOSS train 0.4970695065744853 valid 0.3649802916691083
LOSS train 0.4970695065744853 valid 0.36481051743030546
LOSS train 0.4970695065744853 valid 0.364744926287123
LOSS train 0.4970695065744853 valid 0.36462132388451063
LOSS train 0.4970695065744853 valid 0.3646948112220299
LOSS train 0.4970695065744853 valid 0.3648824042850925
LOSS train 0.4970695065744853 valid 0.3647317235469818
LOSS train 0.4970695065744853 valid 0.3645242331993012
LOSS train 0.4970695065744853 valid 0.36505838360373427
LOSS train 0.4970695065744853 valid 0.36515695275738835
LOSS train 0.4970695065744853 valid 0.36527222903199896
LOSS train 0.4970695065744853 valid 0.3650246913616474
LOSS train 0.4970695065744853 valid 0.36506272317798993
LOSS train 0.4970695065744853 valid 0.36504935766711377
LOSS train 0.4970695065744853 valid 0.36488781051528185
LOSS train 0.4970695065744853 valid 0.36507471617478043
LOSS train 0.4970695065744853 valid 0.36518587160993504
LOSS train 0.4970695065744853 valid 0.3650349047692383
LOSS train 0.4970695065744853 valid 0.3648180208937095
LOSS train 0.4970695065744853 valid 0.3647612039593683
LOSS train 0.4970695065744853 valid 0.3645801278327009
LOSS train 0.4970695065744853 valid 0.36469388731888364
LOSS train 0.4970695065744853 valid 0.36476937359106454
LOSS train 0.4970695065744853 valid 0.3650867328257628
LOSS train 0.4970695065744853 valid 0.36487655310364037
LOSS train 0.4970695065744853 valid 0.36495247462557423
LOSS train 0.4970695065744853 valid 0.3647866068215206
LOSS train 0.4970695065744853 valid 0.3650426974851791
LOSS train 0.4970695065744853 valid 0.36466163923951234
LOSS train 0.4970695065744853 valid 0.36489912605768926
LOSS train 0.4970695065744853 valid 0.3649772491631092
LOSS train 0.4970695065744853 valid 0.364996031721433
LOSS train 0.4970695065744853 valid 0.3650760723660324
LOSS train 0.4970695065744853 valid 0.3648802840003842
LOSS train 0.4970695065744853 valid 0.36508772400469564
LOSS train 0.4970695065744853 valid 0.36507594179023395
LOSS train 0.4970695065744853 valid 0.3651500565390433
LOSS train 0.4970695065744853 valid 0.36539842665959626
LOSS train 0.4970695065744853 valid 0.36537571450707257
LOSS train 0.4970695065744853 valid 0.3653923131619828
LOSS train 0.4970695065744853 valid 0.365076593258096
LOSS train 0.4970695065744853 valid 0.3650880156084895
LOSS train 0.4970695065744853 valid 0.36496296747130635
LOSS train 0.4970695065744853 valid 0.3646642035908169
LOSS train 0.4970695065744853 valid 0.3646200346800447
LOSS train 0.4970695065744853 valid 0.36455709632576966
LOSS train 0.4970695065744853 valid 0.36447373249314047
LOSS train 0.4970695065744853 valid 0.36433992059115905
LOSS train 0.4970695065744853 valid 0.36437559609641573
LOSS train 0.4970695065744853 valid 0.36446805262849447
LOSS train 0.4970695065744853 valid 0.36448259008001294
LOSS train 0.4970695065744853 valid 0.3647823025198544
LOSS train 0.4970695065744853 valid 0.36475724347850735
LOSS train 0.4970695065744853 valid 0.364850563018821
LOSS train 0.4970695065744853 valid 0.3650122519173374
LOSS train 0.4970695065744853 valid 0.3649479294645375
LOSS train 0.4970695065744853 valid 0.36492167813437326
LOSS train 0.4970695065744853 valid 0.36475886912508443
LOSS train 0.4970695065744853 valid 0.3649404018612231
LOSS train 0.4970695065744853 valid 0.36508838983064285
LOSS train 0.4970695065744853 valid 0.36491574804876103
LOSS train 0.4970695065744853 valid 0.3650056188305219
LOSS train 0.4970695065744853 valid 0.3650472903449232
LOSS train 0.4970695065744853 valid 0.3651426272405373
LOSS train 0.4970695065744853 valid 0.3650478798835004
LOSS train 0.4970695065744853 valid 0.36516734471787576
LOSS train 0.4970695065744853 valid 0.36510506481737703
LOSS train 0.4970695065744853 valid 0.3651580485284969
LOSS train 0.4970695065744853 valid 0.36522370305928314
LOSS train 0.4970695065744853 valid 0.36519726698702953
LOSS train 0.4970695065744853 valid 0.36522822326453275
LOSS train 0.4970695065744853 valid 0.3650730473430533
LOSS train 0.4970695065744853 valid 0.36526381454542667
LOSS train 0.4970695065744853 valid 0.3653596824345489
LOSS train 0.4970695065744853 valid 0.3652808638434336
LOSS train 0.4970695065744853 valid 0.3651264398982844
LOSS train 0.4970695065744853 valid 0.3651189075066493
LOSS train 0.4970695065744853 valid 0.3651380374723551
LOSS train 0.4970695065744853 valid 0.3652534739015066
LOSS train 0.4970695065744853 valid 0.36526160408752134
LOSS train 0.4970695065744853 valid 0.3652815162836008
LOSS train 0.4970695065744853 valid 0.3652283737063408
LOSS train 0.4970695065744853 valid 0.3650784400565114
LOSS train 0.4970695065744853 valid 0.3652072835086596
LOSS train 0.4970695065744853 valid 0.36504734766307134
LOSS train 0.4970695065744853 valid 0.3649807648331511
LOSS train 0.4970695065744853 valid 0.36499696126798303
LOSS train 0.4970695065744853 valid 0.3649320139468295
LOSS train 0.4970695065744853 valid 0.3650641676020507
LOSS train 0.4970695065744853 valid 0.3650695409339208
LOSS train 0.4970695065744853 valid 0.36499376930118177
LOSS train 0.4970695065744853 valid 0.36505390746252875
LOSS train 0.4970695065744853 valid 0.36501098201738147
LOSS train 0.4970695065744853 valid 0.3650501734524403
LOSS train 0.4970695065744853 valid 0.3651405631656378
LOSS train 0.4970695065744853 valid 0.365143217773081
LOSS train 0.4970695065744853 valid 0.36514520811480145
LOSS train 0.4970695065744853 valid 0.3651721287104819
LOSS train 0.4970695065744853 valid 0.36520503015012784
LOSS train 0.4970695065744853 valid 0.36531627875402434
LOSS train 0.4970695065744853 valid 0.36534554991003587
LOSS train 0.4970695065744853 valid 0.36548426029357045
LOSS train 0.4970695065744853 valid 0.3655898715306191
LOSS train 0.4970695065744853 valid 0.365563129116823
LOSS train 0.4970695065744853 valid 0.3656174185030129
LOSS train 0.4970695065744853 valid 0.3656609505414963
LOSS train 0.4970695065744853 valid 0.3657174656126234
LOSS train 0.4970695065744853 valid 0.3656623810529709
LOSS train 0.4970695065744853 valid 0.3658227441331889
LOSS train 0.4970695065744853 valid 0.365825328779848
LOSS train 0.4970695065744853 valid 0.36589293110318577
LOSS train 0.4970695065744853 valid 0.36597234917723614
LOSS train 0.4970695065744853 valid 0.3659559692139233
LOSS train 0.4970695065744853 valid 0.3659436558854991
LOSS train 0.4970695065744853 valid 0.3658578710494635
LOSS train 0.4970695065744853 valid 0.3657794662265696
LOSS train 0.4970695065744853 valid 0.36586094929816876
LOSS train 0.4970695065744853 valid 0.3658079539062613
LOSS train 0.4970695065744853 valid 0.3657415294194523
LOSS train 0.4970695065744853 valid 0.365759578447382
LOSS train 0.4970695065744853 valid 0.36564686320815626
LOSS train 0.4970695065744853 valid 0.3655547217776378
LOSS train 0.4970695065744853 valid 0.36575055394429884
LOSS train 0.4970695065744853 valid 0.36570778476797844
LOSS train 0.4970695065744853 valid 0.3657046054861673
LOSS train 0.4970695065744853 valid 0.3657698248986338
LOSS train 0.4970695065744853 valid 0.3657752998021184
LOSS train 0.4970695065744853 valid 0.3657353279309544
LOSS train 0.4970695065744853 valid 0.36575124572645795
LOSS train 0.4970695065744853 valid 0.36573646674233096
LOSS train 0.4970695065744853 valid 0.36573566897327164
LOSS train 0.4970695065744853 valid 0.36589428019523623
LOSS train 0.4970695065744853 valid 0.36597916092055727
LOSS train 0.4970695065744853 valid 0.3661496263174784
LOSS train 0.4970695065744853 valid 0.36609686386915063
LOSS train 0.4970695065744853 valid 0.36623874752540286
LOSS train 0.4970695065744853 valid 0.3661960891648835
LOSS train 0.4970695065744853 valid 0.36615882394835353
LOSS train 0.4970695065744853 valid 0.3661120578008867
LOSS train 0.4970695065744853 valid 0.3661969380323277
LOSS train 0.4970695065744853 valid 0.3661538536254043
LOSS train 0.4970695065744853 valid 0.3660120891836973
LOSS train 0.4970695065744853 valid 0.3660476677034093
LOSS train 0.4970695065744853 valid 0.3659832462782168
LOSS train 0.4970695065744853 valid 0.365945513824093
LOSS train 0.4970695065744853 valid 0.3658709671686996
LOSS train 0.4970695065744853 valid 0.36587624662327317
LOSS train 0.4970695065744853 valid 0.36599092095866237
LOSS train 0.4970695065744853 valid 0.36613455905896447
LOSS train 0.4970695065744853 valid 0.36617202111589375
LOSS train 0.4970695065744853 valid 0.3663568168767766
LOSS train 0.4970695065744853 valid 0.366310531673608
LOSS train 0.4970695065744853 valid 0.36642911645319187
LOSS train 0.4970695065744853 valid 0.36644043378970204
LOSS train 0.4970695065744853 valid 0.36644238102567067
LOSS train 0.4970695065744853 valid 0.3664204282482175
LOSS train 0.4970695065744853 valid 0.366344685012644
LOSS train 0.4970695065744853 valid 0.3662826329253722
LOSS train 0.4970695065744853 valid 0.36634644005272793
LOSS train 0.4970695065744853 valid 0.3663106727943146
LOSS train 0.4970695065744853 valid 0.3663918410150808
LOSS train 0.4970695065744853 valid 0.3663076315607343
LOSS train 0.4970695065744853 valid 0.3661849742682379
LOSS train 0.4970695065744853 valid 0.36617436413223864
LOSS train 0.4970695065744853 valid 0.3661800179591027
LOSS train 0.4970695065744853 valid 0.3662252527937083
LOSS train 0.4970695065744853 valid 0.3662088674411439
LOSS train 0.4970695065744853 valid 0.36608983795126
LOSS train 0.4970695065744853 valid 0.3661067693491015
LOSS train 0.4970695065744853 valid 0.3660983635733525
LOSS train 0.4970695065744853 valid 0.3661192630814021
LOSS train 0.4970695065744853 valid 0.36610081504131187
LOSS train 0.4970695065744853 valid 0.3659988664269857
LOSS train 0.4970695065744853 valid 0.3660239775295127
LOSS train 0.4970695065744853 valid 0.3659228528929245
LOSS train 0.4970695065744853 valid 0.3660022096366298
LOSS train 0.4970695065744853 valid 0.3661219806994422
LOSS train 0.4970695065744853 valid 0.36609067314782656
LOSS train 0.4970695065744853 valid 0.3661007623279135
LOSS train 0.4970695065744853 valid 0.36602261762491006
LOSS train 0.4970695065744853 valid 0.3660768582470042
LOSS train 0.4970695065744853 valid 0.36612656156222023
LOSS train 0.4970695065744853 valid 0.3660881689616612
LOSS train 0.4970695065744853 valid 0.3659580991362894
LOSS train 0.4970695065744853 valid 0.3658940514715591
LOSS train 0.4970695065744853 valid 0.36590114098630455
LOSS train 0.4970695065744853 valid 0.3658479944604342
LOSS train 0.4970695065744853 valid 0.3658757126019671
LOSS train 0.4970695065744853 valid 0.3658694571509035
LOSS train 0.4970695065744853 valid 0.3658234558322213
LOSS train 0.4970695065744853 valid 0.3658680384405994
LOSS train 0.4970695065744853 valid 0.36584895474295465
LOSS train 0.4970695065744853 valid 0.36580507663285233
LOSS train 0.4970695065744853 valid 0.36580156133725095
LOSS train 0.4970695065744853 valid 0.36588189034416274
LOSS train 0.4970695065744853 valid 0.36584572209294436
LOSS train 0.4970695065744853 valid 0.3658429852553776
LOSS train 0.4970695065744853 valid 0.3657364591578894
LOSS train 0.4970695065744853 valid 0.3657751492333337
LOSS train 0.4970695065744853 valid 0.3657569430721631
LOSS train 0.4970695065744853 valid 0.3657266907744273
LOSS train 0.4970695065744853 valid 0.3656437831930816
LOSS train 0.4970695065744853 valid 0.3656742986860305
LOSS train 0.4970695065744853 valid 0.36567344928380124
LOSS train 0.4970695065744853 valid 0.3656548138927011
LOSS train 0.4970695065744853 valid 0.3656388446688652
LOSS train 0.4970695065744853 valid 0.3655913093456855
LOSS train 0.4970695065744853 valid 0.3656466591394752
LOSS train 0.4970695065744853 valid 0.3657726854177061
LOSS train 0.4970695065744853 valid 0.36576592504251293
LOSS train 0.4970695065744853 valid 0.36573947255009936
LOSS train 0.4970695065744853 valid 0.36569667250821086
LOSS train 0.4970695065744853 valid 0.3656715023193475
LOSS train 0.4970695065744853 valid 0.3655544923371579
LOSS train 0.4970695065744853 valid 0.36553923593269094
LOSS train 0.4970695065744853 valid 0.3656111969919262
LOSS train 0.4970695065744853 valid 0.3656035540708855
LOSS train 0.4970695065744853 valid 0.3655512248653741
LOSS train 0.4970695065744853 valid 0.3655278692436501
LOSS train 0.4970695065744853 valid 0.36555724992201877
LOSS train 0.4970695065744853 valid 0.3655008604217068
LOSS train 0.4970695065744853 valid 0.3655039723305141
LOSS train 0.4970695065744853 valid 0.3653717699113829
LOSS train 0.4970695065744853 valid 0.3652772348352343
LOSS train 0.4970695065744853 valid 0.36529029701611043
LOSS train 0.4970695065744853 valid 0.36538728586463043
LOSS train 0.4970695065744853 valid 0.3654336465441662
LOSS train 0.4970695065744853 valid 0.36541679579054
LOSS train 0.4970695065744853 valid 0.3653564184302899
LOSS train 0.4970695065744853 valid 0.36526808236864794
LOSS train 0.4970695065744853 valid 0.3652761184042026
LOSS train 0.4970695065744853 valid 0.365188034091677
LOSS train 0.4970695065744853 valid 0.3651819376014916
LOSS train 0.4970695065744853 valid 0.36521854387088254
LOSS train 0.4970695065744853 valid 0.3653126534591653
LOSS train 0.4970695065744853 valid 0.3653836833723521
LOSS train 0.4970695065744853 valid 0.36540815704305407
LOSS train 0.4970695065744853 valid 0.3654086424058743
LOSS train 0.4970695065744853 valid 0.3653679354851987
LOSS train 0.4970695065744853 valid 0.36531610861836866
LOSS train 0.4970695065744853 valid 0.36532953431347287
LOSS train 0.4970695065744853 valid 0.365359343505568
LOSS train 0.4970695065744853 valid 0.3654138910638328
LOSS train 0.4970695065744853 valid 0.36551431957529396
LOSS train 0.4970695065744853 valid 0.3654517441084891
LOSS train 0.4970695065744853 valid 0.36544925694937236
LOSS train 0.4970695065744853 valid 0.36546920227677854
LOSS train 0.4970695065744853 valid 0.3653816666270866
LOSS train 0.4970695065744853 valid 0.36530307406300744
LOSS train 0.4970695065744853 valid 0.3653180600022492
LOSS train 0.4970695065744853 valid 0.3653281150956141
EPOCH 13:
  batch 1 loss: 0.48351603746414185
  batch 2 loss: 0.48742035031318665
  batch 3 loss: 0.4939921498298645
  batch 4 loss: 0.5049052387475967
  batch 5 loss: 0.5008908152580261
  batch 6 loss: 0.4983850916226705
  batch 7 loss: 0.50003068787711
  batch 8 loss: 0.4997459426522255
  batch 9 loss: 0.5021692050827874
  batch 10 loss: 0.5050599038600921
  batch 11 loss: 0.5025818971070376
  batch 12 loss: 0.5012300759553909
  batch 13 loss: 0.5011180134919974
  batch 14 loss: 0.5016650514943259
  batch 15 loss: 0.5001078069210052
  batch 16 loss: 0.49994681403040886
  batch 17 loss: 0.4995734726681429
  batch 18 loss: 0.49896713925732505
  batch 19 loss: 0.49756747954770136
  batch 20 loss: 0.4972327083349228
  batch 21 loss: 0.497795459770021
  batch 22 loss: 0.4976650056513873
  batch 23 loss: 0.4977301734945048
  batch 24 loss: 0.49716101462642354
  batch 25 loss: 0.49702905416488646
  batch 26 loss: 0.495746652667339
  batch 27 loss: 0.4955435902984054
  batch 28 loss: 0.49499391445091795
  batch 29 loss: 0.494804951651343
  batch 30 loss: 0.4940496236085892
  batch 31 loss: 0.4944605298580662
  batch 32 loss: 0.4942546943202615
  batch 33 loss: 0.4936950956330155
  batch 34 loss: 0.49325669250067544
  batch 35 loss: 0.49479529431888036
  batch 36 loss: 0.4950174449218644
  batch 37 loss: 0.4954819445674484
  batch 38 loss: 0.49601399035830246
  batch 39 loss: 0.4961084364316402
  batch 40 loss: 0.49539603665471077
  batch 41 loss: 0.4954307231961227
  batch 42 loss: 0.4958711216847102
  batch 43 loss: 0.4957122040349384
  batch 44 loss: 0.49598087099465454
  batch 45 loss: 0.4958520379331377
  batch 46 loss: 0.49579355315021845
  batch 47 loss: 0.4959456051917786
  batch 48 loss: 0.4953650012612343
  batch 49 loss: 0.49480682124896924
  batch 50 loss: 0.4946929657459259
  batch 51 loss: 0.4940059670046264
  batch 52 loss: 0.4939678477553221
  batch 53 loss: 0.4942218678177528
  batch 54 loss: 0.49473612010478973
  batch 55 loss: 0.49416334466500716
  batch 56 loss: 0.4932470731437206
  batch 57 loss: 0.4931508391572718
  batch 58 loss: 0.4940681031038021
  batch 59 loss: 0.4937941654253814
  batch 60 loss: 0.4935667648911476
  batch 61 loss: 0.4933492878421408
  batch 62 loss: 0.4941586231993091
  batch 63 loss: 0.4942770945647406
  batch 64 loss: 0.4946925942786038
  batch 65 loss: 0.49428682648218597
  batch 66 loss: 0.49438054949948285
  batch 67 loss: 0.4947240704031133
  batch 68 loss: 0.494821693529101
  batch 69 loss: 0.49472474835921026
  batch 70 loss: 0.4945701756647655
  batch 71 loss: 0.49462362662167614
  batch 72 loss: 0.49436186088456047
  batch 73 loss: 0.4943834820838824
  batch 74 loss: 0.49416022928985387
  batch 75 loss: 0.49399745543797813
  batch 76 loss: 0.494419578658907
  batch 77 loss: 0.49420864396281056
  batch 78 loss: 0.4937458466260861
  batch 79 loss: 0.4941946268081665
  batch 80 loss: 0.49397744461894033
  batch 81 loss: 0.4940077316613845
  batch 82 loss: 0.49450814142459776
  batch 83 loss: 0.49470491294401236
  batch 84 loss: 0.4949179823909487
  batch 85 loss: 0.49484840000376984
  batch 86 loss: 0.49560811353284256
  batch 87 loss: 0.4955653627028411
  batch 88 loss: 0.4949626722796397
  batch 89 loss: 0.4950130129798075
  batch 90 loss: 0.4950086954567168
  batch 91 loss: 0.4951681373538552
  batch 92 loss: 0.4949651266569677
  batch 93 loss: 0.4946872492631276
  batch 94 loss: 0.4949344811921424
  batch 95 loss: 0.49497462040499635
  batch 96 loss: 0.49525372839222354
  batch 97 loss: 0.49535530344727113
  batch 98 loss: 0.4956909104877589
  batch 99 loss: 0.49545073388802885
  batch 100 loss: 0.49580433666706086
  batch 101 loss: 0.49575884094332706
  batch 102 loss: 0.49572228917888567
  batch 103 loss: 0.4958222809347134
  batch 104 loss: 0.4958374775373019
  batch 105 loss: 0.49546721435728525
  batch 106 loss: 0.49564534594427867
  batch 107 loss: 0.4954665879779887
  batch 108 loss: 0.49535060287625704
  batch 109 loss: 0.49569307035262433
  batch 110 loss: 0.4959796052087437
  batch 111 loss: 0.4960012111040923
  batch 112 loss: 0.4960207398980856
  batch 113 loss: 0.49642147875465126
  batch 114 loss: 0.4968148911731285
  batch 115 loss: 0.49678041079769963
  batch 116 loss: 0.4969922399212574
  batch 117 loss: 0.49708234270413715
  batch 118 loss: 0.49721037154480563
  batch 119 loss: 0.4972017287206249
  batch 120 loss: 0.4971790716052055
  batch 121 loss: 0.4969119444366329
  batch 122 loss: 0.4966630114883673
  batch 123 loss: 0.49636512364798446
  batch 124 loss: 0.496654026931332
  batch 125 loss: 0.49648168659210207
  batch 126 loss: 0.4962512254714966
  batch 127 loss: 0.49663627804733634
  batch 128 loss: 0.4963610917329788
  batch 129 loss: 0.4961589265239331
  batch 130 loss: 0.49621549340394827
  batch 131 loss: 0.49647725856941166
  batch 132 loss: 0.49660171478083637
  batch 133 loss: 0.49661007971691906
  batch 134 loss: 0.4965750245905634
  batch 135 loss: 0.4966956403520372
  batch 136 loss: 0.49653179571032524
  batch 137 loss: 0.4966891671184206
  batch 138 loss: 0.4971605696971866
  batch 139 loss: 0.49719350222203373
  batch 140 loss: 0.49705524103982107
  batch 141 loss: 0.4972081607115184
  batch 142 loss: 0.4970283403363026
  batch 143 loss: 0.4968307497618082
  batch 144 loss: 0.49688440519902444
  batch 145 loss: 0.4967963255684951
  batch 146 loss: 0.49673384917925484
  batch 147 loss: 0.4968170876405677
  batch 148 loss: 0.49687761350257975
  batch 149 loss: 0.4968279596143121
  batch 150 loss: 0.4965392833948135
  batch 151 loss: 0.49633830529175055
  batch 152 loss: 0.49657627842143964
  batch 153 loss: 0.4965167104029188
  batch 154 loss: 0.49655379606531813
  batch 155 loss: 0.49660274713270125
  batch 156 loss: 0.49663152335545957
  batch 157 loss: 0.4969035330092072
  batch 158 loss: 0.4968090046055709
  batch 159 loss: 0.49683995329359043
  batch 160 loss: 0.4969206765294075
  batch 161 loss: 0.49698113839818825
  batch 162 loss: 0.49692146167343043
  batch 163 loss: 0.49670367994191456
  batch 164 loss: 0.4966691398039097
  batch 165 loss: 0.4966064640969941
  batch 166 loss: 0.4966876119016165
  batch 167 loss: 0.49665016970948545
  batch 168 loss: 0.4969211600366093
  batch 169 loss: 0.49676478967158755
  batch 170 loss: 0.4967195880763671
  batch 171 loss: 0.4966159070792951
  batch 172 loss: 0.4967075588051663
  batch 173 loss: 0.4965096710389749
  batch 174 loss: 0.4965075680921818
  batch 175 loss: 0.49642129676682606
  batch 176 loss: 0.49642392535778607
  batch 177 loss: 0.4962793718286827
  batch 178 loss: 0.49640634337837775
  batch 179 loss: 0.49639491412226716
  batch 180 loss: 0.49632657517989476
  batch 181 loss: 0.49629434366911157
  batch 182 loss: 0.4963329038122198
  batch 183 loss: 0.49632884553872825
  batch 184 loss: 0.4961675778031349
  batch 185 loss: 0.4962410482200416
  batch 186 loss: 0.4962806951615118
  batch 187 loss: 0.4961476941159702
  batch 188 loss: 0.49609692141096645
  batch 189 loss: 0.4959779183069865
  batch 190 loss: 0.4958923731979571
  batch 191 loss: 0.49591162270276334
  batch 192 loss: 0.4957692955310146
  batch 193 loss: 0.49569408881231913
  batch 194 loss: 0.49561951424657685
  batch 195 loss: 0.49586347922300683
  batch 196 loss: 0.4957739455359323
  batch 197 loss: 0.49577584045792594
  batch 198 loss: 0.4959013532809537
  batch 199 loss: 0.4958023190797873
  batch 200 loss: 0.4958165530860424
  batch 201 loss: 0.4959195257715918
  batch 202 loss: 0.49596420387820445
  batch 203 loss: 0.4961113755045266
  batch 204 loss: 0.49611033250888187
  batch 205 loss: 0.4961857884395413
  batch 206 loss: 0.4962668041291746
  batch 207 loss: 0.49625259047545095
  batch 208 loss: 0.4961490537971258
  batch 209 loss: 0.49612950095149316
  batch 210 loss: 0.496198218918982
  batch 211 loss: 0.49626219173743263
  batch 212 loss: 0.49625346064567566
  batch 213 loss: 0.49623275810564066
  batch 214 loss: 0.49616526471120176
  batch 215 loss: 0.49598719352899595
  batch 216 loss: 0.4957904774281714
  batch 217 loss: 0.4957769183519249
  batch 218 loss: 0.4957546397633509
  batch 219 loss: 0.4956304667747184
  batch 220 loss: 0.4956413621252233
  batch 221 loss: 0.49573026280597327
  batch 222 loss: 0.495886528008693
  batch 223 loss: 0.49588980415476813
  batch 224 loss: 0.49580194441867725
  batch 225 loss: 0.49580003910594517
  batch 226 loss: 0.49588670680480723
  batch 227 loss: 0.4957060434482171
  batch 228 loss: 0.49579626230294244
  batch 229 loss: 0.4957387058235152
  batch 230 loss: 0.49578581491242285
  batch 231 loss: 0.49572133721211253
  batch 232 loss: 0.49557223684828855
  batch 233 loss: 0.4955130356319984
  batch 234 loss: 0.49549237275734925
  batch 235 loss: 0.49559851250749953
  batch 236 loss: 0.4955300760723777
  batch 237 loss: 0.49561775019903226
  batch 238 loss: 0.4956057786691089
  batch 239 loss: 0.4954473120647494
  batch 240 loss: 0.49558883520464103
  batch 241 loss: 0.49564909106468263
  batch 242 loss: 0.4955179328021924
  batch 243 loss: 0.4955329751526868
  batch 244 loss: 0.4955330524043959
  batch 245 loss: 0.49563879686958934
  batch 246 loss: 0.4956597318736518
  batch 247 loss: 0.4956669410471974
  batch 248 loss: 0.495806998182689
  batch 249 loss: 0.4958363925836172
  batch 250 loss: 0.4958808618783951
  batch 251 loss: 0.49586316931295205
  batch 252 loss: 0.495941698551178
  batch 253 loss: 0.4959456227984824
  batch 254 loss: 0.4959538726825414
  batch 255 loss: 0.4960347769307155
  batch 256 loss: 0.49599804007448256
  batch 257 loss: 0.49611101470568764
  batch 258 loss: 0.4960849952790164
  batch 259 loss: 0.49604374607557494
  batch 260 loss: 0.49615037189080163
  batch 261 loss: 0.4962260024300937
  batch 262 loss: 0.49613211582635197
  batch 263 loss: 0.4960949885527897
  batch 264 loss: 0.4960602670907974
  batch 265 loss: 0.4960281613862739
  batch 266 loss: 0.49604702522432
  batch 267 loss: 0.49607233552450547
  batch 268 loss: 0.49600530938426063
  batch 269 loss: 0.4960403672824562
  batch 270 loss: 0.49611374934514363
  batch 271 loss: 0.49610802619219707
  batch 272 loss: 0.4961931632064721
  batch 273 loss: 0.49617085341132167
  batch 274 loss: 0.49605383740289366
  batch 275 loss: 0.49617854367602954
  batch 276 loss: 0.49627864306819613
  batch 277 loss: 0.4963995342005031
  batch 278 loss: 0.4963360474907237
  batch 279 loss: 0.49637203543416913
  batch 280 loss: 0.49620720563190324
  batch 281 loss: 0.4961568997423844
  batch 282 loss: 0.4960361968540976
  batch 283 loss: 0.4959080612069726
  batch 284 loss: 0.49595209546911884
  batch 285 loss: 0.49585007565063344
  batch 286 loss: 0.4958226259771761
  batch 287 loss: 0.4958504866224548
  batch 288 loss: 0.49564473279234433
  batch 289 loss: 0.4957540735447695
  batch 290 loss: 0.495621792509638
  batch 291 loss: 0.49564100776341363
  batch 292 loss: 0.49568105346127733
  batch 293 loss: 0.4957782570209113
  batch 294 loss: 0.49573153743938525
  batch 295 loss: 0.4958497330293817
  batch 296 loss: 0.4958837664610631
  batch 297 loss: 0.496009354639535
  batch 298 loss: 0.49604963456224277
  batch 299 loss: 0.4960678419141865
  batch 300 loss: 0.4961835684378942
  batch 301 loss: 0.4962673312009767
  batch 302 loss: 0.4963159369711844
  batch 303 loss: 0.49634465348995954
  batch 304 loss: 0.49632912217394304
  batch 305 loss: 0.4961696395131408
  batch 306 loss: 0.49623747559544307
  batch 307 loss: 0.49621444824075855
  batch 308 loss: 0.49614291821981404
  batch 309 loss: 0.4961888637743336
  batch 310 loss: 0.4961946945036611
  batch 311 loss: 0.49624591030875204
  batch 312 loss: 0.4963286719643153
  batch 313 loss: 0.4963388263036649
  batch 314 loss: 0.49635760865773365
  batch 315 loss: 0.49635907771095394
  batch 316 loss: 0.49626664628710926
  batch 317 loss: 0.49626829242480663
  batch 318 loss: 0.49624303798630554
  batch 319 loss: 0.49613977637036843
  batch 320 loss: 0.4960997642017901
  batch 321 loss: 0.49611105688635804
  batch 322 loss: 0.49611945570625876
  batch 323 loss: 0.49606069442657497
  batch 324 loss: 0.49592639239114006
  batch 325 loss: 0.4958434074658614
  batch 326 loss: 0.49576835288591914
  batch 327 loss: 0.4957651748387456
  batch 328 loss: 0.4956469524015741
  batch 329 loss: 0.49575517197510394
  batch 330 loss: 0.49569010319131795
  batch 331 loss: 0.4955902232864472
  batch 332 loss: 0.49557612450366995
  batch 333 loss: 0.4955658938612666
  batch 334 loss: 0.49545543413319276
  batch 335 loss: 0.4953664915775185
  batch 336 loss: 0.49530307797803763
  batch 337 loss: 0.4952519413094846
  batch 338 loss: 0.49522887866877946
  batch 339 loss: 0.4953768325414629
  batch 340 loss: 0.4953721805530436
  batch 341 loss: 0.49538499859770724
  batch 342 loss: 0.49530036451175197
  batch 343 loss: 0.49524337896105153
  batch 344 loss: 0.4952606128225493
  batch 345 loss: 0.49539092390433603
  batch 346 loss: 0.495341153761555
  batch 347 loss: 0.49537826915639277
  batch 348 loss: 0.4953696708055748
  batch 349 loss: 0.49524965250389624
  batch 350 loss: 0.49525854076657977
  batch 351 loss: 0.4952608549017512
  batch 352 loss: 0.49531816809692164
  batch 353 loss: 0.4952776943657959
  batch 354 loss: 0.4952977466381202
  batch 355 loss: 0.4954074229992611
  batch 356 loss: 0.49533081607202467
  batch 357 loss: 0.4953440022067863
  batch 358 loss: 0.49534398700271903
  batch 359 loss: 0.49537634119017876
  batch 360 loss: 0.49546617699993983
  batch 361 loss: 0.4955116312259452
  batch 362 loss: 0.49541042440504
  batch 363 loss: 0.495384777052015
  batch 364 loss: 0.4952994898616613
  batch 365 loss: 0.49527591001497556
  batch 366 loss: 0.4951703844011807
  batch 367 loss: 0.4951973894473967
  batch 368 loss: 0.49517743653901247
  batch 369 loss: 0.4951804901364696
  batch 370 loss: 0.4952861147152411
  batch 371 loss: 0.4954365092628407
  batch 372 loss: 0.495339365656017
  batch 373 loss: 0.495303349344724
  batch 374 loss: 0.4952199216832452
  batch 375 loss: 0.49532881704966225
  batch 376 loss: 0.49535438133046983
  batch 377 loss: 0.49532897900839384
  batch 378 loss: 0.4952760873332856
  batch 379 loss: 0.4953019897352737
  batch 380 loss: 0.49542740599105234
  batch 381 loss: 0.4953393695235565
  batch 382 loss: 0.49517807083604226
  batch 383 loss: 0.49520278366054005
  batch 384 loss: 0.49514262937009335
  batch 385 loss: 0.4952287429338926
  batch 386 loss: 0.49512452875394275
  batch 387 loss: 0.4951319884730248
  batch 388 loss: 0.49514369182672696
  batch 389 loss: 0.4951609957647201
  batch 390 loss: 0.4951753795911104
  batch 391 loss: 0.49510563426005566
  batch 392 loss: 0.4951375859732531
  batch 393 loss: 0.4952442318428564
  batch 394 loss: 0.49522969421698965
  batch 395 loss: 0.4952878717380234
  batch 396 loss: 0.49534161035159624
  batch 397 loss: 0.49526620098865903
  batch 398 loss: 0.4952310422557083
  batch 399 loss: 0.49523966921899554
  batch 400 loss: 0.49518912851810454
  batch 401 loss: 0.49517120588152785
  batch 402 loss: 0.4952442517772836
  batch 403 loss: 0.4951706836300512
  batch 404 loss: 0.49514776431392915
  batch 405 loss: 0.49514410194055536
  batch 406 loss: 0.49522751679855026
  batch 407 loss: 0.4952636496587233
  batch 408 loss: 0.495369083668087
  batch 409 loss: 0.4954111103177945
  batch 410 loss: 0.4954376606679544
  batch 411 loss: 0.4954004112966449
  batch 412 loss: 0.49536362688228924
  batch 413 loss: 0.4953871791501311
  batch 414 loss: 0.4953852606136442
  batch 415 loss: 0.49535965431167417
  batch 416 loss: 0.4953486667229579
  batch 417 loss: 0.49533604296277184
  batch 418 loss: 0.4953607623799566
  batch 419 loss: 0.4953515113538091
  batch 420 loss: 0.4953574694338299
  batch 421 loss: 0.49533088671623104
  batch 422 loss: 0.49542567275146737
  batch 423 loss: 0.4954537391380779
  batch 424 loss: 0.49548159567814953
  batch 425 loss: 0.4954992152662838
  batch 426 loss: 0.49547351581949584
  batch 427 loss: 0.4954871790749686
  batch 428 loss: 0.4953975372503851
  batch 429 loss: 0.49532851403131906
  batch 430 loss: 0.49535490121952325
  batch 431 loss: 0.49553762511144933
  batch 432 loss: 0.49559749635281386
  batch 433 loss: 0.49553202887605574
  batch 434 loss: 0.4955957220858693
  batch 435 loss: 0.49560228401216966
  batch 436 loss: 0.49557277102262604
  batch 437 loss: 0.4956314654453941
  batch 438 loss: 0.49573185134968256
  batch 439 loss: 0.49571973404471587
  batch 440 loss: 0.4957658930935643
  batch 441 loss: 0.4957718359234652
  batch 442 loss: 0.4957535630976992
  batch 443 loss: 0.49577281800672646
  batch 444 loss: 0.4956799440824234
  batch 445 loss: 0.4956956237889408
  batch 446 loss: 0.4956651913344593
  batch 447 loss: 0.4956488845999076
  batch 448 loss: 0.4957339319932674
  batch 449 loss: 0.4958009672722466
  batch 450 loss: 0.4958690217468474
  batch 451 loss: 0.4959203454845496
  batch 452 loss: 0.49594017157776166
  batch 453 loss: 0.49595673201363083
  batch 454 loss: 0.4959720363307104
  batch 455 loss: 0.4959778747715793
  batch 456 loss: 0.4959850028287946
  batch 457 loss: 0.4960229864396986
  batch 458 loss: 0.4960105621528417
  batch 459 loss: 0.496020861505683
  batch 460 loss: 0.4961012120480123
  batch 461 loss: 0.4961598010616551
  batch 462 loss: 0.49611943089342736
  batch 463 loss: 0.4960967711058343
  batch 464 loss: 0.49616171939876574
  batch 465 loss: 0.4960078014481452
  batch 466 loss: 0.4958708270936565
  batch 467 loss: 0.4958977579304697
  batch 468 loss: 0.4958550998797783
  batch 469 loss: 0.49587381534230734
  batch 470 loss: 0.49582069275227
  batch 471 loss: 0.4958136224696084
  batch 472 loss: 0.49576669047444555
LOSS train 0.49576669047444555 valid 0.37568986415863037
LOSS train 0.49576669047444555 valid 0.37022748589515686
LOSS train 0.49576669047444555 valid 0.38553643226623535
LOSS train 0.49576669047444555 valid 0.38282476365566254
LOSS train 0.49576669047444555 valid 0.38070145845413206
LOSS train 0.49576669047444555 valid 0.38191787898540497
LOSS train 0.49576669047444555 valid 0.379644261939185
LOSS train 0.49576669047444555 valid 0.37950974330306053
LOSS train 0.49576669047444555 valid 0.3748395906554328
LOSS train 0.49576669047444555 valid 0.37716737389564514
LOSS train 0.49576669047444555 valid 0.3801847018978812
LOSS train 0.49576669047444555 valid 0.3796469171841939
LOSS train 0.49576669047444555 valid 0.38159085237062895
LOSS train 0.49576669047444555 valid 0.3816653553928648
LOSS train 0.49576669047444555 valid 0.3801738639672597
LOSS train 0.49576669047444555 valid 0.38162381388247013
LOSS train 0.49576669047444555 valid 0.3844174935537226
LOSS train 0.49576669047444555 valid 0.384787369105551
LOSS train 0.49576669047444555 valid 0.3851144956915002
LOSS train 0.49576669047444555 valid 0.3867340847849846
LOSS train 0.49576669047444555 valid 0.38590201025917414
LOSS train 0.49576669047444555 valid 0.3838164968924089
LOSS train 0.49576669047444555 valid 0.38464580670647
LOSS train 0.49576669047444555 valid 0.3838631386558215
LOSS train 0.49576669047444555 valid 0.3834338438510895
LOSS train 0.49576669047444555 valid 0.3827900279026765
LOSS train 0.49576669047444555 valid 0.3821450946507631
LOSS train 0.49576669047444555 valid 0.38233152138335363
LOSS train 0.49576669047444555 valid 0.38235830130248233
LOSS train 0.49576669047444555 valid 0.38309434751669563
LOSS train 0.49576669047444555 valid 0.38451092185512664
LOSS train 0.49576669047444555 valid 0.38467837404459715
LOSS train 0.49576669047444555 valid 0.3857208354906602
LOSS train 0.49576669047444555 valid 0.3850383627064088
LOSS train 0.49576669047444555 valid 0.3857734901564462
LOSS train 0.49576669047444555 valid 0.3855409349004428
LOSS train 0.49576669047444555 valid 0.38607988486418854
LOSS train 0.49576669047444555 valid 0.3869356465967078
LOSS train 0.49576669047444555 valid 0.38661649976021206
LOSS train 0.49576669047444555 valid 0.38824365958571433
LOSS train 0.49576669047444555 valid 0.38817321890737955
LOSS train 0.49576669047444555 valid 0.38903743241514477
LOSS train 0.49576669047444555 valid 0.38908058058383854
LOSS train 0.49576669047444555 valid 0.3894250277768482
LOSS train 0.49576669047444555 valid 0.3895722654130724
LOSS train 0.49576669047444555 valid 0.3899716799673827
LOSS train 0.49576669047444555 valid 0.38959218339717133
LOSS train 0.49576669047444555 valid 0.39020760357379913
LOSS train 0.49576669047444555 valid 0.3907355203920481
LOSS train 0.49576669047444555 valid 0.3901776933670044
LOSS train 0.49576669047444555 valid 0.39070771137873334
LOSS train 0.49576669047444555 valid 0.3903104840562894
LOSS train 0.49576669047444555 valid 0.38975995048037115
LOSS train 0.49576669047444555 valid 0.38974784645769334
LOSS train 0.49576669047444555 valid 0.3895344203168696
LOSS train 0.49576669047444555 valid 0.38944909828049795
LOSS train 0.49576669047444555 valid 0.38917943678404154
LOSS train 0.49576669047444555 valid 0.3889777208196706
LOSS train 0.49576669047444555 valid 0.3894553063279491
LOSS train 0.49576669047444555 valid 0.38877168893814085
LOSS train 0.49576669047444555 valid 0.3876975369258005
LOSS train 0.49576669047444555 valid 0.38862427251954235
LOSS train 0.49576669047444555 valid 0.38906341128879124
LOSS train 0.49576669047444555 valid 0.3894142499193549
LOSS train 0.49576669047444555 valid 0.38942206089313214
LOSS train 0.49576669047444555 valid 0.3895499078613339
LOSS train 0.49576669047444555 valid 0.3890960461168147
LOSS train 0.49576669047444555 valid 0.38866646500194774
LOSS train 0.49576669047444555 valid 0.38845026838606683
LOSS train 0.49576669047444555 valid 0.38808455765247346
LOSS train 0.49576669047444555 valid 0.387936961902699
LOSS train 0.49576669047444555 valid 0.3879033480253484
LOSS train 0.49576669047444555 valid 0.38810611546856083
LOSS train 0.49576669047444555 valid 0.3879632369892017
LOSS train 0.49576669047444555 valid 0.3872865271568298
LOSS train 0.49576669047444555 valid 0.3875195615385708
LOSS train 0.49576669047444555 valid 0.3871750239427988
LOSS train 0.49576669047444555 valid 0.38718669766034836
LOSS train 0.49576669047444555 valid 0.3869959953465039
LOSS train 0.49576669047444555 valid 0.3869052089750767
LOSS train 0.49576669047444555 valid 0.38644534643785455
LOSS train 0.49576669047444555 valid 0.38669028296703245
LOSS train 0.49576669047444555 valid 0.3864188079374382
LOSS train 0.49576669047444555 valid 0.3866937504637809
LOSS train 0.49576669047444555 valid 0.3867032797897563
LOSS train 0.49576669047444555 valid 0.3864289858313494
LOSS train 0.49576669047444555 valid 0.3863626793883313
LOSS train 0.49576669047444555 valid 0.38589122552763333
LOSS train 0.49576669047444555 valid 0.38621148500549657
LOSS train 0.49576669047444555 valid 0.3861363225513034
LOSS train 0.49576669047444555 valid 0.38586886603753645
LOSS train 0.49576669047444555 valid 0.3855979627241259
LOSS train 0.49576669047444555 valid 0.38499991387449284
LOSS train 0.49576669047444555 valid 0.38453658876266883
LOSS train 0.49576669047444555 valid 0.38421577183823835
LOSS train 0.49576669047444555 valid 0.3845448313901822
LOSS train 0.49576669047444555 valid 0.38483896390678957
LOSS train 0.49576669047444555 valid 0.3848413484437125
LOSS train 0.49576669047444555 valid 0.38496057011864404
LOSS train 0.49576669047444555 valid 0.38514089852571487
LOSS train 0.49576669047444555 valid 0.3852458147719355
LOSS train 0.49576669047444555 valid 0.3852000972803901
LOSS train 0.49576669047444555 valid 0.385741944162591
LOSS train 0.49576669047444555 valid 0.3855230226539649
LOSS train 0.49576669047444555 valid 0.3854309646856217
LOSS train 0.49576669047444555 valid 0.3854149009259242
LOSS train 0.49576669047444555 valid 0.38514385267952894
LOSS train 0.49576669047444555 valid 0.38556054372478415
LOSS train 0.49576669047444555 valid 0.385651431772687
LOSS train 0.49576669047444555 valid 0.38570878532799807
LOSS train 0.49576669047444555 valid 0.3857188995357032
LOSS train 0.49576669047444555 valid 0.3855564192469631
LOSS train 0.49576669047444555 valid 0.3855944769044893
LOSS train 0.49576669047444555 valid 0.38536993270380454
LOSS train 0.49576669047444555 valid 0.38533645738726074
LOSS train 0.49576669047444555 valid 0.38530296061573355
LOSS train 0.49576669047444555 valid 0.3854532572958205
LOSS train 0.49576669047444555 valid 0.3852168670145132
LOSS train 0.49576669047444555 valid 0.3850248791590458
LOSS train 0.49576669047444555 valid 0.38487628201643626
LOSS train 0.49576669047444555 valid 0.38481284468627175
LOSS train 0.49576669047444555 valid 0.38468688433287573
LOSS train 0.49576669047444555 valid 0.38484553350665707
LOSS train 0.49576669047444555 valid 0.3849834638737863
LOSS train 0.49576669047444555 valid 0.3848343951702118
LOSS train 0.49576669047444555 valid 0.3846559351871884
LOSS train 0.49576669047444555 valid 0.38524231385058305
LOSS train 0.49576669047444555 valid 0.38539502187632024
LOSS train 0.49576669047444555 valid 0.3855173673278602
LOSS train 0.49576669047444555 valid 0.3852938819390077
LOSS train 0.49576669047444555 valid 0.3853422473860151
LOSS train 0.49576669047444555 valid 0.38529953608910245
LOSS train 0.49576669047444555 valid 0.3851290900904433
LOSS train 0.49576669047444555 valid 0.3852930894093727
LOSS train 0.49576669047444555 valid 0.38543642693095737
LOSS train 0.49576669047444555 valid 0.38533451714936423
LOSS train 0.49576669047444555 valid 0.3851172924041748
LOSS train 0.49576669047444555 valid 0.3850187069695929
LOSS train 0.49576669047444555 valid 0.3848423541878625
LOSS train 0.49576669047444555 valid 0.38498047143220904
LOSS train 0.49576669047444555 valid 0.385009266594623
LOSS train 0.49576669047444555 valid 0.3853090147317295
LOSS train 0.49576669047444555 valid 0.38506951011144197
LOSS train 0.49576669047444555 valid 0.3850862220343616
LOSS train 0.49576669047444555 valid 0.3849340835521961
LOSS train 0.49576669047444555 valid 0.38523926698181726
LOSS train 0.49576669047444555 valid 0.38484118402409717
LOSS train 0.49576669047444555 valid 0.3851051344662099
LOSS train 0.49576669047444555 valid 0.3851708143749493
LOSS train 0.49576669047444555 valid 0.3851982831954956
LOSS train 0.49576669047444555 valid 0.38530057431846265
LOSS train 0.49576669047444555 valid 0.3850907001056169
LOSS train 0.49576669047444555 valid 0.38531223348542754
LOSS train 0.49576669047444555 valid 0.38532697728702
LOSS train 0.49576669047444555 valid 0.3854006782654793
LOSS train 0.49576669047444555 valid 0.38567012472030443
LOSS train 0.49576669047444555 valid 0.38561362009139577
LOSS train 0.49576669047444555 valid 0.3855504504864729
LOSS train 0.49576669047444555 valid 0.38523907725166223
LOSS train 0.49576669047444555 valid 0.38532924819737674
LOSS train 0.49576669047444555 valid 0.3852204282461486
LOSS train 0.49576669047444555 valid 0.3849372376262406
LOSS train 0.49576669047444555 valid 0.38487440969315045
LOSS train 0.49576669047444555 valid 0.38479240238666534
LOSS train 0.49576669047444555 valid 0.3846781907659588
LOSS train 0.49576669047444555 valid 0.38453056546578923
LOSS train 0.49576669047444555 valid 0.3845215168541777
LOSS train 0.49576669047444555 valid 0.3846264493962129
LOSS train 0.49576669047444555 valid 0.38464233561380373
LOSS train 0.49576669047444555 valid 0.3849794077522614
LOSS train 0.49576669047444555 valid 0.38498395419957343
LOSS train 0.49576669047444555 valid 0.3850792209769404
LOSS train 0.49576669047444555 valid 0.3852316392639469
LOSS train 0.49576669047444555 valid 0.3851074531845663
LOSS train 0.49576669047444555 valid 0.3850981458595821
LOSS train 0.49576669047444555 valid 0.38492719270288944
LOSS train 0.49576669047444555 valid 0.3851059528730683
LOSS train 0.49576669047444555 valid 0.38524337715647194
LOSS train 0.49576669047444555 valid 0.3850441989618973
LOSS train 0.49576669047444555 valid 0.38514070626762176
LOSS train 0.49576669047444555 valid 0.38515838206802283
LOSS train 0.49576669047444555 valid 0.38525741342659836
LOSS train 0.49576669047444555 valid 0.3851503166344648
LOSS train 0.49576669047444555 valid 0.3852614570894967
LOSS train 0.49576669047444555 valid 0.385176902848321
LOSS train 0.49576669047444555 valid 0.38520607304188514
LOSS train 0.49576669047444555 valid 0.38527738314898896
LOSS train 0.49576669047444555 valid 0.3852595956401622
LOSS train 0.49576669047444555 valid 0.3852709257413471
LOSS train 0.49576669047444555 valid 0.38511014706210084
LOSS train 0.49576669047444555 valid 0.3852739660215627
LOSS train 0.49576669047444555 valid 0.38534002921854454
LOSS train 0.49576669047444555 valid 0.3852462526121288
LOSS train 0.49576669047444555 valid 0.38506355036779777
LOSS train 0.49576669047444555 valid 0.3850659423913711
LOSS train 0.49576669047444555 valid 0.3850780432017482
LOSS train 0.49576669047444555 valid 0.3852465786607132
LOSS train 0.49576669047444555 valid 0.3852468604090238
LOSS train 0.49576669047444555 valid 0.38529768106925427
LOSS train 0.49576669047444555 valid 0.3852432967722416
LOSS train 0.49576669047444555 valid 0.38507126798084124
LOSS train 0.49576669047444555 valid 0.38521999342016655
LOSS train 0.49576669047444555 valid 0.38503299631508703
LOSS train 0.49576669047444555 valid 0.38498065737532633
LOSS train 0.49576669047444555 valid 0.3850080299668196
LOSS train 0.49576669047444555 valid 0.3849192875102886
LOSS train 0.49576669047444555 valid 0.3850564197929585
LOSS train 0.49576669047444555 valid 0.38506369966153914
LOSS train 0.49576669047444555 valid 0.38499111179529766
LOSS train 0.49576669047444555 valid 0.38507506520975204
LOSS train 0.49576669047444555 valid 0.38504936669675094
LOSS train 0.49576669047444555 valid 0.3851046427240912
LOSS train 0.49576669047444555 valid 0.385245100433278
LOSS train 0.49576669047444555 valid 0.38521949417680224
LOSS train 0.49576669047444555 valid 0.3852589848429658
LOSS train 0.49576669047444555 valid 0.38532505708712117
LOSS train 0.49576669047444555 valid 0.3853407727408519
LOSS train 0.49576669047444555 valid 0.3854576685559859
LOSS train 0.49576669047444555 valid 0.3855112314768578
LOSS train 0.49576669047444555 valid 0.385694012994116
LOSS train 0.49576669047444555 valid 0.3858135118743413
LOSS train 0.49576669047444555 valid 0.3858019784764127
LOSS train 0.49576669047444555 valid 0.38582130772115936
LOSS train 0.49576669047444555 valid 0.38584145264966146
LOSS train 0.49576669047444555 valid 0.38586129824320475
LOSS train 0.49576669047444555 valid 0.38583749822810687
LOSS train 0.49576669047444555 valid 0.3859675405834215
LOSS train 0.49576669047444555 valid 0.38596625181666594
LOSS train 0.49576669047444555 valid 0.38605832936461837
LOSS train 0.49576669047444555 valid 0.3861493456622829
LOSS train 0.49576669047444555 valid 0.3861169127416817
LOSS train 0.49576669047444555 valid 0.3861468104196006
LOSS train 0.49576669047444555 valid 0.3860482078509269
LOSS train 0.49576669047444555 valid 0.38596749292989063
LOSS train 0.49576669047444555 valid 0.38606601535005775
LOSS train 0.49576669047444555 valid 0.3860368969834457
LOSS train 0.49576669047444555 valid 0.38597026454748484
LOSS train 0.49576669047444555 valid 0.38597206884071605
LOSS train 0.49576669047444555 valid 0.38584933295908336
LOSS train 0.49576669047444555 valid 0.3857441625247399
LOSS train 0.49576669047444555 valid 0.3859522376070379
LOSS train 0.49576669047444555 valid 0.38590494758826643
LOSS train 0.49576669047444555 valid 0.38589918956835084
LOSS train 0.49576669047444555 valid 0.38598208947748436
LOSS train 0.49576669047444555 valid 0.38599057744960397
LOSS train 0.49576669047444555 valid 0.3859411518021328
LOSS train 0.49576669047444555 valid 0.3859469035135107
LOSS train 0.49576669047444555 valid 0.3859397992491722
LOSS train 0.49576669047444555 valid 0.38594974810818594
LOSS train 0.49576669047444555 valid 0.386100261092186
LOSS train 0.49576669047444555 valid 0.386209860147233
LOSS train 0.49576669047444555 valid 0.3864132631865759
LOSS train 0.49576669047444555 valid 0.386327392616762
LOSS train 0.49576669047444555 valid 0.38648863840760206
LOSS train 0.49576669047444555 valid 0.3864351909534604
LOSS train 0.49576669047444555 valid 0.38639754767064005
LOSS train 0.49576669047444555 valid 0.3863580442588153
LOSS train 0.49576669047444555 valid 0.38646235184151995
LOSS train 0.49576669047444555 valid 0.38644412562653824
LOSS train 0.49576669047444555 valid 0.38631062117906717
LOSS train 0.49576669047444555 valid 0.3863081757364602
LOSS train 0.49576669047444555 valid 0.3862394758763204
LOSS train 0.49576669047444555 valid 0.38622524269180153
LOSS train 0.49576669047444555 valid 0.38618162421114516
LOSS train 0.49576669047444555 valid 0.3861895314927371
LOSS train 0.49576669047444555 valid 0.3863345381236614
LOSS train 0.49576669047444555 valid 0.3865032706144597
LOSS train 0.49576669047444555 valid 0.3865430678671865
LOSS train 0.49576669047444555 valid 0.3867610807090887
LOSS train 0.49576669047444555 valid 0.38671372731526693
LOSS train 0.49576669047444555 valid 0.3868440280761226
LOSS train 0.49576669047444555 valid 0.3868541726294686
LOSS train 0.49576669047444555 valid 0.38684569479344966
LOSS train 0.49576669047444555 valid 0.3868585759705871
LOSS train 0.49576669047444555 valid 0.3867609201778065
LOSS train 0.49576669047444555 valid 0.38672201583782834
LOSS train 0.49576669047444555 valid 0.3868004184767658
LOSS train 0.49576669047444555 valid 0.3867310484965071
LOSS train 0.49576669047444555 valid 0.3868195852498427
LOSS train 0.49576669047444555 valid 0.3867337450385094
LOSS train 0.49576669047444555 valid 0.38659068740559643
LOSS train 0.49576669047444555 valid 0.38657249224946855
LOSS train 0.49576669047444555 valid 0.38658580510439383
LOSS train 0.49576669047444555 valid 0.3866381805757402
LOSS train 0.49576669047444555 valid 0.38661761597583166
LOSS train 0.49576669047444555 valid 0.38650141625137596
LOSS train 0.49576669047444555 valid 0.38651742295521063
LOSS train 0.49576669047444555 valid 0.3864994609935416
LOSS train 0.49576669047444555 valid 0.386549343699815
LOSS train 0.49576669047444555 valid 0.38652824297033506
LOSS train 0.49576669047444555 valid 0.38641340349548053
LOSS train 0.49576669047444555 valid 0.3864136270872534
LOSS train 0.49576669047444555 valid 0.38633328493137814
LOSS train 0.49576669047444555 valid 0.38640069637168833
LOSS train 0.49576669047444555 valid 0.38654029308739357
LOSS train 0.49576669047444555 valid 0.38647811014104533
LOSS train 0.49576669047444555 valid 0.38649643310392745
LOSS train 0.49576669047444555 valid 0.3864315076162351
LOSS train 0.49576669047444555 valid 0.3865084648132324
LOSS train 0.49576669047444555 valid 0.3865743191043536
LOSS train 0.49576669047444555 valid 0.38655966035155365
LOSS train 0.49576669047444555 valid 0.3864158378136868
LOSS train 0.49576669047444555 valid 0.3863708286395561
LOSS train 0.49576669047444555 valid 0.38636771305219125
LOSS train 0.49576669047444555 valid 0.38632958814746043
LOSS train 0.49576669047444555 valid 0.3863542301008125
LOSS train 0.49576669047444555 valid 0.3863425356751544
LOSS train 0.49576669047444555 valid 0.38627428977520434
LOSS train 0.49576669047444555 valid 0.3863349067933351
LOSS train 0.49576669047444555 valid 0.3863084619083712
LOSS train 0.49576669047444555 valid 0.38628754767190987
LOSS train 0.49576669047444555 valid 0.3863106989898743
LOSS train 0.49576669047444555 valid 0.3863875699309876
LOSS train 0.49576669047444555 valid 0.3863414004919635
LOSS train 0.49576669047444555 valid 0.3863287026920016
LOSS train 0.49576669047444555 valid 0.3861918178728864
LOSS train 0.49576669047444555 valid 0.38623237083386924
LOSS train 0.49576669047444555 valid 0.38623714025290506
LOSS train 0.49576669047444555 valid 0.38618950139392505
LOSS train 0.49576669047444555 valid 0.386120677832514
LOSS train 0.49576669047444555 valid 0.3861655363598345
LOSS train 0.49576669047444555 valid 0.3861572221384285
LOSS train 0.49576669047444555 valid 0.38612706419484166
LOSS train 0.49576669047444555 valid 0.3860850535609104
LOSS train 0.49576669047444555 valid 0.38604806248958295
LOSS train 0.49576669047444555 valid 0.3861092602365587
LOSS train 0.49576669047444555 valid 0.3862488385551931
LOSS train 0.49576669047444555 valid 0.3862139125604455
LOSS train 0.49576669047444555 valid 0.38618269381552117
LOSS train 0.49576669047444555 valid 0.38613989127404763
LOSS train 0.49576669047444555 valid 0.3860882251464348
LOSS train 0.49576669047444555 valid 0.3859672125384032
LOSS train 0.49576669047444555 valid 0.3859849041467672
LOSS train 0.49576669047444555 valid 0.38604450538129864
LOSS train 0.49576669047444555 valid 0.3860531875446661
LOSS train 0.49576669047444555 valid 0.3859752570944173
LOSS train 0.49576669047444555 valid 0.38595831376508716
LOSS train 0.49576669047444555 valid 0.3859853247213646
LOSS train 0.49576669047444555 valid 0.38592579811371885
LOSS train 0.49576669047444555 valid 0.3859340942957822
LOSS train 0.49576669047444555 valid 0.385788328661597
LOSS train 0.49576669047444555 valid 0.3856882623761718
LOSS train 0.49576669047444555 valid 0.38570190692434503
LOSS train 0.49576669047444555 valid 0.3858197622520979
LOSS train 0.49576669047444555 valid 0.385888667901357
LOSS train 0.49576669047444555 valid 0.38587065342533794
LOSS train 0.49576669047444555 valid 0.38581539918091523
LOSS train 0.49576669047444555 valid 0.3857152745470233
LOSS train 0.49576669047444555 valid 0.3857201081633909
LOSS train 0.49576669047444555 valid 0.3856277809824262
LOSS train 0.49576669047444555 valid 0.38562836436464576
LOSS train 0.49576669047444555 valid 0.38567633647471666
LOSS train 0.49576669047444555 valid 0.3857425784760764
LOSS train 0.49576669047444555 valid 0.38580379866610814
LOSS train 0.49576669047444555 valid 0.3858250105884713
LOSS train 0.49576669047444555 valid 0.3858182395107291
LOSS train 0.49576669047444555 valid 0.3857905784574877
LOSS train 0.49576669047444555 valid 0.3857331177708823
LOSS train 0.49576669047444555 valid 0.3857412001216644
LOSS train 0.49576669047444555 valid 0.3857799594600995
LOSS train 0.49576669047444555 valid 0.38581858430872995
LOSS train 0.49576669047444555 valid 0.38592645484768884
LOSS train 0.49576669047444555 valid 0.38587205584055795
LOSS train 0.49576669047444555 valid 0.3858595724616732
LOSS train 0.49576669047444555 valid 0.3858987171355992
LOSS train 0.49576669047444555 valid 0.38581265680125504
LOSS train 0.49576669047444555 valid 0.38573922050421505
LOSS train 0.49576669047444555 valid 0.3857541104535694
LOSS train 0.49576669047444555 valid 0.3857566888739423
EPOCH 14:
  batch 1 loss: 0.4710751175880432
  batch 2 loss: 0.47382333874702454
  batch 3 loss: 0.48357125123341876
  batch 4 loss: 0.4979560077190399
  batch 5 loss: 0.4922036051750183
  batch 6 loss: 0.48746295770009357
  batch 7 loss: 0.490036598273686
  batch 8 loss: 0.49005473405122757
  batch 9 loss: 0.4914015730222066
  batch 10 loss: 0.49356715083122255
  batch 11 loss: 0.49285880543968896
  batch 12 loss: 0.4928783153494199
  batch 13 loss: 0.49082513268177325
  batch 14 loss: 0.49117531308106016
  batch 15 loss: 0.49018720189730325
  batch 16 loss: 0.48888870142400265
  batch 17 loss: 0.4875377083525938
  batch 18 loss: 0.487419918179512
  batch 19 loss: 0.48738320250260203
  batch 20 loss: 0.4870359808206558
  batch 21 loss: 0.4867854146730332
  batch 22 loss: 0.48743202740495856
  batch 23 loss: 0.48831150842749554
  batch 24 loss: 0.4878292481104533
  batch 25 loss: 0.4881275761127472
  batch 26 loss: 0.487409858749463
  batch 27 loss: 0.487596755778348
  batch 28 loss: 0.4877030625939369
  batch 29 loss: 0.4883639678872865
  batch 30 loss: 0.4876919915278753
  batch 31 loss: 0.4875803522525295
  batch 32 loss: 0.488064288161695
  batch 33 loss: 0.48794938217509876
  batch 34 loss: 0.4877303058610243
  batch 35 loss: 0.4898568247045789
  batch 36 loss: 0.49035143438312745
  batch 37 loss: 0.4908180422074086
  batch 38 loss: 0.4916323666509829
  batch 39 loss: 0.49178592898906803
  batch 40 loss: 0.49104319885373116
  batch 41 loss: 0.49099106250739677
  batch 42 loss: 0.4915503313144048
  batch 43 loss: 0.49132003548533415
  batch 44 loss: 0.4917763898318464
  batch 45 loss: 0.4915896515051524
  batch 46 loss: 0.49149370452632074
  batch 47 loss: 0.4915868081945054
  batch 48 loss: 0.4911564538876216
  batch 49 loss: 0.4908247894170333
  batch 50 loss: 0.4909264999628067
  batch 51 loss: 0.4898848095360924
  batch 52 loss: 0.4901805640413211
  batch 53 loss: 0.490661749862275
  batch 54 loss: 0.49112509191036224
  batch 55 loss: 0.4906112118200822
  batch 56 loss: 0.4897473837648119
  batch 57 loss: 0.4896575238621026
  batch 58 loss: 0.49065094004417287
  batch 59 loss: 0.4902961622860472
  batch 60 loss: 0.4902692740162214
  batch 61 loss: 0.4901940104414205
  batch 62 loss: 0.49111963520126956
  batch 63 loss: 0.4909652353279174
  batch 64 loss: 0.49141660751774907
  batch 65 loss: 0.49102431123073287
  batch 66 loss: 0.4911290429758303
  batch 67 loss: 0.49157391955603413
  batch 68 loss: 0.49157951333943534
  batch 69 loss: 0.4915291256662728
  batch 70 loss: 0.4912158902202334
  batch 71 loss: 0.4913719812749137
  batch 72 loss: 0.4914095774292946
  batch 73 loss: 0.4914156880280743
  batch 74 loss: 0.4913632366302851
  batch 75 loss: 0.4911126518249512
  batch 76 loss: 0.4917894115573482
  batch 77 loss: 0.4915323269057584
  batch 78 loss: 0.49116517756229794
  batch 79 loss: 0.4915711891047562
  batch 80 loss: 0.49145377315580846
  batch 81 loss: 0.49154614997498786
  batch 82 loss: 0.49197189655245804
  batch 83 loss: 0.4921673920499273
  batch 84 loss: 0.4923873965938886
  batch 85 loss: 0.49230367190697616
  batch 86 loss: 0.4929035170826801
  batch 87 loss: 0.49300363454325447
  batch 88 loss: 0.492454587735913
  batch 89 loss: 0.4925095706843258
  batch 90 loss: 0.4926619562837813
  batch 91 loss: 0.4928755177246345
  batch 92 loss: 0.4927543809880381
  batch 93 loss: 0.4926214554617482
  batch 94 loss: 0.49296727618004416
  batch 95 loss: 0.4931540391947094
  batch 96 loss: 0.49321489067127305
  batch 97 loss: 0.493636748532659
  batch 98 loss: 0.4939517290616522
  batch 99 loss: 0.493695500523153
  batch 100 loss: 0.49405105531215665
  batch 101 loss: 0.4939495059523252
  batch 102 loss: 0.49388306602543475
  batch 103 loss: 0.4940164908043389
  batch 104 loss: 0.49407901185063213
  batch 105 loss: 0.4936731659230732
  batch 106 loss: 0.4940025516838398
  batch 107 loss: 0.4941839428148537
  batch 108 loss: 0.494125800828139
  batch 109 loss: 0.49445047701170686
  batch 110 loss: 0.4948592676357789
  batch 111 loss: 0.4950643071720192
  batch 112 loss: 0.49501462733106955
  batch 113 loss: 0.49525040045248725
  batch 114 loss: 0.4958349066345315
  batch 115 loss: 0.49559302200441774
  batch 116 loss: 0.4956977488151912
  batch 117 loss: 0.4957826955196185
  batch 118 loss: 0.49591149440256216
  batch 119 loss: 0.4957950974211973
  batch 120 loss: 0.4956964368621508
  batch 121 loss: 0.49540084797488754
  batch 122 loss: 0.4951745708946322
  batch 123 loss: 0.4948035321099971
  batch 124 loss: 0.495009929182068
  batch 125 loss: 0.4947718756198883
  batch 126 loss: 0.49459910652940237
  batch 127 loss: 0.4948614767686589
  batch 128 loss: 0.4945885168854147
  batch 129 loss: 0.4944297142269075
  batch 130 loss: 0.49446099538069505
  batch 131 loss: 0.49479672471985564
  batch 132 loss: 0.4950623864477331
  batch 133 loss: 0.4951560394208234
  batch 134 loss: 0.495157411294197
  batch 135 loss: 0.495366891225179
  batch 136 loss: 0.49514220348175836
  batch 137 loss: 0.4952778981549896
  batch 138 loss: 0.4957892238229945
  batch 139 loss: 0.495780549032225
  batch 140 loss: 0.49556407289845605
  batch 141 loss: 0.4957494325671636
  batch 142 loss: 0.4955674686902006
  batch 143 loss: 0.4952906309724688
  batch 144 loss: 0.49538304718832177
  batch 145 loss: 0.4952806594042942
  batch 146 loss: 0.4952195390854796
  batch 147 loss: 0.4953104867821648
  batch 148 loss: 0.4954684378730284
  batch 149 loss: 0.4954290784045354
  batch 150 loss: 0.4951746275027593
  batch 151 loss: 0.49502475332740126
  batch 152 loss: 0.4953932420987832
  batch 153 loss: 0.4953462999630598
  batch 154 loss: 0.4954161752354015
  batch 155 loss: 0.4954927340630562
  batch 156 loss: 0.4954933720903519
  batch 157 loss: 0.4957754750540302
  batch 158 loss: 0.49568660104576545
  batch 159 loss: 0.49566382638313483
  batch 160 loss: 0.4957086158916354
  batch 161 loss: 0.4958327199731554
  batch 162 loss: 0.4956722754387208
  batch 163 loss: 0.4954373845659151
  batch 164 loss: 0.4954758666274024
  batch 165 loss: 0.49535983060345506
  batch 166 loss: 0.49553460547004835
  batch 167 loss: 0.4954715935056081
  batch 168 loss: 0.4957051021712167
  batch 169 loss: 0.49560583343167275
  batch 170 loss: 0.4955065692172331
  batch 171 loss: 0.49543161873231856
  batch 172 loss: 0.49552808701992035
  batch 173 loss: 0.4953606366422135
  batch 174 loss: 0.4953524576521468
  batch 175 loss: 0.4953159054688045
  batch 176 loss: 0.4952640775591135
  batch 177 loss: 0.49508490080887313
  batch 178 loss: 0.4951145312424456
  batch 179 loss: 0.49507552368680857
  batch 180 loss: 0.4950263329678112
  batch 181 loss: 0.4950125556624397
  batch 182 loss: 0.4950289166235662
  batch 183 loss: 0.4949430979666163
  batch 184 loss: 0.49478605357201205
  batch 185 loss: 0.49488616472965963
  batch 186 loss: 0.49491054300338994
  batch 187 loss: 0.49476421182168356
  batch 188 loss: 0.4948256629261565
  batch 189 loss: 0.49469878891157726
  batch 190 loss: 0.4946090633931913
  batch 191 loss: 0.4945579380265081
  batch 192 loss: 0.49445868097245693
  batch 193 loss: 0.4943387755458219
  batch 194 loss: 0.4943232391912913
  batch 195 loss: 0.49455324778190024
  batch 196 loss: 0.49447186382449404
  batch 197 loss: 0.49451453734170364
  batch 198 loss: 0.49468546112378436
  batch 199 loss: 0.49463625619159873
  batch 200 loss: 0.4946385690569878
  batch 201 loss: 0.49482624892571675
  batch 202 loss: 0.4948855060161931
  batch 203 loss: 0.4950305613978156
  batch 204 loss: 0.49498439507157194
  batch 205 loss: 0.4950647953079968
  batch 206 loss: 0.49514181231989446
  batch 207 loss: 0.49511895418743007
  batch 208 loss: 0.4950953224817148
  batch 209 loss: 0.49512083322237554
  batch 210 loss: 0.4951584544919786
  batch 211 loss: 0.4952044903667052
  batch 212 loss: 0.4952299267334758
  batch 213 loss: 0.4952289171062165
  batch 214 loss: 0.4951583666500644
  batch 215 loss: 0.4950044310370157
  batch 216 loss: 0.49481590975213935
  batch 217 loss: 0.49478106811848654
  batch 218 loss: 0.49475437621457863
  batch 219 loss: 0.4946873959613173
  batch 220 loss: 0.49467396343296227
  batch 221 loss: 0.49479678327141846
  batch 222 loss: 0.4949379494866809
  batch 223 loss: 0.4949609325872943
  batch 224 loss: 0.49490880008254734
  batch 225 loss: 0.49492689185672334
  batch 226 loss: 0.4950046270294527
  batch 227 loss: 0.4948277233193099
  batch 228 loss: 0.4948865550390461
  batch 229 loss: 0.4948497160813694
  batch 230 loss: 0.49491013171880144
  batch 231 loss: 0.4948557917173807
  batch 232 loss: 0.4946906603872776
  batch 233 loss: 0.49466580536232485
  batch 234 loss: 0.4946400663282117
  batch 235 loss: 0.49473795916171787
  batch 236 loss: 0.4947072328147242
  batch 237 loss: 0.49476958201404364
  batch 238 loss: 0.49480757517974916
  batch 239 loss: 0.4946861704772486
  batch 240 loss: 0.4948446704695622
  batch 241 loss: 0.4949518431024433
  batch 242 loss: 0.4948259766929406
  batch 243 loss: 0.4948085892347642
  batch 244 loss: 0.49480383855397586
  batch 245 loss: 0.4949084508175753
  batch 246 loss: 0.4949056886560549
  batch 247 loss: 0.49485908466794715
  batch 248 loss: 0.4949300202631181
  batch 249 loss: 0.49498532287567015
  batch 250 loss: 0.49500544118881223
  batch 251 loss: 0.4949851810219753
  batch 252 loss: 0.4950378712207552
  batch 253 loss: 0.49513218713843304
  batch 254 loss: 0.49511129332808995
  batch 255 loss: 0.49518663661152706
  batch 256 loss: 0.4950868794694543
  batch 257 loss: 0.4952034210416593
  batch 258 loss: 0.4951589830624041
  batch 259 loss: 0.4951205991179787
  batch 260 loss: 0.4950739579705092
  batch 261 loss: 0.4951546953784095
  batch 262 loss: 0.4950691866510697
  batch 263 loss: 0.4950329140111974
  batch 264 loss: 0.49500884115695953
  batch 265 loss: 0.4949638047308292
  batch 266 loss: 0.49500770631589386
  batch 267 loss: 0.4950177709708053
  batch 268 loss: 0.4949218472882883
  batch 269 loss: 0.49497109695881275
  batch 270 loss: 0.4950314810982457
  batch 271 loss: 0.49502414882842904
  batch 272 loss: 0.4951202766421963
  batch 273 loss: 0.4950704673926036
  batch 274 loss: 0.4949510955680026
  batch 275 loss: 0.49506378878246654
  batch 276 loss: 0.4951490195117135
  batch 277 loss: 0.49527284309321795
  batch 278 loss: 0.4951776378660751
  batch 279 loss: 0.49524150281396817
  batch 280 loss: 0.4950837611087731
  batch 281 loss: 0.49503312925426984
  batch 282 loss: 0.4948937362390207
  batch 283 loss: 0.4947666007722646
  batch 284 loss: 0.494826786534887
  batch 285 loss: 0.4947414852025216
  batch 286 loss: 0.49469410466564284
  batch 287 loss: 0.4947301389240637
  batch 288 loss: 0.49452176390008795
  batch 289 loss: 0.49463894365155575
  batch 290 loss: 0.49453647465541445
  batch 291 loss: 0.49457360665822764
  batch 292 loss: 0.4946077427227203
  batch 293 loss: 0.49469401832326687
  batch 294 loss: 0.4946507580426274
  batch 295 loss: 0.49480878336954925
  batch 296 loss: 0.4948503119317261
  batch 297 loss: 0.4949880334664675
  batch 298 loss: 0.495025966591483
  batch 299 loss: 0.49502045882984147
  batch 300 loss: 0.49510472188393273
  batch 301 loss: 0.4952015152999333
  batch 302 loss: 0.49522944998662205
  batch 303 loss: 0.4953045499796915
  batch 304 loss: 0.49528258754626703
  batch 305 loss: 0.49511219429188086
  batch 306 loss: 0.4951574719614453
  batch 307 loss: 0.4951303745908147
  batch 308 loss: 0.4950429592039678
  batch 309 loss: 0.4950876116366834
  batch 310 loss: 0.4950414595104033
  batch 311 loss: 0.4951120815284766
  batch 312 loss: 0.49521663890053064
  batch 313 loss: 0.4952518876177815
  batch 314 loss: 0.4953033507439741
  batch 315 loss: 0.49528990028396486
  batch 316 loss: 0.4951876453772376
  batch 317 loss: 0.4952408454207592
  batch 318 loss: 0.49521527678336735
  batch 319 loss: 0.49511895134904915
  batch 320 loss: 0.495102855656296
  batch 321 loss: 0.49514554974817415
  batch 322 loss: 0.4951430689659178
  batch 323 loss: 0.49506565282588405
  batch 324 loss: 0.4949270068311397
  batch 325 loss: 0.49486608798687276
  batch 326 loss: 0.4948304061509349
  batch 327 loss: 0.4948001774626041
  batch 328 loss: 0.4946848473897794
  batch 329 loss: 0.49479503182292345
  batch 330 loss: 0.49472396138942604
  batch 331 loss: 0.49463139559927305
  batch 332 loss: 0.4946413769061307
  batch 333 loss: 0.49463125392123386
  batch 334 loss: 0.4944912723438469
  batch 335 loss: 0.4944016568696321
  batch 336 loss: 0.4943021491524719
  batch 337 loss: 0.4942327168292037
  batch 338 loss: 0.4941861181569523
  batch 339 loss: 0.4942950690742088
  batch 340 loss: 0.4943266221705605
  batch 341 loss: 0.4943457731753151
  batch 342 loss: 0.4942671678393905
  batch 343 loss: 0.49420782106958394
  batch 344 loss: 0.4942212906167951
  batch 345 loss: 0.4943414308886597
  batch 346 loss: 0.4942896256729358
  batch 347 loss: 0.4943352067676676
  batch 348 loss: 0.49434420303709203
  batch 349 loss: 0.4942475871575254
  batch 350 loss: 0.4942594955648695
  batch 351 loss: 0.4942666315964484
  batch 352 loss: 0.4943931952796199
  batch 353 loss: 0.49434648205133064
  batch 354 loss: 0.49437044367278365
  batch 355 loss: 0.4944691842710468
  batch 356 loss: 0.49440964905733475
  batch 357 loss: 0.4943965429685363
  batch 358 loss: 0.4944475850912446
  batch 359 loss: 0.494449224976776
  batch 360 loss: 0.49451066222455764
  batch 361 loss: 0.49454685591594666
  batch 362 loss: 0.49441797306853763
  batch 363 loss: 0.4943774874545326
  batch 364 loss: 0.49427527058255544
  batch 365 loss: 0.4942762459794136
  batch 366 loss: 0.4942026249046534
  batch 367 loss: 0.49421264446398866
  batch 368 loss: 0.49425119534134865
  batch 369 loss: 0.49423917942253875
  batch 370 loss: 0.4943397596075728
  batch 371 loss: 0.49446898120432853
  batch 372 loss: 0.49434545147483067
  batch 373 loss: 0.4943007767679864
  batch 374 loss: 0.4942133740626554
  batch 375 loss: 0.4943189703623454
  batch 376 loss: 0.4943531772240679
  batch 377 loss: 0.49431199104147183
  batch 378 loss: 0.49426137644147117
  batch 379 loss: 0.49427440754656427
  batch 380 loss: 0.4944089520918696
  batch 381 loss: 0.49432974420194553
  batch 382 loss: 0.494152182293812
  batch 383 loss: 0.4941322345957744
  batch 384 loss: 0.49406905798241496
  batch 385 loss: 0.4941440099245542
  batch 386 loss: 0.4940353725395054
  batch 387 loss: 0.49404849524029776
  batch 388 loss: 0.4940331653528607
  batch 389 loss: 0.4940733099045055
  batch 390 loss: 0.49406954707243506
  batch 391 loss: 0.49402164826002876
  batch 392 loss: 0.49408306082596587
  batch 393 loss: 0.49417227089556726
  batch 394 loss: 0.49419950916984967
  batch 395 loss: 0.4943170779113528
  batch 396 loss: 0.49433320888666193
  batch 397 loss: 0.49429409442380334
  batch 398 loss: 0.49432517842731283
  batch 399 loss: 0.4943863832412806
  batch 400 loss: 0.4943494091182947
  batch 401 loss: 0.4943352057749494
  batch 402 loss: 0.4944257235052574
  batch 403 loss: 0.4943667871336783
  batch 404 loss: 0.4943498924079508
  batch 405 loss: 0.4943769477767709
  batch 406 loss: 0.4944911134507268
  batch 407 loss: 0.49452466570774517
  batch 408 loss: 0.49462420120835304
  batch 409 loss: 0.49464631612551535
  batch 410 loss: 0.4946684669430663
  batch 411 loss: 0.4946585858100232
  batch 412 loss: 0.4946463580415087
  batch 413 loss: 0.49469222362913173
  batch 414 loss: 0.4947056529170649
  batch 415 loss: 0.4946648314774755
  batch 416 loss: 0.49470165314582676
  batch 417 loss: 0.4947002987495715
  batch 418 loss: 0.49471161026133303
  batch 419 loss: 0.4946997101665397
  batch 420 loss: 0.4947098476546151
  batch 421 loss: 0.4946870529170274
  batch 422 loss: 0.4947820028987541
  batch 423 loss: 0.4948273861943689
  batch 424 loss: 0.49486549479781455
  batch 425 loss: 0.4948807663076064
  batch 426 loss: 0.4948596989324955
  batch 427 loss: 0.4948718662284297
  batch 428 loss: 0.4947805243117787
  batch 429 loss: 0.49473563691119216
  batch 430 loss: 0.49475697833438254
  batch 431 loss: 0.49495159597795135
  batch 432 loss: 0.4950163856976562
  batch 433 loss: 0.4949301910730763
  batch 434 loss: 0.4949960074117107
  batch 435 loss: 0.4950056607010721
  batch 436 loss: 0.49500529611602834
  batch 437 loss: 0.49507252541232166
  batch 438 loss: 0.49517570721776516
  batch 439 loss: 0.49516915344974716
  batch 440 loss: 0.4951740521598946
  batch 441 loss: 0.49515861266053995
  batch 442 loss: 0.49509422521515667
  batch 443 loss: 0.4950916343967748
  batch 444 loss: 0.49497813852252187
  batch 445 loss: 0.4950109994143582
  batch 446 loss: 0.4949697395076666
  batch 447 loss: 0.4949500796112172
  batch 448 loss: 0.49503472121432424
  batch 449 loss: 0.4951555323361819
  batch 450 loss: 0.49522320873207515
  batch 451 loss: 0.4952700282808418
  batch 452 loss: 0.4952739072980079
  batch 453 loss: 0.4953152968262468
  batch 454 loss: 0.49535372269048566
  batch 455 loss: 0.4953942849740877
  batch 456 loss: 0.49540855271513
  batch 457 loss: 0.4954462392455379
  batch 458 loss: 0.4954211003265006
  batch 459 loss: 0.4954324313368413
  batch 460 loss: 0.49553268027046454
  batch 461 loss: 0.49556517956572343
  batch 462 loss: 0.4955347628691496
  batch 463 loss: 0.4955132848886898
  batch 464 loss: 0.4955680120479444
  batch 465 loss: 0.4954440843033534
  batch 466 loss: 0.4953116194500944
  batch 467 loss: 0.49533855908687924
  batch 468 loss: 0.49528052186609334
  batch 469 loss: 0.49529978798142377
  batch 470 loss: 0.4952651172876358
  batch 471 loss: 0.4952527063793944
  batch 472 loss: 0.49523597640001166
LOSS train 0.49523597640001166 valid 0.3340689539909363
LOSS train 0.49523597640001166 valid 0.33023858070373535
LOSS train 0.49523597640001166 valid 0.34510868787765503
LOSS train 0.49523597640001166 valid 0.3432621583342552
LOSS train 0.49523597640001166 valid 0.3409141004085541
LOSS train 0.49523597640001166 valid 0.3428806612888972
LOSS train 0.49523597640001166 valid 0.3408615461417607
LOSS train 0.49523597640001166 valid 0.34151552245020866
LOSS train 0.49523597640001166 valid 0.33738620744811165
LOSS train 0.49523597640001166 valid 0.3395653396844864
LOSS train 0.49523597640001166 valid 0.3426960462873632
LOSS train 0.49523597640001166 valid 0.3419206514954567
LOSS train 0.49523597640001166 valid 0.34315169086823094
LOSS train 0.49523597640001166 valid 0.343342336160796
LOSS train 0.49523597640001166 valid 0.342070464293162
LOSS train 0.49523597640001166 valid 0.34407652728259563
LOSS train 0.49523597640001166 valid 0.3469083326704362
LOSS train 0.49523597640001166 valid 0.3473089618815316
LOSS train 0.49523597640001166 valid 0.3480358782567476
LOSS train 0.49523597640001166 valid 0.3498294085264206
LOSS train 0.49523597640001166 valid 0.3490735718182155
LOSS train 0.49523597640001166 valid 0.3471349206837741
LOSS train 0.49523597640001166 valid 0.34775954484939575
LOSS train 0.49523597640001166 valid 0.34721538176139194
LOSS train 0.49523597640001166 valid 0.34668216824531556
LOSS train 0.49523597640001166 valid 0.3460259357324013
LOSS train 0.49523597640001166 valid 0.3455285937697799
LOSS train 0.49523597640001166 valid 0.34597654747111456
LOSS train 0.49523597640001166 valid 0.346089041438596
LOSS train 0.49523597640001166 valid 0.3468962619702021
LOSS train 0.49523597640001166 valid 0.34837241230472443
LOSS train 0.49523597640001166 valid 0.3483801204711199
LOSS train 0.49523597640001166 valid 0.3493386181918057
LOSS train 0.49523597640001166 valid 0.34868066801744346
LOSS train 0.49523597640001166 valid 0.34938830307551794
LOSS train 0.49523597640001166 valid 0.3492818988031811
LOSS train 0.49523597640001166 valid 0.3498825608073054
LOSS train 0.49523597640001166 valid 0.35076262605817693
LOSS train 0.49523597640001166 valid 0.3506374068749257
LOSS train 0.49523597640001166 valid 0.35199052691459654
LOSS train 0.49523597640001166 valid 0.3518980639736827
LOSS train 0.49523597640001166 valid 0.35294631052584874
LOSS train 0.49523597640001166 valid 0.3528425326181013
LOSS train 0.49523597640001166 valid 0.3530951907688921
LOSS train 0.49523597640001166 valid 0.35309628314442104
LOSS train 0.49523597640001166 valid 0.3535126920627511
LOSS train 0.49523597640001166 valid 0.35312662923589666
LOSS train 0.49523597640001166 valid 0.35356728608409566
LOSS train 0.49523597640001166 valid 0.3540904448956859
LOSS train 0.49523597640001166 valid 0.35350690484046937
LOSS train 0.49523597640001166 valid 0.3540568188125012
LOSS train 0.49523597640001166 valid 0.35371412279514164
LOSS train 0.49523597640001166 valid 0.3531080388797904
LOSS train 0.49523597640001166 valid 0.35308094653818345
LOSS train 0.49523597640001166 valid 0.35296937335621226
LOSS train 0.49523597640001166 valid 0.3529368149382727
LOSS train 0.49523597640001166 valid 0.352711372208177
LOSS train 0.49523597640001166 valid 0.35235330667989007
LOSS train 0.49523597640001166 valid 0.3529173529754251
LOSS train 0.49523597640001166 valid 0.35241558253765104
LOSS train 0.49523597640001166 valid 0.3513701069550436
LOSS train 0.49523597640001166 valid 0.35227034937950874
LOSS train 0.49523597640001166 valid 0.35267968641387093
LOSS train 0.49523597640001166 valid 0.3530780808068812
LOSS train 0.49523597640001166 valid 0.35304900178542503
LOSS train 0.49523597640001166 valid 0.35311290395982337
LOSS train 0.49523597640001166 valid 0.35265184471856303
LOSS train 0.49523597640001166 valid 0.3521747234113076
LOSS train 0.49523597640001166 valid 0.3520106046959974
LOSS train 0.49523597640001166 valid 0.35164108616965156
LOSS train 0.49523597640001166 valid 0.3516118429916006
LOSS train 0.49523597640001166 valid 0.35152117038766545
LOSS train 0.49523597640001166 valid 0.3516241618215221
LOSS train 0.49523597640001166 valid 0.3515045824083122
LOSS train 0.49523597640001166 valid 0.350895357131958
LOSS train 0.49523597640001166 valid 0.3510926412908654
LOSS train 0.49523597640001166 valid 0.3508667434964861
LOSS train 0.49523597640001166 valid 0.3507773803594785
LOSS train 0.49523597640001166 valid 0.3506100928481621
LOSS train 0.49523597640001166 valid 0.35051742754876614
LOSS train 0.49523597640001166 valid 0.3501472061063037
LOSS train 0.49523597640001166 valid 0.35034924200395257
LOSS train 0.49523597640001166 valid 0.3500827658607299
LOSS train 0.49523597640001166 valid 0.350261390209198
LOSS train 0.49523597640001166 valid 0.350285746420131
LOSS train 0.49523597640001166 valid 0.35009273921334466
LOSS train 0.49523597640001166 valid 0.3499962622406839
LOSS train 0.49523597640001166 valid 0.34957210008393635
LOSS train 0.49523597640001166 valid 0.34989931409278613
LOSS train 0.49523597640001166 valid 0.3498952713277605
LOSS train 0.49523597640001166 valid 0.3496816793640891
LOSS train 0.49523597640001166 valid 0.34939586144426593
LOSS train 0.49523597640001166 valid 0.3487837189628232
LOSS train 0.49523597640001166 valid 0.3482860133368918
LOSS train 0.49523597640001166 valid 0.34796662675706963
LOSS train 0.49523597640001166 valid 0.3481878439585368
LOSS train 0.49523597640001166 valid 0.3485608276018162
LOSS train 0.49523597640001166 valid 0.3485739568666536
LOSS train 0.49523597640001166 valid 0.34867507189211217
LOSS train 0.49523597640001166 valid 0.34887173265218735
LOSS train 0.49523597640001166 valid 0.3489642293736486
LOSS train 0.49523597640001166 valid 0.3489815601531197
LOSS train 0.49523597640001166 valid 0.34949248045393566
LOSS train 0.49523597640001166 valid 0.3493188676925806
LOSS train 0.49523597640001166 valid 0.34921951918374927
LOSS train 0.49523597640001166 valid 0.3492519113252748
LOSS train 0.49523597640001166 valid 0.349010821814849
LOSS train 0.49523597640001166 valid 0.3493464575321586
LOSS train 0.49523597640001166 valid 0.3494698911085041
LOSS train 0.49523597640001166 valid 0.3495835317806764
LOSS train 0.49523597640001166 valid 0.34957005070136477
LOSS train 0.49523597640001166 valid 0.34940106607973576
LOSS train 0.49523597640001166 valid 0.3494537396241078
LOSS train 0.49523597640001166 valid 0.3493034612191351
LOSS train 0.49523597640001166 valid 0.34928201566571776
LOSS train 0.49523597640001166 valid 0.3492159103525096
LOSS train 0.49523597640001166 valid 0.34929267361632776
LOSS train 0.49523597640001166 valid 0.3490677609787149
LOSS train 0.49523597640001166 valid 0.3488790745995626
LOSS train 0.49523597640001166 valid 0.34872728983561196
LOSS train 0.49523597640001166 valid 0.34860253284785375
LOSS train 0.49523597640001166 valid 0.34847566729686297
LOSS train 0.49523597640001166 valid 0.34865842020608545
LOSS train 0.49523597640001166 valid 0.3488245399728898
LOSS train 0.49523597640001166 valid 0.3487088785171509
LOSS train 0.49523597640001166 valid 0.34856179498490836
LOSS train 0.49523597640001166 valid 0.34906334107316384
LOSS train 0.49523597640001166 valid 0.34916861448436975
LOSS train 0.49523597640001166 valid 0.34930528850518455
LOSS train 0.49523597640001166 valid 0.3491315023257182
LOSS train 0.49523597640001166 valid 0.3492224960381748
LOSS train 0.49523597640001166 valid 0.349187059610179
LOSS train 0.49523597640001166 valid 0.3489979610855418
LOSS train 0.49523597640001166 valid 0.3491899466781474
LOSS train 0.49523597640001166 valid 0.34932344997370685
LOSS train 0.49523597640001166 valid 0.3492603133268216
LOSS train 0.49523597640001166 valid 0.34906987682746277
LOSS train 0.49523597640001166 valid 0.3490067385676978
LOSS train 0.49523597640001166 valid 0.34888264665500723
LOSS train 0.49523597640001166 valid 0.34907164765255794
LOSS train 0.49523597640001166 valid 0.3490923710748659
LOSS train 0.49523597640001166 valid 0.34935621413546547
LOSS train 0.49523597640001166 valid 0.3491129310397835
LOSS train 0.49523597640001166 valid 0.34913232405152583
LOSS train 0.49523597640001166 valid 0.3490753529400661
LOSS train 0.49523597640001166 valid 0.349372851726127
LOSS train 0.49523597640001166 valid 0.3489899716409696
LOSS train 0.49523597640001166 valid 0.3492379124100144
LOSS train 0.49523597640001166 valid 0.349308455350415
LOSS train 0.49523597640001166 valid 0.3493691237767537
LOSS train 0.49523597640001166 valid 0.3494711802495236
LOSS train 0.49523597640001166 valid 0.34925633139516177
LOSS train 0.49523597640001166 valid 0.34949349090943926
LOSS train 0.49523597640001166 valid 0.34950442225128026
LOSS train 0.49523597640001166 valid 0.3495478626220457
LOSS train 0.49523597640001166 valid 0.34980866733269816
LOSS train 0.49523597640001166 valid 0.3497342524255157
LOSS train 0.49523597640001166 valid 0.3496770334394672
LOSS train 0.49523597640001166 valid 0.34940574529036034
LOSS train 0.49523597640001166 valid 0.3495232753455639
LOSS train 0.49523597640001166 valid 0.3493786156177521
LOSS train 0.49523597640001166 valid 0.3491355294798627
LOSS train 0.49523597640001166 valid 0.3490761043103926
LOSS train 0.49523597640001166 valid 0.34896033784238306
LOSS train 0.49523597640001166 valid 0.3488890828508319
LOSS train 0.49523597640001166 valid 0.3487546736576471
LOSS train 0.49523597640001166 valid 0.348773330628515
LOSS train 0.49523597640001166 valid 0.34888874491055805
LOSS train 0.49523597640001166 valid 0.3489544887161819
LOSS train 0.49523597640001166 valid 0.3493125720935709
LOSS train 0.49523597640001166 valid 0.3493009105063321
LOSS train 0.49523597640001166 valid 0.34940047128949053
LOSS train 0.49523597640001166 valid 0.34952262801931083
LOSS train 0.49523597640001166 valid 0.34943188076046694
LOSS train 0.49523597640001166 valid 0.34943242277417863
LOSS train 0.49523597640001166 valid 0.34927294945174997
LOSS train 0.49523597640001166 valid 0.3494578638655991
LOSS train 0.49523597640001166 valid 0.34956724004129347
LOSS train 0.49523597640001166 valid 0.3493986584287782
LOSS train 0.49523597640001166 valid 0.3495076975888676
LOSS train 0.49523597640001166 valid 0.34949697298898225
LOSS train 0.49523597640001166 valid 0.34961023468237656
LOSS train 0.49523597640001166 valid 0.3494914889009924
LOSS train 0.49523597640001166 valid 0.34966674171712087
LOSS train 0.49523597640001166 valid 0.3495818171952222
LOSS train 0.49523597640001166 valid 0.34963139459010095
LOSS train 0.49523597640001166 valid 0.3496602338584349
LOSS train 0.49523597640001166 valid 0.3496226899801417
LOSS train 0.49523597640001166 valid 0.3496294196635958
LOSS train 0.49523597640001166 valid 0.3494848150956003
LOSS train 0.49523597640001166 valid 0.3496271587167111
LOSS train 0.49523597640001166 valid 0.34969068551436067
LOSS train 0.49523597640001166 valid 0.349610607395518
LOSS train 0.49523597640001166 valid 0.3494564133513834
LOSS train 0.49523597640001166 valid 0.3494775163821685
LOSS train 0.49523597640001166 valid 0.3494939880103481
LOSS train 0.49523597640001166 valid 0.3496233177971719
LOSS train 0.49523597640001166 valid 0.3496473502330106
LOSS train 0.49523597640001166 valid 0.3496836924073684
LOSS train 0.49523597640001166 valid 0.349584741294384
LOSS train 0.49523597640001166 valid 0.3494236535990416
LOSS train 0.49523597640001166 valid 0.34954698737895135
LOSS train 0.49523597640001166 valid 0.3493895899192453
LOSS train 0.49523597640001166 valid 0.34933847583392086
LOSS train 0.49523597640001166 valid 0.3493468655318749
LOSS train 0.49523597640001166 valid 0.34924343647887407
LOSS train 0.49523597640001166 valid 0.34938068061635114
LOSS train 0.49523597640001166 valid 0.34942094121988004
LOSS train 0.49523597640001166 valid 0.3493652959759726
LOSS train 0.49523597640001166 valid 0.3494329642681848
LOSS train 0.49523597640001166 valid 0.3494274316805799
LOSS train 0.49523597640001166 valid 0.3494936553937084
LOSS train 0.49523597640001166 valid 0.34958496172103526
LOSS train 0.49523597640001166 valid 0.34954644642143606
LOSS train 0.49523597640001166 valid 0.34961750119231466
LOSS train 0.49523597640001166 valid 0.3496888290952753
LOSS train 0.49523597640001166 valid 0.34969207575793637
LOSS train 0.49523597640001166 valid 0.3497889290709014
LOSS train 0.49523597640001166 valid 0.34982646736380174
LOSS train 0.49523597640001166 valid 0.3499800862236456
LOSS train 0.49523597640001166 valid 0.35013099871070136
LOSS train 0.49523597640001166 valid 0.3501014301368782
LOSS train 0.49523597640001166 valid 0.3501338509700758
LOSS train 0.49523597640001166 valid 0.3501490556768009
LOSS train 0.49523597640001166 valid 0.35015767057736713
LOSS train 0.49523597640001166 valid 0.35015243542405355
LOSS train 0.49523597640001166 valid 0.3502467522799706
LOSS train 0.49523597640001166 valid 0.3502663502044845
LOSS train 0.49523597640001166 valid 0.3503915295330198
LOSS train 0.49523597640001166 valid 0.35049425687478936
LOSS train 0.49523597640001166 valid 0.3504972588190269
LOSS train 0.49523597640001166 valid 0.35052632090860397
LOSS train 0.49523597640001166 valid 0.3504276133658037
LOSS train 0.49523597640001166 valid 0.3503584898689873
LOSS train 0.49523597640001166 valid 0.3505104335064584
LOSS train 0.49523597640001166 valid 0.3504732315570621
LOSS train 0.49523597640001166 valid 0.3504084571252895
LOSS train 0.49523597640001166 valid 0.35036463284191965
LOSS train 0.49523597640001166 valid 0.35023425824971377
LOSS train 0.49523597640001166 valid 0.35015472682813803
LOSS train 0.49523597640001166 valid 0.3503776177825769
LOSS train 0.49523597640001166 valid 0.35033593653154765
LOSS train 0.49523597640001166 valid 0.3503337903523151
LOSS train 0.49523597640001166 valid 0.3504002575503021
LOSS train 0.49523597640001166 valid 0.3504302117289329
LOSS train 0.49523597640001166 valid 0.3503992817993086
LOSS train 0.49523597640001166 valid 0.3504364555663908
LOSS train 0.49523597640001166 valid 0.35044296314158746
LOSS train 0.49523597640001166 valid 0.3504612691191784
LOSS train 0.49523597640001166 valid 0.35065656578540805
LOSS train 0.49523597640001166 valid 0.35071609314694346
LOSS train 0.49523597640001166 valid 0.35088840280733413
LOSS train 0.49523597640001166 valid 0.3508145438117001
LOSS train 0.49523597640001166 valid 0.3509741000772461
LOSS train 0.49523597640001166 valid 0.3509340854252086
LOSS train 0.49523597640001166 valid 0.3509133926127106
LOSS train 0.49523597640001166 valid 0.35087969620867926
LOSS train 0.49523597640001166 valid 0.35097727075565693
LOSS train 0.49523597640001166 valid 0.3509352245155909
LOSS train 0.49523597640001166 valid 0.3507961900188373
LOSS train 0.49523597640001166 valid 0.35079823360132534
LOSS train 0.49523597640001166 valid 0.35072925789210635
LOSS train 0.49523597640001166 valid 0.35073093837658265
LOSS train 0.49523597640001166 valid 0.3506852589321859
LOSS train 0.49523597640001166 valid 0.3506915751493202
LOSS train 0.49523597640001166 valid 0.3507991984374541
LOSS train 0.49523597640001166 valid 0.35094482287039025
LOSS train 0.49523597640001166 valid 0.35098540071231216
LOSS train 0.49523597640001166 valid 0.35118169567398866
LOSS train 0.49523597640001166 valid 0.35112853580050996
LOSS train 0.49523597640001166 valid 0.3512531825757115
LOSS train 0.49523597640001166 valid 0.3512733767137808
LOSS train 0.49523597640001166 valid 0.35126882322105296
LOSS train 0.49523597640001166 valid 0.35124536685264895
LOSS train 0.49523597640001166 valid 0.35114264672452755
LOSS train 0.49523597640001166 valid 0.35110322796348215
LOSS train 0.49523597640001166 valid 0.35118349515143715
LOSS train 0.49523597640001166 valid 0.3511167477360732
LOSS train 0.49523597640001166 valid 0.3512065412750381
LOSS train 0.49523597640001166 valid 0.3511052680867059
LOSS train 0.49523597640001166 valid 0.35097130231585794
LOSS train 0.49523597640001166 valid 0.3509495637729658
LOSS train 0.49523597640001166 valid 0.350967988740429
LOSS train 0.49523597640001166 valid 0.3510287726219271
LOSS train 0.49523597640001166 valid 0.35101945452522815
LOSS train 0.49523597640001166 valid 0.35092049441137513
LOSS train 0.49523597640001166 valid 0.35093299852431026
LOSS train 0.49523597640001166 valid 0.35089128588636714
LOSS train 0.49523597640001166 valid 0.3509325700647691
LOSS train 0.49523597640001166 valid 0.3509209323545982
LOSS train 0.49523597640001166 valid 0.3508092019566146
LOSS train 0.49523597640001166 valid 0.3508204699379124
LOSS train 0.49523597640001166 valid 0.3507285731440925
LOSS train 0.49523597640001166 valid 0.35078265624386923
LOSS train 0.49523597640001166 valid 0.3509275821305938
LOSS train 0.49523597640001166 valid 0.35086072477939967
LOSS train 0.49523597640001166 valid 0.3508733867194115
LOSS train 0.49523597640001166 valid 0.3508194023930786
LOSS train 0.49523597640001166 valid 0.3509215768364361
LOSS train 0.49523597640001166 valid 0.3509877899289131
LOSS train 0.49523597640001166 valid 0.3509727130300579
LOSS train 0.49523597640001166 valid 0.35083289750364444
LOSS train 0.49523597640001166 valid 0.3507798201966994
LOSS train 0.49523597640001166 valid 0.3507966941320582
LOSS train 0.49523597640001166 valid 0.3507675181646816
LOSS train 0.49523597640001166 valid 0.35077795805105194
LOSS train 0.49523597640001166 valid 0.3507531961905451
LOSS train 0.49523597640001166 valid 0.3507071624135042
LOSS train 0.49523597640001166 valid 0.35074845612242
LOSS train 0.49523597640001166 valid 0.35074351208825266
LOSS train 0.49523597640001166 valid 0.3507439598584865
LOSS train 0.49523597640001166 valid 0.3507596352734627
LOSS train 0.49523597640001166 valid 0.3508322262725891
LOSS train 0.49523597640001166 valid 0.3507770691897459
LOSS train 0.49523597640001166 valid 0.3507619573010339
LOSS train 0.49523597640001166 valid 0.3506335053074209
LOSS train 0.49523597640001166 valid 0.35066559252678786
LOSS train 0.49523597640001166 valid 0.35066567005226446
LOSS train 0.49523597640001166 valid 0.3506300898741779
LOSS train 0.49523597640001166 valid 0.3505488901399076
LOSS train 0.49523597640001166 valid 0.3505874615034953
LOSS train 0.49523597640001166 valid 0.3505688845555975
LOSS train 0.49523597640001166 valid 0.3505438158386632
LOSS train 0.49523597640001166 valid 0.35049182259374195
LOSS train 0.49523597640001166 valid 0.35044727435478795
LOSS train 0.49523597640001166 valid 0.3504916021794629
LOSS train 0.49523597640001166 valid 0.35064177246997846
LOSS train 0.49523597640001166 valid 0.35062065765988537
LOSS train 0.49523597640001166 valid 0.35060863627126515
LOSS train 0.49523597640001166 valid 0.35055411286426313
LOSS train 0.49523597640001166 valid 0.3504941937966649
LOSS train 0.49523597640001166 valid 0.35037961270076684
LOSS train 0.49523597640001166 valid 0.3504076667197116
LOSS train 0.49523597640001166 valid 0.3504672602800552
LOSS train 0.49523597640001166 valid 0.35044544543792955
LOSS train 0.49523597640001166 valid 0.35036751583573367
LOSS train 0.49523597640001166 valid 0.3503835011129917
LOSS train 0.49523597640001166 valid 0.35039084435567347
LOSS train 0.49523597640001166 valid 0.350327466881029
LOSS train 0.49523597640001166 valid 0.3503398194032557
LOSS train 0.49523597640001166 valid 0.3502101092394496
LOSS train 0.49523597640001166 valid 0.35010073669472636
LOSS train 0.49523597640001166 valid 0.350087442829032
LOSS train 0.49523597640001166 valid 0.35020470359297684
LOSS train 0.49523597640001166 valid 0.3502679173497186
LOSS train 0.49523597640001166 valid 0.35025702907859935
LOSS train 0.49523597640001166 valid 0.35021717386905327
LOSS train 0.49523597640001166 valid 0.3501306602667118
LOSS train 0.49523597640001166 valid 0.3501258213233128
LOSS train 0.49523597640001166 valid 0.3500334107024329
LOSS train 0.49523597640001166 valid 0.3500337345987304
LOSS train 0.49523597640001166 valid 0.350060701708902
LOSS train 0.49523597640001166 valid 0.3501107355015136
LOSS train 0.49523597640001166 valid 0.35015912194036497
LOSS train 0.49523597640001166 valid 0.3501910341457582
LOSS train 0.49523597640001166 valid 0.3501991637971964
LOSS train 0.49523597640001166 valid 0.350172530703184
LOSS train 0.49523597640001166 valid 0.3501279424855163
LOSS train 0.49523597640001166 valid 0.350132203948863
LOSS train 0.49523597640001166 valid 0.35016106954879234
LOSS train 0.49523597640001166 valid 0.35018828156251985
LOSS train 0.49523597640001166 valid 0.35031454866103706
LOSS train 0.49523597640001166 valid 0.3502846266612534
LOSS train 0.49523597640001166 valid 0.3502544045120805
LOSS train 0.49523597640001166 valid 0.35029837693253607
LOSS train 0.49523597640001166 valid 0.35022137033157663
LOSS train 0.49523597640001166 valid 0.35016964656130817
LOSS train 0.49523597640001166 valid 0.3501729050894146
LOSS train 0.49523597640001166 valid 0.350177882001975
EPOCH 15:
  batch 1 loss: 0.47154414653778076
  batch 2 loss: 0.4844387471675873
  batch 3 loss: 0.49018293619155884
  batch 4 loss: 0.5003462433815002
  batch 5 loss: 0.4946463227272034
  batch 6 loss: 0.49046678344408673
  batch 7 loss: 0.49068463700158255
  batch 8 loss: 0.49000367522239685
  batch 9 loss: 0.4922706021202935
  batch 10 loss: 0.4948703408241272
  batch 11 loss: 0.4939494891600175
  batch 12 loss: 0.49340206136306125
  batch 13 loss: 0.49253276448983413
  batch 14 loss: 0.4925817825964519
  batch 15 loss: 0.4921420931816101
  batch 16 loss: 0.4922619257122278
  batch 17 loss: 0.49124272781259876
  batch 18 loss: 0.48946117692523533
  batch 19 loss: 0.48924207059960617
  batch 20 loss: 0.4895890712738037
  batch 21 loss: 0.48881748460588004
  batch 22 loss: 0.4890521493825046
  batch 23 loss: 0.4900036661521248
  batch 24 loss: 0.48914525657892227
  batch 25 loss: 0.4892172908782959
  batch 26 loss: 0.4881157737511855
  batch 27 loss: 0.48788578201223304
  batch 28 loss: 0.4881575469459806
  batch 29 loss: 0.48874314694569027
  batch 30 loss: 0.4879274606704712
  batch 31 loss: 0.48814838355587375
  batch 32 loss: 0.48847402073442936
  batch 33 loss: 0.4886866401542317
  batch 34 loss: 0.4884321926271214
  batch 35 loss: 0.49050213864871434
  batch 36 loss: 0.49088435620069504
  batch 37 loss: 0.4914308842774984
  batch 38 loss: 0.4923545710350338
  batch 39 loss: 0.4926582414370317
  batch 40 loss: 0.4917812943458557
  batch 41 loss: 0.4917902553953776
  batch 42 loss: 0.49243115669205073
  batch 43 loss: 0.4924021134542864
  batch 44 loss: 0.49272567372430454
  batch 45 loss: 0.4926441093285879
  batch 46 loss: 0.49253728078759235
  batch 47 loss: 0.49248230140259924
  batch 48 loss: 0.49191046444078285
  batch 49 loss: 0.4913228294070886
  batch 50 loss: 0.49138118505477907
  batch 51 loss: 0.49034300972433653
  batch 52 loss: 0.4905800773547246
  batch 53 loss: 0.49100828620622744
  batch 54 loss: 0.4912711977958679
  batch 55 loss: 0.49058283892544835
  batch 56 loss: 0.4898606442979404
  batch 57 loss: 0.4895761964613931
  batch 58 loss: 0.4902957523691243
  batch 59 loss: 0.49007918774071385
  batch 60 loss: 0.4897340267896652
  batch 61 loss: 0.48957553847891383
  batch 62 loss: 0.49019212876596757
  batch 63 loss: 0.49012369059381033
  batch 64 loss: 0.4904404659755528
  batch 65 loss: 0.4901566161559178
  batch 66 loss: 0.4901240255796548
  batch 67 loss: 0.49038400979184393
  batch 68 loss: 0.4906056212151752
  batch 69 loss: 0.4906162472738736
  batch 70 loss: 0.49040312085832866
  batch 71 loss: 0.49062823241865133
  batch 72 loss: 0.4905295670032501
  batch 73 loss: 0.4906085909229435
  batch 74 loss: 0.4904989692810419
  batch 75 loss: 0.49038541396458946
  batch 76 loss: 0.490815793997363
  batch 77 loss: 0.4905948182205101
  batch 78 loss: 0.4901349303814081
  batch 79 loss: 0.4906749434863465
  batch 80 loss: 0.49049969129264354
  batch 81 loss: 0.4904991638513259
  batch 82 loss: 0.4909610937281353
  batch 83 loss: 0.49115286534091074
  batch 84 loss: 0.49144491908096133
  batch 85 loss: 0.4913771208594827
  batch 86 loss: 0.49197679619456447
  batch 87 loss: 0.4921748638153076
  batch 88 loss: 0.49166358600963245
  batch 89 loss: 0.4916720772057437
  batch 90 loss: 0.49163127938906354
  batch 91 loss: 0.4917449970821758
  batch 92 loss: 0.4915616308217463
  batch 93 loss: 0.4914674524978925
  batch 94 loss: 0.4919542388079014
  batch 95 loss: 0.49210629933758787
  batch 96 loss: 0.4922461146488786
  batch 97 loss: 0.49246984996746496
  batch 98 loss: 0.4929262080362865
  batch 99 loss: 0.4927425261097725
  batch 100 loss: 0.49317950516939163
  batch 101 loss: 0.49303096975430405
  batch 102 loss: 0.4928968960747999
  batch 103 loss: 0.49305816153878146
  batch 104 loss: 0.49307893073329556
  batch 105 loss: 0.49275120865731015
  batch 106 loss: 0.49302598749691584
  batch 107 loss: 0.49289408103327886
  batch 108 loss: 0.49287761057968493
  batch 109 loss: 0.49321403716682294
  batch 110 loss: 0.49360261153091084
  batch 111 loss: 0.4936392291172131
  batch 112 loss: 0.4935724705989872
  batch 113 loss: 0.4937995057717889
  batch 114 loss: 0.49427125720601334
  batch 115 loss: 0.4940260718698087
  batch 116 loss: 0.49405623946724264
  batch 117 loss: 0.4939932565913241
  batch 118 loss: 0.49410616012953096
  batch 119 loss: 0.4940118980007011
  batch 120 loss: 0.4938132551809152
  batch 121 loss: 0.4936111478273534
  batch 122 loss: 0.4933799632260057
  batch 123 loss: 0.4931200575537798
  batch 124 loss: 0.49334669569807665
  batch 125 loss: 0.4930964367389679
  batch 126 loss: 0.49286456902821857
  batch 127 loss: 0.4932728053077938
  batch 128 loss: 0.492982768220827
  batch 129 loss: 0.49279027669004694
  batch 130 loss: 0.4928216198315987
  batch 131 loss: 0.4930201875799485
  batch 132 loss: 0.49332536553794687
  batch 133 loss: 0.49337931257441525
  batch 134 loss: 0.4933965083823275
  batch 135 loss: 0.49354915376062747
  batch 136 loss: 0.4933387012604405
  batch 137 loss: 0.4934423937849755
  batch 138 loss: 0.4939462410798971
  batch 139 loss: 0.49392440486297334
  batch 140 loss: 0.4937119709593909
  batch 141 loss: 0.49389713241698896
  batch 142 loss: 0.4937487721023425
  batch 143 loss: 0.4934934381838445
  batch 144 loss: 0.49361539011200267
  batch 145 loss: 0.49340819264280383
  batch 146 loss: 0.49323834356379836
  batch 147 loss: 0.4933895924869849
  batch 148 loss: 0.49345050772299637
  batch 149 loss: 0.493296852247827
  batch 150 loss: 0.49295672317345934
  batch 151 loss: 0.492782875796817
  batch 152 loss: 0.49307775222941447
  batch 153 loss: 0.49291272451675017
  batch 154 loss: 0.49294070667260653
  batch 155 loss: 0.49295826400479964
  batch 156 loss: 0.4929392601435001
  batch 157 loss: 0.49326939719497775
  batch 158 loss: 0.49314937259577496
  batch 159 loss: 0.49316922823588055
  batch 160 loss: 0.49327813982963564
  batch 161 loss: 0.49335880716394936
  batch 162 loss: 0.4933344368581419
  batch 163 loss: 0.4931195813454002
  batch 164 loss: 0.4931730838810525
  batch 165 loss: 0.49304042061169945
  batch 166 loss: 0.49319947322449054
  batch 167 loss: 0.49317101536396735
  batch 168 loss: 0.49338546129209654
  batch 169 loss: 0.4931994371512938
  batch 170 loss: 0.4931018762728747
  batch 171 loss: 0.4929744054002371
  batch 172 loss: 0.49305699245874274
  batch 173 loss: 0.4928982151037007
  batch 174 loss: 0.4928728211885211
  batch 175 loss: 0.4927888185637338
  batch 176 loss: 0.49280100417408074
  batch 177 loss: 0.49259888688049747
  batch 178 loss: 0.4926429575078943
  batch 179 loss: 0.4926274933295543
  batch 180 loss: 0.49265551765759785
  batch 181 loss: 0.49268378095073595
  batch 182 loss: 0.4927082577577004
  batch 183 loss: 0.49271651043917963
  batch 184 loss: 0.49258359278673713
  batch 185 loss: 0.49268379324191325
  batch 186 loss: 0.4926965449766446
  batch 187 loss: 0.4926705840118429
  batch 188 loss: 0.49266199276168293
  batch 189 loss: 0.492549504079516
  batch 190 loss: 0.49247916356513377
  batch 191 loss: 0.4924875798961879
  batch 192 loss: 0.4923937185667455
  batch 193 loss: 0.49241511160845586
  batch 194 loss: 0.49243488477677416
  batch 195 loss: 0.4926835625599592
  batch 196 loss: 0.4925863501064631
  batch 197 loss: 0.49261385126767426
  batch 198 loss: 0.4927884898703508
  batch 199 loss: 0.4926369751817617
  batch 200 loss: 0.4926123821735382
  batch 201 loss: 0.4927460619466222
  batch 202 loss: 0.4927736193236738
  batch 203 loss: 0.49290121218253824
  batch 204 loss: 0.4928179614099802
  batch 205 loss: 0.49288523080872326
  batch 206 loss: 0.4929732668747022
  batch 207 loss: 0.4929092727997453
  batch 208 loss: 0.4928599495727282
  batch 209 loss: 0.49279644743107154
  batch 210 loss: 0.4928224853106907
  batch 211 loss: 0.4928471217223253
  batch 212 loss: 0.4929171730324907
  batch 213 loss: 0.49291537709079436
  batch 214 loss: 0.4928642149283507
  batch 215 loss: 0.49266937749330386
  batch 216 loss: 0.4925357773900032
  batch 217 loss: 0.4924934047707764
  batch 218 loss: 0.4924707645123158
  batch 219 loss: 0.4923619950470859
  batch 220 loss: 0.49237268282608554
  batch 221 loss: 0.49249547113120823
  batch 222 loss: 0.4926195170159812
  batch 223 loss: 0.49265526722899466
  batch 224 loss: 0.49258799225624117
  batch 225 loss: 0.4926291615433163
  batch 226 loss: 0.49264999551583183
  batch 227 loss: 0.49243441447287406
  batch 228 loss: 0.49253716071446735
  batch 229 loss: 0.4925337847663846
  batch 230 loss: 0.49253253560999166
  batch 231 loss: 0.49246678685213063
  batch 232 loss: 0.4923407557452547
  batch 233 loss: 0.4922890643960928
  batch 234 loss: 0.49224431252377665
  batch 235 loss: 0.49234928818459206
  batch 236 loss: 0.4922754542302277
  batch 237 loss: 0.4923927004327251
  batch 238 loss: 0.492408564862083
  batch 239 loss: 0.4922555607731871
  batch 240 loss: 0.492411778618892
  batch 241 loss: 0.492527781927734
  batch 242 loss: 0.4924339899593148
  batch 243 loss: 0.49245526307404286
  batch 244 loss: 0.49248841807979055
  batch 245 loss: 0.4926419590200697
  batch 246 loss: 0.49268340979649766
  batch 247 loss: 0.49270035573828075
  batch 248 loss: 0.49282034126020247
  batch 249 loss: 0.4928745069656985
  batch 250 loss: 0.4929361107349396
  batch 251 loss: 0.4929511678883754
  batch 252 loss: 0.4930242199509863
  batch 253 loss: 0.4930379211667027
  batch 254 loss: 0.4930445779496291
  batch 255 loss: 0.4931172836060618
  batch 256 loss: 0.4930624538101256
  batch 257 loss: 0.49318423948399287
  batch 258 loss: 0.4931392512580221
  batch 259 loss: 0.4930757608653035
  batch 260 loss: 0.49302537968525517
  batch 261 loss: 0.49317686927729637
  batch 262 loss: 0.4931042863212469
  batch 263 loss: 0.49315288832885684
  batch 264 loss: 0.49309947590033215
  batch 265 loss: 0.4930617461789329
  batch 266 loss: 0.49310348031664253
  batch 267 loss: 0.493153516831023
  batch 268 loss: 0.49306750330907195
  batch 269 loss: 0.4930876055836234
  batch 270 loss: 0.4931748322866581
  batch 271 loss: 0.4931236926699916
  batch 272 loss: 0.49314075105768795
  batch 273 loss: 0.493099991327677
  batch 274 loss: 0.4929905569683896
  batch 275 loss: 0.49308591506697913
  batch 276 loss: 0.4932041104505028
  batch 277 loss: 0.49333043143637345
  batch 278 loss: 0.49318935684591747
  batch 279 loss: 0.49324304175205985
  batch 280 loss: 0.49313564098307067
  batch 281 loss: 0.49308145332590964
  batch 282 loss: 0.4929962594669761
  batch 283 loss: 0.49287607886765955
  batch 284 loss: 0.49292400720673546
  batch 285 loss: 0.4928686887548681
  batch 286 loss: 0.49282650920477783
  batch 287 loss: 0.49286051795457714
  batch 288 loss: 0.49262756823251647
  batch 289 loss: 0.49273884141733904
  batch 290 loss: 0.492640378146336
  batch 291 loss: 0.49266242765888724
  batch 292 loss: 0.49273191402627997
  batch 293 loss: 0.4927900554580493
  batch 294 loss: 0.4927737882145408
  batch 295 loss: 0.49293676240969514
  batch 296 loss: 0.49299970863235965
  batch 297 loss: 0.4931303996229011
  batch 298 loss: 0.4931958404763433
  batch 299 loss: 0.4932293105484251
  batch 300 loss: 0.4933068997661273
  batch 301 loss: 0.4933932068141988
  batch 302 loss: 0.493449575557614
  batch 303 loss: 0.4935506850776106
  batch 304 loss: 0.49352342351094675
  batch 305 loss: 0.4933517093541192
  batch 306 loss: 0.49338186673479145
  batch 307 loss: 0.4933765354878739
  batch 308 loss: 0.4933439810554703
  batch 309 loss: 0.4933477535988521
  batch 310 loss: 0.4932913134174962
  batch 311 loss: 0.4933477074770299
  batch 312 loss: 0.4934575584454414
  batch 313 loss: 0.4934687777258718
  batch 314 loss: 0.4934995283556592
  batch 315 loss: 0.49352690369363816
  batch 316 loss: 0.49341614610409434
  batch 317 loss: 0.4934384647039961
  batch 318 loss: 0.49341278734072197
  batch 319 loss: 0.4933143399165342
  batch 320 loss: 0.4933065160177648
  batch 321 loss: 0.49335708787136734
  batch 322 loss: 0.4933868234757311
  batch 323 loss: 0.49334742954640937
  batch 324 loss: 0.4932389207828192
  batch 325 loss: 0.49316630400144135
  batch 326 loss: 0.49312586332757047
  batch 327 loss: 0.49311756404168017
  batch 328 loss: 0.4929879287757525
  batch 329 loss: 0.4931265023341657
  batch 330 loss: 0.4930607894153306
  batch 331 loss: 0.4929843236132331
  batch 332 loss: 0.49300053832401713
  batch 333 loss: 0.49299100614166835
  batch 334 loss: 0.4928658924952239
  batch 335 loss: 0.4927904355881819
  batch 336 loss: 0.4927032298098008
  batch 337 loss: 0.4926327467849064
  batch 338 loss: 0.4925505214717967
  batch 339 loss: 0.4926314142073854
  batch 340 loss: 0.49259599596261977
  batch 341 loss: 0.4926357682674162
  batch 342 loss: 0.4925409578091917
  batch 343 loss: 0.492466766180867
  batch 344 loss: 0.4924751684762711
  batch 345 loss: 0.4926543016364609
  batch 346 loss: 0.49258527934895774
  batch 347 loss: 0.49262136341171925
  batch 348 loss: 0.49265535175800323
  batch 349 loss: 0.4925902732634613
  batch 350 loss: 0.4926134088209697
  batch 351 loss: 0.492591957166324
  batch 352 loss: 0.4927161619575186
  batch 353 loss: 0.49269947789546115
  batch 354 loss: 0.49273742440730167
  batch 355 loss: 0.492840877553107
  batch 356 loss: 0.49278140026197004
  batch 357 loss: 0.49276205630195574
  batch 358 loss: 0.49282635981477174
  batch 359 loss: 0.49284917854997107
  batch 360 loss: 0.49292220663693215
  batch 361 loss: 0.49295089441323214
  batch 362 loss: 0.49282859973815263
  batch 363 loss: 0.4927824289017144
  batch 364 loss: 0.4926717588370973
  batch 365 loss: 0.49271901004934965
  batch 366 loss: 0.49263046486455886
  batch 367 loss: 0.4926314641409414
  batch 368 loss: 0.4926284090008425
  batch 369 loss: 0.4926377416949285
  batch 370 loss: 0.4926992403494345
  batch 371 loss: 0.49281465011144265
  batch 372 loss: 0.4927033567300407
  batch 373 loss: 0.49267818724821466
  batch 374 loss: 0.49261167262964706
  batch 375 loss: 0.4927144954999288
  batch 376 loss: 0.4927686191302665
  batch 377 loss: 0.4927227392753176
  batch 378 loss: 0.49265601158772826
  batch 379 loss: 0.4926885471809508
  batch 380 loss: 0.4928025639370868
  batch 381 loss: 0.4927260841284524
  batch 382 loss: 0.4925546650799157
  batch 383 loss: 0.4925812608890683
  batch 384 loss: 0.49251074250787497
  batch 385 loss: 0.4926130164753307
  batch 386 loss: 0.49255326336220756
  batch 387 loss: 0.492556355643334
  batch 388 loss: 0.4925478849675238
  batch 389 loss: 0.492629089744661
  batch 390 loss: 0.49267300909910444
  batch 391 loss: 0.49265281326325655
  batch 392 loss: 0.4926931995670406
  batch 393 loss: 0.4928341452553679
  batch 394 loss: 0.49283242369363756
  batch 395 loss: 0.49292643847344797
  batch 396 loss: 0.4929863943746596
  batch 397 loss: 0.49293967045524556
  batch 398 loss: 0.4929364505574931
  batch 399 loss: 0.4930263075762823
  batch 400 loss: 0.4930201210826635
  batch 401 loss: 0.49296518216406615
  batch 402 loss: 0.49302368318263573
  batch 403 loss: 0.4929565664556423
  batch 404 loss: 0.4929494446899631
  batch 405 loss: 0.4929611090524697
  batch 406 loss: 0.49307491560581285
  batch 407 loss: 0.4931255585584945
  batch 408 loss: 0.4931861928426752
  batch 409 loss: 0.49320168024461836
  batch 410 loss: 0.49323526250153055
  batch 411 loss: 0.4932183625489256
  batch 412 loss: 0.4931972295913881
  batch 413 loss: 0.4932064414745959
  batch 414 loss: 0.49321406352635166
  batch 415 loss: 0.4931739624006202
  batch 416 loss: 0.49317203634060347
  batch 417 loss: 0.49315980169698775
  batch 418 loss: 0.4931670733188328
  batch 419 loss: 0.4931530285991177
  batch 420 loss: 0.4931679130310104
  batch 421 loss: 0.49317593982270663
  batch 422 loss: 0.4932794370357459
  batch 423 loss: 0.493339305510194
  batch 424 loss: 0.4933750994925229
  batch 425 loss: 0.49342093846377205
  batch 426 loss: 0.4934026393252359
  batch 427 loss: 0.49340666547871304
  batch 428 loss: 0.49329249832396194
  batch 429 loss: 0.4932422223207834
  batch 430 loss: 0.4932454448106677
  batch 431 loss: 0.49344086308213786
  batch 432 loss: 0.49348386590955434
  batch 433 loss: 0.49340402453656007
  batch 434 loss: 0.49348037562886693
  batch 435 loss: 0.493461738989271
  batch 436 loss: 0.49346508024209135
  batch 437 loss: 0.4935103652815524
  batch 438 loss: 0.4935946242041784
  batch 439 loss: 0.49359121429893044
  batch 440 loss: 0.4936437553302808
  batch 441 loss: 0.4936296199860216
  batch 442 loss: 0.49359431303194745
  batch 443 loss: 0.49360028198556494
  batch 444 loss: 0.4935014690901782
  batch 445 loss: 0.4935324541638407
  batch 446 loss: 0.493487324415301
  batch 447 loss: 0.49347961642331456
  batch 448 loss: 0.49357938806393314
  batch 449 loss: 0.4936751763114419
  batch 450 loss: 0.4937073587046729
  batch 451 loss: 0.49374902314463104
  batch 452 loss: 0.4937642211407687
  batch 453 loss: 0.49377033897319905
  batch 454 loss: 0.49380757131240444
  batch 455 loss: 0.49384661611619884
  batch 456 loss: 0.4938459913981588
  batch 457 loss: 0.49388336717952
  batch 458 loss: 0.49389021515065407
  batch 459 loss: 0.4939047442931755
  batch 460 loss: 0.49400547840025116
  batch 461 loss: 0.49401781874468426
  batch 462 loss: 0.493974365584262
  batch 463 loss: 0.49396059412678167
  batch 464 loss: 0.4939974945937765
  batch 465 loss: 0.49386224682613084
  batch 466 loss: 0.49374567950743975
  batch 467 loss: 0.4937548057935988
  batch 468 loss: 0.49370570251574886
  batch 469 loss: 0.4937229610201138
  batch 470 loss: 0.49367124317808353
  batch 471 loss: 0.49369203405268886
  batch 472 loss: 0.4936872459948063
LOSS train 0.4936872459948063 valid 0.3281959593296051
LOSS train 0.4936872459948063 valid 0.322703555226326
LOSS train 0.4936872459948063 valid 0.3358209232489268
LOSS train 0.4936872459948063 valid 0.3336082175374031
LOSS train 0.4936872459948063 valid 0.33099849820137023
LOSS train 0.4936872459948063 valid 0.33259401222070056
LOSS train 0.4936872459948063 valid 0.3306753252233778
LOSS train 0.4936872459948063 valid 0.3311035931110382
LOSS train 0.4936872459948063 valid 0.3276267382833693
LOSS train 0.4936872459948063 valid 0.3298261076211929
LOSS train 0.4936872459948063 valid 0.3325446600263769
LOSS train 0.4936872459948063 valid 0.3317537009716034
LOSS train 0.4936872459948063 valid 0.33329145266459537
LOSS train 0.4936872459948063 valid 0.3335286123411996
LOSS train 0.4936872459948063 valid 0.3320104976495107
LOSS train 0.4936872459948063 valid 0.3341955505311489
LOSS train 0.4936872459948063 valid 0.3366244540495031
LOSS train 0.4936872459948063 valid 0.3368900054030948
LOSS train 0.4936872459948063 valid 0.33762525414165695
LOSS train 0.4936872459948063 valid 0.3395042583346367
LOSS train 0.4936872459948063 valid 0.33879222188677105
LOSS train 0.4936872459948063 valid 0.3366689763285897
LOSS train 0.4936872459948063 valid 0.3370619040468465
LOSS train 0.4936872459948063 valid 0.33633984501163167
LOSS train 0.4936872459948063 valid 0.33567214131355283
LOSS train 0.4936872459948063 valid 0.33515216639408696
LOSS train 0.4936872459948063 valid 0.33477043001740064
LOSS train 0.4936872459948063 valid 0.33505851881844656
LOSS train 0.4936872459948063 valid 0.3348895671038792
LOSS train 0.4936872459948063 valid 0.33574002583821616
LOSS train 0.4936872459948063 valid 0.3372337587418095
LOSS train 0.4936872459948063 valid 0.33715023566037416
LOSS train 0.4936872459948063 valid 0.33802192590453406
LOSS train 0.4936872459948063 valid 0.3373964455197839
LOSS train 0.4936872459948063 valid 0.3381558392729078
LOSS train 0.4936872459948063 valid 0.33813148819737965
LOSS train 0.4936872459948063 valid 0.3386189236834243
LOSS train 0.4936872459948063 valid 0.33945737622286143
LOSS train 0.4936872459948063 valid 0.33923109601705503
LOSS train 0.4936872459948063 valid 0.3403960332274437
LOSS train 0.4936872459948063 valid 0.34043028296493905
LOSS train 0.4936872459948063 valid 0.34167714629854473
LOSS train 0.4936872459948063 valid 0.34163456739381304
LOSS train 0.4936872459948063 valid 0.34186222607439215
LOSS train 0.4936872459948063 valid 0.3419057812955644
LOSS train 0.4936872459948063 valid 0.34235738282618317
LOSS train 0.4936872459948063 valid 0.3419157342707857
LOSS train 0.4936872459948063 valid 0.34230442593495053
LOSS train 0.4936872459948063 valid 0.34276507581983295
LOSS train 0.4936872459948063 valid 0.34220982670783995
LOSS train 0.4936872459948063 valid 0.34273305126264986
LOSS train 0.4936872459948063 valid 0.3424902672951038
LOSS train 0.4936872459948063 valid 0.341956338230169
LOSS train 0.4936872459948063 valid 0.3419773987045995
LOSS train 0.4936872459948063 valid 0.34168529510498047
LOSS train 0.4936872459948063 valid 0.3415327269051756
LOSS train 0.4936872459948063 valid 0.3413560594383039
LOSS train 0.4936872459948063 valid 0.34098397195339203
LOSS train 0.4936872459948063 valid 0.3416038453578949
LOSS train 0.4936872459948063 valid 0.3410598595937093
LOSS train 0.4936872459948063 valid 0.34004043702219355
LOSS train 0.4936872459948063 valid 0.3409924752289249
LOSS train 0.4936872459948063 valid 0.34121419796867974
LOSS train 0.4936872459948063 valid 0.3415886275470257
LOSS train 0.4936872459948063 valid 0.3416404384833116
LOSS train 0.4936872459948063 valid 0.34166869972691394
LOSS train 0.4936872459948063 valid 0.3411580164041092
LOSS train 0.4936872459948063 valid 0.34068844686536226
LOSS train 0.4936872459948063 valid 0.3405572003212528
LOSS train 0.4936872459948063 valid 0.3402267234666007
LOSS train 0.4936872459948063 valid 0.34015670124913605
LOSS train 0.4936872459948063 valid 0.3400908046298557
LOSS train 0.4936872459948063 valid 0.34017146654324987
LOSS train 0.4936872459948063 valid 0.3401136482889588
LOSS train 0.4936872459948063 valid 0.3395466792583466
LOSS train 0.4936872459948063 valid 0.33971934608722987
LOSS train 0.4936872459948063 valid 0.3395114452033848
LOSS train 0.4936872459948063 valid 0.3394300567033963
LOSS train 0.4936872459948063 valid 0.3392198708238481
LOSS train 0.4936872459948063 valid 0.33912023939192293
LOSS train 0.4936872459948063 valid 0.3388201380953377
LOSS train 0.4936872459948063 valid 0.3390513582200539
LOSS train 0.4936872459948063 valid 0.3388646754873804
LOSS train 0.4936872459948063 valid 0.33891664871147703
LOSS train 0.4936872459948063 valid 0.3389737613060895
LOSS train 0.4936872459948063 valid 0.33871510694193285
LOSS train 0.4936872459948063 valid 0.3385934442624278
LOSS train 0.4936872459948063 valid 0.3381243409080939
LOSS train 0.4936872459948063 valid 0.33845774511272986
LOSS train 0.4936872459948063 valid 0.3383371439245012
LOSS train 0.4936872459948063 valid 0.3381343948972094
LOSS train 0.4936872459948063 valid 0.3378342756110689
LOSS train 0.4936872459948063 valid 0.3372682457970035
LOSS train 0.4936872459948063 valid 0.3367799295389906
LOSS train 0.4936872459948063 valid 0.3365134380365673
LOSS train 0.4936872459948063 valid 0.33663129930694896
LOSS train 0.4936872459948063 valid 0.33695300276746454
LOSS train 0.4936872459948063 valid 0.3369443386184926
LOSS train 0.4936872459948063 valid 0.33702379284483014
LOSS train 0.4936872459948063 valid 0.33720170587301257
LOSS train 0.4936872459948063 valid 0.33736032483601336
LOSS train 0.4936872459948063 valid 0.3373501660192714
LOSS train 0.4936872459948063 valid 0.3378453092667663
LOSS train 0.4936872459948063 valid 0.33765005750151783
LOSS train 0.4936872459948063 valid 0.3375757186185746
LOSS train 0.4936872459948063 valid 0.33764678633437967
LOSS train 0.4936872459948063 valid 0.3374055239641778
LOSS train 0.4936872459948063 valid 0.33774069061985723
LOSS train 0.4936872459948063 valid 0.33785360832826805
LOSS train 0.4936872459948063 valid 0.33797664642333985
LOSS train 0.4936872459948063 valid 0.33795594497843906
LOSS train 0.4936872459948063 valid 0.337883466056415
LOSS train 0.4936872459948063 valid 0.33788767958109356
LOSS train 0.4936872459948063 valid 0.3376997826915038
LOSS train 0.4936872459948063 valid 0.33763310002244035
LOSS train 0.4936872459948063 valid 0.3376281325673235
LOSS train 0.4936872459948063 valid 0.337724959748423
LOSS train 0.4936872459948063 valid 0.3375642913377891
LOSS train 0.4936872459948063 valid 0.33737250561473753
LOSS train 0.4936872459948063 valid 0.33722730601827305
LOSS train 0.4936872459948063 valid 0.33709133287106663
LOSS train 0.4936872459948063 valid 0.33692054645937
LOSS train 0.4936872459948063 valid 0.33706594022308906
LOSS train 0.4936872459948063 valid 0.3373035060301904
LOSS train 0.4936872459948063 valid 0.3372382652759552
LOSS train 0.4936872459948063 valid 0.3370987427613092
LOSS train 0.4936872459948063 valid 0.3374917962419705
LOSS train 0.4936872459948063 valid 0.3375417608767748
LOSS train 0.4936872459948063 valid 0.3376649119133173
LOSS train 0.4936872459948063 valid 0.3374653641994183
LOSS train 0.4936872459948063 valid 0.3375112236911104
LOSS train 0.4936872459948063 valid 0.33746323079773877
LOSS train 0.4936872459948063 valid 0.3372716737869091
LOSS train 0.4936872459948063 valid 0.33740229281916545
LOSS train 0.4936872459948063 valid 0.33748805500842904
LOSS train 0.4936872459948063 valid 0.3374333611744292
LOSS train 0.4936872459948063 valid 0.33725885470418165
LOSS train 0.4936872459948063 valid 0.33720721563567285
LOSS train 0.4936872459948063 valid 0.3370933957237134
LOSS train 0.4936872459948063 valid 0.3372469806245395
LOSS train 0.4936872459948063 valid 0.337278054749712
LOSS train 0.4936872459948063 valid 0.3375383458087142
LOSS train 0.4936872459948063 valid 0.33726139689658907
LOSS train 0.4936872459948063 valid 0.3372944297475947
LOSS train 0.4936872459948063 valid 0.3372478133645551
LOSS train 0.4936872459948063 valid 0.33751526148351907
LOSS train 0.4936872459948063 valid 0.33715236430265466
LOSS train 0.4936872459948063 valid 0.33738982435819265
LOSS train 0.4936872459948063 valid 0.337447436863944
LOSS train 0.4936872459948063 valid 0.3374792575836182
LOSS train 0.4936872459948063 valid 0.337553960203335
LOSS train 0.4936872459948063 valid 0.33736417442560196
LOSS train 0.4936872459948063 valid 0.3376175617080888
LOSS train 0.4936872459948063 valid 0.33759629494184024
LOSS train 0.4936872459948063 valid 0.33764745996844386
LOSS train 0.4936872459948063 valid 0.3379270774431718
LOSS train 0.4936872459948063 valid 0.33790905612289523
LOSS train 0.4936872459948063 valid 0.3378921556699125
LOSS train 0.4936872459948063 valid 0.3376595615965765
LOSS train 0.4936872459948063 valid 0.33770586010068654
LOSS train 0.4936872459948063 valid 0.33750984739072576
LOSS train 0.4936872459948063 valid 0.33722484626887755
LOSS train 0.4936872459948063 valid 0.33717749820896453
LOSS train 0.4936872459948063 valid 0.337078988733815
LOSS train 0.4936872459948063 valid 0.33698161894624884
LOSS train 0.4936872459948063 valid 0.3368626633681447
LOSS train 0.4936872459948063 valid 0.33688869251462517
LOSS train 0.4936872459948063 valid 0.337017357172001
LOSS train 0.4936872459948063 valid 0.3371142706222083
LOSS train 0.4936872459948063 valid 0.33744892495519974
LOSS train 0.4936872459948063 valid 0.33739222786579914
LOSS train 0.4936872459948063 valid 0.33742390538370887
LOSS train 0.4936872459948063 valid 0.3375364285328485
LOSS train 0.4936872459948063 valid 0.3374837278977208
LOSS train 0.4936872459948063 valid 0.33751577496528623
LOSS train 0.4936872459948063 valid 0.3373935093933886
LOSS train 0.4936872459948063 valid 0.3376164382460427
LOSS train 0.4936872459948063 valid 0.33776157441433896
LOSS train 0.4936872459948063 valid 0.3376388742937056
LOSS train 0.4936872459948063 valid 0.3377326352728738
LOSS train 0.4936872459948063 valid 0.33773371330282304
LOSS train 0.4936872459948063 valid 0.33782776977334705
LOSS train 0.4936872459948063 valid 0.3377120012794036
LOSS train 0.4936872459948063 valid 0.33787881226643274
LOSS train 0.4936872459948063 valid 0.337816163172593
LOSS train 0.4936872459948063 valid 0.3378851831920685
LOSS train 0.4936872459948063 valid 0.3378667386776623
LOSS train 0.4936872459948063 valid 0.3378324922412
LOSS train 0.4936872459948063 valid 0.33781378247119764
LOSS train 0.4936872459948063 valid 0.337685795363627
LOSS train 0.4936872459948063 valid 0.3378411823230264
LOSS train 0.4936872459948063 valid 0.337906155269593
LOSS train 0.4936872459948063 valid 0.3378301542348812
LOSS train 0.4936872459948063 valid 0.3376810650542839
LOSS train 0.4936872459948063 valid 0.3377052389658414
LOSS train 0.4936872459948063 valid 0.33775679463026476
LOSS train 0.4936872459948063 valid 0.337908234844353
LOSS train 0.4936872459948063 valid 0.3379293419797011
LOSS train 0.4936872459948063 valid 0.3379175300574183
LOSS train 0.4936872459948063 valid 0.33785922065377233
LOSS train 0.4936872459948063 valid 0.33769521339615777
LOSS train 0.4936872459948063 valid 0.3377948624662834
LOSS train 0.4936872459948063 valid 0.3376619401823711
LOSS train 0.4936872459948063 valid 0.337621032315142
LOSS train 0.4936872459948063 valid 0.3376294828042751
LOSS train 0.4936872459948063 valid 0.3375329401307893
LOSS train 0.4936872459948063 valid 0.3376814890023015
LOSS train 0.4936872459948063 valid 0.3377090036295928
LOSS train 0.4936872459948063 valid 0.33759403656544296
LOSS train 0.4936872459948063 valid 0.3376831318650927
LOSS train 0.4936872459948063 valid 0.3376899103135294
LOSS train 0.4936872459948063 valid 0.33773391609484293
LOSS train 0.4936872459948063 valid 0.3377869578314499
LOSS train 0.4936872459948063 valid 0.33775113328037976
LOSS train 0.4936872459948063 valid 0.3377823714600053
LOSS train 0.4936872459948063 valid 0.33784444712930256
LOSS train 0.4936872459948063 valid 0.3378802672509224
LOSS train 0.4936872459948063 valid 0.3379580338887118
LOSS train 0.4936872459948063 valid 0.3379655808346457
LOSS train 0.4936872459948063 valid 0.3381324289874597
LOSS train 0.4936872459948063 valid 0.33827852595985203
LOSS train 0.4936872459948063 valid 0.33826158913943144
LOSS train 0.4936872459948063 valid 0.33825346292936215
LOSS train 0.4936872459948063 valid 0.33828737520213636
LOSS train 0.4936872459948063 valid 0.3383395781781938
LOSS train 0.4936872459948063 valid 0.33832544470782827
LOSS train 0.4936872459948063 valid 0.33840338498485245
LOSS train 0.4936872459948063 valid 0.3384329055746396
LOSS train 0.4936872459948063 valid 0.3385321090575389
LOSS train 0.4936872459948063 valid 0.3386252899532733
LOSS train 0.4936872459948063 valid 0.33865744585082647
LOSS train 0.4936872459948063 valid 0.3386717586424844
LOSS train 0.4936872459948063 valid 0.3385816925073386
LOSS train 0.4936872459948063 valid 0.33853158354759216
LOSS train 0.4936872459948063 valid 0.3386884442035188
LOSS train 0.4936872459948063 valid 0.3386234331686618
LOSS train 0.4936872459948063 valid 0.33852113638749104
LOSS train 0.4936872459948063 valid 0.3384958091152816
LOSS train 0.4936872459948063 valid 0.33835660476066076
LOSS train 0.4936872459948063 valid 0.3382634541640679
LOSS train 0.4936872459948063 valid 0.3384577573829667
LOSS train 0.4936872459948063 valid 0.3383883666401067
LOSS train 0.4936872459948063 valid 0.3383810565550141
LOSS train 0.4936872459948063 valid 0.3384642951556894
LOSS train 0.4936872459948063 valid 0.3384940758043406
LOSS train 0.4936872459948063 valid 0.33847804755214755
LOSS train 0.4936872459948063 valid 0.3385051656589817
LOSS train 0.4936872459948063 valid 0.3384969004940602
LOSS train 0.4936872459948063 valid 0.33852396576280097
LOSS train 0.4936872459948063 valid 0.3387207546234131
LOSS train 0.4936872459948063 valid 0.33873617007912865
LOSS train 0.4936872459948063 valid 0.3389078492210025
LOSS train 0.4936872459948063 valid 0.3388316114193837
LOSS train 0.4936872459948063 valid 0.3389899943053253
LOSS train 0.4936872459948063 valid 0.33898407372773864
LOSS train 0.4936872459948063 valid 0.33896569604985416
LOSS train 0.4936872459948063 valid 0.3389325661418039
LOSS train 0.4936872459948063 valid 0.3389985637609349
LOSS train 0.4936872459948063 valid 0.3389803690109474
LOSS train 0.4936872459948063 valid 0.33883583488372654
LOSS train 0.4936872459948063 valid 0.3388483220590029
LOSS train 0.4936872459948063 valid 0.338781776546522
LOSS train 0.4936872459948063 valid 0.3387847348991002
LOSS train 0.4936872459948063 valid 0.3387394008988684
LOSS train 0.4936872459948063 valid 0.3387364442618388
LOSS train 0.4936872459948063 valid 0.3388162406539558
LOSS train 0.4936872459948063 valid 0.3389665149570851
LOSS train 0.4936872459948063 valid 0.3390156384279479
LOSS train 0.4936872459948063 valid 0.3392361677269067
LOSS train 0.4936872459948063 valid 0.3391820899866245
LOSS train 0.4936872459948063 valid 0.33932479754145295
LOSS train 0.4936872459948063 valid 0.33935864587478776
LOSS train 0.4936872459948063 valid 0.3393728983052921
LOSS train 0.4936872459948063 valid 0.3393519054146579
LOSS train 0.4936872459948063 valid 0.3392713514241305
LOSS train 0.4936872459948063 valid 0.3392343062205591
LOSS train 0.4936872459948063 valid 0.33929881173781107
LOSS train 0.4936872459948063 valid 0.3392440375449846
LOSS train 0.4936872459948063 valid 0.3392777469636719
LOSS train 0.4936872459948063 valid 0.3391805279467787
LOSS train 0.4936872459948063 valid 0.33905025489389684
LOSS train 0.4936872459948063 valid 0.33900672081091726
LOSS train 0.4936872459948063 valid 0.33903209828235237
LOSS train 0.4936872459948063 valid 0.339081664215511
LOSS train 0.4936872459948063 valid 0.33905671364382695
LOSS train 0.4936872459948063 valid 0.3389798641413242
LOSS train 0.4936872459948063 valid 0.33901121630901243
LOSS train 0.4936872459948063 valid 0.3389619927232464
LOSS train 0.4936872459948063 valid 0.3389901074364936
LOSS train 0.4936872459948063 valid 0.3389894431007319
LOSS train 0.4936872459948063 valid 0.3388661651062392
LOSS train 0.4936872459948063 valid 0.3389034031392777
LOSS train 0.4936872459948063 valid 0.33882770715313154
LOSS train 0.4936872459948063 valid 0.33888259976088597
LOSS train 0.4936872459948063 valid 0.3389820154440605
LOSS train 0.4936872459948063 valid 0.3389169868786593
LOSS train 0.4936872459948063 valid 0.33893178659256057
LOSS train 0.4936872459948063 valid 0.33886009864759126
LOSS train 0.4936872459948063 valid 0.33892690447660595
LOSS train 0.4936872459948063 valid 0.33899219741423925
LOSS train 0.4936872459948063 valid 0.3389846049867991
LOSS train 0.4936872459948063 valid 0.3388796686534061
LOSS train 0.4936872459948063 valid 0.3388317844065109
LOSS train 0.4936872459948063 valid 0.3388775705702995
LOSS train 0.4936872459948063 valid 0.33885051197692995
LOSS train 0.4936872459948063 valid 0.33886614071777443
LOSS train 0.4936872459948063 valid 0.33886107452917563
LOSS train 0.4936872459948063 valid 0.33881537548520346
LOSS train 0.4936872459948063 valid 0.3388525080719426
LOSS train 0.4936872459948063 valid 0.338840475870717
LOSS train 0.4936872459948063 valid 0.338814269883073
LOSS train 0.4936872459948063 valid 0.3388337838726166
LOSS train 0.4936872459948063 valid 0.338909648763486
LOSS train 0.4936872459948063 valid 0.33887390450687166
LOSS train 0.4936872459948063 valid 0.3388319758195726
LOSS train 0.4936872459948063 valid 0.3387273099226288
LOSS train 0.4936872459948063 valid 0.33876278695623957
LOSS train 0.4936872459948063 valid 0.33878009077512994
LOSS train 0.4936872459948063 valid 0.338728348476386
LOSS train 0.4936872459948063 valid 0.3386522583663464
LOSS train 0.4936872459948063 valid 0.3386792631535515
LOSS train 0.4936872459948063 valid 0.3386886297545818
LOSS train 0.4936872459948063 valid 0.3386651719502251
LOSS train 0.4936872459948063 valid 0.3386307875683278
LOSS train 0.4936872459948063 valid 0.3385942835074205
LOSS train 0.4936872459948063 valid 0.3386228269228906
LOSS train 0.4936872459948063 valid 0.338789667922787
LOSS train 0.4936872459948063 valid 0.3387720148737838
LOSS train 0.4936872459948063 valid 0.33877894780556117
LOSS train 0.4936872459948063 valid 0.3387197387940956
LOSS train 0.4936872459948063 valid 0.3386813900982145
LOSS train 0.4936872459948063 valid 0.3385809415794281
LOSS train 0.4936872459948063 valid 0.33858860326600865
LOSS train 0.4936872459948063 valid 0.33865372327987303
LOSS train 0.4936872459948063 valid 0.33862041635299794
LOSS train 0.4936872459948063 valid 0.33854555312011925
LOSS train 0.4936872459948063 valid 0.3385299676780531
LOSS train 0.4936872459948063 valid 0.33855660982738583
LOSS train 0.4936872459948063 valid 0.33849177397457897
LOSS train 0.4936872459948063 valid 0.3385073262102464
LOSS train 0.4936872459948063 valid 0.3383729512915234
LOSS train 0.4936872459948063 valid 0.3382747521003087
LOSS train 0.4936872459948063 valid 0.3382632945265089
LOSS train 0.4936872459948063 valid 0.33836673607313356
LOSS train 0.4936872459948063 valid 0.33840661238932956
LOSS train 0.4936872459948063 valid 0.33839472999117964
LOSS train 0.4936872459948063 valid 0.33834176044642755
LOSS train 0.4936872459948063 valid 0.3382709588983963
LOSS train 0.4936872459948063 valid 0.33828152899755787
LOSS train 0.4936872459948063 valid 0.3381926792008536
LOSS train 0.4936872459948063 valid 0.3381820616559086
LOSS train 0.4936872459948063 valid 0.3382110676982186
LOSS train 0.4936872459948063 valid 0.3382661403407456
LOSS train 0.4936872459948063 valid 0.338280277400367
LOSS train 0.4936872459948063 valid 0.3383105770802834
LOSS train 0.4936872459948063 valid 0.3383160232660476
LOSS train 0.4936872459948063 valid 0.3382966526750089
LOSS train 0.4936872459948063 valid 0.3382431860576129
LOSS train 0.4936872459948063 valid 0.33825369382635134
LOSS train 0.4936872459948063 valid 0.3382817977004581
LOSS train 0.4936872459948063 valid 0.33831765158024524
LOSS train 0.4936872459948063 valid 0.33842751128568177
LOSS train 0.4936872459948063 valid 0.338398928730941
LOSS train 0.4936872459948063 valid 0.33836564462591
LOSS train 0.4936872459948063 valid 0.3384219331284092
LOSS train 0.4936872459948063 valid 0.33836598401186896
LOSS train 0.4936872459948063 valid 0.338305510600841
LOSS train 0.4936872459948063 valid 0.3382969760214505
LOSS train 0.4936872459948063 valid 0.3382818527661042
Training bichrom
DEVICE = mps
####################
Total Parameters = 606342
Total Trainable Parameters = 1157
bimodal_network(
  (base_model): bichrom_seq(
    (conv1d): Conv1d(4, 256, kernel_size=(24,), stride=(1,))
    (relu): ReLU()
    (batchNorm1d): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (maxPool1d): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=True)
    (lstm): LSTM(256, 32, batch_first=True)
    (tanh): Tanh()
    (model_dense_repeat): Sequential(
      (0): Linear(in_features=32, out_features=512, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=512, out_features=512, bias=True)
      (4): ReLU()
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=512, out_features=512, bias=True)
      (7): ReLU()
      (8): Dropout(p=0.5, inplace=False)
    )
    (linear): Linear(in_features=512, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
  (linear): Linear(in_features=512, out_features=1, bias=True)
  (tanh): Tanh()
  (model): bichrom_chrom(
    (_reshape): _reshape()
    (conv1d): Conv1d(12, 15, kernel_size=(1,), stride=(1,), padding=valid)
    (relu): ReLU()
    (lstm): LSTM(15, 5, batch_first=True)
    (relu2): ReLU()
    (linear): Linear(in_features=5, out_features=1, bias=True)
    (tanh): Tanh()
  )
  (linear2): Linear(in_features=2, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
base_model.conv1d.weight False
base_model.conv1d.bias False
base_model.batchNorm1d.weight False
base_model.batchNorm1d.bias False
base_model.lstm.weight_ih_l0 False
base_model.lstm.weight_hh_l0 False
base_model.lstm.bias_ih_l0 False
base_model.lstm.bias_hh_l0 False
base_model.model_dense_repeat.0.weight False
base_model.model_dense_repeat.0.bias False
base_model.model_dense_repeat.3.weight False
base_model.model_dense_repeat.3.bias False
base_model.model_dense_repeat.6.weight False
base_model.model_dense_repeat.6.bias False
base_model.linear.weight False
base_model.linear.bias False
linear.weight True
linear.bias True
model.conv1d.weight True
model.conv1d.bias True
model.lstm.weight_ih_l0 True
model.lstm.weight_hh_l0 True
model.lstm.bias_ih_l0 True
model.lstm.bias_hh_l0 True
model.linear.weight True
model.linear.bias True
linear2.weight True
linear2.bias True
####################
Epochs = 15
EPOCH 1:
  batch 1 loss: 0.7544081807136536
####################
/Users/spg5958/research/bichrom/bichrom_pytorch/trainNN/train_sc.py:179: UserWarning: The operator 'aten::linalg_vector_norm' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1679382518396/work/aten/src/ATen/mps/MPSFallback.mm:12.)
  print("Base Model Weight Norm = "+str(torch.linalg.norm(torch.sub(w1,w2))))
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.7349044382572174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.7245693802833557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.7172428071498871
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.7074270486831665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.6986061334609985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.69140625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.6855798959732056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.6798056430286832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.6732965469360351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.6686134121634744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.664431224266688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.6586967569131118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.6536037283284324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.6498249014218648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.647215947508812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.6437152554007137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.6401331490940518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.6370985445223356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.6346307307481766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.6312907621974037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.6284974244507876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.6258317465367524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.6235069756706556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.6214823603630066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.6191420348790976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.617148984361578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.6145070897681373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.6127449890662884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.6111002286275228
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.6090980076020763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.6068282164633274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.604808969931169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.6028317458489362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.601173334462302
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.5991799765162997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.5972773819356352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.5952880304110678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.5939442821038075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.5923204526305199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.5906771843026324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.5889233960991814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.5877238026885099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.5859350277618929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.5845817433463203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.5821626562139263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.5808281327815766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.5790158392240604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.5776707280655297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.5762223774194717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.5748175470268025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.5733294005577381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.572433923775295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.5707615194497285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.5694839650934392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.5684543954474586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.5674283640426502
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.5657853854113611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.5645881370972778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.5632358695069949
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.5616429335758334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.5604490863700067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.5593122532443394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.5584469106979668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.5574232757091522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.5563764676000132
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.5549976972501669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.5540216828093809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.5531736465467922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.5524178956236158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.5515576365967871
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.5505236668719186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.5496464339021134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.5488179527424477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.5478829840819041
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.5474488684221318
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.5464726349750122
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.5456240685322346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.5451141327996797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.5444495420902967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.5438723199897342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.5431347423937263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.5423776428383517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.5414351746439934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.5409905731678009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.540081454917442
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.5393637148128159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.5388175086541609
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.5378398741229197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.5371206078264449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.5361529575599419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.5356349585496861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.5352725543642557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.5347705768777969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.5340239618953906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.5334012567376097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.5325681757681149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.5321243049538865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.5317203610232382
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.5312342426180839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.530599976235097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.5302214251429427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.5299681590020078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.5292262824682089
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.5287985949289231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.5281105572884938
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.5276997323348144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.5275214910507202
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.5270909967772458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.5268535825339231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.5262721964904854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.5256427664841924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.5249917035081745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.5246790618750087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.5239774056102918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.5234670603069765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.5231626181520967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.5225684036642818
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.5220690274438938
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.5216527126729489
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.5210394521882712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.520630415590083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.5204907222007348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.519916529617002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.5195616147518158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.519068285586342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.5185469466400897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.5184356060344726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.5181491675302964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.5178242752185235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.5172467798222112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.5169518957986976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.5167335908215746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.5163021583610506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.5158589391796677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.5155419426805833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.5152551966862087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.5148318675549134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.5148202551783417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.514386842080525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.513640174840359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.5134351595606602
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.5132018223509088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.5131197265452809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.5128252058193601
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.5123994517816256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.5119465313801149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.5117662573182905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.5114156015767347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.5110597523053487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.5108373855912922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.5104085693233892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.509895455603506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.5094254580024001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.5092245557615834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.5089586019898072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.5087149938580336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.5083542479367196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.5081504978848703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.5077228197827935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.5073311552868126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.5069572108763235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.5068318756080112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.506440397442841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.5059636011268154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.5056268170655492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.504984165380101
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.5048182910042149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.5046393056592998
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.5043331768582849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.5040933930734445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.5037052787320558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.5031725933097001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.5027847581211178
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.5024839149202619
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.5020857182416049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.5017040843344004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.5013457622086064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.5011104806508432
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.5007849834031529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.500621143131625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.5005372811804761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.5002924698949511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.5000344626605511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.49988493452201016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.49963716201243863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.49925344082760936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.49881308541653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4985299302787377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.49827464756212736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.49804200036987584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4978695212242504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.49759619949395173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.49736081063747406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4970893491537143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.49692052161815214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4968742814463407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4969288801605051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.496709260958523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.496525873541832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.49626539210181925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.49599455296993256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.49586436387353344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4956311839176159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.495414484564851
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.49524496495723724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.49498012517961326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4946383878302116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.49444210543586875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4942738095919291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4940106114505027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4938431148821453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4934725415818568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4931532552587652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.49296413784803345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.49269237355501566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4924602273697128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.49224119325843424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.49210274723022496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.49199929413470356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4917776559003338
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.49153391654426987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4913890081136216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.49135827605745624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4909884072674645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4906966328884648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.49048746931920495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.49024254671837153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.49015799216828493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4899964841811553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.48985744399941844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4896457678285138
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4894106866464083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4891937200584982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.489093298227229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.48901552441766705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.48897570975219146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.48891503557938487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.48879379408130086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4885914602627357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4884100823481548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.48819427549346417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4880958471769168
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4879248682104173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4877873359894266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.48764925868045994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4875129797921972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.48739648898763044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4871789899217077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4871080605983734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.48696582749545336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.48679316398643313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4865515193213587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4863386060309222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4862897292071698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4861328793922439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.48590763591606795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.48581667105818904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4857495406419614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4856228097127034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.48538690405787177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.48522871038840926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4850815624111959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.48485673399585666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48457584740980614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4844985200946492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4843050982621725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.48418634240307024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.48407705964652137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.48389157387945386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.48382757598623577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.483579807312173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.48340355312867916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4831502728001045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4828924781625921
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4827976967545523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4826105734071146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4823509287491119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.48231533693156364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.48206728845834734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4818988808321359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4816931590754935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4814643007917033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4812617131941755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.48116517255180763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.480998842449455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.48086690040830954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4807324367057946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.48072327327975767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.48067214417046517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4805599757281366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.48037066963845737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4802218093806973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.480056576988324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.47996293983217014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4797837890281871
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.47976267387971333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.47952619064974306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4793125421905199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.47918452342351275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.47909846060299793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.47887143097965923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4787006654558402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.47853430978169564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4782967757006161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4781188831415052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.47791490385897384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4776345311434238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4775644026720794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4774574342273897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4773328803551542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4772090976819014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.47711878634108523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.47688893746038913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4767545465439085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4766619103618815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.47652355259525286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.476353220219882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4762137645277484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4759983685798943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4758337532805505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4756416927398362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.47554364781999736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.47541615100186546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.47528301963439357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4751725348592536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4750119293683895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4748843772018828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4746559934413179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4745207945505778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.47445559231536266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4742477890777301
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4741531328575031
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4739476979492667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4738398692501125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4736960782181649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4734666299749199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.47335867486761873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4731916389634124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4732243133818402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4730506566437808
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.47303924313065604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4729617071221243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4727268704148226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.47259537983631744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4724021814978881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4723329783688361
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.472192900961843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4719925595388713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.47182816445827486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4716681563786292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.47156445758247917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4714830837742803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4712308780790049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4711239086910033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.47095724605442435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.47087586310063423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4707640194693091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4706425715787829
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.47055514007806776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4704012791535861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4703548659277226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.47027311262677196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4701476611278869
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.47012689113616946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.47002277266783793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4699014168669158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.469840247022069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4697758996389746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.46969866575421515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4695657183217874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.46940374887117775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.46930297370251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.46917314556511963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4689980371793111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4688953624919374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4688106311252958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4687082273146463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.46854858607604194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4683543942476574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.46822667802412676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4680859877176934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4680219568098183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.467934331856668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4677578873448558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.46767165392174004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4675475941918001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.46741722170839606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.46725248509017236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4671259845678623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.46697821915911897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.46681249795519575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4667799541058431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.46658168059920296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4664605820480781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.46635193204638936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.466165062762628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.4660789431938574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4659482996565357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.465960878059268
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4657534725796849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4655038275528903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4652963172709084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.46518741968539684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.46508671832673343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4649282740841945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4647725614048632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4646138713932505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.46451766071226314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.4644079624879651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.46438673892740495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4642069625478346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.46404881259430986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.46398923276127246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.46383472925209135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4637506373513203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4635930936113536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4634390134703029
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4633738562855914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4632331306735675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4631523037608049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.46300332318832527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.462910348007865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.46282247784283925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.46272746079108296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4625748030736413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.46255369962518056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.462407821597897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4621512779405901
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.46216663246931033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.46213641949430145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.46207825701545785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4618427070679345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.46170613650352726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4615325688630685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4614615414394151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4613571444556151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.46122516419517395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.46103335017495384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.46094801622358234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4608726137214237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4608237166210537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4607961780599762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.46071291956547145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4607663211527835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4606799731206466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.46055134824191696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.46051565843767356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.46046819473162526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.46039295825693344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4602881147301118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.46020143643944667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.460095114923734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.460000297571594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4598677536943457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4597929278878789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4596923538188183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.45967339193977125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.45963457233246113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.45956801493530686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.459466536818254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.45936771021002815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4592822949134505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.45922895720035867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.45919704533392386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.459161090684551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.45905593956563406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.45889648967064345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4588706558828415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.45884579426430644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4587561689997428
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4587491507626186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4587491507626186 valid 0.48529210686683655
LOSS train 0.4587491507626186 valid 0.4818057417869568
LOSS train 0.4587491507626186 valid 0.5000792543093363
LOSS train 0.4587491507626186 valid 0.49469228833913803
LOSS train 0.4587491507626186 valid 0.49123011231422425
LOSS train 0.4587491507626186 valid 0.4925509492556254
LOSS train 0.4587491507626186 valid 0.4918563110487802
LOSS train 0.4587491507626186 valid 0.4905771240592003
LOSS train 0.4587491507626186 valid 0.48459457026587593
LOSS train 0.4587491507626186 valid 0.48808213472366335
LOSS train 0.4587491507626186 valid 0.4912876703522422
LOSS train 0.4587491507626186 valid 0.48992953201135
LOSS train 0.4587491507626186 valid 0.4918332329163185
LOSS train 0.4587491507626186 valid 0.49171911818640573
LOSS train 0.4587491507626186 valid 0.49038374423980713
LOSS train 0.4587491507626186 valid 0.4920781999826431
LOSS train 0.4587491507626186 valid 0.4943322644514196
LOSS train 0.4587491507626186 valid 0.49510063727696735
LOSS train 0.4587491507626186 valid 0.49559831619262695
LOSS train 0.4587491507626186 valid 0.49675326645374296
LOSS train 0.4587491507626186 valid 0.49554891671453205
LOSS train 0.4587491507626186 valid 0.4930114976384423
LOSS train 0.4587491507626186 valid 0.4939489325751429
LOSS train 0.4587491507626186 valid 0.4925142613550027
LOSS train 0.4587491507626186 valid 0.49121363878250124
LOSS train 0.4587491507626186 valid 0.4906491797703963
LOSS train 0.4587491507626186 valid 0.48985933153717603
LOSS train 0.4587491507626186 valid 0.49038432964256834
LOSS train 0.4587491507626186 valid 0.489713565028947
LOSS train 0.4587491507626186 valid 0.49061834315458935
LOSS train 0.4587491507626186 valid 0.49193149516659396
LOSS train 0.4587491507626186 valid 0.4918417576700449
LOSS train 0.4587491507626186 valid 0.4927396972974141
LOSS train 0.4587491507626186 valid 0.492243147948209
LOSS train 0.4587491507626186 valid 0.49304400341851373
LOSS train 0.4587491507626186 valid 0.49312211324771243
LOSS train 0.4587491507626186 valid 0.49377969390637166
LOSS train 0.4587491507626186 valid 0.49476395704244314
LOSS train 0.4587491507626186 valid 0.494184442055531
LOSS train 0.4587491507626186 valid 0.49581107348203657
LOSS train 0.4587491507626186 valid 0.4958195308359658
LOSS train 0.4587491507626186 valid 0.49692266895657494
LOSS train 0.4587491507626186 valid 0.4970832896787067
LOSS train 0.4587491507626186 valid 0.4974267360838977
LOSS train 0.4587491507626186 valid 0.49760683112674287
LOSS train 0.4587491507626186 valid 0.49802891326987225
LOSS train 0.4587491507626186 valid 0.4973819896261743
LOSS train 0.4587491507626186 valid 0.4979835407187541
LOSS train 0.4587491507626186 valid 0.4984592302721374
LOSS train 0.4587491507626186 valid 0.4980581420660019
LOSS train 0.4587491507626186 valid 0.49877801537513733
LOSS train 0.4587491507626186 valid 0.49850813356729656
LOSS train 0.4587491507626186 valid 0.4980507830403886
LOSS train 0.4587491507626186 valid 0.49820792454260365
LOSS train 0.4587491507626186 valid 0.4977487639947371
LOSS train 0.4587491507626186 valid 0.49740670195647646
LOSS train 0.4587491507626186 valid 0.4973701881734948
LOSS train 0.4587491507626186 valid 0.49728136483965246
LOSS train 0.4587491507626186 valid 0.4978247683937267
LOSS train 0.4587491507626186 valid 0.4971782609820366
LOSS train 0.4587491507626186 valid 0.4959917522844721
LOSS train 0.4587491507626186 valid 0.49708645622576436
LOSS train 0.4587491507626186 valid 0.4973985548057253
LOSS train 0.4587491507626186 valid 0.497992052230984
LOSS train 0.4587491507626186 valid 0.4982780075990237
LOSS train 0.4587491507626186 valid 0.49834840812466363
LOSS train 0.4587491507626186 valid 0.4978900066952207
LOSS train 0.4587491507626186 valid 0.4974333157434183
LOSS train 0.4587491507626186 valid 0.4971762403197911
LOSS train 0.4587491507626186 valid 0.4967823381934847
LOSS train 0.4587491507626186 valid 0.4964650491593589
LOSS train 0.4587491507626186 valid 0.4962529138558441
LOSS train 0.4587491507626186 valid 0.49652158683293485
LOSS train 0.4587491507626186 valid 0.49657358068066676
LOSS train 0.4587491507626186 valid 0.49606305996576944
LOSS train 0.4587491507626186 valid 0.4961894381987421
LOSS train 0.4587491507626186 valid 0.49598216042890175
LOSS train 0.4587491507626186 valid 0.4960185400186441
LOSS train 0.4587491507626186 valid 0.4957720656183702
LOSS train 0.4587491507626186 valid 0.4956788558512926
LOSS train 0.4587491507626186 valid 0.49535820366423805
LOSS train 0.4587491507626186 valid 0.49569755501863433
LOSS train 0.4587491507626186 valid 0.49544848483729076
LOSS train 0.4587491507626186 valid 0.49553733319044113
LOSS train 0.4587491507626186 valid 0.49560596557224496
LOSS train 0.4587491507626186 valid 0.49524726701337235
LOSS train 0.4587491507626186 valid 0.49489053569991015
LOSS train 0.4587491507626186 valid 0.49440638145262544
LOSS train 0.4587491507626186 valid 0.49484372306405827
LOSS train 0.4587491507626186 valid 0.49476822051737046
LOSS train 0.4587491507626186 valid 0.49448778439354113
LOSS train 0.4587491507626186 valid 0.49423837143441907
LOSS train 0.4587491507626186 valid 0.4936451203720544
LOSS train 0.4587491507626186 valid 0.4929769391075094
LOSS train 0.4587491507626186 valid 0.49260960597740977
LOSS train 0.4587491507626186 valid 0.4928355182831486
LOSS train 0.4587491507626186 valid 0.4932412735580169
LOSS train 0.4587491507626186 valid 0.4932483960779346
LOSS train 0.4587491507626186 valid 0.493468673843326
LOSS train 0.4587491507626186 valid 0.49374297708272935
LOSS train 0.4587491507626186 valid 0.49388632886480577
LOSS train 0.4587491507626186 valid 0.4939137700141645
LOSS train 0.4587491507626186 valid 0.4944025199968838
LOSS train 0.4587491507626186 valid 0.4942905647823444
LOSS train 0.4587491507626186 valid 0.4943559371289753
LOSS train 0.4587491507626186 valid 0.49447663690683974
LOSS train 0.4587491507626186 valid 0.49414577968766754
LOSS train 0.4587491507626186 valid 0.4945437397669863
LOSS train 0.4587491507626186 valid 0.49472153050090195
LOSS train 0.4587491507626186 valid 0.4949149096553976
LOSS train 0.4587491507626186 valid 0.4949296659177488
LOSS train 0.4587491507626186 valid 0.49480871324028286
LOSS train 0.4587491507626186 valid 0.4947758074355336
LOSS train 0.4587491507626186 valid 0.49456134804508145
LOSS train 0.4587491507626186 valid 0.49453034452770067
LOSS train 0.4587491507626186 valid 0.49438519827250776
LOSS train 0.4587491507626186 valid 0.4944302426953601
LOSS train 0.4587491507626186 valid 0.49432427575022486
LOSS train 0.4587491507626186 valid 0.49406699999039916
LOSS train 0.4587491507626186 valid 0.49400057792663576
LOSS train 0.4587491507626186 valid 0.493826141534758
LOSS train 0.4587491507626186 valid 0.49370799299146306
LOSS train 0.4587491507626186 valid 0.49376041181688385
LOSS train 0.4587491507626186 valid 0.49405986887793385
LOSS train 0.4587491507626186 valid 0.4939828338623047
LOSS train 0.4587491507626186 valid 0.49387444957854254
LOSS train 0.4587491507626186 valid 0.4943349943386288
LOSS train 0.4587491507626186 valid 0.4944041334092617
LOSS train 0.4587491507626186 valid 0.49460902786994165
LOSS train 0.4587491507626186 valid 0.49443303025685825
LOSS train 0.4587491507626186 valid 0.4944575174164226
LOSS train 0.4587491507626186 valid 0.4943885200402953
LOSS train 0.4587491507626186 valid 0.49428536995012956
LOSS train 0.4587491507626186 valid 0.49452164346602423
LOSS train 0.4587491507626186 valid 0.49469935960239836
LOSS train 0.4587491507626186 valid 0.49466221231748075
LOSS train 0.4587491507626186 valid 0.49446650164840866
LOSS train 0.4587491507626186 valid 0.49433135230472125
LOSS train 0.4587491507626186 valid 0.4940361914446028
LOSS train 0.4587491507626186 valid 0.49420338762657984
LOSS train 0.4587491507626186 valid 0.49418687904980163
LOSS train 0.4587491507626186 valid 0.4945047976265491
LOSS train 0.4587491507626186 valid 0.4941360825425261
LOSS train 0.4587491507626186 valid 0.4941941810150941
LOSS train 0.4587491507626186 valid 0.49404314489200196
LOSS train 0.4587491507626186 valid 0.49442801798043184
LOSS train 0.4587491507626186 valid 0.4939143540096932
LOSS train 0.4587491507626186 valid 0.49420875955272364
LOSS train 0.4587491507626186 valid 0.4943180668274028
LOSS train 0.4587491507626186 valid 0.49447234551111857
LOSS train 0.4587491507626186 valid 0.4945108306328982
LOSS train 0.4587491507626186 valid 0.494344560135352
LOSS train 0.4587491507626186 valid 0.4945874909559886
LOSS train 0.4587491507626186 valid 0.49460448576258376
LOSS train 0.4587491507626186 valid 0.494762102634676
LOSS train 0.4587491507626186 valid 0.49518173703780544
LOSS train 0.4587491507626186 valid 0.4951338270667252
LOSS train 0.4587491507626186 valid 0.49506401449819154
LOSS train 0.4587491507626186 valid 0.4947201204749773
LOSS train 0.4587491507626186 valid 0.49476868435740473
LOSS train 0.4587491507626186 valid 0.49464698052554396
LOSS train 0.4587491507626186 valid 0.4942980839146508
LOSS train 0.4587491507626186 valid 0.49426849031009557
LOSS train 0.4587491507626186 valid 0.4941232682364743
LOSS train 0.4587491507626186 valid 0.4940378508784554
LOSS train 0.4587491507626186 valid 0.4938763166407505
LOSS train 0.4587491507626186 valid 0.4939029871703622
LOSS train 0.4587491507626186 valid 0.49405221126618837
LOSS train 0.4587491507626186 valid 0.49416097892812016
LOSS train 0.4587491507626186 valid 0.49455934885670155
LOSS train 0.4587491507626186 valid 0.4945105704647756
LOSS train 0.4587491507626186 valid 0.4945573134477748
LOSS train 0.4587491507626186 valid 0.49464793839206583
LOSS train 0.4587491507626186 valid 0.4946732360056077
LOSS train 0.4587491507626186 valid 0.4947621750831604
LOSS train 0.4587491507626186 valid 0.4945685345340859
LOSS train 0.4587491507626186 valid 0.4949032553171707
LOSS train 0.4587491507626186 valid 0.49501548054512967
LOSS train 0.4587491507626186 valid 0.4949105593412282
LOSS train 0.4587491507626186 valid 0.4950213798218303
LOSS train 0.4587491507626186 valid 0.49503847265111806
LOSS train 0.4587491507626186 valid 0.4951194808050826
LOSS train 0.4587491507626186 valid 0.4950288047230309
LOSS train 0.4587491507626186 valid 0.49520126681612886
LOSS train 0.4587491507626186 valid 0.4951418423974836
LOSS train 0.4587491507626186 valid 0.4951678798083336
LOSS train 0.4587491507626186 valid 0.49517884404264034
LOSS train 0.4587491507626186 valid 0.4951579424929112
LOSS train 0.4587491507626186 valid 0.4950849437524402
LOSS train 0.4587491507626186 valid 0.4949287839626011
LOSS train 0.4587491507626186 valid 0.4951725984431062
LOSS train 0.4587491507626186 valid 0.49524889870857197
LOSS train 0.4587491507626186 valid 0.4951600262538139
LOSS train 0.4587491507626186 valid 0.4949460983583608
LOSS train 0.4587491507626186 valid 0.4949475338825813
LOSS train 0.4587491507626186 valid 0.49501481302538697
LOSS train 0.4587491507626186 valid 0.49524579722869216
LOSS train 0.4587491507626186 valid 0.4953166034185525
LOSS train 0.4587491507626186 valid 0.4953288095979834
LOSS train 0.4587491507626186 valid 0.4952613528072834
LOSS train 0.4587491507626186 valid 0.4949673282269815
LOSS train 0.4587491507626186 valid 0.49511099555114707
LOSS train 0.4587491507626186 valid 0.49490924656684765
LOSS train 0.4587491507626186 valid 0.4949232380764157
LOSS train 0.4587491507626186 valid 0.49497321727799204
LOSS train 0.4587491507626186 valid 0.4948134192274612
LOSS train 0.4587491507626186 valid 0.4950143123306514
LOSS train 0.4587491507626186 valid 0.4949819908405726
LOSS train 0.4587491507626186 valid 0.49491851794662656
LOSS train 0.4587491507626186 valid 0.495050278589839
LOSS train 0.4587491507626186 valid 0.49508506638743865
LOSS train 0.4587491507626186 valid 0.4951508957541214
LOSS train 0.4587491507626186 valid 0.49516304487913426
LOSS train 0.4587491507626186 valid 0.4951066512649304
LOSS train 0.4587491507626186 valid 0.49508335784424184
LOSS train 0.4587491507626186 valid 0.49517618699206245
LOSS train 0.4587491507626186 valid 0.49520305911516815
LOSS train 0.4587491507626186 valid 0.4952604806204455
LOSS train 0.4587491507626186 valid 0.4952352792705031
LOSS train 0.4587491507626186 valid 0.49542734812606465
LOSS train 0.4587491507626186 valid 0.49564342827818514
LOSS train 0.4587491507626186 valid 0.49565778739817506
LOSS train 0.4587491507626186 valid 0.4956281439071279
LOSS train 0.4587491507626186 valid 0.4956543033144304
LOSS train 0.4587491507626186 valid 0.4956998634338379
LOSS train 0.4587491507626186 valid 0.4956892214517678
LOSS train 0.4587491507626186 valid 0.4957452605474363
LOSS train 0.4587491507626186 valid 0.4957364447284163
LOSS train 0.4587491507626186 valid 0.4958275033396925
LOSS train 0.4587491507626186 valid 0.49595580722974697
LOSS train 0.4587491507626186 valid 0.4959281409457649
LOSS train 0.4587491507626186 valid 0.4959853109100769
LOSS train 0.4587491507626186 valid 0.49585625772312475
LOSS train 0.4587491507626186 valid 0.4958062459770431
LOSS train 0.4587491507626186 valid 0.49597105472645864
LOSS train 0.4587491507626186 valid 0.49591674087411264
LOSS train 0.4587491507626186 valid 0.4957985395117651
LOSS train 0.4587491507626186 valid 0.4957848040997481
LOSS train 0.4587491507626186 valid 0.49566562355312843
LOSS train 0.4587491507626186 valid 0.49551895124216877
LOSS train 0.4587491507626186 valid 0.4958000792754636
LOSS train 0.4587491507626186 valid 0.495725840453274
LOSS train 0.4587491507626186 valid 0.4956911352190952
LOSS train 0.4587491507626186 valid 0.495813857458654
LOSS train 0.4587491507626186 valid 0.4957813138864478
LOSS train 0.4587491507626186 valid 0.49578247613053983
LOSS train 0.4587491507626186 valid 0.49580620923022994
LOSS train 0.4587491507626186 valid 0.4957980252802372
LOSS train 0.4587491507626186 valid 0.49583399259900474
LOSS train 0.4587491507626186 valid 0.49607299625873563
LOSS train 0.4587491507626186 valid 0.4961778867054745
LOSS train 0.4587491507626186 valid 0.4964282256033685
LOSS train 0.4587491507626186 valid 0.49633317973773944
LOSS train 0.4587491507626186 valid 0.4965564181485514
LOSS train 0.4587491507626186 valid 0.4965424651024388
LOSS train 0.4587491507626186 valid 0.49655499623622745
LOSS train 0.4587491507626186 valid 0.4965198106107081
LOSS train 0.4587491507626186 valid 0.4965990334749222
LOSS train 0.4587491507626186 valid 0.496571888909837
LOSS train 0.4587491507626186 valid 0.4964272958727983
LOSS train 0.4587491507626186 valid 0.4964531857620254
LOSS train 0.4587491507626186 valid 0.49640223634152014
LOSS train 0.4587491507626186 valid 0.49635840074191073
LOSS train 0.4587491507626186 valid 0.496275432407856
LOSS train 0.4587491507626186 valid 0.4963028086806243
LOSS train 0.4587491507626186 valid 0.49647071935180437
LOSS train 0.4587491507626186 valid 0.49666478303487827
LOSS train 0.4587491507626186 valid 0.4967601557276142
LOSS train 0.4587491507626186 valid 0.4969921557433543
LOSS train 0.4587491507626186 valid 0.4969178448120753
LOSS train 0.4587491507626186 valid 0.4970158667362044
LOSS train 0.4587491507626186 valid 0.4970795583418187
LOSS train 0.4587491507626186 valid 0.49709555746871475
LOSS train 0.4587491507626186 valid 0.4971162186269342
LOSS train 0.4587491507626186 valid 0.49696043155410075
LOSS train 0.4587491507626186 valid 0.496932785904062
LOSS train 0.4587491507626186 valid 0.4970209244571438
LOSS train 0.4587491507626186 valid 0.49702353453893455
LOSS train 0.4587491507626186 valid 0.49713876309360655
LOSS train 0.4587491507626186 valid 0.49700564433421407
LOSS train 0.4587491507626186 valid 0.4968640208244324
LOSS train 0.4587491507626186 valid 0.49686412238482885
LOSS train 0.4587491507626186 valid 0.49688817028864535
LOSS train 0.4587491507626186 valid 0.496938572698076
LOSS train 0.4587491507626186 valid 0.49687572696752713
LOSS train 0.4587491507626186 valid 0.4967520410989548
LOSS train 0.4587491507626186 valid 0.4967315150262587
LOSS train 0.4587491507626186 valid 0.49667909441308844
LOSS train 0.4587491507626186 valid 0.4967748420667483
LOSS train 0.4587491507626186 valid 0.49676563852819905
LOSS train 0.4587491507626186 valid 0.4965815357735886
LOSS train 0.4587491507626186 valid 0.49663974997931964
LOSS train 0.4587491507626186 valid 0.4965244879494755
LOSS train 0.4587491507626186 valid 0.496627302599602
LOSS train 0.4587491507626186 valid 0.4967312010668092
LOSS train 0.4587491507626186 valid 0.496665395796299
LOSS train 0.4587491507626186 valid 0.49669857478703716
LOSS train 0.4587491507626186 valid 0.49659148038633716
LOSS train 0.4587491507626186 valid 0.49666703624470177
LOSS train 0.4587491507626186 valid 0.4967195657889048
LOSS train 0.4587491507626186 valid 0.4967122303687061
LOSS train 0.4587491507626186 valid 0.4965996653433667
LOSS train 0.4587491507626186 valid 0.4965557872068764
LOSS train 0.4587491507626186 valid 0.4965903285498682
LOSS train 0.4587491507626186 valid 0.4965727406447051
LOSS train 0.4587491507626186 valid 0.4966065820330888
LOSS train 0.4587491507626186 valid 0.496608295056253
LOSS train 0.4587491507626186 valid 0.4965067661621354
LOSS train 0.4587491507626186 valid 0.4965049587792949
LOSS train 0.4587491507626186 valid 0.49651114181164774
LOSS train 0.4587491507626186 valid 0.4964999642786106
LOSS train 0.4587491507626186 valid 0.496524378657341
LOSS train 0.4587491507626186 valid 0.4966309318146386
LOSS train 0.4587491507626186 valid 0.4966225734182224
LOSS train 0.4587491507626186 valid 0.4966284505904667
LOSS train 0.4587491507626186 valid 0.49649469799633267
LOSS train 0.4587491507626186 valid 0.4965381197372822
LOSS train 0.4587491507626186 valid 0.49653430639197993
LOSS train 0.4587491507626186 valid 0.49650953817517035
LOSS train 0.4587491507626186 valid 0.4964362675324082
LOSS train 0.4587491507626186 valid 0.49646984918095244
LOSS train 0.4587491507626186 valid 0.49648485550228855
LOSS train 0.4587491507626186 valid 0.4964676637767638
LOSS train 0.4587491507626186 valid 0.49646957457801444
LOSS train 0.4587491507626186 valid 0.4964070026691143
LOSS train 0.4587491507626186 valid 0.49650391771749486
LOSS train 0.4587491507626186 valid 0.4966954968026654
LOSS train 0.4587491507626186 valid 0.49666553181482526
LOSS train 0.4587491507626186 valid 0.4966911897289717
LOSS train 0.4587491507626186 valid 0.49665557769211854
LOSS train 0.4587491507626186 valid 0.4966314552053584
LOSS train 0.4587491507626186 valid 0.4965164388518736
LOSS train 0.4587491507626186 valid 0.4965262711943091
LOSS train 0.4587491507626186 valid 0.49657917111933586
LOSS train 0.4587491507626186 valid 0.4965761474709013
LOSS train 0.4587491507626186 valid 0.4965228507561343
LOSS train 0.4587491507626186 valid 0.4965086033683856
LOSS train 0.4587491507626186 valid 0.4965586476248397
LOSS train 0.4587491507626186 valid 0.496485176603351
LOSS train 0.4587491507626186 valid 0.49650089504087674
LOSS train 0.4587491507626186 valid 0.49633287745486954
LOSS train 0.4587491507626186 valid 0.49617989204431834
LOSS train 0.4587491507626186 valid 0.4961717188705856
LOSS train 0.4587491507626186 valid 0.4963540210453577
LOSS train 0.4587491507626186 valid 0.4963993209859599
LOSS train 0.4587491507626186 valid 0.49640970483336144
LOSS train 0.4587491507626186 valid 0.496324934688013
LOSS train 0.4587491507626186 valid 0.49621256440877914
LOSS train 0.4587491507626186 valid 0.4962035988839103
LOSS train 0.4587491507626186 valid 0.4960591868843351
LOSS train 0.4587491507626186 valid 0.49602564727818527
LOSS train 0.4587491507626186 valid 0.4960515315390446
LOSS train 0.4587491507626186 valid 0.4960603253024158
LOSS train 0.4587491507626186 valid 0.49609299584970634
LOSS train 0.4587491507626186 valid 0.4961037580396088
LOSS train 0.4587491507626186 valid 0.49609698874227115
LOSS train 0.4587491507626186 valid 0.4960385667843645
LOSS train 0.4587491507626186 valid 0.49596971056980793
LOSS train 0.4587491507626186 valid 0.4960016604917627
LOSS train 0.4587491507626186 valid 0.4960502811604076
LOSS train 0.4587491507626186 valid 0.49607977081203725
LOSS train 0.4587491507626186 valid 0.49622418834359605
LOSS train 0.4587491507626186 valid 0.49614071919898356
LOSS train 0.4587491507626186 valid 0.4961081773533926
LOSS train 0.4587491507626186 valid 0.4961674060723553
LOSS train 0.4587491507626186 valid 0.4961236439278868
LOSS train 0.4587491507626186 valid 0.49604713340221374
LOSS train 0.4587491507626186 valid 0.496033722858714
LOSS train 0.4587491507626186 valid 0.4959991605785804
EPOCH 2:
  batch 1 loss: 0.39057254791259766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.40881913900375366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.4213777581850688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.42631757259368896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4293674826622009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4289079010486603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.42579015663691927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4304179549217224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4282865093814002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4271867036819458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4259231226010756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.42682230720917386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.42342236179571885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.42177663317748476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4228968441486359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4242376983165741
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.42418524973532734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4234015742937724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.42305303874768707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4221263140439987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4213320896739051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.42118989066644147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4220972423968108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.42274333784977597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.42333121061325074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.42449193046643185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.42485615279939437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.42396206515175955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4250203340217985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.42494893570741016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.42542955663896376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4253530381247401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.42530097834991687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.42536963697742014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4255745870726449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.42563681138886345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4253791022945095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.42513175700840194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.42565246881582797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.42576845213770864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4258168855818307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.425157402242933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4261192235835763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.42562670328400354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.42599276039335465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4250381187252376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.42531272325109926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4247339740395546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4248471132346562
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.42498366415500644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.42481253252309914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.42470128719623274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4248668467098812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4244073623860324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.42429797811941666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.42457730003765654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4250362191283912
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.42428562353397237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4245270788669586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.42430971513191856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4238563648989943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4238037495843826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.42374343153030153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.42404566146433353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.42408943543067346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.42398320680314844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.42345212955973044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.42317987058092565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4232127040192701
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.42364844850131445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4236632917128818
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.42336080016361344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.423344515366097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.42347539759971
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.42331499179204307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4237240121552819
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4237676270596393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.42366737776841873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.42388291939904416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4241238232702017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4243873545417079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.424355602845913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4242321561618024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.42405946056048077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.42420461528441483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4241143049195755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4240464225582693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4242411391301589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.42407076747229927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.42422682146231333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4238294228747651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.42387630466533743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.42425863364691374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4243015764241523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4239740788936615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.42408209045728046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.42384551788113783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.42410293920915954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.42429771838766156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4244056984782219
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.42418823472344047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.424206697473339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4244987423558837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.42420606458416354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4242992210955847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.42415116165044175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.42426924532819016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.42458828262708803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.42452119988039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.42482414543628694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.42459656794865924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.42446984350681305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4241448701482958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.42415057540985573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.423826172300007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.42367086097084244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4236581409588838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.42345022271245214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.42326918144186004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4232023999094963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.42303064785713007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.422978793744181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.42339629298303183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4233378703075071
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4234197447299957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.42330985622746603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.42317265107875734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.42340156459249556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4234577500542929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.42344253063201903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4231004924264573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.42301957535021234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.42306767213613466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.42299867143381886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4228521698051029
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4228679496137535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4229378852530988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4228464000035023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4231144067623632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.42311206481286456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.42263713732678837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.42269462640856353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4228517744507823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4230676990830236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4231199679703548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.42300033732636333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.42296190468632444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.42307919565890284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4231338092944766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.42312467416127525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.42317589643775233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4230199720906584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4227930196360046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4225562988937675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4226601577574207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4227072497208913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.422745446490634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4225067692466929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4226615031560262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4225358160212636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.422328451775616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4221634872165727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.42230617488088784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4221122831833072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.42190197814594615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4218225768172597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.42142655553218134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.42138736109648434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.42134936515396165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4213302058332107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.42135723484189885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.42116342017123864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4208848970818382
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.42086405623918294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4207768212045942
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4205988445742564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4204020277928498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4202600751030311
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.420239243260975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.42007893406682545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.42010163997418315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.42021760737502967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4201169282686515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.42005768758447276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4201451314462198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.42006072546205214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4199565433882137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.41970913270686533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4196471344856989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4195881170661826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4195828898102825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.41949046806742746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4193987884978556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4193540994346756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4193235661738958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.41929713423763004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.41944853046218755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.41977802897342525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.41968165615096165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4196764187514782
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4196316985348564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.41954984198702444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.41968373080779764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4195982298138095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4195857014597916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.41962226907026423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4196507518994059
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.419431136491207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.41943506361765154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.41942083778835476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4193936577905411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.41941044535839334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.41917813453875796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.41903486806098544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4189335757909819
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4188587091587208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4188546896804862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4188402966348403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.41894040232924024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4189707264304161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4188625684420987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4187636767421757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.41876377947127336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.41897923153425964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4187466499540541
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4186231442521104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4186237871909457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4185241302638723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4185557964066751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.418573620137961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4185926520721221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.41855768859386444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4184165158241092
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.418417919267956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4184643487981025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.41854905488632493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4186977452366664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4187601917431134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4188266804278146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.41882957766453427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4187807754856917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.41872839937525347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4188557110205599
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.41879169630711194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.41881910392216276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4188386250317581
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.41884321481110115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.41885953949343774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4188151180026043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.41888554298877717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4189068821084452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.41885865527012994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4187796718989436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4187012257303779
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4187676311707964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.41874454892240465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.41868503768620324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4187555649252825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4188573096939956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.41893279724396193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.41881078527348253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.41878673900629726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4187493115776845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.41865261418349814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4184726868035658
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.41853867056674526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.418447327971012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.418436428393001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4184836495986215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4184568038693181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.41850082262855615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4183525778353214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.41829651026498704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4181504958737506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.41798083500428634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.418050961865895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4179944389563605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4178344727420121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.41794526299268114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.41785251668521334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4178014179141496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4177298881906144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4176887688704177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4176278722957826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.41767593465353314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.41761885708445434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.41761508397109004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.41766828888406354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.41780515247150274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.41789100550372027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4179287217941481
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.41785406494793825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.41785003361848433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4178314048822234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4179093534663572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.41784022214847644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.41793616984027004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4177909018409332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4177351047761464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4177280895908674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.417755561314548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4176334919321616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4176080005593819
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.41756867313463436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4174443937715937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.41740782558918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4173687490655856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.41719945568542977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.41727541170073945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.41730312781949197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4173156183057276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4173212277774627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.41735873426111364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4172401871461018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.41721608695529755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4172354597079603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4172173230805984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4171360592422245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4170974930252027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.41702951937913896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.41700963104996724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4169332721033452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4169543152992201
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.416934415422104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4169033366900224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.41690594881224485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.41688045704401233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4168480040460098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.41674244711826636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4167354495236368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.416835986775574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4167159108153309
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4167513707736591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.41669698532469973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4167233996426881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4167060973566203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.41660681720657233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.41665154228196344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.41662145232380665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.41679303339299034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.41671135610848925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4168145026554141
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.41686210262184586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4167580376704072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4167578026868295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4167057975179198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.41671874457889746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4166912669422983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.41661974437598853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.41655988608087813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.41650055463497454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.41652389480309054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.41656015429213095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4164473638359436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.41647909577463715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4164174151387108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.41644222671244324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.41641079039214046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.416422825586829
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.41642441062463653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.41638131022783526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.41646059178515693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.41648645949429386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4164705351813809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.41655267395385326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.41652480557642346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.41650503281026835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.41652443834944913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4165574104643773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.41659159136785046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4166193002799772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4165719862106026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4165637982914339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.41654449613655314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.41648882484436034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4164638732500533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4165003351096449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4164933477129255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4164564213211744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.41639059970253395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4163387729896335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.41630028905980876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.41635040818244295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4163691618014127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4162820797461968
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.41632139883510805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4162816587806672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4162688432741411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4161855768421928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4161342163116504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.41608357658166717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.41603947035512145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.41610431746975457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4159838691883281
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.41593860614148875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4159323273584096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.41583833518796964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.4158775110789879
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.41585376380679
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.415975406691432
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.415879600437502
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.41570568907616745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4155860140217149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.41555488330893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4155602334458151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4155305784030501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4154641645839232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4153723737188414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4153760138962846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.4153464947531863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4154370081250685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.41536558303728843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4153072065504642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.41533417503039044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.41526075134794393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4153018934079088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4152257098711366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.41518352947166665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4152150487700624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4151666430490358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4151876855491176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4151110374390796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4151150051583635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.41512703023991493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.41513148490120383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.41507544106161093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.41514935468343156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4150969636078193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.41494639645089637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4150690027447634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.41510537564063016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4151631504021309
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4150051003790893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4149757161530481
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4148819469172379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4149015536275479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4148928829270588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.41482879507215054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4147191909831314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.41471095850521866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4147176568875778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4147482373460925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.41480547149348207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.41482994591330624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4149679319242413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4149689070312432
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4149046642268264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4150120170920023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.41503957152897636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4150065063767963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.41497857237602287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.41497139823911466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.41494846561097154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.41491750263432575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4148447124512641
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4148430621022718
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.41480815104113106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4148468931559392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4148600180034804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.41485555735619173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.41482410545980075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4147943416973213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.41479187656684774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.41479640376978905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.414837565665604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.41490797685707076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4148625102237154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4147875329368135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4148270988515191
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.41488215377990234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.41484288399892755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4149046007985786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4149046007985786 valid 0.4623211920261383
LOSS train 0.4149046007985786 valid 0.4608311802148819
LOSS train 0.4149046007985786 valid 0.48056166370709735
LOSS train 0.4149046007985786 valid 0.47664597630500793
LOSS train 0.4149046007985786 valid 0.4739705681800842
LOSS train 0.4149046007985786 valid 0.47631117204825085
LOSS train 0.4149046007985786 valid 0.4759758412837982
LOSS train 0.4149046007985786 valid 0.475021418184042
LOSS train 0.4149046007985786 valid 0.4688747293419308
LOSS train 0.4149046007985786 valid 0.4723082631826401
LOSS train 0.4149046007985786 valid 0.4756437025286935
LOSS train 0.4149046007985786 valid 0.47423884520928067
LOSS train 0.4149046007985786 valid 0.4762885639300713
LOSS train 0.4149046007985786 valid 0.4763006291219166
LOSS train 0.4149046007985786 valid 0.4746889233589172
LOSS train 0.4149046007985786 valid 0.4766093119978905
LOSS train 0.4149046007985786 valid 0.47902144404018626
LOSS train 0.4149046007985786 valid 0.47989288138018715
LOSS train 0.4149046007985786 valid 0.48057123391251816
LOSS train 0.4149046007985786 valid 0.48214620500802996
LOSS train 0.4149046007985786 valid 0.4809433079901196
LOSS train 0.4149046007985786 valid 0.4781363037499515
LOSS train 0.4149046007985786 valid 0.4789871340212615
LOSS train 0.4149046007985786 valid 0.47741712133089703
LOSS train 0.4149046007985786 valid 0.4761585927009582
LOSS train 0.4149046007985786 valid 0.4755648122383998
LOSS train 0.4149046007985786 valid 0.4748935986448217
LOSS train 0.4149046007985786 valid 0.4755535476974079
LOSS train 0.4149046007985786 valid 0.47480547941964246
LOSS train 0.4149046007985786 valid 0.47575828731060027
LOSS train 0.4149046007985786 valid 0.47741849095590655
LOSS train 0.4149046007985786 valid 0.4773549698293209
LOSS train 0.4149046007985786 valid 0.47849079876235034
LOSS train 0.4149046007985786 valid 0.4778616919237025
LOSS train 0.4149046007985786 valid 0.4786938922745841
LOSS train 0.4149046007985786 valid 0.4788207618726624
LOSS train 0.4149046007985786 valid 0.47937202050879196
LOSS train 0.4149046007985786 valid 0.4805304149263783
LOSS train 0.4149046007985786 valid 0.4799861388328748
LOSS train 0.4149046007985786 valid 0.481577068567276
LOSS train 0.4149046007985786 valid 0.48150325257603716
LOSS train 0.4149046007985786 valid 0.4826281141667139
LOSS train 0.4149046007985786 valid 0.48277718313904694
LOSS train 0.4149046007985786 valid 0.4832243790680712
LOSS train 0.4149046007985786 valid 0.4833863225248125
LOSS train 0.4149046007985786 valid 0.48386090799518255
LOSS train 0.4149046007985786 valid 0.4831601603234068
LOSS train 0.4149046007985786 valid 0.48364450223743916
LOSS train 0.4149046007985786 valid 0.48417200786726816
LOSS train 0.4149046007985786 valid 0.4837843412160873
LOSS train 0.4149046007985786 valid 0.484479651147244
LOSS train 0.4149046007985786 valid 0.48418263689829755
LOSS train 0.4149046007985786 valid 0.48364706365567334
LOSS train 0.4149046007985786 valid 0.48377798387297877
LOSS train 0.4149046007985786 valid 0.4832491614601829
LOSS train 0.4149046007985786 valid 0.4829369293791907
LOSS train 0.4149046007985786 valid 0.4828394996492486
LOSS train 0.4149046007985786 valid 0.4826685221030794
LOSS train 0.4149046007985786 valid 0.48329415462784847
LOSS train 0.4149046007985786 valid 0.4826712071895599
LOSS train 0.4149046007985786 valid 0.4814540748713446
LOSS train 0.4149046007985786 valid 0.48268339662782606
LOSS train 0.4149046007985786 valid 0.4830150571134355
LOSS train 0.4149046007985786 valid 0.4835970257408917
LOSS train 0.4149046007985786 valid 0.4838668781977433
LOSS train 0.4149046007985786 valid 0.4838999333706769
LOSS train 0.4149046007985786 valid 0.4834445492545171
LOSS train 0.4149046007985786 valid 0.48291224898660884
LOSS train 0.4149046007985786 valid 0.48260612461877905
LOSS train 0.4149046007985786 valid 0.4821885321821485
LOSS train 0.4149046007985786 valid 0.4817965400051063
LOSS train 0.4149046007985786 valid 0.48156281891796326
LOSS train 0.4149046007985786 valid 0.4818562718286906
LOSS train 0.4149046007985786 valid 0.4818207025527954
LOSS train 0.4149046007985786 valid 0.48124863068262735
LOSS train 0.4149046007985786 valid 0.4814126522917497
LOSS train 0.4149046007985786 valid 0.48118834603916516
LOSS train 0.4149046007985786 valid 0.48116059104601544
LOSS train 0.4149046007985786 valid 0.480881994283652
LOSS train 0.4149046007985786 valid 0.4808341398835182
LOSS train 0.4149046007985786 valid 0.48041275842690173
LOSS train 0.4149046007985786 valid 0.4807252040723475
LOSS train 0.4149046007985786 valid 0.480495532234031
LOSS train 0.4149046007985786 valid 0.48055784297840937
LOSS train 0.4149046007985786 valid 0.4806693326024448
LOSS train 0.4149046007985786 valid 0.4802385350299436
LOSS train 0.4149046007985786 valid 0.4798608525045987
LOSS train 0.4149046007985786 valid 0.47933827103538945
LOSS train 0.4149046007985786 valid 0.4797429278325499
LOSS train 0.4149046007985786 valid 0.47970832718743217
LOSS train 0.4149046007985786 valid 0.4793913406985147
LOSS train 0.4149046007985786 valid 0.4790618413168451
LOSS train 0.4149046007985786 valid 0.4784595927884502
LOSS train 0.4149046007985786 valid 0.47770648148465666
LOSS train 0.4149046007985786 valid 0.47729596432886623
LOSS train 0.4149046007985786 valid 0.47759670360634726
LOSS train 0.4149046007985786 valid 0.4780124072561559
LOSS train 0.4149046007985786 valid 0.478004268541628
LOSS train 0.4149046007985786 valid 0.4782490107146176
LOSS train 0.4149046007985786 valid 0.478562248647213
LOSS train 0.4149046007985786 valid 0.4787108809641092
LOSS train 0.4149046007985786 valid 0.4787447963859521
LOSS train 0.4149046007985786 valid 0.4793405200092538
LOSS train 0.4149046007985786 valid 0.47919032034965664
LOSS train 0.4149046007985786 valid 0.47921731443632215
LOSS train 0.4149046007985786 valid 0.47936841986089385
LOSS train 0.4149046007985786 valid 0.4790131767219472
LOSS train 0.4149046007985786 valid 0.47941474340580126
LOSS train 0.4149046007985786 valid 0.47957202764826085
LOSS train 0.4149046007985786 valid 0.47971264151009646
LOSS train 0.4149046007985786 valid 0.47976384479720313
LOSS train 0.4149046007985786 valid 0.479599747008511
LOSS train 0.4149046007985786 valid 0.4795322199310877
LOSS train 0.4149046007985786 valid 0.4793308066171512
LOSS train 0.4149046007985786 valid 0.4793127440887949
LOSS train 0.4149046007985786 valid 0.47922025441095745
LOSS train 0.4149046007985786 valid 0.4792700325831389
LOSS train 0.4149046007985786 valid 0.4791102866500111
LOSS train 0.4149046007985786 valid 0.47882450002582133
LOSS train 0.4149046007985786 valid 0.47872111027439435
LOSS train 0.4149046007985786 valid 0.4785594509160223
LOSS train 0.4149046007985786 valid 0.4784429329829138
LOSS train 0.4149046007985786 valid 0.4785108830386061
LOSS train 0.4149046007985786 valid 0.47882894186242936
LOSS train 0.4149046007985786 valid 0.4787274832725525
LOSS train 0.4149046007985786 valid 0.4786152210500505
LOSS train 0.4149046007985786 valid 0.47908418619726584
LOSS train 0.4149046007985786 valid 0.4791848207823932
LOSS train 0.4149046007985786 valid 0.47938704629277074
LOSS train 0.4149046007985786 valid 0.47915555972319385
LOSS train 0.4149046007985786 valid 0.4791513958960089
LOSS train 0.4149046007985786 valid 0.4790848204583833
LOSS train 0.4149046007985786 valid 0.4789338116358994
LOSS train 0.4149046007985786 valid 0.4791589953116517
LOSS train 0.4149046007985786 valid 0.4793631761162369
LOSS train 0.4149046007985786 valid 0.4793720379033509
LOSS train 0.4149046007985786 valid 0.4791705567036232
LOSS train 0.4149046007985786 valid 0.4790238895709964
LOSS train 0.4149046007985786 valid 0.4787148685335255
LOSS train 0.4149046007985786 valid 0.47887652197054453
LOSS train 0.4149046007985786 valid 0.4788829515166316
LOSS train 0.4149046007985786 valid 0.4791977741348911
LOSS train 0.4149046007985786 valid 0.4788226493588694
LOSS train 0.4149046007985786 valid 0.4788655953274833
LOSS train 0.4149046007985786 valid 0.4786743647065656
LOSS train 0.4149046007985786 valid 0.47906265213881455
LOSS train 0.4149046007985786 valid 0.4785630891517717
LOSS train 0.4149046007985786 valid 0.4789223576316962
LOSS train 0.4149046007985786 valid 0.47901451127641154
LOSS train 0.4149046007985786 valid 0.4791534908612569
LOSS train 0.4149046007985786 valid 0.4792173228516484
LOSS train 0.4149046007985786 valid 0.4789917520002315
LOSS train 0.4149046007985786 valid 0.4792471251456566
LOSS train 0.4149046007985786 valid 0.47924784290326106
LOSS train 0.4149046007985786 valid 0.47939967070856404
LOSS train 0.4149046007985786 valid 0.4797896616733991
LOSS train 0.4149046007985786 valid 0.4797123289032347
LOSS train 0.4149046007985786 valid 0.4796453701167167
LOSS train 0.4149046007985786 valid 0.47930452077643676
LOSS train 0.4149046007985786 valid 0.47934207431972026
LOSS train 0.4149046007985786 valid 0.47919294071493684
LOSS train 0.4149046007985786 valid 0.47881943355371925
LOSS train 0.4149046007985786 valid 0.4787653554802292
LOSS train 0.4149046007985786 valid 0.47860299777693865
LOSS train 0.4149046007985786 valid 0.47849741433606
LOSS train 0.4149046007985786 valid 0.4783205345093486
LOSS train 0.4149046007985786 valid 0.4783664361802404
LOSS train 0.4149046007985786 valid 0.4785467689590795
LOSS train 0.4149046007985786 valid 0.47867845201633386
LOSS train 0.4149046007985786 valid 0.47911714017391205
LOSS train 0.4149046007985786 valid 0.4790333112080892
LOSS train 0.4149046007985786 valid 0.47909169210944064
LOSS train 0.4149046007985786 valid 0.47919470485235227
LOSS train 0.4149046007985786 valid 0.47920431659139434
LOSS train 0.4149046007985786 valid 0.4792972528934479
LOSS train 0.4149046007985786 valid 0.47912668995559216
LOSS train 0.4149046007985786 valid 0.479475680549266
LOSS train 0.4149046007985786 valid 0.47963709493031664
LOSS train 0.4149046007985786 valid 0.47950597948202206
LOSS train 0.4149046007985786 valid 0.4796003391345342
LOSS train 0.4149046007985786 valid 0.4796113882275576
LOSS train 0.4149046007985786 valid 0.4797213539317414
LOSS train 0.4149046007985786 valid 0.47960834359862115
LOSS train 0.4149046007985786 valid 0.4798140619759974
LOSS train 0.4149046007985786 valid 0.4797419991042163
LOSS train 0.4149046007985786 valid 0.47980514184762074
LOSS train 0.4149046007985786 valid 0.4798323320832482
LOSS train 0.4149046007985786 valid 0.4798158794007403
LOSS train 0.4149046007985786 valid 0.4797395371570789
LOSS train 0.4149046007985786 valid 0.47957440881352675
LOSS train 0.4149046007985786 valid 0.4798233750915028
LOSS train 0.4149046007985786 valid 0.47991700982674956
LOSS train 0.4149046007985786 valid 0.47979886575066366
LOSS train 0.4149046007985786 valid 0.4795884895570499
LOSS train 0.4149046007985786 valid 0.47957957692635367
LOSS train 0.4149046007985786 valid 0.47966666261152346
LOSS train 0.4149046007985786 valid 0.47993257944353945
LOSS train 0.4149046007985786 valid 0.47998653081330384
LOSS train 0.4149046007985786 valid 0.480019878801988
LOSS train 0.4149046007985786 valid 0.47994989544153216
LOSS train 0.4149046007985786 valid 0.47964538092636944
LOSS train 0.4149046007985786 valid 0.47980875780086707
LOSS train 0.4149046007985786 valid 0.4796114405387728
LOSS train 0.4149046007985786 valid 0.47962650379129484
LOSS train 0.4149046007985786 valid 0.47964782671230594
LOSS train 0.4149046007985786 valid 0.4794558036385231
LOSS train 0.4149046007985786 valid 0.4796606289303821
LOSS train 0.4149046007985786 valid 0.4796411164391499
LOSS train 0.4149046007985786 valid 0.4795535467743303
LOSS train 0.4149046007985786 valid 0.47967052388758885
LOSS train 0.4149046007985786 valid 0.47971653599309694
LOSS train 0.4149046007985786 valid 0.47978390711096097
LOSS train 0.4149046007985786 valid 0.4798063525291676
LOSS train 0.4149046007985786 valid 0.4797676931196284
LOSS train 0.4149046007985786 valid 0.4797657785027526
LOSS train 0.4149046007985786 valid 0.47983546154918494
LOSS train 0.4149046007985786 valid 0.47988203634864174
LOSS train 0.4149046007985786 valid 0.479978862295457
LOSS train 0.4149046007985786 valid 0.47996367833930065
LOSS train 0.4149046007985786 valid 0.4801622503183105
LOSS train 0.4149046007985786 valid 0.48038229184452763
LOSS train 0.4149046007985786 valid 0.4803881488136343
LOSS train 0.4149046007985786 valid 0.4803730099725082
LOSS train 0.4149046007985786 valid 0.48040726594626904
LOSS train 0.4149046007985786 valid 0.48044450733396743
LOSS train 0.4149046007985786 valid 0.480435562740385
LOSS train 0.4149046007985786 valid 0.48050285002733645
LOSS train 0.4149046007985786 valid 0.48048435399929684
LOSS train 0.4149046007985786 valid 0.4805998954450199
LOSS train 0.4149046007985786 valid 0.48073762616385585
LOSS train 0.4149046007985786 valid 0.4807647029300789
LOSS train 0.4149046007985786 valid 0.48081897366149673
LOSS train 0.4149046007985786 valid 0.48069591212681945
LOSS train 0.4149046007985786 valid 0.4806352513722884
LOSS train 0.4149046007985786 valid 0.4808206767477888
LOSS train 0.4149046007985786 valid 0.4807413387096534
LOSS train 0.4149046007985786 valid 0.48063138617744927
LOSS train 0.4149046007985786 valid 0.4806061023924531
LOSS train 0.4149046007985786 valid 0.4804562386359131
LOSS train 0.4149046007985786 valid 0.48030427284538746
LOSS train 0.4149046007985786 valid 0.4805947189756449
LOSS train 0.4149046007985786 valid 0.4805005223544176
LOSS train 0.4149046007985786 valid 0.4804422402823413
LOSS train 0.4149046007985786 valid 0.4805758530732061
LOSS train 0.4149046007985786 valid 0.4805666294633126
LOSS train 0.4149046007985786 valid 0.48056037602870444
LOSS train 0.4149046007985786 valid 0.480605582114656
LOSS train 0.4149046007985786 valid 0.4805813288736728
LOSS train 0.4149046007985786 valid 0.48060726676600046
LOSS train 0.4149046007985786 valid 0.4808665693998337
LOSS train 0.4149046007985786 valid 0.48096577235427035
LOSS train 0.4149046007985786 valid 0.48122894894036033
LOSS train 0.4149046007985786 valid 0.4811051361881226
LOSS train 0.4149046007985786 valid 0.48132077105871335
LOSS train 0.4149046007985786 valid 0.4813188018752079
LOSS train 0.4149046007985786 valid 0.4813051534583792
LOSS train 0.4149046007985786 valid 0.4812816925317861
LOSS train 0.4149046007985786 valid 0.48134183375410333
LOSS train 0.4149046007985786 valid 0.4813126051748121
LOSS train 0.4149046007985786 valid 0.48115136692157157
LOSS train 0.4149046007985786 valid 0.4811867228869734
LOSS train 0.4149046007985786 valid 0.4811183319974492
LOSS train 0.4149046007985786 valid 0.4810628607699173
LOSS train 0.4149046007985786 valid 0.48098191596341855
LOSS train 0.4149046007985786 valid 0.48099652371316587
LOSS train 0.4149046007985786 valid 0.48116908037572875
LOSS train 0.4149046007985786 valid 0.481371354744229
LOSS train 0.4149046007985786 valid 0.48148481681275723
LOSS train 0.4149046007985786 valid 0.4817327416076093
LOSS train 0.4149046007985786 valid 0.48165254107228034
LOSS train 0.4149046007985786 valid 0.4817669796327823
LOSS train 0.4149046007985786 valid 0.48184500897631927
LOSS train 0.4149046007985786 valid 0.48186717987497213
LOSS train 0.4149046007985786 valid 0.48188776789355453
LOSS train 0.4149046007985786 valid 0.481748274456371
LOSS train 0.4149046007985786 valid 0.4817183369743651
LOSS train 0.4149046007985786 valid 0.4818058683123399
LOSS train 0.4149046007985786 valid 0.48178306993820685
LOSS train 0.4149046007985786 valid 0.4818815567587439
LOSS train 0.4149046007985786 valid 0.48175073244741984
LOSS train 0.4149046007985786 valid 0.48158591147843627
LOSS train 0.4149046007985786 valid 0.4815756034977893
LOSS train 0.4149046007985786 valid 0.48160058765445074
LOSS train 0.4149046007985786 valid 0.4816549796033913
LOSS train 0.4149046007985786 valid 0.48160352518683985
LOSS train 0.4149046007985786 valid 0.4814671201931013
LOSS train 0.4149046007985786 valid 0.481471071052219
LOSS train 0.4149046007985786 valid 0.4813995021912787
LOSS train 0.4149046007985786 valid 0.48150633548782773
LOSS train 0.4149046007985786 valid 0.4815056829616941
LOSS train 0.4149046007985786 valid 0.48132562719259886
LOSS train 0.4149046007985786 valid 0.4813696654283837
LOSS train 0.4149046007985786 valid 0.48124279615822096
LOSS train 0.4149046007985786 valid 0.48132972378714556
LOSS train 0.4149046007985786 valid 0.48146553150678084
LOSS train 0.4149046007985786 valid 0.4813914049316097
LOSS train 0.4149046007985786 valid 0.4814212841016275
LOSS train 0.4149046007985786 valid 0.48130308471670086
LOSS train 0.4149046007985786 valid 0.48139051559776763
LOSS train 0.4149046007985786 valid 0.48142350822687147
LOSS train 0.4149046007985786 valid 0.48142204074764566
LOSS train 0.4149046007985786 valid 0.48129445965716383
LOSS train 0.4149046007985786 valid 0.4812343234669651
LOSS train 0.4149046007985786 valid 0.48128026870912627
LOSS train 0.4149046007985786 valid 0.48125516948152763
LOSS train 0.4149046007985786 valid 0.4812873532764273
LOSS train 0.4149046007985786 valid 0.48127349191845825
LOSS train 0.4149046007985786 valid 0.48117176511070947
LOSS train 0.4149046007985786 valid 0.48117173846485545
LOSS train 0.4149046007985786 valid 0.4811896575074042
LOSS train 0.4149046007985786 valid 0.48118174449807194
LOSS train 0.4149046007985786 valid 0.48119802333605594
LOSS train 0.4149046007985786 valid 0.4813150738755735
LOSS train 0.4149046007985786 valid 0.48129006366061555
LOSS train 0.4149046007985786 valid 0.48127720053233797
LOSS train 0.4149046007985786 valid 0.48114797227744815
LOSS train 0.4149046007985786 valid 0.48118521099210915
LOSS train 0.4149046007985786 valid 0.481189673801638
LOSS train 0.4149046007985786 valid 0.48118571446607106
LOSS train 0.4149046007985786 valid 0.48113093338906765
LOSS train 0.4149046007985786 valid 0.48115350106423516
LOSS train 0.4149046007985786 valid 0.4811688590308894
LOSS train 0.4149046007985786 valid 0.48115627518379284
LOSS train 0.4149046007985786 valid 0.4811492282667278
LOSS train 0.4149046007985786 valid 0.48108863573807936
LOSS train 0.4149046007985786 valid 0.48118843476465145
LOSS train 0.4149046007985786 valid 0.4813722113221428
LOSS train 0.4149046007985786 valid 0.48134895523146887
LOSS train 0.4149046007985786 valid 0.4813743394921253
LOSS train 0.4149046007985786 valid 0.48132670476581113
LOSS train 0.4149046007985786 valid 0.4812858865520385
LOSS train 0.4149046007985786 valid 0.48115822466382063
LOSS train 0.4149046007985786 valid 0.4811836900832775
LOSS train 0.4149046007985786 valid 0.4812419404705128
LOSS train 0.4149046007985786 valid 0.4812417920845658
LOSS train 0.4149046007985786 valid 0.48118974907057627
LOSS train 0.4149046007985786 valid 0.48118471948966074
LOSS train 0.4149046007985786 valid 0.4812289436717005
LOSS train 0.4149046007985786 valid 0.4811569291405973
LOSS train 0.4149046007985786 valid 0.4811862411744454
LOSS train 0.4149046007985786 valid 0.4810196958329321
LOSS train 0.4149046007985786 valid 0.4808612031894818
LOSS train 0.4149046007985786 valid 0.4808580600833059
LOSS train 0.4149046007985786 valid 0.4810578616899113
LOSS train 0.4149046007985786 valid 0.48111145271771194
LOSS train 0.4149046007985786 valid 0.48111635722176876
LOSS train 0.4149046007985786 valid 0.4810300472833925
LOSS train 0.4149046007985786 valid 0.48090766798490764
LOSS train 0.4149046007985786 valid 0.48091692176452683
LOSS train 0.4149046007985786 valid 0.4807706810746874
LOSS train 0.4149046007985786 valid 0.4807259234947357
LOSS train 0.4149046007985786 valid 0.48075235643508757
LOSS train 0.4149046007985786 valid 0.48077714493862295
LOSS train 0.4149046007985786 valid 0.480820123001007
LOSS train 0.4149046007985786 valid 0.48083474770398205
LOSS train 0.4149046007985786 valid 0.48083506013905064
LOSS train 0.4149046007985786 valid 0.48077186341045286
LOSS train 0.4149046007985786 valid 0.48070123916564705
LOSS train 0.4149046007985786 valid 0.48073725024637737
LOSS train 0.4149046007985786 valid 0.4807739357981417
LOSS train 0.4149046007985786 valid 0.48080401663304695
LOSS train 0.4149046007985786 valid 0.4809583887375521
LOSS train 0.4149046007985786 valid 0.4808719466047839
LOSS train 0.4149046007985786 valid 0.4808275742190225
LOSS train 0.4149046007985786 valid 0.4808890071633744
LOSS train 0.4149046007985786 valid 0.48083886715883767
LOSS train 0.4149046007985786 valid 0.48075750762500297
LOSS train 0.4149046007985786 valid 0.48075100957699446
LOSS train 0.4149046007985786 valid 0.48072411721637903
EPOCH 3:
  batch 1 loss: 0.36922305822372437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.39161112904548645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.4040215114752452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4082145392894745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4141089618206024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.41441381474335987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.41071303827422007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.41540898755192757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.41417815619044834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4131068080663681
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.41103778914971784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.41046152263879776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.40743385140712446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.406098057116781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4077820062637329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.40888814255595207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4092732071876526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4087734752231174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4088041249074434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4076643943786621
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.406780515398298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.40714615177024494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.40812491463578265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40873174990216893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4092667257785797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.41049946271456206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4106358157263862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.41015041193791796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.41117493756886186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.41112919052441915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.41189895906756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4118306543678045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4116206476182649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.41180629677632274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.41243747132165093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4124871798687511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4120233155585624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4118627905845642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4127415678439996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.41309144869446757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.41291107637126273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.41210961696647463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.41306150375410566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.41232400319793006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.41281647549735173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4119204023609991
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4123277784662044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.41216667244831723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.412274423910647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4125452220439911
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4122970221089382
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4121360033750534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4121401861028851
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.41166390092284594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.41157511472702024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.41172613576054573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4123496564856747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.41169321588401137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4119568936905618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.41193253646294276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.41136171436700664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.41128970009665333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.41111683892825296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.41136205149814487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.41132745696948125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4114001158512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4108561668823014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.41071560496793075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4107461256393488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.41136280255658286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4114175346535696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.41100644113288987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4108776429744616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.41101446788053253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.41089429418245954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4111837246700337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4111539717618521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.41093777387570113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4111490408076516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.41122606918215754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.41147147799715583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4115197734861839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4113243419721902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4111266111334165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4111620331511778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.41116062153217403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.41104514845486345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4112641276283698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4111131282334917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.41122355858484905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4108951655063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4108535822318948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4111272218406841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4112075342142836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.41098249993826214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.411115041313072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4108335689171073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4111957233779284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.41144022586369755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4116178569197655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.41141078938352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4114394748912138
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.41186571584164516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4117047176338159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.41167993971279687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.41152906221038893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.41165641005908216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.41197913222842747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4119753066552888
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.41237671781669966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4120474656422933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.41193849965929985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.41171381325848333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4116883058297007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4113458591958751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4112388789653778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.41125271106377626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4110785876795397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4108550145345576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4108973662058512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4106646569307185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.41058139429717766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.41102874521317523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.41103926637480337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4111155381202698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4110179619183616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4109032834608724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4111333843320608
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.41119998647261036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.41119114343936625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4110033252767024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4108331456328883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4109053593829162
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.41078942925182743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.41070657836066354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4107513454030542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.41088133463024223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4107342373201813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4110374800164065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.41106500093426024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4106386329265351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4106419348800686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.41095296298707285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.41117662750184536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.41131071057812923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.41125389239559434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.41122871981997067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.41130327231980657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.41136168153493996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.41138442476590475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.41142407434665607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.41121400265317215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.41108006784339357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4109114133692407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4109801128987343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.41105849716143733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.41115725894642485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4110207750072962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.41123235000754305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4111335430294275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.41093675283171377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.41079196002748275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.41096299155358157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4107708204083326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4106299006577694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4105774946959622
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.41018842901298386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.41017751147349674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4100943066664701
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4100837542730219
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4100894448701401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.40984490011320557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4095960099228545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.40958070772132654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4095178748880114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4094394582577727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4092766812628945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.40909983468859384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4091642572227137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4090074850453271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4090361397569351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4091576439338726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4089842399612802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4089358565600022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4089699480984662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.40887621605908997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.408716050380054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4084884078895792
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4084126745897626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.40841313224089776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4084031959478768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.408323732825617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4082577004642684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.40820142334883974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4081956702929277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4081862859275876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.40829889922577717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4087317775596272
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.40863777794430606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4086159399151802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.408638136896921
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4086052748826471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.40874852364873654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.40871503715421637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4086750090122223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.40871755084366473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.40876915374239864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4085897906468465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.40857665034002094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.40859665515876953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4086168943705717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.40867411345243454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4084653522766812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40830154577705347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.40817774326302286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4081479178534614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.40822312441839054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4082362608078423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.40840938265465165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.40846520188179886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4083786991117227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.40827924133958043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4082879527000034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.408592459479613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.408425466881858
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4082800913437278
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4083913512166901
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4083040631131122
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4083263879259601
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4083710968494415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.40843810973229344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4083978346195714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4082598950985675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4082565252852236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4083642341989152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4084895772196479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40868446482384757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.408755354144994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.40882901728901405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4088102793941895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4087151092365075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.40864810039681837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4087775532355524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4087251320969863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.40881265949229806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.40881441909123245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4088317922011078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.40889747573002694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.40885850858975603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4090144416093826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.40901545877475665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4090190947292343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.40897105439849524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4089216175745791
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.40903504023364945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4089917272794992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.40891179222077245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.40894400692263316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.409102131386061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.40918842886502926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.40907093471494216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.40905381261392404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4089964899046793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4089016005622618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.408748475335679
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4087916898324077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.40871992383556865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4087240228902048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40875968580795485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.40869323909282684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4087570690140953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4086185790160123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4086262930880536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4084920491615351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.408307429226962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4083901216154513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4083470704323118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.40819332871934494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.40834022988982527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.40825239643454553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4082226586723667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4081462229608644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.40813883696765024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.40807484142797096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4081738409243132
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4081098426888873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.4081046874099492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4081708330454098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.40832354979119084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.40843103003912956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.40845301982873083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40839830643101915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4084248492945583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.40839257674152346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4084588493331004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.40840202086680644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4085151866228894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4083530086798956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.40833678323289624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4083458919326464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.40837992000025375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.40828161928432666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.40829731312522005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4082555465008083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.40815612839870763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4081154061493531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4081056309251133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.40796932800636665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.40809978183033396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4081689084729841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.40818125728242266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.40818509698296207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4082265019226379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4081246806367947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.40813023429068307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4081646317168127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.40816785268227007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4081019178126593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4080974560546277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4080349483527243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4080193363060461
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4079714504458149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.40798860548450483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.40797802511556647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4079612790621244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4079619827080358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4079451385076622
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4079500250518322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.40784069134833967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4078593466318015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4079622544370749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.40784374121800965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4079221763589361
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.40790556888737367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4079166050277539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4078852411891733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4077759312592911
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4078261102797717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.40781016617046345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40798551720731396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4079007783418527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.40799745080763833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.40804113339057124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.40794028047212333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4079282183578049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.407862991266857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4078850831181584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.40787862832176275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4078214072907893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4077542843137469
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.40768755110580357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.40772601758891885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.407777339220047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.40765495269985524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4076671309034589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.40761413743321817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.40764552780560087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4076477831135915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4077068762360841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4077246448232068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4077174686659076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4078254733461043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.40782726582745216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.40781285621962704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4079274532729632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.40788515042411827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4078804292698322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.40791372930550057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4079425775100222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.40796294429817714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.40796730139184834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4079082109915313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4078826882724148
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4078764235750239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4078148788611094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.407790795919743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4078209406501102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4078359971286128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.40779927404386074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4077532628649159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40771453203804536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.40769042612994527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4077734475658706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.407806994781519
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4077061770024238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4077638038699491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.40775083294210507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.40773475738530307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4076685743037717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4076050463395241
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.40754436585299497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.40747266422425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.40752419965867775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4074234119072783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4073573810390279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.40733583294080966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.40727550294297166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40734501669754336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4073382787835927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4074788188934326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4073910552664588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.40719510214542276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.40708284564408714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.40707822380089526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.407093980282913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.40705679349711377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.40699221966307636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4069497653228395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4069609606324315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.40697340470988574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.40706452763573675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.40699792190373524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4069589635506092
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.40701397684749197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4069532428161207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4069844569581059
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.40693011022300174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.40687580349627867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.40691656386368596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.40686204412153787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4069135779439695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.40687459071665577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4068979163682771
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4069035551598612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.40689805486622976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4068607729225651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.40692004903418116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.40688736117053254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.40674695483732337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.40686224567335705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4069224831814556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4069834320495526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4068219813133222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.40684306758889405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4067719212893782
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.40680458847809275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.40681078620851724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.40675246735958204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.40664935023746623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.406645187667825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.40666551594020556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4067111386837463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4067863451304339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4068297616936065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4069823212837905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4069885094336865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.406934922306863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4069991381173687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.407013101474214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.40699830419487426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.40696064932911996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.40695860975347786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4069469780321942
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4069311998226569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.40685549699343165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4068763525993155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.40684905074357464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.40690613593336794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4069220895081564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4069323001348454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.40688813547250247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.40685455565586753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4068320399355425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.40684510311432953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4069011200499791
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.406958645121734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4069172517262894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4068589901440164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.40691245637977047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4069841891527176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4069241590307523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4070179024869103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4070179024869103 valid 0.4531843662261963
LOSS train 0.4070179024869103 valid 0.45270904898643494
LOSS train 0.4070179024869103 valid 0.4728393356005351
LOSS train 0.4070179024869103 valid 0.4688097909092903
LOSS train 0.4070179024869103 valid 0.46595818400382993
LOSS train 0.4070179024869103 valid 0.4686027516921361
LOSS train 0.4070179024869103 valid 0.4689405347619738
LOSS train 0.4070179024869103 valid 0.4680379219353199
LOSS train 0.4070179024869103 valid 0.46174658338228863
LOSS train 0.4070179024869103 valid 0.4649874776601791
LOSS train 0.4070179024869103 valid 0.46844162995165045
LOSS train 0.4070179024869103 valid 0.46712355067332584
LOSS train 0.4070179024869103 valid 0.46924466582444996
LOSS train 0.4070179024869103 valid 0.46923097329480307
LOSS train 0.4070179024869103 valid 0.4677018562952677
LOSS train 0.4070179024869103 valid 0.46965647116303444
LOSS train 0.4070179024869103 valid 0.4721566052997814
LOSS train 0.4070179024869103 valid 0.4731372859742906
LOSS train 0.4070179024869103 valid 0.473759274733694
LOSS train 0.4070179024869103 valid 0.4753823548555374
LOSS train 0.4070179024869103 valid 0.4742982004370008
LOSS train 0.4070179024869103 valid 0.47144795141436835
LOSS train 0.4070179024869103 valid 0.4723524749279022
LOSS train 0.4070179024869103 valid 0.4707683262725671
LOSS train 0.4070179024869103 valid 0.46958799719810485
LOSS train 0.4070179024869103 valid 0.4690183401107788
LOSS train 0.4070179024869103 valid 0.46837622037640325
LOSS train 0.4070179024869103 valid 0.4690438647355352
LOSS train 0.4070179024869103 valid 0.4682200561309683
LOSS train 0.4070179024869103 valid 0.4691439876953761
LOSS train 0.4070179024869103 valid 0.4708736029363448
LOSS train 0.4070179024869103 valid 0.4708459237590432
LOSS train 0.4070179024869103 valid 0.47208307457692694
LOSS train 0.4070179024869103 valid 0.4714036084273282
LOSS train 0.4070179024869103 valid 0.47226320590291704
LOSS train 0.4070179024869103 valid 0.47244493580526775
LOSS train 0.4070179024869103 valid 0.47291985154151917
LOSS train 0.4070179024869103 valid 0.4741282063095193
LOSS train 0.4070179024869103 valid 0.47360329521008027
LOSS train 0.4070179024869103 valid 0.4751398704946041
LOSS train 0.4070179024869103 valid 0.4750286776845048
LOSS train 0.4070179024869103 valid 0.47611516856011893
LOSS train 0.4070179024869103 valid 0.47624325890873753
LOSS train 0.4070179024869103 valid 0.47673759338530625
LOSS train 0.4070179024869103 valid 0.47694655855496726
LOSS train 0.4070179024869103 valid 0.47743662025617517
LOSS train 0.4070179024869103 valid 0.47669249138933545
LOSS train 0.4070179024869103 valid 0.47709545493125916
LOSS train 0.4070179024869103 valid 0.47765700184569065
LOSS train 0.4070179024869103 valid 0.4772926092147827
LOSS train 0.4070179024869103 valid 0.477959229665644
LOSS train 0.4070179024869103 valid 0.47766539798333096
LOSS train 0.4070179024869103 valid 0.4771409237159873
LOSS train 0.4070179024869103 valid 0.47721247871716815
LOSS train 0.4070179024869103 valid 0.4766715531999415
LOSS train 0.4070179024869103 valid 0.4763567719076361
LOSS train 0.4070179024869103 valid 0.4762442462276994
LOSS train 0.4070179024869103 valid 0.47609496887387903
LOSS train 0.4070179024869103 valid 0.47672660219467294
LOSS train 0.4070179024869103 valid 0.47608355631430943
LOSS train 0.4070179024869103 valid 0.47488989155800615
LOSS train 0.4070179024869103 valid 0.4761010730458844
LOSS train 0.4070179024869103 valid 0.4764346546596951
LOSS train 0.4070179024869103 valid 0.4770111897960305
LOSS train 0.4070179024869103 valid 0.47727218407850996
LOSS train 0.4070179024869103 valid 0.4772856781880061
LOSS train 0.4070179024869103 valid 0.4768629252020992
LOSS train 0.4070179024869103 valid 0.47632694595000324
LOSS train 0.4070179024869103 valid 0.47598371643950976
LOSS train 0.4070179024869103 valid 0.4755652742726462
LOSS train 0.4070179024869103 valid 0.4751336452826648
LOSS train 0.4070179024869103 valid 0.47488918610745007
LOSS train 0.4070179024869103 valid 0.4752296499193531
LOSS train 0.4070179024869103 valid 0.4751684661652591
LOSS train 0.4070179024869103 valid 0.47462587952613833
LOSS train 0.4070179024869103 valid 0.47478827677275004
LOSS train 0.4070179024869103 valid 0.47456897001761894
LOSS train 0.4070179024869103 valid 0.47454479107489955
LOSS train 0.4070179024869103 valid 0.4742486250551441
LOSS train 0.4070179024869103 valid 0.4742230664938688
LOSS train 0.4070179024869103 valid 0.47375642591052586
LOSS train 0.4070179024869103 valid 0.47403341131966287
LOSS train 0.4070179024869103 valid 0.47381586769977246
LOSS train 0.4070179024869103 valid 0.4738915591012864
LOSS train 0.4070179024869103 valid 0.474009730535395
LOSS train 0.4070179024869103 valid 0.47353582777256187
LOSS train 0.4070179024869103 valid 0.47312825575642203
LOSS train 0.4070179024869103 valid 0.4726036170666868
LOSS train 0.4070179024869103 valid 0.47299769219387783
LOSS train 0.4070179024869103 valid 0.4730026433865229
LOSS train 0.4070179024869103 valid 0.4726589148516183
LOSS train 0.4070179024869103 valid 0.4723115398184113
LOSS train 0.4070179024869103 valid 0.4717302940865999
LOSS train 0.4070179024869103 valid 0.4709486127533811
LOSS train 0.4070179024869103 valid 0.47051494905823155
LOSS train 0.4070179024869103 valid 0.47082064642260474
LOSS train 0.4070179024869103 valid 0.4712340275651401
LOSS train 0.4070179024869103 valid 0.47119905176211374
LOSS train 0.4070179024869103 valid 0.4714531380720813
LOSS train 0.4070179024869103 valid 0.47178956747055056
LOSS train 0.4070179024869103 valid 0.47192388979515226
LOSS train 0.4070179024869103 valid 0.47197194339013565
LOSS train 0.4070179024869103 valid 0.47258168082792784
LOSS train 0.4070179024869103 valid 0.47243552282452583
LOSS train 0.4070179024869103 valid 0.4724620452948979
LOSS train 0.4070179024869103 valid 0.47263288863424985
LOSS train 0.4070179024869103 valid 0.47228674938745585
LOSS train 0.4070179024869103 valid 0.4726753701214437
LOSS train 0.4070179024869103 valid 0.47283350081618775
LOSS train 0.4070179024869103 valid 0.47294437912377446
LOSS train 0.4070179024869103 valid 0.47299965625410684
LOSS train 0.4070179024869103 valid 0.4728074387780258
LOSS train 0.4070179024869103 valid 0.4727265871731581
LOSS train 0.4070179024869103 valid 0.4725244871357031
LOSS train 0.4070179024869103 valid 0.4725304204484691
LOSS train 0.4070179024869103 valid 0.4724618946683818
LOSS train 0.4070179024869103 valid 0.4725035388245542
LOSS train 0.4070179024869103 valid 0.47231545412944537
LOSS train 0.4070179024869103 valid 0.47201392605525105
LOSS train 0.4070179024869103 valid 0.4719229593873024
LOSS train 0.4070179024869103 valid 0.47177249907462065
LOSS train 0.4070179024869103 valid 0.4716756668735723
LOSS train 0.4070179024869103 valid 0.4717435092945409
LOSS train 0.4070179024869103 valid 0.47206507887571086
LOSS train 0.4070179024869103 valid 0.47195142817497254
LOSS train 0.4070179024869103 valid 0.4718626941007281
LOSS train 0.4070179024869103 valid 0.4723291054485351
LOSS train 0.4070179024869103 valid 0.47243893262930214
LOSS train 0.4070179024869103 valid 0.4726330016472543
LOSS train 0.4070179024869103 valid 0.47238145287220296
LOSS train 0.4070179024869103 valid 0.4723677798991895
LOSS train 0.4070179024869103 valid 0.47229995759147586
LOSS train 0.4070179024869103 valid 0.47212615766023336
LOSS train 0.4070179024869103 valid 0.47234315703164287
LOSS train 0.4070179024869103 valid 0.47256402086328575
LOSS train 0.4070179024869103 valid 0.4726126638843733
LOSS train 0.4070179024869103 valid 0.4724139458071576
LOSS train 0.4070179024869103 valid 0.47225436049958935
LOSS train 0.4070179024869103 valid 0.4719348144617012
LOSS train 0.4070179024869103 valid 0.47209092101880484
LOSS train 0.4070179024869103 valid 0.4720973323845694
LOSS train 0.4070179024869103 valid 0.47239889624253123
LOSS train 0.4070179024869103 valid 0.4720393794399875
LOSS train 0.4070179024869103 valid 0.4720686243640052
LOSS train 0.4070179024869103 valid 0.47186405617615274
LOSS train 0.4070179024869103 valid 0.47223467573727645
LOSS train 0.4070179024869103 valid 0.4717605738412766
LOSS train 0.4070179024869103 valid 0.4721471892820822
LOSS train 0.4070179024869103 valid 0.47223127028286055
LOSS train 0.4070179024869103 valid 0.47237685044606526
LOSS train 0.4070179024869103 valid 0.472460643345157
LOSS train 0.4070179024869103 valid 0.47220810326306445
LOSS train 0.4070179024869103 valid 0.47246892253557843
LOSS train 0.4070179024869103 valid 0.47246277816109844
LOSS train 0.4070179024869103 valid 0.4726156436627911
LOSS train 0.4070179024869103 valid 0.4729788756141296
LOSS train 0.4070179024869103 valid 0.47289047746142004
LOSS train 0.4070179024869103 valid 0.47281443261647527
LOSS train 0.4070179024869103 valid 0.4724814312637977
LOSS train 0.4070179024869103 valid 0.4725156528875232
LOSS train 0.4070179024869103 valid 0.4723786049007629
LOSS train 0.4070179024869103 valid 0.4720045523143109
LOSS train 0.4070179024869103 valid 0.47193875543178954
LOSS train 0.4070179024869103 valid 0.47177335601754306
LOSS train 0.4070179024869103 valid 0.47165292591759655
LOSS train 0.4070179024869103 valid 0.47146938256470555
LOSS train 0.4070179024869103 valid 0.47153208641234984
LOSS train 0.4070179024869103 valid 0.4717270625489099
LOSS train 0.4070179024869103 valid 0.47186891161478484
LOSS train 0.4070179024869103 valid 0.47230992615222933
LOSS train 0.4070179024869103 valid 0.47221266125377853
LOSS train 0.4070179024869103 valid 0.472261598810207
LOSS train 0.4070179024869103 valid 0.4723729983919618
LOSS train 0.4070179024869103 valid 0.4723821445100609
LOSS train 0.4070179024869103 valid 0.4724798241683415
LOSS train 0.4070179024869103 valid 0.47232792069288815
LOSS train 0.4070179024869103 valid 0.4726842865768799
LOSS train 0.4070179024869103 valid 0.4728556802768386
LOSS train 0.4070179024869103 valid 0.472714701344847
LOSS train 0.4070179024869103 valid 0.47279262161917157
LOSS train 0.4070179024869103 valid 0.47279185978747207
LOSS train 0.4070179024869103 valid 0.47290277824952054
LOSS train 0.4070179024869103 valid 0.47278838486619335
LOSS train 0.4070179024869103 valid 0.4730044180608314
LOSS train 0.4070179024869103 valid 0.4729404091835022
LOSS train 0.4070179024869103 valid 0.47301550449863555
LOSS train 0.4070179024869103 valid 0.4730417706112173
LOSS train 0.4070179024869103 valid 0.4730320861364933
LOSS train 0.4070179024869103 valid 0.47294916456969327
LOSS train 0.4070179024869103 valid 0.47278276901496086
LOSS train 0.4070179024869103 valid 0.473040962406478
LOSS train 0.4070179024869103 valid 0.47313933866098523
LOSS train 0.4070179024869103 valid 0.47301378228503804
LOSS train 0.4070179024869103 valid 0.47280898859205933
LOSS train 0.4070179024869103 valid 0.47279138213548905
LOSS train 0.4070179024869103 valid 0.47289488768699217
LOSS train 0.4070179024869103 valid 0.47317786159249126
LOSS train 0.4070179024869103 valid 0.4732250787995078
LOSS train 0.4070179024869103 valid 0.47326392474486
LOSS train 0.4070179024869103 valid 0.4731947745382786
LOSS train 0.4070179024869103 valid 0.47288253577194406
LOSS train 0.4070179024869103 valid 0.47305345018901446
LOSS train 0.4070179024869103 valid 0.4728666520471056
LOSS train 0.4070179024869103 valid 0.47289248278328017
LOSS train 0.4070179024869103 valid 0.4729064265402352
LOSS train 0.4070179024869103 valid 0.47269638750738313
LOSS train 0.4070179024869103 valid 0.47291123679870567
LOSS train 0.4070179024869103 valid 0.4729026746577941
LOSS train 0.4070179024869103 valid 0.47279675811101374
LOSS train 0.4070179024869103 valid 0.47291508827890666
LOSS train 0.4070179024869103 valid 0.4729712342763964
LOSS train 0.4070179024869103 valid 0.4730373232994439
LOSS train 0.4070179024869103 valid 0.47305735092207857
LOSS train 0.4070179024869103 valid 0.4730186146274905
LOSS train 0.4070179024869103 valid 0.47303251873615176
LOSS train 0.4070179024869103 valid 0.47309177217108234
LOSS train 0.4070179024869103 valid 0.4731360327812933
LOSS train 0.4070179024869103 valid 0.4732449586511752
LOSS train 0.4070179024869103 valid 0.47322707565407773
LOSS train 0.4070179024869103 valid 0.47342218201268804
LOSS train 0.4070179024869103 valid 0.4736401968681974
LOSS train 0.4070179024869103 valid 0.4736429656948055
LOSS train 0.4070179024869103 valid 0.4736441651801892
LOSS train 0.4070179024869103 valid 0.47368079689996584
LOSS train 0.4070179024869103 valid 0.47371625158521863
LOSS train 0.4070179024869103 valid 0.47370215010853994
LOSS train 0.4070179024869103 valid 0.47376751138250206
LOSS train 0.4070179024869103 valid 0.47373895556257484
LOSS train 0.4070179024869103 valid 0.47385581690151096
LOSS train 0.4070179024869103 valid 0.47398733600326204
LOSS train 0.4070179024869103 valid 0.4740397091551777
LOSS train 0.4070179024869103 valid 0.4740940972134985
LOSS train 0.4070179024869103 valid 0.4739826600439047
LOSS train 0.4070179024869103 valid 0.4739257596496843
LOSS train 0.4070179024869103 valid 0.4741138787979775
LOSS train 0.4070179024869103 valid 0.4740190374649177
LOSS train 0.4070179024869103 valid 0.4739171150867446
LOSS train 0.4070179024869103 valid 0.47388337101756023
LOSS train 0.4070179024869103 valid 0.47372529010393627
LOSS train 0.4070179024869103 valid 0.47357078529894353
LOSS train 0.4070179024869103 valid 0.47386032404741313
LOSS train 0.4070179024869103 valid 0.4737557575476071
LOSS train 0.4070179024869103 valid 0.4736861538739852
LOSS train 0.4070179024869103 valid 0.4738188946589095
LOSS train 0.4070179024869103 valid 0.4738200227825009
LOSS train 0.4070179024869103 valid 0.47381204124388654
LOSS train 0.4070179024869103 valid 0.4738681036451085
LOSS train 0.4070179024869103 valid 0.4738373579757829
LOSS train 0.4070179024869103 valid 0.4738635529715373
LOSS train 0.4070179024869103 valid 0.4741298476457596
LOSS train 0.4070179024869103 valid 0.4742272321683952
LOSS train 0.4070179024869103 valid 0.4744945718418984
LOSS train 0.4070179024869103 valid 0.4743585011704637
LOSS train 0.4070179024869103 valid 0.4745677840991283
LOSS train 0.4070179024869103 valid 0.4745704260526919
LOSS train 0.4070179024869103 valid 0.47454358148388565
LOSS train 0.4070179024869103 valid 0.47452570735712457
LOSS train 0.4070179024869103 valid 0.4745769183072009
LOSS train 0.4070179024869103 valid 0.47454068202769895
LOSS train 0.4070179024869103 valid 0.4743830585708985
LOSS train 0.4070179024869103 valid 0.47441945701723354
LOSS train 0.4070179024869103 valid 0.4743526568849578
LOSS train 0.4070179024869103 valid 0.4742945854201516
LOSS train 0.4070179024869103 valid 0.47421668808568607
LOSS train 0.4070179024869103 valid 0.4742251582865445
LOSS train 0.4070179024869103 valid 0.47439031829511313
LOSS train 0.4070179024869103 valid 0.47459111521753033
LOSS train 0.4070179024869103 valid 0.47472226286112373
LOSS train 0.4070179024869103 valid 0.4749660367859341
LOSS train 0.4070179024869103 valid 0.4748905563796008
LOSS train 0.4070179024869103 valid 0.4749954670557677
LOSS train 0.4070179024869103 valid 0.4750834210392307
LOSS train 0.4070179024869103 valid 0.47511285685357596
LOSS train 0.4070179024869103 valid 0.4751336561502331
LOSS train 0.4070179024869103 valid 0.47500833944840865
LOSS train 0.4070179024869103 valid 0.47498749110145844
LOSS train 0.4070179024869103 valid 0.47507391660222076
LOSS train 0.4070179024869103 valid 0.4750396729373246
LOSS train 0.4070179024869103 valid 0.4751301300995666
LOSS train 0.4070179024869103 valid 0.4749993183783123
LOSS train 0.4070179024869103 valid 0.47482426077445633
LOSS train 0.4070179024869103 valid 0.47480676391868726
LOSS train 0.4070179024869103 valid 0.4748243233550985
LOSS train 0.4070179024869103 valid 0.4748819280468242
LOSS train 0.4070179024869103 valid 0.4748297382865036
LOSS train 0.4070179024869103 valid 0.4746851969015348
LOSS train 0.4070179024869103 valid 0.474701848283462
LOSS train 0.4070179024869103 valid 0.4746259254299932
LOSS train 0.4070179024869103 valid 0.4747337422568905
LOSS train 0.4070179024869103 valid 0.47473552021487003
LOSS train 0.4070179024869103 valid 0.4745603907354099
LOSS train 0.4070179024869103 valid 0.47459984999405197
LOSS train 0.4070179024869103 valid 0.4744646208481577
LOSS train 0.4070179024869103 valid 0.47453961931929295
LOSS train 0.4070179024869103 valid 0.4746903197240021
LOSS train 0.4070179024869103 valid 0.4746185478729171
LOSS train 0.4070179024869103 valid 0.47464822257809364
LOSS train 0.4070179024869103 valid 0.4745217367706683
LOSS train 0.4070179024869103 valid 0.4746093698169874
LOSS train 0.4070179024869103 valid 0.47462774217128756
LOSS train 0.4070179024869103 valid 0.47462842709994396
LOSS train 0.4070179024869103 valid 0.4744962389698092
LOSS train 0.4070179024869103 valid 0.47442921956773637
LOSS train 0.4070179024869103 valid 0.4744828859050023
LOSS train 0.4070179024869103 valid 0.4744576563600634
LOSS train 0.4070179024869103 valid 0.4744848551508648
LOSS train 0.4070179024869103 valid 0.47446128570684004
LOSS train 0.4070179024869103 valid 0.4743581107491023
LOSS train 0.4070179024869103 valid 0.4743558505013537
LOSS train 0.4070179024869103 valid 0.4743808157982365
LOSS train 0.4070179024869103 valid 0.4743760272237649
LOSS train 0.4070179024869103 valid 0.4743868952187208
LOSS train 0.4070179024869103 valid 0.4745038762069739
LOSS train 0.4070179024869103 valid 0.4744735112425628
LOSS train 0.4070179024869103 valid 0.4744583719306522
LOSS train 0.4070179024869103 valid 0.4743406479305859
LOSS train 0.4070179024869103 valid 0.47437709804965117
LOSS train 0.4070179024869103 valid 0.47438133315845105
LOSS train 0.4070179024869103 valid 0.47439067462768675
LOSS train 0.4070179024869103 valid 0.4743494788184762
LOSS train 0.4070179024869103 valid 0.4743624530105947
LOSS train 0.4070179024869103 valid 0.47437981381919814
LOSS train 0.4070179024869103 valid 0.47436680845431867
LOSS train 0.4070179024869103 valid 0.4743559660367024
LOSS train 0.4070179024869103 valid 0.4742929199108711
LOSS train 0.4070179024869103 valid 0.47439417380131094
LOSS train 0.4070179024869103 valid 0.4745643644704731
LOSS train 0.4070179024869103 valid 0.4745448913152625
LOSS train 0.4070179024869103 valid 0.4745760945020113
LOSS train 0.4070179024869103 valid 0.47453247082955907
LOSS train 0.4070179024869103 valid 0.47448658285904505
LOSS train 0.4070179024869103 valid 0.47436279246965085
LOSS train 0.4070179024869103 valid 0.4743950262263015
LOSS train 0.4070179024869103 valid 0.47445069440824544
LOSS train 0.4070179024869103 valid 0.47446051898287306
LOSS train 0.4070179024869103 valid 0.4744150366279341
LOSS train 0.4070179024869103 valid 0.4744171969791548
LOSS train 0.4070179024869103 valid 0.4744578110572149
LOSS train 0.4070179024869103 valid 0.47438848616450935
LOSS train 0.4070179024869103 valid 0.474421930576072
LOSS train 0.4070179024869103 valid 0.4742662398871089
LOSS train 0.4070179024869103 valid 0.47410403017760716
LOSS train 0.4070179024869103 valid 0.47410847398699546
LOSS train 0.4070179024869103 valid 0.47431559418869573
LOSS train 0.4070179024869103 valid 0.4743749363698821
LOSS train 0.4070179024869103 valid 0.4743776019081215
LOSS train 0.4070179024869103 valid 0.47430048947375514
LOSS train 0.4070179024869103 valid 0.4741727951271781
LOSS train 0.4070179024869103 valid 0.474192828452348
LOSS train 0.4070179024869103 valid 0.47405249161379676
LOSS train 0.4070179024869103 valid 0.47400254503614203
LOSS train 0.4070179024869103 valid 0.4740328411148353
LOSS train 0.4070179024869103 valid 0.4740584628609017
LOSS train 0.4070179024869103 valid 0.4741030630923934
LOSS train 0.4070179024869103 valid 0.4741212650923662
LOSS train 0.4070179024869103 valid 0.4741188749001267
LOSS train 0.4070179024869103 valid 0.4740525344673659
LOSS train 0.4070179024869103 valid 0.47397821017816744
LOSS train 0.4070179024869103 valid 0.4740209519697099
LOSS train 0.4070179024869103 valid 0.4740505509906345
LOSS train 0.4070179024869103 valid 0.4740797911984769
LOSS train 0.4070179024869103 valid 0.4742366032705781
LOSS train 0.4070179024869103 valid 0.474150887205581
LOSS train 0.4070179024869103 valid 0.47410171569048704
LOSS train 0.4070179024869103 valid 0.47416054483962383
LOSS train 0.4070179024869103 valid 0.47410974419507823
LOSS train 0.4070179024869103 valid 0.47402904217184727
LOSS train 0.4070179024869103 valid 0.47402691484793374
LOSS train 0.4070179024869103 valid 0.4740081595049964
EPOCH 4:
  batch 1 loss: 0.36749839782714844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.38640059530735016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.39996303121248883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4036734625697136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4084793388843536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.40916245182355243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4061996979372842
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4119053855538368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4106515248616536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4096878796815872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.40838657455010846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.40666353702545166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.40378313339673555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.40242732422692434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.40392354130744934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.40438518300652504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4047824898186852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.40492412944634754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4048543180290021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.40395175367593766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4030331302256811
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4034648903391578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.40442126859789307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40533727779984474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.40579678654670714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4071327241567465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4071636310330144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.40645398625305723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.40786397970955945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.40783494810263315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.40826137315842415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.40835229214280844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.407877347686074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.40801213506390066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.40825574227741784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4083048229416211
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.40825305999936284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4082368737772891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4087449251077114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4092967055737972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4090612959571001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4083261042833328
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4092984137146972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.40870698405937717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.40912765661875405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4082469104424767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4084363649500177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.40835883282124996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.40831516774333254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4083891159296036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.40799887682877334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4080814083035176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4082572555766915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4078860608515916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.40772670669989153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.40794126210468157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.40841017062203927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4076184065177523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4078780160111896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.40786583175261815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.407416969537735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4075080651429392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4073770533478449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4076833971776068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.40749048040463376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.407547470295068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.407065275889724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.40687960123314576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.40709549274997436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.40743793845176696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.407352885310079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40706103833185303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.40701260591206484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4070255538901767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.40696996927261353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4072901390885052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4073594827930649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4071427679214722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40727482490901706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4074813276529312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4078340030010836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40773434682590204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.40738192452005595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4072247002096403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.40724173398578867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4072194095960883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4071301793915102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4073814411054958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.40729001800665693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4075572113196055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.40722079198439043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4073518598857133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.40765070338403026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.40773825822992527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4074581629351566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.40777195896953344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.40737429199759495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4078195213663335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.40797205615525295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4080674448609352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.40780961838099034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.40776340137509737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.40817974377604366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4078858672426297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.40792720374606906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.40774625483548865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4079530991126444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.40828733836059217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4082410901511481
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.408651385253126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.408407155726407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4083910746765988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4080340978318611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4079917585640623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.407502832101739
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.40737421784935324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.40741962551051736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.40721176387900015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4070125948481199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.40699599335590997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.40676038964720795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4067388106076444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4071751328987804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4070765404931961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4072439723014832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4070792008960058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.407000704778461
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.40726193762384355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.40741757736649625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.40735837954741255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.40710914999474096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.40697943419218063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4070520221738887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4070145396599129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.40686982406510247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.40681520082494793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4068892300128937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4067487567663193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4071253754680963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4071443689720971
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4067572919612235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.40674966300877047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4069947527421938
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4072620374047094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4074119337673845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4073534313946554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4073650042215983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4075050670150164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.40749983399506384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4074811186393102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4075814676995309
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4074383068241571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4072810035515455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.40712038979127807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.40726989200038294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4073075839342215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.40740932856395745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4072038584117648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.40742674676127405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4073922362178564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.40721783763873654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.40707256415008025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4072395886745921
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4069888073860145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4068617020592545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.40682804476783935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4064698581567068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4063816540652797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.40629127586381675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.40625106815029594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4062487340112876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4060492886360301
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4057922029081797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.40584991718160696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4058368468284607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.40567650171843445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4055223311744841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.40535316356782164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.40539216345914914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4052131038573053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.40529123821311236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4054041121687208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.40528238177950915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.40530127448880154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4053596598071021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.40527674155209653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.40512145346498746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.40491695305768477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4048451331872789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4048473115030088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4048947265947052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4047243227250874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4046451951246805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.40457870204424123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4045791467030843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.40463095644907077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4047940787930174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.40522019971500745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.40517810720894204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4051417250931263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.40508998759943454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.40506460643050696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4051980775565349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.40511398601765725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4050917058456235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.40513075902624035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4051985023678213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.40503483838759935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4050664396947651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4050392511345091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.405060574765454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.40507026115116085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.40487967088748594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40467689861761075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.40457790632580604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.40451371724958773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4045633977184647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4045512573708088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4047146756627244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.40478991703553635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4047115151159364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.40462695961599954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4046122979690141
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.404896135575005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.404782936308119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.40462318089156024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4046605565474422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4045144733891152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4045228825385914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4045178099818852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.40462948027111234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4046187000028018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4044430130541069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4044677714506785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.40460130153818336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40469260816856967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40486672734409446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.40494183494764213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.40509227766152706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.40507261690994106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4049972860892284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4049226775888569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4050326395181962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4049122020846508
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.40499392358624203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.40502900563604466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.40501693265158156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.40505417508463704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4050110349932828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4051268026828766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.405102084001222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.40511632048421437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.40508298051687097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.40504867225650726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4051110811093274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4050903945462778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.40501951556725263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4050835982080578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.40523251120188064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.40533508429160486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4052077418771283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.40515589668550567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.40509029712967093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4049932277112296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.404846054877875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.40489486834608523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4048575246601962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.40486063975006786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40492081453809065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.404855622737496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4049564508714359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.40481828054522767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4048132875681797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.404654384420736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.404474314884706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.40458441288142966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.40455786512646863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.40438467264175415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.40451039293760893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.404426383120673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.40438703116148816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.40431201817296075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4042971392191762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.404290931850252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4043858556370986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.40435156486667956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40436810556189107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4044304962994324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.40457338507200197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.40469670449865275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4047306506699303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4047142805097854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4047236358142957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4047171107563032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.40478288662635675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4047334886885978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.40486983117029723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4047502845325726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4047592712883965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4047504655520121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.40478093234011503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.40464390636674613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4046248672622265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4046227586896796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.40452280161810705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.40456612262071345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40455790567864036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4043903291805998
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.40451539614053994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4045621794077658
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.40456160155523246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4045862747499576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.40461287711755917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4044764761332494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.40446342286609466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4045103718585606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.40452218394174183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.40445977449417114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4044394480023638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4043697350658476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4043558079319951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.404326242041884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.404358084818158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4043745031511342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4043569882099445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.40436158425237506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4043595413549231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.40436812944528533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.40429302986632004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.40427706747344044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.40436843964988733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.40424651894942826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4042778463514001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.40425175116090717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.40427768790899815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.404260701987715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4041485254064158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.40420159926781285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.40416835068249773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40434400956420335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4042681459982025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4043935695063998
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.40445592217473175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4043503468639629
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.40433685261270275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.40429819577691184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.404310417965441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4043104753069494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4042456643629211
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4041769604172025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4041193074140793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4041546084494753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4042004122274793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.40409538848588694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4041111491095852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4040701561764385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4040851226540841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4040585803752505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4040979559541081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4041245334678226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4041207112433838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.40424606055844553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4042490694476882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4042424263207467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4043634888244002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4043454774579064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4043387707312685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4043782583397368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.40442729513173503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4044400004116265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.404461583519239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.40442203057389103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4044096590526622
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.40441992886882416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4043435634771983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.40432854321725825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.40437593905932073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4043864527392009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.404345702606015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.40429909001839787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4042575535342449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4042449173814963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.40432010641608473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4043748283293098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4042763998756161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.40433295943576436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.40428166888480965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4042784706833436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.40424313398130757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4042107678376711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4041808814648777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4040963702968189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.40416014528153205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.40404685045861954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.40401490964467013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.404031130024279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4039741135214078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40403793475136685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.40404459572674933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.40417070880532263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4040542357877603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.40389178493129674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4037875394075739
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4037680265189397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.40378536375952356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4037546134494208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.403685944525557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.40362127914148216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4036332282868458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.4036273995550667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.40371620444775785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4036804672005107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.40365604958869067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4037353809616992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4036901887640896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4037134451075242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4036625902429759
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.40362498670388636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.40365535319562745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.40363072369779857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.40368721561590454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.403634280955057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.40364223239551483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.40367780836685646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4036938499001896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4036285852042722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4037090178395881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.40366490380229236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.40351708327140007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.40364879043989405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.40368634904896855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.40376694265891006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4036138114835594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4036089278723238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4035169180097251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4035403649194525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.403560943952687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.40351359498555256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.40341415322451496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.40340973565524274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.40343774392220977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.40346275452035585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.40351120115133765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.40353199410008955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.40368201156680505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.40367441754704636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.40364231979286913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4036961122682052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4037230344684193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.40371123519208696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4036966434735681
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.40368712739606877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.40367314883941585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4036654132184478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.40362516130719867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4036389828512543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4035735294646716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4036159917517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.40362176584781906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.40365498370450476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.40360771245656457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.40358217370200467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4035899036002726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.40361861884593964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4037106907495888
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4037671160160728
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.40373854138100684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4036697600769181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4037212718651493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40381439714989764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.40373822249424685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.40381587050476314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.40381587050476314 valid 0.4504757523536682
LOSS train 0.40381587050476314 valid 0.4501923620700836
LOSS train 0.40381587050476314 valid 0.4710542559623718
LOSS train 0.40381587050476314 valid 0.4673786014318466
LOSS train 0.40381587050476314 valid 0.46438315510749817
LOSS train 0.40381587050476314 valid 0.467246616880099
LOSS train 0.40381587050476314 valid 0.46762721453394207
LOSS train 0.40381587050476314 valid 0.46680082753300667
LOSS train 0.40381587050476314 valid 0.460364881489012
LOSS train 0.40381587050476314 valid 0.46358334124088285
LOSS train 0.40381587050476314 valid 0.46709347584030847
LOSS train 0.40381587050476314 valid 0.4656858965754509
LOSS train 0.40381587050476314 valid 0.4678630462059608
LOSS train 0.40381587050476314 valid 0.46787043128694805
LOSS train 0.40381587050476314 valid 0.46630441149075824
LOSS train 0.40381587050476314 valid 0.46835559234023094
LOSS train 0.40381587050476314 valid 0.47092966823016896
LOSS train 0.40381587050476314 valid 0.47196025649706524
LOSS train 0.40381587050476314 valid 0.4726144859665318
LOSS train 0.40381587050476314 valid 0.47431068420410155
LOSS train 0.40381587050476314 valid 0.4732364785103571
LOSS train 0.40381587050476314 valid 0.47031137347221375
LOSS train 0.40381587050476314 valid 0.47118929417236993
LOSS train 0.40381587050476314 valid 0.4695932020743688
LOSS train 0.40381587050476314 valid 0.4684756553173065
LOSS train 0.40381587050476314 valid 0.46789948642253876
LOSS train 0.40381587050476314 valid 0.4672617956444069
LOSS train 0.40381587050476314 valid 0.46796690991946627
LOSS train 0.40381587050476314 valid 0.4671615619083931
LOSS train 0.40381587050476314 valid 0.46806935369968417
LOSS train 0.40381587050476314 valid 0.4698597836878992
LOSS train 0.40381587050476314 valid 0.46983111929148436
LOSS train 0.40381587050476314 valid 0.4711181783314907
LOSS train 0.40381587050476314 valid 0.47041696748312783
LOSS train 0.40381587050476314 valid 0.4712616775717054
LOSS train 0.40381587050476314 valid 0.471430216398504
LOSS train 0.40381587050476314 valid 0.4718912678795892
LOSS train 0.40381587050476314 valid 0.4731071716860721
LOSS train 0.40381587050476314 valid 0.472599202241653
LOSS train 0.40381587050476314 valid 0.4741633251309395
LOSS train 0.40381587050476314 valid 0.47404411507815847
LOSS train 0.40381587050476314 valid 0.47514635466393973
LOSS train 0.40381587050476314 valid 0.4752553659816121
LOSS train 0.40381587050476314 valid 0.4757372973994775
LOSS train 0.40381587050476314 valid 0.47592688732677035
LOSS train 0.40381587050476314 valid 0.47642811420171155
LOSS train 0.40381587050476314 valid 0.4756898328344873
LOSS train 0.40381587050476314 valid 0.47607934288680553
LOSS train 0.40381587050476314 valid 0.4766340188834132
LOSS train 0.40381587050476314 valid 0.47626871764659884
LOSS train 0.40381587050476314 valid 0.4769313703565037
LOSS train 0.40381587050476314 valid 0.476624951339685
LOSS train 0.40381587050476314 valid 0.476086326365201
LOSS train 0.40381587050476314 valid 0.4761413004663255
LOSS train 0.40381587050476314 valid 0.47560091343793004
LOSS train 0.40381587050476314 valid 0.4753063518021788
LOSS train 0.40381587050476314 valid 0.47517427174668564
LOSS train 0.40381587050476314 valid 0.47500345316426507
LOSS train 0.40381587050476314 valid 0.475657227685896
LOSS train 0.40381587050476314 valid 0.4750026653210322
LOSS train 0.40381587050476314 valid 0.47379937865695015
LOSS train 0.40381587050476314 valid 0.47504678993455823
LOSS train 0.40381587050476314 valid 0.4753783718934135
LOSS train 0.40381587050476314 valid 0.47595367254689336
LOSS train 0.40381587050476314 valid 0.4762034622522501
LOSS train 0.40381587050476314 valid 0.4762187947829564
LOSS train 0.40381587050476314 valid 0.4757843039818664
LOSS train 0.40381587050476314 valid 0.475224969579893
LOSS train 0.40381587050476314 valid 0.4748695224955462
LOSS train 0.40381587050476314 valid 0.47443267447607856
LOSS train 0.40381587050476314 valid 0.47399927276960563
LOSS train 0.40381587050476314 valid 0.47376101464033127
LOSS train 0.40381587050476314 valid 0.4741129887430635
LOSS train 0.40381587050476314 valid 0.47403358768772436
LOSS train 0.40381587050476314 valid 0.4734601628780365
LOSS train 0.40381587050476314 valid 0.47362448706438665
LOSS train 0.40381587050476314 valid 0.47340209220911
LOSS train 0.40381587050476314 valid 0.4733635595975778
LOSS train 0.40381587050476314 valid 0.47306479758854153
LOSS train 0.40381587050476314 valid 0.47302603013813493
LOSS train 0.40381587050476314 valid 0.4725331998901603
LOSS train 0.40381587050476314 valid 0.47280595578798434
LOSS train 0.40381587050476314 valid 0.4725852612271366
LOSS train 0.40381587050476314 valid 0.47266211041382383
LOSS train 0.40381587050476314 valid 0.4727809692130369
LOSS train 0.40381587050476314 valid 0.47228561792262763
LOSS train 0.40381587050476314 valid 0.4718742062305582
LOSS train 0.40381587050476314 valid 0.4713207683102651
LOSS train 0.40381587050476314 valid 0.4717224913366725
LOSS train 0.40381587050476314 valid 0.471716371178627
LOSS train 0.40381587050476314 valid 0.47137234400916883
LOSS train 0.40381587050476314 valid 0.47100149516178214
LOSS train 0.40381587050476314 valid 0.4704040503630074
LOSS train 0.40381587050476314 valid 0.46960897933929524
LOSS train 0.40381587050476314 valid 0.46916368854673285
LOSS train 0.40381587050476314 valid 0.4694804744794965
LOSS train 0.40381587050476314 valid 0.46989943716943877
LOSS train 0.40381587050476314 valid 0.4698667042717642
LOSS train 0.40381587050476314 valid 0.47013137075636124
LOSS train 0.40381587050476314 valid 0.47047449469566344
LOSS train 0.40381587050476314 valid 0.4706108481577127
LOSS train 0.40381587050476314 valid 0.47066519336373197
LOSS train 0.40381587050476314 valid 0.4712880268258956
LOSS train 0.40381587050476314 valid 0.471124634719812
LOSS train 0.40381587050476314 valid 0.47114969832556586
LOSS train 0.40381587050476314 valid 0.4713181659298123
LOSS train 0.40381587050476314 valid 0.4709752048844489
LOSS train 0.40381587050476314 valid 0.471380245078493
LOSS train 0.40381587050476314 valid 0.4715346847105464
LOSS train 0.40381587050476314 valid 0.4716435036875985
LOSS train 0.40381587050476314 valid 0.4717045257220397
LOSS train 0.40381587050476314 valid 0.47150364172245773
LOSS train 0.40381587050476314 valid 0.47142039331714664
LOSS train 0.40381587050476314 valid 0.47121979008641157
LOSS train 0.40381587050476314 valid 0.47123466781947926
LOSS train 0.40381587050476314 valid 0.47117571018893145
LOSS train 0.40381587050476314 valid 0.4712227063301282
LOSS train 0.40381587050476314 valid 0.4710179148084026
LOSS train 0.40381587050476314 valid 0.47071596554347445
LOSS train 0.40381587050476314 valid 0.47061746269464494
LOSS train 0.40381587050476314 valid 0.47046498720310936
LOSS train 0.40381587050476314 valid 0.47036633970307523
LOSS train 0.40381587050476314 valid 0.47044458767262903
LOSS train 0.40381587050476314 valid 0.4707727312080322
LOSS train 0.40381587050476314 valid 0.4706484160423279
LOSS train 0.40381587050476314 valid 0.4705575361611351
LOSS train 0.40381587050476314 valid 0.4710326755610038
LOSS train 0.40381587050476314 valid 0.4711540776770562
LOSS train 0.40381587050476314 valid 0.4713416342125383
LOSS train 0.40381587050476314 valid 0.4710831873691999
LOSS train 0.40381587050476314 valid 0.47106856494459487
LOSS train 0.40381587050476314 valid 0.4710042029619217
LOSS train 0.40381587050476314 valid 0.4708201143526493
LOSS train 0.40381587050476314 valid 0.4710364617518525
LOSS train 0.40381587050476314 valid 0.47126062004654495
LOSS train 0.40381587050476314 valid 0.47132206182269487
LOSS train 0.40381587050476314 valid 0.47112181108363355
LOSS train 0.40381587050476314 valid 0.4709646205107371
LOSS train 0.40381587050476314 valid 0.47064107613597844
LOSS train 0.40381587050476314 valid 0.4708018864904131
LOSS train 0.40381587050476314 valid 0.47081375248888707
LOSS train 0.40381587050476314 valid 0.471113576855458
LOSS train 0.40381587050476314 valid 0.47075255892493506
LOSS train 0.40381587050476314 valid 0.4707794504033195
LOSS train 0.40381587050476314 valid 0.47057563724188967
LOSS train 0.40381587050476314 valid 0.4709436207601469
LOSS train 0.40381587050476314 valid 0.47047622045692133
LOSS train 0.40381587050476314 valid 0.47088127583265305
LOSS train 0.40381587050476314 valid 0.47096810964929975
LOSS train 0.40381587050476314 valid 0.47110295673211416
LOSS train 0.40381587050476314 valid 0.47118884660550303
LOSS train 0.40381587050476314 valid 0.47092773392796516
LOSS train 0.40381587050476314 valid 0.4711960178185133
LOSS train 0.40381587050476314 valid 0.4711905503040784
LOSS train 0.40381587050476314 valid 0.47133843860318586
LOSS train 0.40381587050476314 valid 0.47169901048525786
LOSS train 0.40381587050476314 valid 0.47160476256328027
LOSS train 0.40381587050476314 valid 0.47153283221812187
LOSS train 0.40381587050476314 valid 0.47120286027590436
LOSS train 0.40381587050476314 valid 0.47123565468937156
LOSS train 0.40381587050476314 valid 0.4710866036992636
LOSS train 0.40381587050476314 valid 0.47069922899022515
LOSS train 0.40381587050476314 valid 0.4706339040782554
LOSS train 0.40381587050476314 valid 0.4704689250850096
LOSS train 0.40381587050476314 valid 0.47034253586422314
LOSS train 0.40381587050476314 valid 0.47015543820628203
LOSS train 0.40381587050476314 valid 0.4702234414523233
LOSS train 0.40381587050476314 valid 0.47042583354881834
LOSS train 0.40381587050476314 valid 0.47057427633443527
LOSS train 0.40381587050476314 valid 0.471030840102364
LOSS train 0.40381587050476314 valid 0.470918617750469
LOSS train 0.40381587050476314 valid 0.47096737855395604
LOSS train 0.40381587050476314 valid 0.4710844200470544
LOSS train 0.40381587050476314 valid 0.4710916940165662
LOSS train 0.40381587050476314 valid 0.4711900874546596
LOSS train 0.40381587050476314 valid 0.47104119255461474
LOSS train 0.40381587050476314 valid 0.47140197077039947
LOSS train 0.40381587050476314 valid 0.47158587363998544
LOSS train 0.40381587050476314 valid 0.47143733051902087
LOSS train 0.40381587050476314 valid 0.4715142261650827
LOSS train 0.40381587050476314 valid 0.4715088065816553
LOSS train 0.40381587050476314 valid 0.47162714731562266
LOSS train 0.40381587050476314 valid 0.4715089317553682
LOSS train 0.40381587050476314 valid 0.471733245998621
LOSS train 0.40381587050476314 valid 0.47166615144626517
LOSS train 0.40381587050476314 valid 0.4717486835615609
LOSS train 0.40381587050476314 valid 0.4717770070634424
LOSS train 0.40381587050476314 valid 0.4717668794254039
LOSS train 0.40381587050476314 valid 0.47168111753842185
LOSS train 0.40381587050476314 valid 0.4715124991379286
LOSS train 0.40381587050476314 valid 0.4717827284835396
LOSS train 0.40381587050476314 valid 0.4718864855046074
LOSS train 0.40381587050476314 valid 0.47175727792354444
LOSS train 0.40381587050476314 valid 0.47155274911639616
LOSS train 0.40381587050476314 valid 0.47153150806060207
LOSS train 0.40381587050476314 valid 0.47163815188164615
LOSS train 0.40381587050476314 valid 0.4719261466549133
LOSS train 0.40381587050476314 valid 0.4719717905978964
LOSS train 0.40381587050476314 valid 0.4720128698265133
LOSS train 0.40381587050476314 valid 0.47194249019026757
LOSS train 0.40381587050476314 valid 0.47163126673271405
LOSS train 0.40381587050476314 valid 0.47180295329872923
LOSS train 0.40381587050476314 valid 0.4716180740612481
LOSS train 0.40381587050476314 valid 0.4716419525006238
LOSS train 0.40381587050476314 valid 0.4716488650659236
LOSS train 0.40381587050476314 valid 0.4714306982107533
LOSS train 0.40381587050476314 valid 0.4716573459802618
LOSS train 0.40381587050476314 valid 0.4716516410788664
LOSS train 0.40381587050476314 valid 0.4715397975376348
LOSS train 0.40381587050476314 valid 0.471665813383602
LOSS train 0.40381587050476314 valid 0.47171982741468893
LOSS train 0.40381587050476314 valid 0.4717881971935056
LOSS train 0.40381587050476314 valid 0.4718135682070199
LOSS train 0.40381587050476314 valid 0.4717739753634016
LOSS train 0.40381587050476314 valid 0.47179042572198915
LOSS train 0.40381587050476314 valid 0.4718490423703635
LOSS train 0.40381587050476314 valid 0.4718967905516998
LOSS train 0.40381587050476314 valid 0.4720054249697869
LOSS train 0.40381587050476314 valid 0.4719866080099045
LOSS train 0.40381587050476314 valid 0.4721846343441443
LOSS train 0.40381587050476314 valid 0.472403980083595
LOSS train 0.40381587050476314 valid 0.472401958596599
LOSS train 0.40381587050476314 valid 0.4724105762259308
LOSS train 0.40381587050476314 valid 0.4724499309169395
LOSS train 0.40381587050476314 valid 0.47248732460869686
LOSS train 0.40381587050476314 valid 0.4724724603965219
LOSS train 0.40381587050476314 valid 0.47253838509715074
LOSS train 0.40381587050476314 valid 0.4725073369448645
LOSS train 0.40381587050476314 valid 0.47262722579152305
LOSS train 0.40381587050476314 valid 0.47276243321273637
LOSS train 0.40381587050476314 valid 0.47282499216851737
LOSS train 0.40381587050476314 valid 0.47287897919786387
LOSS train 0.40381587050476314 valid 0.4727720398248009
LOSS train 0.40381587050476314 valid 0.4727144136897519
LOSS train 0.40381587050476314 valid 0.47290523965308007
LOSS train 0.40381587050476314 valid 0.47280443194559063
LOSS train 0.40381587050476314 valid 0.47269953378645174
LOSS train 0.40381587050476314 valid 0.47266410140931103
LOSS train 0.40381587050476314 valid 0.4724998830751395
LOSS train 0.40381587050476314 valid 0.47234467019637427
LOSS train 0.40381587050476314 valid 0.4726305814204869
LOSS train 0.40381587050476314 valid 0.4725254488385413
LOSS train 0.40381587050476314 valid 0.47245927467758275
LOSS train 0.40381587050476314 valid 0.47258987326602464
LOSS train 0.40381587050476314 valid 0.4725949257004018
LOSS train 0.40381587050476314 valid 0.47258711697124856
LOSS train 0.40381587050476314 valid 0.47264455361404883
LOSS train 0.40381587050476314 valid 0.4726113404237455
LOSS train 0.40381587050476314 valid 0.47263630458628797
LOSS train 0.40381587050476314 valid 0.4729061230421066
LOSS train 0.40381587050476314 valid 0.4729996914882584
LOSS train 0.40381587050476314 valid 0.4732715750024432
LOSS train 0.40381587050476314 valid 0.47313118628833606
LOSS train 0.40381587050476314 valid 0.4733425288453815
LOSS train 0.40381587050476314 valid 0.47334973660169866
LOSS train 0.40381587050476314 valid 0.4733202555216849
LOSS train 0.40381587050476314 valid 0.4733047120070179
LOSS train 0.40381587050476314 valid 0.4733535438313965
LOSS train 0.40381587050476314 valid 0.4733208834434568
LOSS train 0.40381587050476314 valid 0.4731642335653305
LOSS train 0.40381587050476314 valid 0.47320076971675246
LOSS train 0.40381587050476314 valid 0.47312891392307427
LOSS train 0.40381587050476314 valid 0.4730718649158913
LOSS train 0.40381587050476314 valid 0.4729913915648605
LOSS train 0.40381587050476314 valid 0.47299273745068965
LOSS train 0.40381587050476314 valid 0.4731558011214536
LOSS train 0.40381587050476314 valid 0.47335857275719945
LOSS train 0.40381587050476314 valid 0.47349486099695093
LOSS train 0.40381587050476314 valid 0.47374387290397985
LOSS train 0.40381587050476314 valid 0.4736645037377322
LOSS train 0.40381587050476314 valid 0.4737791404732919
LOSS train 0.40381587050476314 valid 0.47387249439078216
LOSS train 0.40381587050476314 valid 0.4739050917573028
LOSS train 0.40381587050476314 valid 0.47392507908988174
LOSS train 0.40381587050476314 valid 0.4738074943152341
LOSS train 0.40381587050476314 valid 0.4737816611709802
LOSS train 0.40381587050476314 valid 0.47387159214983776
LOSS train 0.40381587050476314 valid 0.4738321875711139
LOSS train 0.40381587050476314 valid 0.4739194654435667
LOSS train 0.40381587050476314 valid 0.47378472547445977
LOSS train 0.40381587050476314 valid 0.4736073340597526
LOSS train 0.40381587050476314 valid 0.4735856564543771
LOSS train 0.40381587050476314 valid 0.47360567164084094
LOSS train 0.40381587050476314 valid 0.4736624020086208
LOSS train 0.40381587050476314 valid 0.47360880584047554
LOSS train 0.40381587050476314 valid 0.4734651996539189
LOSS train 0.40381587050476314 valid 0.47348975439520247
LOSS train 0.40381587050476314 valid 0.47341362655990654
LOSS train 0.40381587050476314 valid 0.47352281862476703
LOSS train 0.40381587050476314 valid 0.4735293912476507
LOSS train 0.40381587050476314 valid 0.47335583565571054
LOSS train 0.40381587050476314 valid 0.4733978546645543
LOSS train 0.40381587050476314 valid 0.4732616800090152
LOSS train 0.40381587050476314 valid 0.47333572054801343
LOSS train 0.40381587050476314 valid 0.47349556937056075
LOSS train 0.40381587050476314 valid 0.47342199399261864
LOSS train 0.40381587050476314 valid 0.4734551161025911
LOSS train 0.40381587050476314 valid 0.47332569886774023
LOSS train 0.40381587050476314 valid 0.4734145607238629
LOSS train 0.40381587050476314 valid 0.47343212177356087
LOSS train 0.40381587050476314 valid 0.47343365308454266
LOSS train 0.40381587050476314 valid 0.4733003392716907
LOSS train 0.40381587050476314 valid 0.47323079038374494
LOSS train 0.40381587050476314 valid 0.47328718241892365
LOSS train 0.40381587050476314 valid 0.4732588773868123
LOSS train 0.40381587050476314 valid 0.47328487058091007
LOSS train 0.40381587050476314 valid 0.4732623397333226
LOSS train 0.40381587050476314 valid 0.4731589455109138
LOSS train 0.40381587050476314 valid 0.4731607073526166
LOSS train 0.40381587050476314 valid 0.47318698446596824
LOSS train 0.40381587050476314 valid 0.47317918033078554
LOSS train 0.40381587050476314 valid 0.47319202526257587
LOSS train 0.40381587050476314 valid 0.47330941807347743
LOSS train 0.40381587050476314 valid 0.4732744222993304
LOSS train 0.40381587050476314 valid 0.4732554516148946
LOSS train 0.40381587050476314 valid 0.47313627893034416
LOSS train 0.40381587050476314 valid 0.47317216928448963
LOSS train 0.40381587050476314 valid 0.47317587973186803
LOSS train 0.40381587050476314 valid 0.47318548038835434
LOSS train 0.40381587050476314 valid 0.47314420277252794
LOSS train 0.40381587050476314 valid 0.47315708137004175
LOSS train 0.40381587050476314 valid 0.47317588838361063
LOSS train 0.40381587050476314 valid 0.47316523906616237
LOSS train 0.40381587050476314 valid 0.47314629758949633
LOSS train 0.40381587050476314 valid 0.4730833401129796
LOSS train 0.40381587050476314 valid 0.47318264576920704
LOSS train 0.40381587050476314 valid 0.47335365451074884
LOSS train 0.40381587050476314 valid 0.4733313957183826
LOSS train 0.40381587050476314 valid 0.4733606749030232
LOSS train 0.40381587050476314 valid 0.47331370476520424
LOSS train 0.40381587050476314 valid 0.47326790161003157
LOSS train 0.40381587050476314 valid 0.47314038361052435
LOSS train 0.40381587050476314 valid 0.4731774727503459
LOSS train 0.40381587050476314 valid 0.47323285043239594
LOSS train 0.40381587050476314 valid 0.47324286387927494
LOSS train 0.40381587050476314 valid 0.4731917626978386
LOSS train 0.40381587050476314 valid 0.4731939674661846
LOSS train 0.40381587050476314 valid 0.4732330479389112
LOSS train 0.40381587050476314 valid 0.4731650863249393
LOSS train 0.40381587050476314 valid 0.47320181622224694
LOSS train 0.40381587050476314 valid 0.47304535751119037
LOSS train 0.40381587050476314 valid 0.47287949501422416
LOSS train 0.40381587050476314 valid 0.4728807539355998
LOSS train 0.40381587050476314 valid 0.47309202908776526
LOSS train 0.40381587050476314 valid 0.4731551358665245
LOSS train 0.40381587050476314 valid 0.47315633968810816
LOSS train 0.40381587050476314 valid 0.47308065568335805
LOSS train 0.40381587050476314 valid 0.4729516705733606
LOSS train 0.40381587050476314 valid 0.47297561108895225
LOSS train 0.40381587050476314 valid 0.47283329120704104
LOSS train 0.40381587050476314 valid 0.4727768334228429
LOSS train 0.40381587050476314 valid 0.4728083016181534
LOSS train 0.40381587050476314 valid 0.472837681895275
LOSS train 0.40381587050476314 valid 0.47288304020119254
LOSS train 0.40381587050476314 valid 0.4728981302657598
LOSS train 0.40381587050476314 valid 0.4728942487514421
LOSS train 0.40381587050476314 valid 0.4728267928298448
LOSS train 0.40381587050476314 valid 0.47275041834602144
LOSS train 0.40381587050476314 valid 0.4727949865349156
LOSS train 0.40381587050476314 valid 0.47282348904344773
LOSS train 0.40381587050476314 valid 0.4728523889076677
LOSS train 0.40381587050476314 valid 0.47301194648057715
LOSS train 0.40381587050476314 valid 0.47292799627813753
LOSS train 0.40381587050476314 valid 0.47287367857419527
LOSS train 0.40381587050476314 valid 0.4729321440605268
LOSS train 0.40381587050476314 valid 0.47288038756678014
LOSS train 0.40381587050476314 valid 0.4727976317301758
LOSS train 0.40381587050476314 valid 0.4727990055537742
LOSS train 0.40381587050476314 valid 0.4727798304583645
EPOCH 5:
  batch 1 loss: 0.3647804260253906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.38172106444835663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.3967963457107544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4031934291124344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.40688408613204957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4083130657672882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.40302864568574087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4081892929971218
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4075054493215349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.40629426538944247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4046100513501601
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4036040132244428
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4006677017762111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.3991250459636961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4011469999949137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4025870021432638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4029402855564566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4033281322982576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.40342537039204646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.40244206190109255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.40190936837877544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4020266289060766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.40282225090524426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.403787770618995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.40393242359161374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.405405662380732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.40553032137729506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.40474139686141697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4056498583020835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4053227335214615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4059476775507773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4062034096568823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4059815533233411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.405947827241
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4064651310443878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.40699834873278934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4067342740458411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4064867472962329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.40701655164743084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4077838517725468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4077593546088149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4069716078894479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4079933471457903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4072150655768134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.40747060179710387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.406375355694605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.40666824135374513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4063617642968893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4064878614581361
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.406602748632431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4064464054855646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4061856579322081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4063070888789195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4059962917257238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.40592066808180377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.40621400997042656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4066921331380543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4058153264481446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4060688438051838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4060275142391523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4054371949102058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4054435981858161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.40529895822207135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.40553248347714543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4056131647183345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.40557592565363104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4051570069434038
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4049621868659468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.40505985634914343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.40562299575124466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4057543202185295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40529422296418083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.40523613234088846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.40536522462561325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4052600089708964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4054989559870017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.40562203526496887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4055422319051547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40553883585748796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.40567141957581043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4057624825724849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40591765249647743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4056426394416625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4056192934513092
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4056782347314498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.40565499316814335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.405526725040085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4057848050513051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4057059277979176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.40592442916499244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4055381217500666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.40550714893185574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.405886774101565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.40596251126299515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4056445259796946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.40599120998134214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4056547526846227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.40616345679273413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4064337933304334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4065770995616913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.406338632106781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4063027866330801
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4066307275619322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.40642825771982855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4062947026320866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.40601021191983855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4061052874426975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4063772377040651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4063246531770864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4067269934849306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.40645158022373645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4063143629048552
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4060287744598051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4059795504599287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.40546618311301524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.40530943228253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.405392349530489
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4052306461637303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40507104241547465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.40509054909149805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4047755333017712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4047481039019882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4052107229949982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4051974173034391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4052992250919342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4051782370559753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4050678014755249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.40527332201600075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.40539253312487933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.40530187166654147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4050657897050144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4048919370680144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4049584224708098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.40493794608472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.40484536356396145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.40488510995226745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4050017301618618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.40487612783908844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4051049615410592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.40507271864584515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4046567699587937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.404659155808704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4049554262961541
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4052453512946765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.40534351796939455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4053248810033276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4053295325665247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.40543874957271525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.40558738296463986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.40560303469498954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4057339098279839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.40562941977067996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.405478595323812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.405210043122242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.40539060273478106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.40547365007492214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4055258916441802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.40536137113842785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.40560015548700057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4055809937417507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4053961940063453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4052557803598451
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4054507483368271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4052197349871077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4050402664777004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.40496459010853825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4045976555632974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4045206395288308
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4044671986230026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.40445189546136295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.40446972690130534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4042432815876118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4040639300566877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.40409572542398825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.40409880093165806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4039599499241872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.40381106060777006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4036209886328558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4036369929766522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.40347930408186383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4035338970179057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.40365906534614143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.40353945630495663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4034872822787451
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4035446714710545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4034335102124881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.40329581578785084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.40305874243061596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.40298515621316494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4030251368096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4030097641869989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4028875104462107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4028265616745529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4027179455019764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4027484899912125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.40280090059552875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4028736231895873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.40329155867749994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4031599307779092
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4031428152322769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4031134768208461
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.40309302272773023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.40330718171420354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4032581033659916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4032058497754539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4032493219213578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.40332540653753973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4031224179153259
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4031292428240251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.40319001986866904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.40323190496996114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.403273214709084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4030819315585732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40290954500158255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.40279365791830907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.40278073248487933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.40284510458120004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.40284434548758585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.40301152247272126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4030759693546729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4030481926186592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.40296445008333737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.40300063060538116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4032686416591917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.40312580956353083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.40297947889935654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4030706713115591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4029955731933577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4030488894756184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4030838169481443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4031831415700706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.403173150173549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4029960228138216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.403016791639165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.40313289165496824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40321909800424416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4034056998003384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4034314711554712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.403581079204711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4035531176875035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4035411196378257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4034873103060998
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.40360960229434106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.40354650137854403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4036722888751906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4037155472650761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.40370549279668555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4037695616003006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4037483627777023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4039101995229721
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4038535355334263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4038417243531772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.40380437513113965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.40375041269411255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.40383748996491525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4038183676311746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.40371853333502894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.40373375006886414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4038774957988253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4039670407772064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.40385556894700647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.40386476464398946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.40379352148041525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4036862662795818
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4035442964085993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4036059218241756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4035597637798009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4035451532299839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40356937770949863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.40347870224052007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.40353414086398165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.40337511327336817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4033762187093169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.40323363810125057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4030633387782357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4032160103105117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.40316692747794336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.40302135050296783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4031412254311278
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4030710959008762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4030604723085288
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4029766560023558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4029661213761926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.40296368164495683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4030779393095719
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.40303462514510524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40302173642746664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.40307844719953007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.40324864554570206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.403375555420744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4034303730910586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40340808840238884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4034186515181545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4034072386772454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4034739586256318
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.40346834335375475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.40357769348404626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4034248461459307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.40340185733543193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.40337991426388425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.40342659708669415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.40330270268269724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.40331525564587156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.403296470347988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4031655793307257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4031429437835232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40315674677345575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4029985545324041
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4031332780435247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4032017201185226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.403233322779082
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4032146348020969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4032764450048867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.40313605195397784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4031326080125476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4031813613410237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.40318244893092087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.40313094188957094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4031264678251033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4030498992651701
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.40304726640754773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4029999631717338
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4030079345215954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.40302361575541673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4030133661857018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4029947641802712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.40302114685376483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4030275832770801
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.402956623255663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4029653549194336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.40305751706178095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.402961144874613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.40299878535685957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.40296409845709086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4029883406055507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.402975188923024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.40286936807703194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4029761563391375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.40291752795905844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40308561807169635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.40298299137448285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4031354479970988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.40318522786955097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4031077509009561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.40310438828191897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.40305134214762317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.40309435962256507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4030930997653939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.40301770432972295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4029354832002095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4028594329995647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4029023880138993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.402995188074139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.40287174528601477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.402879412661136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4028615811735057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4029199493532421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.40289088184607097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.40292151243241714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4029533875485261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4029263057371916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.40300443924922313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4030216844449687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4030354059823267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4031470913593083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4031288095347868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4031320375057917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4031745603551035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.40321359805621426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.40324857661852964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.40326174338551546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.40326762816277884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4032693237625562
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.40327102033530965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4032048099040985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4031985631172961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.40325382589029063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4032720522905784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.40324460524367783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4032278536181701
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4031811994830454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.40316712169747076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4032674552410763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40329501653711003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4032051571777889
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4032552121062353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4032317197446059
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.40323877495895954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.40319574101418637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.40317111603724654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4031450424505317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4030726678973558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4031625505318775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.40305242396248175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4030135911476763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4030060208205021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4029339530906389
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40302306952788003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4030037942088039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.40312937274575233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4030347478360012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.40288346664822516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4027714991096232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.40274008120050525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.40276952231371843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4027378363855954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.40265303718370066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4025946970955998
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.40259332776361106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.40259824860386734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4026956843198651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4026291982352155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4025917427736102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.40264780984984505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.40259944703205525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4026423833118035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4025834189187423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.40255737090795235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4026132467822983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4025684316953023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.40262860880894785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4026035777341698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4026061369031315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.40265206029673795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.40265559434890746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.40262988363633134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4027158274583571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.40267993078053554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4025339222315586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.402673093038936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.40272061039289575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4027662333101034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.40258937750622525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4025947417943708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4025062389757441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4025558266754544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4025462805133663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4024850167504184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4023739355435947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4023617720739408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4023920913942817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.40243988676308506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4025147627223426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.40255605583792337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.40272727910052525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4027235687046308
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4026650647722368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4027523970497506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4027522173119016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4027537867095735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4027639191325118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.40277438696506807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4027582747783619
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.40276860737853115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4027114942178621
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.40272441107714385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.40270838108834867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4027864633689281
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.40281280505111794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4028269493061563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4028031271346996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4027828672231534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.40277563791810567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.40282366309186507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4028802030829973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.40295366220208195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.40293048650855934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4028736875097976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.40291409540786416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40299091770293866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4029275745849447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.40301323290598595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.40301323290598595 valid 0.4507647752761841
LOSS train 0.40301323290598595 valid 0.4512910544872284
LOSS train 0.40301323290598595 valid 0.471860150496165
LOSS train 0.40301323290598595 valid 0.4682736098766327
LOSS train 0.40301323290598595 valid 0.4650917172431946
LOSS train 0.40301323290598595 valid 0.4681491057078044
LOSS train 0.40301323290598595 valid 0.4691942845072065
LOSS train 0.40301323290598595 valid 0.46852121874690056
LOSS train 0.40301323290598595 valid 0.4623430205716027
LOSS train 0.40301323290598595 valid 0.4653288185596466
LOSS train 0.40301323290598595 valid 0.4687794555317272
LOSS train 0.40301323290598595 valid 0.46743425478537876
LOSS train 0.40301323290598595 valid 0.4696308443179497
LOSS train 0.40301323290598595 valid 0.4696817717381886
LOSS train 0.40301323290598595 valid 0.4681973735491435
LOSS train 0.40301323290598595 valid 0.470207154750824
LOSS train 0.40301323290598595 valid 0.4727451450684491
LOSS train 0.40301323290598595 valid 0.4738427831066979
LOSS train 0.40301323290598595 valid 0.47443154924794245
LOSS train 0.40301323290598595 valid 0.4761358588933945
LOSS train 0.40301323290598595 valid 0.47517402399153935
LOSS train 0.40301323290598595 valid 0.47230580990964716
LOSS train 0.40301323290598595 valid 0.47320482782695605
LOSS train 0.40301323290598595 valid 0.4716536986331145
LOSS train 0.40301323290598595 valid 0.47060348391532897
LOSS train 0.40301323290598595 valid 0.47007942772828615
LOSS train 0.40301323290598595 valid 0.4694550070497725
LOSS train 0.40301323290598595 valid 0.47019304654427935
LOSS train 0.40301323290598595 valid 0.4693563816876247
LOSS train 0.40301323290598595 valid 0.47021184662977855
LOSS train 0.40301323290598595 valid 0.4720038204423843
LOSS train 0.40301323290598595 valid 0.4719872334972024
LOSS train 0.40301323290598595 valid 0.4733114323832772
LOSS train 0.40301323290598595 valid 0.47259441806989555
LOSS train 0.40301323290598595 valid 0.47346934165273397
LOSS train 0.40301323290598595 valid 0.47366595019896823
LOSS train 0.40301323290598595 valid 0.4740564960080224
LOSS train 0.40301323290598595 valid 0.47529962894163635
LOSS train 0.40301323290598595 valid 0.47483874972050005
LOSS train 0.40301323290598595 valid 0.4763220436871052
LOSS train 0.40301323290598595 valid 0.4761969018273237
LOSS train 0.40301323290598595 valid 0.47726747180734364
LOSS train 0.40301323290598595 valid 0.4773655734782995
LOSS train 0.40301323290598595 valid 0.477861840616573
LOSS train 0.40301323290598595 valid 0.4780691425005595
LOSS train 0.40301323290598595 valid 0.47857192677000293
LOSS train 0.40301323290598595 valid 0.4778345506241981
LOSS train 0.40301323290598595 valid 0.4781417225797971
LOSS train 0.40301323290598595 valid 0.4786999213452242
LOSS train 0.40301323290598595 valid 0.47832017302513125
LOSS train 0.40301323290598595 valid 0.478939062240077
LOSS train 0.40301323290598595 valid 0.47864024914228
LOSS train 0.40301323290598595 valid 0.47810618213887485
LOSS train 0.40301323290598595 valid 0.47810852693186867
LOSS train 0.40301323290598595 valid 0.47756649526682765
LOSS train 0.40301323290598595 valid 0.4772788706634726
LOSS train 0.40301323290598595 valid 0.47713634685466166
LOSS train 0.40301323290598595 valid 0.47697705287357856
LOSS train 0.40301323290598595 valid 0.4776187301692316
LOSS train 0.40301323290598595 valid 0.47696346789598465
LOSS train 0.40301323290598595 valid 0.4758091173211082
LOSS train 0.40301323290598595 valid 0.47700301918291277
LOSS train 0.40301323290598595 valid 0.47732568212917875
LOSS train 0.40301323290598595 valid 0.47790556913241744
LOSS train 0.40301323290598595 valid 0.47814709360782914
LOSS train 0.40301323290598595 valid 0.4781475532235521
LOSS train 0.40301323290598595 valid 0.4777430402698801
LOSS train 0.40301323290598595 valid 0.4772021472454071
LOSS train 0.40301323290598595 valid 0.4768358805905218
LOSS train 0.40301323290598595 valid 0.47640650357518877
LOSS train 0.40301323290598595 valid 0.47596635029349527
LOSS train 0.40301323290598595 valid 0.47571220497290295
LOSS train 0.40301323290598595 valid 0.4760791414404569
LOSS train 0.40301323290598595 valid 0.4759890022310051
LOSS train 0.40301323290598595 valid 0.47544963399569196
LOSS train 0.40301323290598595 valid 0.4756101632588788
LOSS train 0.40301323290598595 valid 0.47539250688119367
LOSS train 0.40301323290598595 valid 0.47535973214186156
LOSS train 0.40301323290598595 valid 0.47505650678767436
LOSS train 0.40301323290598595 valid 0.4750258557498455
LOSS train 0.40301323290598595 valid 0.4745161055046835
LOSS train 0.40301323290598595 valid 0.47475918909398523
LOSS train 0.40301323290598595 valid 0.474562423774995
LOSS train 0.40301323290598595 valid 0.47465205299002783
LOSS train 0.40301323290598595 valid 0.4747776189271142
LOSS train 0.40301323290598595 valid 0.47427907343520675
LOSS train 0.40301323290598595 valid 0.47385212025423157
LOSS train 0.40301323290598595 valid 0.4733121825212782
LOSS train 0.40301323290598595 valid 0.47369940394765875
LOSS train 0.40301323290598595 valid 0.47370865046977995
LOSS train 0.40301323290598595 valid 0.4733569880763253
LOSS train 0.40301323290598595 valid 0.4729835582168206
LOSS train 0.40301323290598595 valid 0.47241933659840657
LOSS train 0.40301323290598595 valid 0.471629465831087
LOSS train 0.40301323290598595 valid 0.471182276073255
LOSS train 0.40301323290598595 valid 0.4714947572598855
LOSS train 0.40301323290598595 valid 0.4719029388476893
LOSS train 0.40301323290598595 valid 0.4718630295626971
LOSS train 0.40301323290598595 valid 0.472126264764805
LOSS train 0.40301323290598595 valid 0.47247354388237
LOSS train 0.40301323290598595 valid 0.4725920817639568
LOSS train 0.40301323290598595 valid 0.47264713341114567
LOSS train 0.40301323290598595 valid 0.47325877715083003
LOSS train 0.40301323290598595 valid 0.47311110995136774
LOSS train 0.40301323290598595 valid 0.473141143151692
LOSS train 0.40301323290598595 valid 0.47330993920002346
LOSS train 0.40301323290598595 valid 0.47298063463139756
LOSS train 0.40301323290598595 valid 0.4733722077475654
LOSS train 0.40301323290598595 valid 0.47351236819127285
LOSS train 0.40301323290598595 valid 0.47360688041556964
LOSS train 0.40301323290598595 valid 0.4736652256132246
LOSS train 0.40301323290598595 valid 0.47344973949449404
LOSS train 0.40301323290598595 valid 0.47336180758687246
LOSS train 0.40301323290598595 valid 0.4731601487126267
LOSS train 0.40301323290598595 valid 0.47319364651389745
LOSS train 0.40301323290598595 valid 0.4731563627719879
LOSS train 0.40301323290598595 valid 0.473200891007725
LOSS train 0.40301323290598595 valid 0.4729921709177858
LOSS train 0.40301323290598595 valid 0.47269443729344535
LOSS train 0.40301323290598595 valid 0.4725965139766534
LOSS train 0.40301323290598595 valid 0.47245347820037653
LOSS train 0.40301323290598595 valid 0.472367131807765
LOSS train 0.40301323290598595 valid 0.4724390186914584
LOSS train 0.40301323290598595 valid 0.47275129104814223
LOSS train 0.40301323290598595 valid 0.4726304314136505
LOSS train 0.40301323290598595 valid 0.47255583651482114
LOSS train 0.40301323290598595 valid 0.4730148507854131
LOSS train 0.40301323290598595 valid 0.47314458549953997
LOSS train 0.40301323290598595 valid 0.4733299204083376
LOSS train 0.40301323290598595 valid 0.47306490380030414
LOSS train 0.40301323290598595 valid 0.47305194635427633
LOSS train 0.40301323290598595 valid 0.4729768085208806
LOSS train 0.40301323290598595 valid 0.472789777624876
LOSS train 0.40301323290598595 valid 0.47298564706275714
LOSS train 0.40301323290598595 valid 0.4732155433407536
LOSS train 0.40301323290598595 valid 0.4733002054340699
LOSS train 0.40301323290598595 valid 0.4731079957781047
LOSS train 0.40301323290598595 valid 0.47295006504957227
LOSS train 0.40301323290598595 valid 0.4726302259259944
LOSS train 0.40301323290598595 valid 0.4727839082479477
LOSS train 0.40301323290598595 valid 0.47280340034065516
LOSS train 0.40301323290598595 valid 0.4730854030226318
LOSS train 0.40301323290598595 valid 0.47274801572719655
LOSS train 0.40301323290598595 valid 0.4727563936677244
LOSS train 0.40301323290598595 valid 0.47255094441874274
LOSS train 0.40301323290598595 valid 0.47289581719326645
LOSS train 0.40301323290598595 valid 0.47246160008469407
LOSS train 0.40301323290598595 valid 0.4728765433301797
LOSS train 0.40301323290598595 valid 0.47295113457929366
LOSS train 0.40301323290598595 valid 0.47308353006839754
LOSS train 0.40301323290598595 valid 0.4731820790183465
LOSS train 0.40301323290598595 valid 0.47290325615751116
LOSS train 0.40301323290598595 valid 0.47317293520067255
LOSS train 0.40301323290598595 valid 0.4731666592808513
LOSS train 0.40301323290598595 valid 0.47331663447041666
LOSS train 0.40301323290598595 valid 0.47364768118430406
LOSS train 0.40301323290598595 valid 0.47355531127589523
LOSS train 0.40301323290598595 valid 0.47347623449337634
LOSS train 0.40301323290598595 valid 0.4731600629458637
LOSS train 0.40301323290598595 valid 0.4731871262192726
LOSS train 0.40301323290598595 valid 0.4730415229471574
LOSS train 0.40301323290598595 valid 0.4726657135251128
LOSS train 0.40301323290598595 valid 0.47259472100281275
LOSS train 0.40301323290598595 valid 0.4724358845411277
LOSS train 0.40301323290598595 valid 0.4722977603926803
LOSS train 0.40301323290598595 valid 0.47212066187197904
LOSS train 0.40301323290598595 valid 0.47219740523549614
LOSS train 0.40301323290598595 valid 0.4724071320323717
LOSS train 0.40301323290598595 valid 0.4725595575112563
LOSS train 0.40301323290598595 valid 0.47301458961823406
LOSS train 0.40301323290598595 valid 0.47289810578028363
LOSS train 0.40301323290598595 valid 0.4729339026434477
LOSS train 0.40301323290598595 valid 0.4730551871605691
LOSS train 0.40301323290598595 valid 0.4730566779429885
LOSS train 0.40301323290598595 valid 0.47314726999827794
LOSS train 0.40301323290598595 valid 0.4730232031169263
LOSS train 0.40301323290598595 valid 0.47337309738336986
LOSS train 0.40301323290598595 valid 0.4735596958505973
LOSS train 0.40301323290598595 valid 0.47340051738243527
LOSS train 0.40301323290598595 valid 0.4734621011548572
LOSS train 0.40301323290598595 valid 0.47344829594891374
LOSS train 0.40301323290598595 valid 0.4735724279186228
LOSS train 0.40301323290598595 valid 0.4734565145005294
LOSS train 0.40301323290598595 valid 0.4736771990099679
LOSS train 0.40301323290598595 valid 0.4736148781067616
LOSS train 0.40301323290598595 valid 0.4737089143324924
LOSS train 0.40301323290598595 valid 0.47373292073209017
LOSS train 0.40301323290598595 valid 0.4737397798515381
LOSS train 0.40301323290598595 valid 0.47364733443058354
LOSS train 0.40301323290598595 valid 0.4734851035632585
LOSS train 0.40301323290598595 valid 0.473749962308644
LOSS train 0.40301323290598595 valid 0.47385451492543024
LOSS train 0.40301323290598595 valid 0.4737185662892198
LOSS train 0.40301323290598595 valid 0.473527757623761
LOSS train 0.40301323290598595 valid 0.473498305449119
LOSS train 0.40301323290598595 valid 0.47361741397453816
LOSS train 0.40301323290598595 valid 0.4739101294636121
LOSS train 0.40301323290598595 valid 0.47394446998533574
LOSS train 0.40301323290598595 valid 0.47398285844817234
LOSS train 0.40301323290598595 valid 0.4739133585989475
LOSS train 0.40301323290598595 valid 0.4736089930308992
LOSS train 0.40301323290598595 valid 0.47378076140833375
LOSS train 0.40301323290598595 valid 0.4736077797236701
LOSS train 0.40301323290598595 valid 0.4736354675363092
LOSS train 0.40301323290598595 valid 0.47363426191050834
LOSS train 0.40301323290598595 valid 0.4734116417979731
LOSS train 0.40301323290598595 valid 0.4736420081721412
LOSS train 0.40301323290598595 valid 0.47364411202187723
LOSS train 0.40301323290598595 valid 0.4735266245438151
LOSS train 0.40301323290598595 valid 0.4736477805035455
LOSS train 0.40301323290598595 valid 0.4737039845419156
LOSS train 0.40301323290598595 valid 0.47377058765235935
LOSS train 0.40301323290598595 valid 0.4737936401031387
LOSS train 0.40301323290598595 valid 0.4737581034130025
LOSS train 0.40301323290598595 valid 0.4737830511359281
LOSS train 0.40301323290598595 valid 0.4738324771600741
LOSS train 0.40301323290598595 valid 0.4738844741599351
LOSS train 0.40301323290598595 valid 0.4739955298670935
LOSS train 0.40301323290598595 valid 0.47397148132868555
LOSS train 0.40301323290598595 valid 0.4741664584387432
LOSS train 0.40301323290598595 valid 0.4743780152560359
LOSS train 0.40301323290598595 valid 0.4743760436236321
LOSS train 0.40301323290598595 valid 0.47440513981831983
LOSS train 0.40301323290598595 valid 0.47444510779210497
LOSS train 0.40301323290598595 valid 0.474476531346639
LOSS train 0.40301323290598595 valid 0.4744587568318949
LOSS train 0.40301323290598595 valid 0.4745280006120909
LOSS train 0.40301323290598595 valid 0.47449133388305964
LOSS train 0.40301323290598595 valid 0.4746035669308042
LOSS train 0.40301323290598595 valid 0.47472741487233533
LOSS train 0.40301323290598595 valid 0.4748092701424768
LOSS train 0.40301323290598595 valid 0.4748596830357765
LOSS train 0.40301323290598595 valid 0.47476237180918585
LOSS train 0.40301323290598595 valid 0.4747108207044438
LOSS train 0.40301323290598595 valid 0.47490038833719617
LOSS train 0.40301323290598595 valid 0.47478736318269016
LOSS train 0.40301323290598595 valid 0.4746900903776225
LOSS train 0.40301323290598595 valid 0.47464874837578847
LOSS train 0.40301323290598595 valid 0.47448802268654733
LOSS train 0.40301323290598595 valid 0.47433904310067493
LOSS train 0.40301323290598595 valid 0.4746137493873533
LOSS train 0.40301323290598595 valid 0.4745122577286949
LOSS train 0.40301323290598595 valid 0.4744399321177369
LOSS train 0.40301323290598595 valid 0.4745681045241043
LOSS train 0.40301323290598595 valid 0.47458244574313263
LOSS train 0.40301323290598595 valid 0.4745771864323112
LOSS train 0.40301323290598595 valid 0.47463977735052226
LOSS train 0.40301323290598595 valid 0.47460298492543157
LOSS train 0.40301323290598595 valid 0.4746266621423055
LOSS train 0.40301323290598595 valid 0.47488839375972747
LOSS train 0.40301323290598595 valid 0.47497378058167566
LOSS train 0.40301323290598595 valid 0.47523466190175406
LOSS train 0.40301323290598595 valid 0.47509220077586267
LOSS train 0.40301323290598595 valid 0.4752966399033239
LOSS train 0.40301323290598595 valid 0.47530971239594855
LOSS train 0.40301323290598595 valid 0.4752697416115552
LOSS train 0.40301323290598595 valid 0.47525784245724806
LOSS train 0.40301323290598595 valid 0.4752987310174824
LOSS train 0.40301323290598595 valid 0.4752618805091814
LOSS train 0.40301323290598595 valid 0.47511313202289435
LOSS train 0.40301323290598595 valid 0.4751488166750619
LOSS train 0.40301323290598595 valid 0.47508099026807393
LOSS train 0.40301323290598595 valid 0.4750248784121452
LOSS train 0.40301323290598595 valid 0.47495117941589066
LOSS train 0.40301323290598595 valid 0.47494592160548804
LOSS train 0.40301323290598595 valid 0.4750983001370179
LOSS train 0.40301323290598595 valid 0.47529210345575423
LOSS train 0.40301323290598595 valid 0.4754346999437062
LOSS train 0.40301323290598595 valid 0.4756727439098642
LOSS train 0.40301323290598595 valid 0.47560130600576045
LOSS train 0.40301323290598595 valid 0.4757029255817737
LOSS train 0.40301323290598595 valid 0.4758027428213288
LOSS train 0.40301323290598595 valid 0.475839200037303
LOSS train 0.40301323290598595 valid 0.4758620523188236
LOSS train 0.40301323290598595 valid 0.4757575850053267
LOSS train 0.40301323290598595 valid 0.47573828124913614
LOSS train 0.40301323290598595 valid 0.47582527758412413
LOSS train 0.40301323290598595 valid 0.475778078539766
LOSS train 0.40301323290598595 valid 0.4758575882322045
LOSS train 0.40301323290598595 valid 0.47572722147618024
LOSS train 0.40301323290598595 valid 0.4755437330631175
LOSS train 0.40301323290598595 valid 0.47551558415095013
LOSS train 0.40301323290598595 valid 0.47553066230072993
LOSS train 0.40301323290598595 valid 0.47558667930498927
LOSS train 0.40301323290598595 valid 0.4755326920434048
LOSS train 0.40301323290598595 valid 0.47538386764643076
LOSS train 0.40301323290598595 valid 0.4754188107488878
LOSS train 0.40301323290598595 valid 0.4753420426406794
LOSS train 0.40301323290598595 valid 0.47544572953534375
LOSS train 0.40301323290598595 valid 0.47545063814212535
LOSS train 0.40301323290598595 valid 0.47528676632343697
LOSS train 0.40301323290598595 valid 0.4753273697952702
LOSS train 0.40301323290598595 valid 0.47519430090949805
LOSS train 0.40301323290598595 valid 0.47525875006808715
LOSS train 0.40301323290598595 valid 0.4754234866570618
LOSS train 0.40301323290598595 valid 0.4753503750103551
LOSS train 0.40301323290598595 valid 0.47538088056374883
LOSS train 0.40301323290598595 valid 0.4752557698712253
LOSS train 0.40301323290598595 valid 0.4753450385503546
LOSS train 0.40301323290598595 valid 0.47534720132748287
LOSS train 0.40301323290598595 valid 0.47535164787919815
LOSS train 0.40301323290598595 valid 0.4752162846903138
LOSS train 0.40301323290598595 valid 0.4751415474973496
LOSS train 0.40301323290598595 valid 0.4751976750006801
LOSS train 0.40301323290598595 valid 0.47516522466159256
LOSS train 0.40301323290598595 valid 0.4751861471366259
LOSS train 0.40301323290598595 valid 0.47515588785227425
LOSS train 0.40301323290598595 valid 0.47505459305527925
LOSS train 0.40301323290598595 valid 0.4750583746672448
LOSS train 0.40301323290598595 valid 0.47508570994100263
LOSS train 0.40301323290598595 valid 0.47507824679279637
LOSS train 0.40301323290598595 valid 0.47509166369071376
LOSS train 0.40301323290598595 valid 0.47520452528335033
LOSS train 0.40301323290598595 valid 0.4751709095991341
LOSS train 0.40301323290598595 valid 0.4751489850263747
LOSS train 0.40301323290598595 valid 0.4750420094668111
LOSS train 0.40301323290598595 valid 0.47507658911052186
LOSS train 0.40301323290598595 valid 0.47508000990129867
LOSS train 0.40301323290598595 valid 0.4750953863220155
LOSS train 0.40301323290598595 valid 0.47506294418126344
LOSS train 0.40301323290598595 valid 0.47506863732946997
LOSS train 0.40301323290598595 valid 0.47508504348141806
LOSS train 0.40301323290598595 valid 0.4750716301494339
LOSS train 0.40301323290598595 valid 0.47505299949351654
LOSS train 0.40301323290598595 valid 0.474991233257147
LOSS train 0.40301323290598595 valid 0.47508503990304984
LOSS train 0.40301323290598595 valid 0.47524431438985587
LOSS train 0.40301323290598595 valid 0.47522417092468683
LOSS train 0.40301323290598595 valid 0.4752567723891655
LOSS train 0.40301323290598595 valid 0.47521053516503536
LOSS train 0.40301323290598595 valid 0.4751604420000693
LOSS train 0.40301323290598595 valid 0.4750376649829279
LOSS train 0.40301323290598595 valid 0.4750781637412292
LOSS train 0.40301323290598595 valid 0.4751286762738656
LOSS train 0.40301323290598595 valid 0.4751471335318551
LOSS train 0.40301323290598595 valid 0.47510523446613834
LOSS train 0.40301323290598595 valid 0.4751116562667869
LOSS train 0.40301323290598595 valid 0.4751455591627832
LOSS train 0.40301323290598595 valid 0.4750779636841608
LOSS train 0.40301323290598595 valid 0.4751130083028008
LOSS train 0.40301323290598595 valid 0.47497072212856883
LOSS train 0.40301323290598595 valid 0.47480645566655877
LOSS train 0.40301323290598595 valid 0.4748125151016969
LOSS train 0.40301323290598595 valid 0.4750214560433876
LOSS train 0.40301323290598595 valid 0.4750841401625371
LOSS train 0.40301323290598595 valid 0.47507969466592537
LOSS train 0.40301323290598595 valid 0.4750133513201898
LOSS train 0.40301323290598595 valid 0.47488643528743724
LOSS train 0.40301323290598595 valid 0.47491917543561546
LOSS train 0.40301323290598595 valid 0.4747867547614234
LOSS train 0.40301323290598595 valid 0.474730095207861
LOSS train 0.40301323290598595 valid 0.4747635308991779
LOSS train 0.40301323290598595 valid 0.4747912871938927
LOSS train 0.40301323290598595 valid 0.4748404361939026
LOSS train 0.40301323290598595 valid 0.4748585605285537
LOSS train 0.40301323290598595 valid 0.474852725277456
LOSS train 0.40301323290598595 valid 0.4747877289601067
LOSS train 0.40301323290598595 valid 0.4747078515297874
LOSS train 0.40301323290598595 valid 0.47475646979961555
LOSS train 0.40301323290598595 valid 0.4747804627650314
LOSS train 0.40301323290598595 valid 0.47481104327040696
LOSS train 0.40301323290598595 valid 0.47496498388480085
LOSS train 0.40301323290598595 valid 0.4748837704829276
LOSS train 0.40301323290598595 valid 0.4748280995658466
LOSS train 0.40301323290598595 valid 0.47488199717377966
LOSS train 0.40301323290598595 valid 0.47482727329587676
LOSS train 0.40301323290598595 valid 0.4747467646806701
LOSS train 0.40301323290598595 valid 0.4747504476133896
LOSS train 0.40301323290598595 valid 0.4747353909299949
EPOCH 6:
  batch 1 loss: 0.3678765892982483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.3843829333782196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.4012870689233144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.40359392017126083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4088858485221863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.40846844514211017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.40465760231018066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4107047840952873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4096025029818217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.40746986865997314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.40520328825170343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4039080838362376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4012444225641397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.39994238317012787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.40143583416938783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.40285525284707546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.40294718567062826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.40310051871670616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4029406669892763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.40182754397392273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.40100500555265517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4016479104757309
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4026481962722281
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40347255890568096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4039051043987274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.40511085322270024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4051897978341138
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4039919621178082
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4051779518867361
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.40526720782121023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4057744712598862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4059037985280156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4053595093163577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.40554074329488415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.405826815537044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.40561903682019973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4054146119066187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4050194668142419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4057485247269655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.40637101158499717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.40628214580256766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4056829930770965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.40675341528515485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4065955199978568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4069621920585632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.406204544979593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4063959197795137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.406217809766531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.40642724596724217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4063664150238037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4060091446427738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.40605285419867587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4061326294575097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4057902925544315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4055379645390944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4058581713054861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4063921476665296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4055323729227329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4057504019494784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4058329164981842
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.40531622190944483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4053720745348161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.40528028966888546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4056838545948267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.40560511717429526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.40581454652728455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.40522621905625755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.405013225534383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4049919973249021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.40554060084479193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.40553167000622814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40530116524961257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.405143140930019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4052407258265727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4050397562980652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4052775537497119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.40541968910725085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4053159314088332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4052997159806988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4055776968598366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.40582707193162704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40580796904680205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.40543377758508703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4053086429124787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4053577223244835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.40526005105916846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4051327297742339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.40534929829564964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4051849256070812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4053415897819731
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4049619432989058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.40501110417687375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4051847445067539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4051805075178755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4048299274946514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.40510223247110844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.40473437739401746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4051050425184016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.40524949750514944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.40543020457029344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.40516128132839013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4050936815785427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4053209675747214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4050783116657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4051370975517091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.40499428617504407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.40508668333570536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.40531465383591475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4052005248879074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4056299884210933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4053811200030215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4053680231528623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.40503852240807187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.40503178955170144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.40458509533301645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.40439531232776316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4043258553386753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4041457118119224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4039134746339141
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4039908247689406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.40374004274360403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.40367243548885723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.40418741010068876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.40410777421728256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.40416392731666567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4040309576288102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.40388861298561096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.40410963259637356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4042228663614554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.40417618384728066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.40390490939598955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.40374668190876645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.40385522564550985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4037127043329068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.403632163339191
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4036199128364815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4038042419583258
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.40365034752133966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.40400281162570706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.40415538251399996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.40377912580544223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4037636707366352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.40413462928125077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.40443231186105144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.40453008269441537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.40454419120533824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4045139530889031
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4046960412650495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4047433755941839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4047760399182638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4049242205967177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.40475258584085266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.40462112933202504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.40437900129850807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.40453983199211857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4046242512189425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4046201770472678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.40444061839127843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4046691618625473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.40453474409878254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4043542189257486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.40420581915496306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4043255896290387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4041292954508851
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.403982308958516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4039435117359621
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4035631239771129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.40351868811107816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4034653591686452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.40348063269082235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4035174304630324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.40331076778644737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.40303325342994206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4031267541235891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4030636475767408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.40291467495262623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.40275083103422393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.40255760359630155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.402621251744265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4024610623717308
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.40253833035079156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.40265192762835994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.40253611128838335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.40252573933938274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4026610856120651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4025435119226415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4024113351329763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.40221228640764317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4021431193465278
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.40216066476545836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4021539527396257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.40203248243778944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.401993314836927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.401947794194074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.40194762211579543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.40195920576854627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4020495148479636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4025078284921068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.40243786169056917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4024088211357594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4024032818440774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4024285615080654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4025782399576873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.40250172144642066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.40250714334045967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.40253904505262095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4026200064426459
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4024117220766269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4024093086924849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4024507516906375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4025136882094975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.40255799074217957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4023443461863648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4022022700198343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.40209752875705096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.40203308369274493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4021203627784131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.40213473428279983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.40232469393238085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4023782889951359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4022752244817725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.40219645443800334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.40220677064138677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.40247032538588556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.40232955124643116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.402193767702685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4022596204070793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4021358410255951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.40214192672067334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4022247266510259
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.40229503171784536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4022817539757696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4021254509303703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.40208985344467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.40222927040242135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40231516881514406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40250554894596213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4025352375597513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.40264433310620457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.40260748292009035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4025597033164313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.40248946857846474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4025883677074448
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.40249020642921574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4025496502311862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4025900727365075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4026128111580605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.40267111240856107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.40264987562554905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.402791669011116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4027624183679482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4027766078000977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.40276194867409265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4026878308358155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.40277134121633046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.40272783127147704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4026683113222456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4027277789143629
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4028873714010688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.40298225845281893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4028777780432354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.40285330885694226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4027875865820243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.40272782426891907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4025960015800764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.40265088052229775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4026169924253828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.40261319524316647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4026731407775312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4026172865320135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.40265796523252534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4025064230184345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4025103413796687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.40236270123154577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.40216990449211815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.40231132939241937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4022654845826462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4021150984352441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4022446833417407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.40215328889233726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4021018474127474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.40199905232334815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.40196951476086995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4019788330499555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40207491224272207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4020451022820039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40202934380607735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4020713061715166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.40219508786927455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4022780666063572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.40230861367638576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40230580786727876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.40234222113069007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.40236867629751866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.40247639053958956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.40247566857047984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4026261372397644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.40251529226767135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.40253428003461067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4025947989026705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4026119469408181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.40248944250163654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4024576774918207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4024739093882473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4023463824733359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.40235768336486194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40237616298641365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.40221970044560246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.40233464235240973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.40240427611335633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4024374473516581
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4024069204162329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.40246221661186826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4023485857589989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4023270887987954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4023701226032233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.40238937594537105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4023211633071959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4023141381695726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4022603248246014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4022911809315191
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4022624826764468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.40230058710272465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4022617565444958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4022445912544544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4022297223835635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.40225123584452754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.402245479840331
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4021806422519104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4022135539488359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4023231186895572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.40220416489853916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4022624844366366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4022007344547146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.40224732329596335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.402262009414179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.40212222058270736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4021714111051616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4021194939416418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40226924033725964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.40218104085614603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4023026984337478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4023611860963415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4022375377284926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4022397802359816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.40216759389880075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4022055528521194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4022107945605256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.40215927131879636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4020724587781089
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.40198824870959987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.40200035443360155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40209626155264316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.40198614797686455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4020082221064769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4019573911019925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.40200874351319815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4020217952615056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.40205904376540014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4020721271634102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.40205469578917336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.40217036659217015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4021849713542245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.40215401973698167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4022708868327206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4022474196113524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.40220514922440864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4022478730134342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4022703855664426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4022871547454112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.40228759599824476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4022552202786169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4022547574688858
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.402256799493244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4021904415289561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4021666404256161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.40217384529999145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4021732542249892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4021714453175074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.402100718570383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40204176165926175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.40204353014212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.40211395899869756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4021536575164646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4020535282500379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4020961656626024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.402052266653194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.40204420632001053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.40200035523019906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.40199478367964425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4019559069210306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4018901164586447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4019765998722639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4018544957873785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4018235239047038
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.40182806724550746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.401776838512805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40183086146661384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.40183928466978525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.40198078989982605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4018676804188184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4016890164038435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.401561030161292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.40154014402391885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.40154358921227634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.40151847319062706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.40147867864707176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4014369606533471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.40146737481970657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.40147448712732736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4016029984121485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4015361631234873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4015020564306735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4015607509924018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.40150265758296094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4015358682148732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.40146803898777034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.40141685249987974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.40145751442715777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.40142640145052044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.40149409598239527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.40145740463835367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.40150220470225556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4015175967283969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4015060995606815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4014487149010242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4015266801769337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4014755333556193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4013252592448032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4014752381762793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.40151902162005343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4015460802173173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.40139649192400395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4013748898209515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4013201532007634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4013573789131751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.40136036004027187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.40130646050520685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4012362415942624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.40125998109579086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.401293371945552
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4013610718207122
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4014317799637065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4014521693592673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.40161210606607156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.40161499046958615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.40154874938179713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.40162089633356246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4016400602187771
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4016344956556956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.401623210066438
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.40162210819204297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.40160576140643744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4015999651690412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4015274220770532
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.40152803141819804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.40148700385698866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.40152961907168144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4015691058957759
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.40159440131291096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.40156448339950496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4015331875323217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.40154051413803843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4015822669426943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4016817230691192
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.40177203855545224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.40174030881111833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.40166142971342444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4016977031347848
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.401780913992131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.40171802904448944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4018198321178808
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4018198321178808 valid 0.4370877146720886
LOSS train 0.4018198321178808 valid 0.436645969748497
LOSS train 0.4018198321178808 valid 0.45787710944811505
LOSS train 0.4018198321178808 valid 0.4547525569796562
LOSS train 0.4018198321178808 valid 0.4515520751476288
LOSS train 0.4018198321178808 valid 0.45450842877229053
LOSS train 0.4018198321178808 valid 0.4547748565673828
LOSS train 0.4018198321178808 valid 0.45410290732979774
LOSS train 0.4018198321178808 valid 0.4476163420412276
LOSS train 0.4018198321178808 valid 0.4507666498422623
LOSS train 0.4018198321178808 valid 0.45429903810674493
LOSS train 0.4018198321178808 valid 0.4527800629536311
LOSS train 0.4018198321178808 valid 0.4549811299030597
LOSS train 0.4018198321178808 valid 0.45503500529697966
LOSS train 0.4018198321178808 valid 0.45348231395085653
LOSS train 0.4018198321178808 valid 0.4556009043008089
LOSS train 0.4018198321178808 valid 0.4582027459845823
LOSS train 0.4018198321178808 valid 0.45924807257122463
LOSS train 0.4018198321178808 valid 0.45994420114316437
LOSS train 0.4018198321178808 valid 0.4617022231221199
LOSS train 0.4018198321178808 valid 0.46063275706200374
LOSS train 0.4018198321178808 valid 0.45769364860924805
LOSS train 0.4018198321178808 valid 0.458507943412532
LOSS train 0.4018198321178808 valid 0.4569532809158166
LOSS train 0.4018198321178808 valid 0.4559051203727722
LOSS train 0.4018198321178808 valid 0.45531368026366603
LOSS train 0.4018198321178808 valid 0.4546847144762675
LOSS train 0.4018198321178808 valid 0.45541955530643463
LOSS train 0.4018198321178808 valid 0.45468839694713725
LOSS train 0.4018198321178808 valid 0.4555658628543218
LOSS train 0.4018198321178808 valid 0.45738254535582756
LOSS train 0.4018198321178808 valid 0.4573398157954216
LOSS train 0.4018198321178808 valid 0.45865583419799805
LOSS train 0.4018198321178808 valid 0.4579603759681477
LOSS train 0.4018198321178808 valid 0.45877139568328856
LOSS train 0.4018198321178808 valid 0.4589218952589565
LOSS train 0.4018198321178808 valid 0.4593754048283036
LOSS train 0.4018198321178808 valid 0.46056602895259857
LOSS train 0.4018198321178808 valid 0.46009183694154787
LOSS train 0.4018198321178808 valid 0.4616686969995499
LOSS train 0.4018198321178808 valid 0.46155442479180125
LOSS train 0.4018198321178808 valid 0.46267108619213104
LOSS train 0.4018198321178808 valid 0.46274649681046953
LOSS train 0.4018198321178808 valid 0.4631812931461768
LOSS train 0.4018198321178808 valid 0.46333230667644076
LOSS train 0.4018198321178808 valid 0.46383377326571423
LOSS train 0.4018198321178808 valid 0.4631351866620652
LOSS train 0.4018198321178808 valid 0.4635274348159631
LOSS train 0.4018198321178808 valid 0.4640599397980437
LOSS train 0.4018198321178808 valid 0.46368951082229615
LOSS train 0.4018198321178808 valid 0.4643417234514274
LOSS train 0.4018198321178808 valid 0.4640285653563646
LOSS train 0.4018198321178808 valid 0.4634846420782917
LOSS train 0.4018198321178808 valid 0.4635353044227318
LOSS train 0.4018198321178808 valid 0.46301930275830355
LOSS train 0.4018198321178808 valid 0.46275901475123
LOSS train 0.4018198321178808 valid 0.4626156311286123
LOSS train 0.4018198321178808 valid 0.46241594183033913
LOSS train 0.4018198321178808 valid 0.46308745974201265
LOSS train 0.4018198321178808 valid 0.4624379570285479
LOSS train 0.4018198321178808 valid 0.4612430734712569
LOSS train 0.4018198321178808 valid 0.4625213655733293
LOSS train 0.4018198321178808 valid 0.4628420779629359
LOSS train 0.4018198321178808 valid 0.4633964844979346
LOSS train 0.4018198321178808 valid 0.4636298587689033
LOSS train 0.4018198321178808 valid 0.4636584281018286
LOSS train 0.4018198321178808 valid 0.4632100956653481
LOSS train 0.4018198321178808 valid 0.4626309244948275
LOSS train 0.4018198321178808 valid 0.4622789573842201
LOSS train 0.4018198321178808 valid 0.46182602856840405
LOSS train 0.4018198321178808 valid 0.46140914189983423
LOSS train 0.4018198321178808 valid 0.46118611055943703
LOSS train 0.4018198321178808 valid 0.4615363343937756
LOSS train 0.4018198321178808 valid 0.46143568649485306
LOSS train 0.4018198321178808 valid 0.46083136439323424
LOSS train 0.4018198321178808 valid 0.4609927915428814
LOSS train 0.4018198321178808 valid 0.46076924963430926
LOSS train 0.4018198321178808 valid 0.46071642064131224
LOSS train 0.4018198321178808 valid 0.4604294552833219
LOSS train 0.4018198321178808 valid 0.4603639397770166
LOSS train 0.4018198321178808 valid 0.45986228187878925
LOSS train 0.4018198321178808 valid 0.46013052289078876
LOSS train 0.4018198321178808 valid 0.45990244092711485
LOSS train 0.4018198321178808 valid 0.45998074469112216
LOSS train 0.4018198321178808 valid 0.46008542635861566
LOSS train 0.4018198321178808 valid 0.4595879583164703
LOSS train 0.4018198321178808 valid 0.4591963479573699
LOSS train 0.4018198321178808 valid 0.4586157768287442
LOSS train 0.4018198321178808 valid 0.4590270057153166
LOSS train 0.4018198321178808 valid 0.4589970502588484
LOSS train 0.4018198321178808 valid 0.4586718465600695
LOSS train 0.4018198321178808 valid 0.4582815484508224
LOSS train 0.4018198321178808 valid 0.4576758610945876
LOSS train 0.4018198321178808 valid 0.45689627306258424
LOSS train 0.4018198321178808 valid 0.4564522191097862
LOSS train 0.4018198321178808 valid 0.4567701897273461
LOSS train 0.4018198321178808 valid 0.45718332971494224
LOSS train 0.4018198321178808 valid 0.4571552772303017
LOSS train 0.4018198321178808 valid 0.4574189435954046
LOSS train 0.4018198321178808 valid 0.45775938749313355
LOSS train 0.4018198321178808 valid 0.45789814467477324
LOSS train 0.4018198321178808 valid 0.4579525952245675
LOSS train 0.4018198321178808 valid 0.4585759466134229
LOSS train 0.4018198321178808 valid 0.4583912789821625
LOSS train 0.4018198321178808 valid 0.4584099014600118
LOSS train 0.4018198321178808 valid 0.458563468928607
LOSS train 0.4018198321178808 valid 0.4582315700076451
LOSS train 0.4018198321178808 valid 0.458651261749091
LOSS train 0.4018198321178808 valid 0.4588011579776029
LOSS train 0.4018198321178808 valid 0.4589131566611203
LOSS train 0.4018198321178808 valid 0.45898061131571866
LOSS train 0.4018198321178808 valid 0.4587849852229868
LOSS train 0.4018198321178808 valid 0.4587072017973503
LOSS train 0.4018198321178808 valid 0.4585093510778327
LOSS train 0.4018198321178808 valid 0.45852954284004543
LOSS train 0.4018198321178808 valid 0.4584847287885074
LOSS train 0.4018198321178808 valid 0.4585382793194208
LOSS train 0.4018198321178808 valid 0.45832587020882104
LOSS train 0.4018198321178808 valid 0.45803428222151366
LOSS train 0.4018198321178808 valid 0.45792572423815725
LOSS train 0.4018198321178808 valid 0.45776882422857046
LOSS train 0.4018198321178808 valid 0.4576589760721707
LOSS train 0.4018198321178808 valid 0.4577483714111452
LOSS train 0.4018198321178808 valid 0.4580767330142759
LOSS train 0.4018198321178808 valid 0.45794552063941957
LOSS train 0.4018198321178808 valid 0.4578432036297662
LOSS train 0.4018198321178808 valid 0.4583165047206278
LOSS train 0.4018198321178808 valid 0.458445260534063
LOSS train 0.4018198321178808 valid 0.45862228255863335
LOSS train 0.4018198321178808 valid 0.4583652613254694
LOSS train 0.4018198321178808 valid 0.45835250388574966
LOSS train 0.4018198321178808 valid 0.45829750642631994
LOSS train 0.4018198321178808 valid 0.4581078042213182
LOSS train 0.4018198321178808 valid 0.45832200882150165
LOSS train 0.4018198321178808 valid 0.458538395607913
LOSS train 0.4018198321178808 valid 0.458604446009678
LOSS train 0.4018198321178808 valid 0.45840505113566876
LOSS train 0.4018198321178808 valid 0.458256581771201
LOSS train 0.4018198321178808 valid 0.4579383205595634
LOSS train 0.4018198321178808 valid 0.45810393563338686
LOSS train 0.4018198321178808 valid 0.4581279348819814
LOSS train 0.4018198321178808 valid 0.4584252292841253
LOSS train 0.4018198321178808 valid 0.45806797442736324
LOSS train 0.4018198321178808 valid 0.4580993445383178
LOSS train 0.4018198321178808 valid 0.4579057245418943
LOSS train 0.4018198321178808 valid 0.4582676156742932
LOSS train 0.4018198321178808 valid 0.4578119228486301
LOSS train 0.4018198321178808 valid 0.4582244741755563
LOSS train 0.4018198321178808 valid 0.4583164259491351
LOSS train 0.4018198321178808 valid 0.45843198617299397
LOSS train 0.4018198321178808 valid 0.4585124615407148
LOSS train 0.4018198321178808 valid 0.45825272916178955
LOSS train 0.4018198321178808 valid 0.4585222442165699
LOSS train 0.4018198321178808 valid 0.4585143259980462
LOSS train 0.4018198321178808 valid 0.45865047420224836
LOSS train 0.4018198321178808 valid 0.45900800155523497
LOSS train 0.4018198321178808 valid 0.4589088181401514
LOSS train 0.4018198321178808 valid 0.45884864032268524
LOSS train 0.4018198321178808 valid 0.45853036585843787
LOSS train 0.4018198321178808 valid 0.45856227111071346
LOSS train 0.4018198321178808 valid 0.4583977190604121
LOSS train 0.4018198321178808 valid 0.45800063731493773
LOSS train 0.4018198321178808 valid 0.4579403632623286
LOSS train 0.4018198321178808 valid 0.4577822665252337
LOSS train 0.4018198321178808 valid 0.45765643173998055
LOSS train 0.4018198321178808 valid 0.4574693100280072
LOSS train 0.4018198321178808 valid 0.457540987494463
LOSS train 0.4018198321178808 valid 0.4577424387846674
LOSS train 0.4018198321178808 valid 0.457893821967424
LOSS train 0.4018198321178808 valid 0.4583594038205988
LOSS train 0.4018198321178808 valid 0.45823581908878525
LOSS train 0.4018198321178808 valid 0.4582846071137938
LOSS train 0.4018198321178808 valid 0.45840665474103365
LOSS train 0.4018198321178808 valid 0.4584104312562394
LOSS train 0.4018198321178808 valid 0.45850833211626324
LOSS train 0.4018198321178808 valid 0.4583632241595875
LOSS train 0.4018198321178808 valid 0.4587180439361745
LOSS train 0.4018198321178808 valid 0.4589155249381333
LOSS train 0.4018198321178808 valid 0.4587667341338856
LOSS train 0.4018198321178808 valid 0.45884418686230977
LOSS train 0.4018198321178808 valid 0.4588356694793174
LOSS train 0.4018198321178808 valid 0.4589588258947645
LOSS train 0.4018198321178808 valid 0.4588387707869212
LOSS train 0.4018198321178808 valid 0.45906640896978584
LOSS train 0.4018198321178808 valid 0.45899404158463347
LOSS train 0.4018198321178808 valid 0.45907899945653896
LOSS train 0.4018198321178808 valid 0.459110750393434
LOSS train 0.4018198321178808 valid 0.4590935306029117
LOSS train 0.4018198321178808 valid 0.45900933594300003
LOSS train 0.4018198321178808 valid 0.4588421852965104
LOSS train 0.4018198321178808 valid 0.45911854973638244
LOSS train 0.4018198321178808 valid 0.4592256471514702
LOSS train 0.4018198321178808 valid 0.4590970571176993
LOSS train 0.4018198321178808 valid 0.4588951953907603
LOSS train 0.4018198321178808 valid 0.45887393340086324
LOSS train 0.4018198321178808 valid 0.4589798724164768
LOSS train 0.4018198321178808 valid 0.4592628533465003
LOSS train 0.4018198321178808 valid 0.45930661110564913
LOSS train 0.4018198321178808 valid 0.45934848434961023
LOSS train 0.4018198321178808 valid 0.45927855744957924
LOSS train 0.4018198321178808 valid 0.4589783172702315
LOSS train 0.4018198321178808 valid 0.4591444686497792
LOSS train 0.4018198321178808 valid 0.4589632508789965
LOSS train 0.4018198321178808 valid 0.45898018514408784
LOSS train 0.4018198321178808 valid 0.45898004813892085
LOSS train 0.4018198321178808 valid 0.45876270055192186
LOSS train 0.4018198321178808 valid 0.45899870818939764
LOSS train 0.4018198321178808 valid 0.45899340381415993
LOSS train 0.4018198321178808 valid 0.4588785905872235
LOSS train 0.4018198321178808 valid 0.45901120801766715
LOSS train 0.4018198321178808 valid 0.45905923829259465
LOSS train 0.4018198321178808 valid 0.45912848539509865
LOSS train 0.4018198321178808 valid 0.45916254377700916
LOSS train 0.4018198321178808 valid 0.4591195891115153
LOSS train 0.4018198321178808 valid 0.4591363840324934
LOSS train 0.4018198321178808 valid 0.45919552197058994
LOSS train 0.4018198321178808 valid 0.4592463772417763
LOSS train 0.4018198321178808 valid 0.4593505834767578
LOSS train 0.4018198321178808 valid 0.45933233943159724
LOSS train 0.4018198321178808 valid 0.4595313534140587
LOSS train 0.4018198321178808 valid 0.459748634520699
LOSS train 0.4018198321178808 valid 0.45973962612517244
LOSS train 0.4018198321178808 valid 0.45975440513392735
LOSS train 0.4018198321178808 valid 0.4597966470090406
LOSS train 0.4018198321178808 valid 0.4598382912741767
LOSS train 0.4018198321178808 valid 0.45982430624750864
LOSS train 0.4018198321178808 valid 0.4598923128606989
LOSS train 0.4018198321178808 valid 0.4598623974281445
LOSS train 0.4018198321178808 valid 0.4599832509802939
LOSS train 0.4018198321178808 valid 0.4601204050623852
LOSS train 0.4018198321178808 valid 0.460186531017353
LOSS train 0.4018198321178808 valid 0.4602384766371086
LOSS train 0.4018198321178808 valid 0.46013691880672275
LOSS train 0.4018198321178808 valid 0.46007738383407265
LOSS train 0.4018198321178808 valid 0.46026655181925347
LOSS train 0.4018198321178808 valid 0.4601627350863764
LOSS train 0.4018198321178808 valid 0.4600528400658555
LOSS train 0.4018198321178808 valid 0.46001624672853647
LOSS train 0.4018198321178808 valid 0.45985058448803473
LOSS train 0.4018198321178808 valid 0.45969645492732525
LOSS train 0.4018198321178808 valid 0.4599723977913995
LOSS train 0.4018198321178808 valid 0.4598703804341229
LOSS train 0.4018198321178808 valid 0.4598152069643201
LOSS train 0.4018198321178808 valid 0.45993846874745165
LOSS train 0.4018198321178808 valid 0.45994666668833517
LOSS train 0.4018198321178808 valid 0.4599384836307386
LOSS train 0.4018198321178808 valid 0.45999373248231556
LOSS train 0.4018198321178808 valid 0.4599614053243591
LOSS train 0.4018198321178808 valid 0.4599862200428683
LOSS train 0.4018198321178808 valid 0.4602531076669693
LOSS train 0.4018198321178808 valid 0.46033974377757525
LOSS train 0.4018198321178808 valid 0.46061133108441793
LOSS train 0.4018198321178808 valid 0.4604726989749863
LOSS train 0.4018198321178808 valid 0.460682383203131
LOSS train 0.4018198321178808 valid 0.46069352860544244
LOSS train 0.4018198321178808 valid 0.46066408744081855
LOSS train 0.4018198321178808 valid 0.4606507385751153
LOSS train 0.4018198321178808 valid 0.4606990530047306
LOSS train 0.4018198321178808 valid 0.46067347190554997
LOSS train 0.4018198321178808 valid 0.4605218292428897
LOSS train 0.4018198321178808 valid 0.46055600869244545
LOSS train 0.4018198321178808 valid 0.4604804139328367
LOSS train 0.4018198321178808 valid 0.46042673907352494
LOSS train 0.4018198321178808 valid 0.46034349286646553
LOSS train 0.4018198321178808 valid 0.4603377293865636
LOSS train 0.4018198321178808 valid 0.4604918101900502
LOSS train 0.4018198321178808 valid 0.4606933570309971
LOSS train 0.4018198321178808 valid 0.4608276660985021
LOSS train 0.4018198321178808 valid 0.46107956035872816
LOSS train 0.4018198321178808 valid 0.4609966782508073
LOSS train 0.4018198321178808 valid 0.46112488303677185
LOSS train 0.4018198321178808 valid 0.4612189983839498
LOSS train 0.4018198321178808 valid 0.4612528907728719
LOSS train 0.4018198321178808 valid 0.4612715049599209
LOSS train 0.4018198321178808 valid 0.46116537495092913
LOSS train 0.4018198321178808 valid 0.4611322265388309
LOSS train 0.4018198321178808 valid 0.46122496792986073
LOSS train 0.4018198321178808 valid 0.4611802286595749
LOSS train 0.4018198321178808 valid 0.4612653816259035
LOSS train 0.4018198321178808 valid 0.46112699434161186
LOSS train 0.4018198321178808 valid 0.46095346715102414
LOSS train 0.4018198321178808 valid 0.4609274780708002
LOSS train 0.4018198321178808 valid 0.46095162851229154
LOSS train 0.4018198321178808 valid 0.4610047664650729
LOSS train 0.4018198321178808 valid 0.4609505934673443
LOSS train 0.4018198321178808 valid 0.4608144295382333
LOSS train 0.4018198321178808 valid 0.46084383223530306
LOSS train 0.4018198321178808 valid 0.4607692805843221
LOSS train 0.4018198321178808 valid 0.46087584446045765
LOSS train 0.4018198321178808 valid 0.4608888753529253
LOSS train 0.4018198321178808 valid 0.460718069904039
LOSS train 0.4018198321178808 valid 0.460763423614306
LOSS train 0.4018198321178808 valid 0.4606305042427961
LOSS train 0.4018198321178808 valid 0.46070560407476363
LOSS train 0.4018198321178808 valid 0.4608684485241518
LOSS train 0.4018198321178808 valid 0.4607936417734301
LOSS train 0.4018198321178808 valid 0.46082955638968987
LOSS train 0.4018198321178808 valid 0.4607016984248321
LOSS train 0.4018198321178808 valid 0.4607908588189345
LOSS train 0.4018198321178808 valid 0.46081307649612424
LOSS train 0.4018198321178808 valid 0.46081528176500947
LOSS train 0.4018198321178808 valid 0.4606840570044044
LOSS train 0.4018198321178808 valid 0.46061601093893395
LOSS train 0.4018198321178808 valid 0.4606721521796365
LOSS train 0.4018198321178808 valid 0.46064008083499847
LOSS train 0.4018198321178808 valid 0.46066559081763225
LOSS train 0.4018198321178808 valid 0.4606464856610624
LOSS train 0.4018198321178808 valid 0.4605454963136029
LOSS train 0.4018198321178808 valid 0.46055315266149327
LOSS train 0.4018198321178808 valid 0.46057591226793104
LOSS train 0.4018198321178808 valid 0.46056312571767827
LOSS train 0.4018198321178808 valid 0.46057895437265056
LOSS train 0.4018198321178808 valid 0.46069359579406227
LOSS train 0.4018198321178808 valid 0.46065357574232063
LOSS train 0.4018198321178808 valid 0.4606316497401586
LOSS train 0.4018198321178808 valid 0.46050993664355216
LOSS train 0.4018198321178808 valid 0.4605444430928877
LOSS train 0.4018198321178808 valid 0.4605485582314197
LOSS train 0.4018198321178808 valid 0.46055462209034864
LOSS train 0.4018198321178808 valid 0.46051013814285396
LOSS train 0.4018198321178808 valid 0.46052457294731497
LOSS train 0.4018198321178808 valid 0.46054508652746307
LOSS train 0.4018198321178808 valid 0.4605392512891315
LOSS train 0.4018198321178808 valid 0.4605108311882726
LOSS train 0.4018198321178808 valid 0.4604490907375629
LOSS train 0.4018198321178808 valid 0.4605445617729901
LOSS train 0.4018198321178808 valid 0.4607167624005484
LOSS train 0.4018198321178808 valid 0.46068892491663377
LOSS train 0.4018198321178808 valid 0.46071440923540063
LOSS train 0.4018198321178808 valid 0.460660783720739
LOSS train 0.4018198321178808 valid 0.46061775880637845
LOSS train 0.4018198321178808 valid 0.46048669032303685
LOSS train 0.4018198321178808 valid 0.46052761290882444
LOSS train 0.4018198321178808 valid 0.4605815350830912
LOSS train 0.4018198321178808 valid 0.4605872021682227
LOSS train 0.4018198321178808 valid 0.46052798513500465
LOSS train 0.4018198321178808 valid 0.460529338889023
LOSS train 0.4018198321178808 valid 0.46056671043824865
LOSS train 0.4018198321178808 valid 0.4605008651197484
LOSS train 0.4018198321178808 valid 0.4605404660105705
LOSS train 0.4018198321178808 valid 0.46038491128127246
LOSS train 0.4018198321178808 valid 0.46021900400083665
LOSS train 0.4018198321178808 valid 0.460213899699314
LOSS train 0.4018198321178808 valid 0.4604233691338883
LOSS train 0.4018198321178808 valid 0.46048732736836306
LOSS train 0.4018198321178808 valid 0.4604860840505258
LOSS train 0.4018198321178808 valid 0.4604128150843749
LOSS train 0.4018198321178808 valid 0.4602884530336007
LOSS train 0.4018198321178808 valid 0.46031305245137144
LOSS train 0.4018198321178808 valid 0.4601713083471571
LOSS train 0.4018198321178808 valid 0.4601114731908184
LOSS train 0.4018198321178808 valid 0.46014365274459124
LOSS train 0.4018198321178808 valid 0.46017889589831107
LOSS train 0.4018198321178808 valid 0.4602217111883864
LOSS train 0.4018198321178808 valid 0.46023160429068016
LOSS train 0.4018198321178808 valid 0.4602264128206821
LOSS train 0.4018198321178808 valid 0.46016009949168574
LOSS train 0.4018198321178808 valid 0.4600839298530664
LOSS train 0.4018198321178808 valid 0.4601265915090991
LOSS train 0.4018198321178808 valid 0.46015586016906634
LOSS train 0.4018198321178808 valid 0.46018443452684504
LOSS train 0.4018198321178808 valid 0.46034323354123047
LOSS train 0.4018198321178808 valid 0.4602636991289365
LOSS train 0.4018198321178808 valid 0.46020518791872067
LOSS train 0.4018198321178808 valid 0.46026253855391724
LOSS train 0.4018198321178808 valid 0.4602104773124059
LOSS train 0.4018198321178808 valid 0.4601269170276476
LOSS train 0.4018198321178808 valid 0.4601312136358541
LOSS train 0.4018198321178808 valid 0.46011100430798724
EPOCH 7:
  batch 1 loss: 0.3668164908885956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.38575609028339386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.40017639597256977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.40558499097824097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4103083610534668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.41205931703249615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4065186551639012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4114745631814003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4109154674741957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.40927488207817075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.406836981123144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4054980625708898
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4024553413574512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.4007485147033419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.40228959123293556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.40357781387865543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4032432331758387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4042206373479631
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4044059985562375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4028727859258652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.40223133138247896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.40245749056339264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.40355068963506946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40451812123258907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.40513920187950136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4063783482863353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4062596669903508
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.40518260427883696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.406393857865498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4057783971230189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.40657953677638886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.40668375231325626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4064020099061908
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4062955703805475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4064082588468279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4066091602047284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.40622414044431737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4060626547587545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.40677163004875183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.40733832120895386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4071138108648905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.40642530009860084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4075182988200077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4068572704087604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.40723439256350197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4063705782527509
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4065535417262544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.40617421207328636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4063238094047624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.40640145003795625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4060642806922688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.40550599705714446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.40563741495024486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4052643400651437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4049644080075351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4052060145352568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.40576769385421485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4048611619349184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.405193963798426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.40533415029446285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.40469128137729204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4046857669468849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.404682604566453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4050263627432287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4050285793267764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4050198238004338
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.40451755007701135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4044106979580486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4044984509979469
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.40497850009373254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4050390434936738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40464183936516446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.40476510541079797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.40477181568339066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4044944838682811
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4045480528944417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4046897597901233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.40455289337879574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40460039203680015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.40478716902434825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.40492802416836776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40493373681859274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.40470456466617355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.40462831407785416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4047193572801702
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.40457484992437587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4044832292644457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.40474428507414734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.40463769904683144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4048090351952447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.40448796356117334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4045258818761162
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4048265071325405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.40487724415799403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4045307084133751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4047368948037426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4043938883186616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.40483260124313586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.40508161139006565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.40534553170204163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.40506649076348483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.405162521144923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.40543745009644516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4051628184433167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4051663753532228
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.40497873948430113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4051453312423742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.40540803334227316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4053495881754324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.40574500398202373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4054050910043287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4054595362395048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.405181601775431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.40510821577749756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4046700806721397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.40450166551203565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4045049734095223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4043803922200607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40418143482769237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4042083928982417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.40398162726528386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4038430909152891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4042914727839028
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4043555620216554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.40444722247123716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4042560134142164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.40410277810622386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.40431590052321553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.40445506642031115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.404316550722489
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4041594269166466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4040364097013618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.40417654935578656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.404040221847705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.40388596698089885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4039097426130491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.40402162205563846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4038760018521461
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4041902637310165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.40421293654612134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4038040661220009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4037947050282653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4041141673818335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4043595337619384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.40453530406129773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.404466132390989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4044324165704299
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.40451734875505035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.40464046117443364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4046461041768392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4048259047088244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4046556994711098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4045015370923709
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.40422360579688826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.40443277743554884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.40449459583331376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4045181684433275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.40429631705525554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4045844617879616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4045381136238575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4043507081751498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4041707076040315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4044767519447701
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4042378306025412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.40411369078087084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.40407106783016616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.403659560009391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4035263206987154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.403498467961712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.40355676728136397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4035479067361843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.40331888909256736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4030764499151638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4031488535733059
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.40311823538371494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4030122504654256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4028485661509347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.40263760541931964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.40263673929528815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4024570988284217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.40254540239249803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4026419255104694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4025336841090781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.40256392000162083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4026533118776373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.40250043731222873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.40233773104647264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4021125906642447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.40210250335395653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4021479934453964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4021590261559212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.40210315538570285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.40206891962283636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4019764641818312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.40198739354427043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4020330688478995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.40221138094282394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.40264100799656877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.40258588563257725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.40255908995866774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.40254470809775206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4025328255230837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.40277392641076903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4027300119107845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.40270162282920463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.40270625850529346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4027562642443007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.402535741432355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4026421924527182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.40269487500190737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.40265281194759206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.40273267283754527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.402556535083923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40232995570263014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4022537009660588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4022134652844182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4023153330049207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.40231104482204544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4024980251919733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.40253399366682224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4024551721180187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4023514109420347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.40242587143530223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4027278336829373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4025537207391527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.40239172237636767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.40242870460522856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4022894759188619
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.40230186654490674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4023474860450496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4024304294740999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4024358241465585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4022897205639295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.40231615126642406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.40236808746419056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4024607385114088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40268889861770824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.40273312748480244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4028483227705856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4028647132217884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.40279184782653427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4027392369163923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4028577456258452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.40276182674970784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4028121829032898
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4028241616196749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4027993419633703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.40281769945736856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.40282336439952315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4029428675174713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4029386758329384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4029304508178953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.40285176356790564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.40281469157830935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4029199984728121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.402895376435481
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.40282119097412794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.402896458441897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4030260602479736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.40313101055530404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4029790469056345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.4029715648134246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4029161476816968
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4028329986966018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4027047879291031
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4027823502183857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.40272577960839434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4027412951882206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4027777965627195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.40273750446460865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.40277990511862555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.40263156592845917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4026395383771959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4024909571574552
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4023355154557662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4024712365606557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4024326979898804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4022848023999509
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4024064697886026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.40234862715005876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4023051745526731
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.40222014666449096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.40221814521631166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.402190297737088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40229923766955994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4022414775995108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40222224105110566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.40229413140979076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4024430201952845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4025584958750626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4025944305449417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40256152189757727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.40262114533792176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.40261363861512167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.40268047027668713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4026749965709609
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.40276300726514874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.40261997132493343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4026017534892296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4026142496864001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4026345813591219
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4024938653833819
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.40246382316347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.40245672795725496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4023494785926381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4023377269116882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40234430770144014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.40218160146629656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.40232371126563804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4023838621954764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4024032577632708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4024212944966096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.40246625468372915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.40234636937736706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.40234135370405893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4023703179216083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4023789718324078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4022833823033099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4022680163196635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.40222943397238853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4022429313429419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4022001911024129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.40219584264253316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4021813795890337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.40215472826590903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4021339899191827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4021605047246367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.40215537342719915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4020734063397787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.40205005434426394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.40215761558887103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4020337253270379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.40207871204023965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.40206745133071603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.40211624102805976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.40207184496380033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.401938734493199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4020028233351792
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4019662486416752
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40216894938665276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4021091704144855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4021977169646157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4022654780667308
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.40217177370606466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.402158829872159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4021131681396782
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.40214744407780234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4021402882604763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.40205386451800434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4019714935336794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4018950205073397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4019335379654711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40202409890150553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4019046163154861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4019262004906023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4018809813796804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4019487932616589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.40194744054831605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.40199015831216794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.40201558934317694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4019770340741176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4021100066808047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.40212974666563933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4021256304867975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4022413322370346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4022101317761374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.40217101598305666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.40221560624954494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4022577329864347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4022868924044274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.40228857754697056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.40225631807760526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.40223947023578366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.402256130455012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.40219974700609845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.40217827743989354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.40221693020916743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.40221673620756343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4021844480943554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4021429095613329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40212188829274315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.40213394055815893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4022273469531505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40223681926727295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4021261063489047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4021603667365455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.40211767712920826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4021349355732043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.40208532249406553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4020329706943952
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4019967976128659
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4019353404945257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.402023779299423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.40190074989940916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4018270580074455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4018231701068204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4017270371055123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40180706221554147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4018094128833379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4019476210325956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.401843398660793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4016671678171822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4015531387577578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4015393482133894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.40152826522603446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.40148882523839696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.40142144361643595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.40135634748959076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4014129288913568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.40143399929128043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4015354053672503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4014891848257444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4014454845510441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4015158237034572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4014700368226293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4015042702309214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4014441344520743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.40140444503731704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.40146251510037445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.40140657453309925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.401479360468314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4014520501779719
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.40146815734552155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.40150048035495683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.40148941965664137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4014439535252925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.40153134539199936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.40145952519133826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4013308234564908
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.40144683822642924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.40148506073276846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.401557687394045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.40140460882396123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4014003516479571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4013217485499108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4013831863572838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.40140537095833695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4013747553166733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4012930803934371
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4013113824481314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4013166925669257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4013420621868712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.40142764820471305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4014617802726256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.40163245160927935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.401641222928137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4015953727483216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4016840180515179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4016886652843458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.40168149411678317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.40167403954624337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.40167144903566987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4016651048039232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4016448675535849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.40156101335535993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4015672791814595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.40153531994287506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.40156818340699224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.40161218589946857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.40163250889467156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4015999018111612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.40159829141515674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4015933369843543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4016316794501296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.40170583116110936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4018008346337617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4017612646938136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4016815635383639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4017107238901704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40180103740793593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4017308993450902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.40181046105542423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.40181046105542423 valid 0.4353373944759369
LOSS train 0.40181046105542423 valid 0.4356802850961685
LOSS train 0.40181046105542423 valid 0.45678797364234924
LOSS train 0.40181046105542423 valid 0.45352737605571747
LOSS train 0.40181046105542423 valid 0.45028570890426634
LOSS train 0.40181046105542423 valid 0.4534117579460144
LOSS train 0.40181046105542423 valid 0.4541495782988412
LOSS train 0.40181046105542423 valid 0.4535049796104431
LOSS train 0.40181046105542423 valid 0.4471307595570882
LOSS train 0.40181046105542423 valid 0.4501397043466568
LOSS train 0.40181046105542423 valid 0.4536665000698783
LOSS train 0.40181046105542423 valid 0.4522110124429067
LOSS train 0.40181046105542423 valid 0.45439277245448184
LOSS train 0.40181046105542423 valid 0.45444021267550333
LOSS train 0.40181046105542423 valid 0.45293368299802145
LOSS train 0.40181046105542423 valid 0.4549804124981165
LOSS train 0.40181046105542423 valid 0.45760147185886607
LOSS train 0.40181046105542423 valid 0.45868227382500965
LOSS train 0.40181046105542423 valid 0.4593131777487303
LOSS train 0.40181046105542423 valid 0.46102135479450224
LOSS train 0.40181046105542423 valid 0.46003277812685284
LOSS train 0.40181046105542423 valid 0.4571161066943949
LOSS train 0.40181046105542423 valid 0.45794247673905414
LOSS train 0.40181046105542423 valid 0.45639873171846074
LOSS train 0.40181046105542423 valid 0.4553788614273071
LOSS train 0.40181046105542423 valid 0.4548067290049333
LOSS train 0.40181046105542423 valid 0.454186980371122
LOSS train 0.40181046105542423 valid 0.45491898698466166
LOSS train 0.40181046105542423 valid 0.45417195353014717
LOSS train 0.40181046105542423 valid 0.45499765674273174
LOSS train 0.40181046105542423 valid 0.4568143448522014
LOSS train 0.40181046105542423 valid 0.45678989216685295
LOSS train 0.40181046105542423 valid 0.4581489057251901
LOSS train 0.40181046105542423 valid 0.45742449339698343
LOSS train 0.40181046105542423 valid 0.45824511987822397
LOSS train 0.40181046105542423 valid 0.4584129750728607
LOSS train 0.40181046105542423 valid 0.45881203702978185
LOSS train 0.40181046105542423 valid 0.46003059180159317
LOSS train 0.40181046105542423 valid 0.4595649716181633
LOSS train 0.40181046105542423 valid 0.46108224540948867
LOSS train 0.40181046105542423 valid 0.4609500743993899
LOSS train 0.40181046105542423 valid 0.46205579170158934
LOSS train 0.40181046105542423 valid 0.4621129354765249
LOSS train 0.40181046105542423 valid 0.4625844643874602
LOSS train 0.40181046105542423 valid 0.46277008321550156
LOSS train 0.40181046105542423 valid 0.4632769667583963
LOSS train 0.40181046105542423 valid 0.462556780018705
LOSS train 0.40181046105542423 valid 0.4628882793088754
LOSS train 0.40181046105542423 valid 0.4634364660905332
LOSS train 0.40181046105542423 valid 0.46307151675224306
LOSS train 0.40181046105542423 valid 0.4637041980145024
LOSS train 0.40181046105542423 valid 0.46340197840562236
LOSS train 0.40181046105542423 valid 0.4628562572992073
LOSS train 0.40181046105542423 valid 0.46287901644353513
LOSS train 0.40181046105542423 valid 0.4623665771701119
LOSS train 0.40181046105542423 valid 0.46210008380668505
LOSS train 0.40181046105542423 valid 0.46194999730377867
LOSS train 0.40181046105542423 valid 0.4617655457093798
LOSS train 0.40181046105542423 valid 0.46243219810017083
LOSS train 0.40181046105542423 valid 0.4617781336108843
LOSS train 0.40181046105542423 valid 0.4606081936203065
LOSS train 0.40181046105542423 valid 0.46186241074915857
LOSS train 0.40181046105542423 valid 0.46217585839922465
LOSS train 0.40181046105542423 valid 0.46272699208930135
LOSS train 0.40181046105542423 valid 0.46295280823340784
LOSS train 0.40181046105542423 valid 0.462962373639598
LOSS train 0.40181046105542423 valid 0.46254783868789673
LOSS train 0.40181046105542423 valid 0.4619697507689981
LOSS train 0.40181046105542423 valid 0.4616045398988586
LOSS train 0.40181046105542423 valid 0.4611626126936504
LOSS train 0.40181046105542423 valid 0.4607280526362674
LOSS train 0.40181046105542423 valid 0.46049199667241836
LOSS train 0.40181046105542423 valid 0.4608638209022888
LOSS train 0.40181046105542423 valid 0.46074778687309575
LOSS train 0.40181046105542423 valid 0.4601692036787669
LOSS train 0.40181046105542423 valid 0.46033437628495066
LOSS train 0.40181046105542423 valid 0.46011091710685137
LOSS train 0.40181046105542423 valid 0.46006018725725323
LOSS train 0.40181046105542423 valid 0.45976100013225896
LOSS train 0.40181046105542423 valid 0.4597058277577162
LOSS train 0.40181046105542423 valid 0.4591881886676506
LOSS train 0.40181046105542423 valid 0.45942912196240776
LOSS train 0.40181046105542423 valid 0.4592115379959704
LOSS train 0.40181046105542423 valid 0.45928735427913214
LOSS train 0.40181046105542423 valid 0.45940060089616214
LOSS train 0.40181046105542423 valid 0.45888756631418715
LOSS train 0.40181046105542423 valid 0.45848268030703754
LOSS train 0.40181046105542423 valid 0.45791090923276817
LOSS train 0.40181046105542423 valid 0.45831038375918787
LOSS train 0.40181046105542423 valid 0.4583064728313022
LOSS train 0.40181046105542423 valid 0.45796350266907243
LOSS train 0.40181046105542423 valid 0.45756635847298993
LOSS train 0.40181046105542423 valid 0.4569795500206691
LOSS train 0.40181046105542423 valid 0.45619515123519494
LOSS train 0.40181046105542423 valid 0.45573950911823075
LOSS train 0.40181046105542423 valid 0.45606270711869
LOSS train 0.40181046105542423 valid 0.4564775630985339
LOSS train 0.40181046105542423 valid 0.45643574577205037
LOSS train 0.40181046105542423 valid 0.45670144696428316
LOSS train 0.40181046105542423 valid 0.4570521095395088
LOSS train 0.40181046105542423 valid 0.45718414358573384
LOSS train 0.40181046105542423 valid 0.4572379180029327
LOSS train 0.40181046105542423 valid 0.45786447606040437
LOSS train 0.40181046105542423 valid 0.457686858681532
LOSS train 0.40181046105542423 valid 0.45770249934423535
LOSS train 0.40181046105542423 valid 0.45787034591413894
LOSS train 0.40181046105542423 valid 0.4575481818658169
LOSS train 0.40181046105542423 valid 0.45794935276110965
LOSS train 0.40181046105542423 valid 0.45810204662314247
LOSS train 0.40181046105542423 valid 0.45820024826309896
LOSS train 0.40181046105542423 valid 0.45827479190654585
LOSS train 0.40181046105542423 valid 0.4580656327307224
LOSS train 0.40181046105542423 valid 0.45797964165696
LOSS train 0.40181046105542423 valid 0.4577808542209759
LOSS train 0.40181046105542423 valid 0.4578076772067858
LOSS train 0.40181046105542423 valid 0.4577785637871972
LOSS train 0.40181046105542423 valid 0.45782924870140534
LOSS train 0.40181046105542423 valid 0.45760056906837526
LOSS train 0.40181046105542423 valid 0.45730473689672324
LOSS train 0.40181046105542423 valid 0.4572055213153362
LOSS train 0.40181046105542423 valid 0.4570615555136657
LOSS train 0.40181046105542423 valid 0.4569633678823221
LOSS train 0.40181046105542423 valid 0.45704842558721215
LOSS train 0.40181046105542423 valid 0.4573745662646909
LOSS train 0.40181046105542423 valid 0.4572356221675873
LOSS train 0.40181046105542423 valid 0.4571485812701876
LOSS train 0.40181046105542423 valid 0.45761693931940034
LOSS train 0.40181046105542423 valid 0.4577471762895584
LOSS train 0.40181046105542423 valid 0.45792145876921425
LOSS train 0.40181046105542423 valid 0.45765721316520985
LOSS train 0.40181046105542423 valid 0.45763478274563796
LOSS train 0.40181046105542423 valid 0.45757330479947006
LOSS train 0.40181046105542423 valid 0.45737506505241965
LOSS train 0.40181046105542423 valid 0.45757953044193894
LOSS train 0.40181046105542423 valid 0.4578058315647973
LOSS train 0.40181046105542423 valid 0.4578860077787848
LOSS train 0.40181046105542423 valid 0.4576889550598868
LOSS train 0.40181046105542423 valid 0.457536524620609
LOSS train 0.40181046105542423 valid 0.4572135463035364
LOSS train 0.40181046105542423 valid 0.45737064480781553
LOSS train 0.40181046105542423 valid 0.45739804430210845
LOSS train 0.40181046105542423 valid 0.45768423861181234
LOSS train 0.40181046105542423 valid 0.45733874702787064
LOSS train 0.40181046105542423 valid 0.45735717937350273
LOSS train 0.40181046105542423 valid 0.45716030803220026
LOSS train 0.40181046105542423 valid 0.4575124778976179
LOSS train 0.40181046105542423 valid 0.45707459433549114
LOSS train 0.40181046105542423 valid 0.45749482633294286
LOSS train 0.40181046105542423 valid 0.45757668550382524
LOSS train 0.40181046105542423 valid 0.4576993894577026
LOSS train 0.40181046105542423 valid 0.45779038896623825
LOSS train 0.40181046105542423 valid 0.45751956771863134
LOSS train 0.40181046105542423 valid 0.45779051578122804
LOSS train 0.40181046105542423 valid 0.4577735261870669
LOSS train 0.40181046105542423 valid 0.4579121083982529
LOSS train 0.40181046105542423 valid 0.458249667325081
LOSS train 0.40181046105542423 valid 0.4581436421840813
LOSS train 0.40181046105542423 valid 0.4580761886472943
LOSS train 0.40181046105542423 valid 0.45776627892218297
LOSS train 0.40181046105542423 valid 0.45779338404536246
LOSS train 0.40181046105542423 valid 0.45763911260581164
LOSS train 0.40181046105542423 valid 0.45725072423617047
LOSS train 0.40181046105542423 valid 0.4571812196743269
LOSS train 0.40181046105542423 valid 0.4570242002969835
LOSS train 0.40181046105542423 valid 0.45688741875417305
LOSS train 0.40181046105542423 valid 0.4567000129854823
LOSS train 0.40181046105542423 valid 0.45677970840545473
LOSS train 0.40181046105542423 valid 0.4569855449455125
LOSS train 0.40181046105542423 valid 0.4571394197334199
LOSS train 0.40181046105542423 valid 0.4576031414901509
LOSS train 0.40181046105542423 valid 0.4574766159057617
LOSS train 0.40181046105542423 valid 0.4575197998174401
LOSS train 0.40181046105542423 valid 0.45764163222616117
LOSS train 0.40181046105542423 valid 0.45764184169385624
LOSS train 0.40181046105542423 valid 0.45774059057235716
LOSS train 0.40181046105542423 valid 0.45760746706615796
LOSS train 0.40181046105542423 valid 0.4579665202878963
LOSS train 0.40181046105542423 valid 0.45816633758250247
LOSS train 0.40181046105542423 valid 0.4580117505688907
LOSS train 0.40181046105542423 valid 0.4580759464038743
LOSS train 0.40181046105542423 valid 0.45805966837630085
LOSS train 0.40181046105542423 valid 0.4581801432829637
LOSS train 0.40181046105542423 valid 0.4580611902507928
LOSS train 0.40181046105542423 valid 0.45828829657124437
LOSS train 0.40181046105542423 valid 0.458221699579342
LOSS train 0.40181046105542423 valid 0.4583139161589325
LOSS train 0.40181046105542423 valid 0.4583422909764683
LOSS train 0.40181046105542423 valid 0.45832793890161716
LOSS train 0.40181046105542423 valid 0.45824481097478714
LOSS train 0.40181046105542423 valid 0.45807877480983733
LOSS train 0.40181046105542423 valid 0.4583514449796127
LOSS train 0.40181046105542423 valid 0.45845661607260507
LOSS train 0.40181046105542423 valid 0.4583245290375744
LOSS train 0.40181046105542423 valid 0.4581326041946706
LOSS train 0.40181046105542423 valid 0.45811170966197284
LOSS train 0.40181046105542423 valid 0.45822225374226666
LOSS train 0.40181046105542423 valid 0.4585118991166807
LOSS train 0.40181046105542423 valid 0.45854903757572174
LOSS train 0.40181046105542423 valid 0.4585920328171409
LOSS train 0.40181046105542423 valid 0.4585197146236897
LOSS train 0.40181046105542423 valid 0.4582152847033828
LOSS train 0.40181046105542423 valid 0.4583831342435119
LOSS train 0.40181046105542423 valid 0.45821051130741103
LOSS train 0.40181046105542423 valid 0.45823583284429475
LOSS train 0.40181046105542423 valid 0.4582291787717401
LOSS train 0.40181046105542423 valid 0.4580057750917175
LOSS train 0.40181046105542423 valid 0.4582435778085736
LOSS train 0.40181046105542423 valid 0.45824521937622475
LOSS train 0.40181046105542423 valid 0.4581238432078841
LOSS train 0.40181046105542423 valid 0.45825389396576655
LOSS train 0.40181046105542423 valid 0.4583093971720239
LOSS train 0.40181046105542423 valid 0.4583746506920401
LOSS train 0.40181046105542423 valid 0.45840773797930684
LOSS train 0.40181046105542423 valid 0.4583682686647522
LOSS train 0.40181046105542423 valid 0.4583928981492686
LOSS train 0.40181046105542423 valid 0.4584452137351036
LOSS train 0.40181046105542423 valid 0.4584967533838914
LOSS train 0.40181046105542423 valid 0.458608500317696
LOSS train 0.40181046105542423 valid 0.4585900856479662
LOSS train 0.40181046105542423 valid 0.4587863865223798
LOSS train 0.40181046105542423 valid 0.4590004415533661
LOSS train 0.40181046105542423 valid 0.45899014027269036
LOSS train 0.40181046105542423 valid 0.4590126222559155
LOSS train 0.40181046105542423 valid 0.4590572708153299
LOSS train 0.40181046105542423 valid 0.45909832451078625
LOSS train 0.40181046105542423 valid 0.4590825512345913
LOSS train 0.40181046105542423 valid 0.4591514848927569
LOSS train 0.40181046105542423 valid 0.45911670567696555
LOSS train 0.40181046105542423 valid 0.4592347283030181
LOSS train 0.40181046105542423 valid 0.4593659616034964
LOSS train 0.40181046105542423 valid 0.4594468657588546
LOSS train 0.40181046105542423 valid 0.45949806940966637
LOSS train 0.40181046105542423 valid 0.4594034602457873
LOSS train 0.40181046105542423 valid 0.4593460492343984
LOSS train 0.40181046105542423 valid 0.4595365690424087
LOSS train 0.40181046105542423 valid 0.4594260288749711
LOSS train 0.40181046105542423 valid 0.45932106453658156
LOSS train 0.40181046105542423 valid 0.459282176334317
LOSS train 0.40181046105542423 valid 0.4591129227662186
LOSS train 0.40181046105542423 valid 0.4589591580132643
LOSS train 0.40181046105542423 valid 0.45923217079946116
LOSS train 0.40181046105542423 valid 0.4591269665513157
LOSS train 0.40181046105542423 valid 0.4590661319685571
LOSS train 0.40181046105542423 valid 0.45918851186994647
LOSS train 0.40181046105542423 valid 0.4592016499869678
LOSS train 0.40181046105542423 valid 0.459191194273592
LOSS train 0.40181046105542423 valid 0.45925335543841
LOSS train 0.40181046105542423 valid 0.4592173216083357
LOSS train 0.40181046105542423 valid 0.45924380804640225
LOSS train 0.40181046105542423 valid 0.45951209700107576
LOSS train 0.40181046105542423 valid 0.45959399230926634
LOSS train 0.40181046105542423 valid 0.45986269059635343
LOSS train 0.40181046105542423 valid 0.4597183786362056
LOSS train 0.40181046105542423 valid 0.4599224340727949
LOSS train 0.40181046105542423 valid 0.45993366019398557
LOSS train 0.40181046105542423 valid 0.4598956744885072
LOSS train 0.40181046105542423 valid 0.4598851129702557
LOSS train 0.40181046105542423 valid 0.45992654492688734
LOSS train 0.40181046105542423 valid 0.45989910216865393
LOSS train 0.40181046105542423 valid 0.45974754668199097
LOSS train 0.40181046105542423 valid 0.45978121647889586
LOSS train 0.40181046105542423 valid 0.4597077393577299
LOSS train 0.40181046105542423 valid 0.4596497941153131
LOSS train 0.40181046105542423 valid 0.45956912264227867
LOSS train 0.40181046105542423 valid 0.45956031781322554
LOSS train 0.40181046105542423 valid 0.4597130334915075
LOSS train 0.40181046105542423 valid 0.4599105121937584
LOSS train 0.40181046105542423 valid 0.46005493068872994
LOSS train 0.40181046105542423 valid 0.460300991304745
LOSS train 0.40181046105542423 valid 0.4602231621742249
LOSS train 0.40181046105542423 valid 0.46034426530788747
LOSS train 0.40181046105542423 valid 0.46044337431735854
LOSS train 0.40181046105542423 valid 0.46047956439164967
LOSS train 0.40181046105542423 valid 0.46049752298497804
LOSS train 0.40181046105542423 valid 0.46040251417593525
LOSS train 0.40181046105542423 valid 0.46037787091040955
LOSS train 0.40181046105542423 valid 0.46046803757171767
LOSS train 0.40181046105542423 valid 0.4604183365758374
LOSS train 0.40181046105542423 valid 0.4604967561246674
LOSS train 0.40181046105542423 valid 0.4603605277836323
LOSS train 0.40181046105542423 valid 0.460180093915437
LOSS train 0.40181046105542423 valid 0.46015084275962614
LOSS train 0.40181046105542423 valid 0.46016811650549144
LOSS train 0.40181046105542423 valid 0.4602230659253161
LOSS train 0.40181046105542423 valid 0.4601678871271903
LOSS train 0.40181046105542423 valid 0.46002764822719816
LOSS train 0.40181046105542423 valid 0.4600630101426553
LOSS train 0.40181046105542423 valid 0.4599855427319805
LOSS train 0.40181046105542423 valid 0.4600909495642441
LOSS train 0.40181046105542423 valid 0.4601053518467936
LOSS train 0.40181046105542423 valid 0.45994030825051246
LOSS train 0.40181046105542423 valid 0.45998213399354726
LOSS train 0.40181046105542423 valid 0.45984545411103417
LOSS train 0.40181046105542423 valid 0.45991230325228505
LOSS train 0.40181046105542423 valid 0.4600811092530267
LOSS train 0.40181046105542423 valid 0.4600072340989435
LOSS train 0.40181046105542423 valid 0.46004014936360443
LOSS train 0.40181046105542423 valid 0.4599095957991261
LOSS train 0.40181046105542423 valid 0.4600002852371305
LOSS train 0.40181046105542423 valid 0.46001327166954675
LOSS train 0.40181046105542423 valid 0.4600143068256568
LOSS train 0.40181046105542423 valid 0.45988019906132427
LOSS train 0.40181046105542423 valid 0.4598096597312701
LOSS train 0.40181046105542423 valid 0.4598691905603597
LOSS train 0.40181046105542423 valid 0.45983667500683517
LOSS train 0.40181046105542423 valid 0.459859470818557
LOSS train 0.40181046105542423 valid 0.45983397290838657
LOSS train 0.40181046105542423 valid 0.45973353881340523
LOSS train 0.40181046105542423 valid 0.4597408067447082
LOSS train 0.40181046105542423 valid 0.45976756368913957
LOSS train 0.40181046105542423 valid 0.45975699292501837
LOSS train 0.40181046105542423 valid 0.4597700172318862
LOSS train 0.40181046105542423 valid 0.4598815927680689
LOSS train 0.40181046105542423 valid 0.4598394750979296
LOSS train 0.40181046105542423 valid 0.4598165467618004
LOSS train 0.40181046105542423 valid 0.45970331236154216
LOSS train 0.40181046105542423 valid 0.4597392090675583
LOSS train 0.40181046105542423 valid 0.4597430200134433
LOSS train 0.40181046105542423 valid 0.45975510519126367
LOSS train 0.40181046105542423 valid 0.4597174054943025
LOSS train 0.40181046105542423 valid 0.4597250816420974
LOSS train 0.40181046105542423 valid 0.4597461474423083
LOSS train 0.40181046105542423 valid 0.45973923802375793
LOSS train 0.40181046105542423 valid 0.4597133249964243
LOSS train 0.40181046105542423 valid 0.4596519403274243
LOSS train 0.40181046105542423 valid 0.45974800502595725
LOSS train 0.40181046105542423 valid 0.45991055006645504
LOSS train 0.40181046105542423 valid 0.4598838113611791
LOSS train 0.40181046105542423 valid 0.4599133300563847
LOSS train 0.40181046105542423 valid 0.4598655610373526
LOSS train 0.40181046105542423 valid 0.4598180727296005
LOSS train 0.40181046105542423 valid 0.4596916554742549
LOSS train 0.40181046105542423 valid 0.4597340590424008
LOSS train 0.40181046105542423 valid 0.4597873602084771
LOSS train 0.40181046105542423 valid 0.4597984043519888
LOSS train 0.40181046105542423 valid 0.4597465947625183
LOSS train 0.40181046105542423 valid 0.45975194292181676
LOSS train 0.40181046105542423 valid 0.45978590140681297
LOSS train 0.40181046105542423 valid 0.45972262089934673
LOSS train 0.40181046105542423 valid 0.459764606023536
LOSS train 0.40181046105542423 valid 0.4596166809982568
LOSS train 0.40181046105542423 valid 0.45945206641802316
LOSS train 0.40181046105542423 valid 0.4594532533741553
LOSS train 0.40181046105542423 valid 0.459665319514136
LOSS train 0.40181046105542423 valid 0.4597312265548153
LOSS train 0.40181046105542423 valid 0.45972928663209683
LOSS train 0.40181046105542423 valid 0.4596616146543871
LOSS train 0.40181046105542423 valid 0.45953629097376747
LOSS train 0.40181046105542423 valid 0.4595648947793638
LOSS train 0.40181046105542423 valid 0.45942947115216937
LOSS train 0.40181046105542423 valid 0.459367103980817
LOSS train 0.40181046105542423 valid 0.45940104804255744
LOSS train 0.40181046105542423 valid 0.4594325336282044
LOSS train 0.40181046105542423 valid 0.4594772247608099
LOSS train 0.40181046105542423 valid 0.4594905561964277
LOSS train 0.40181046105542423 valid 0.4594856267062466
LOSS train 0.40181046105542423 valid 0.4594193649392168
LOSS train 0.40181046105542423 valid 0.4593416406622146
LOSS train 0.40181046105542423 valid 0.4593868434097109
LOSS train 0.40181046105542423 valid 0.4594115999009874
LOSS train 0.40181046105542423 valid 0.45944034211193097
LOSS train 0.40181046105542423 valid 0.45959910289358696
LOSS train 0.40181046105542423 valid 0.4595206193523302
LOSS train 0.40181046105542423 valid 0.45946126283852606
LOSS train 0.40181046105542423 valid 0.4595145587235281
LOSS train 0.40181046105542423 valid 0.45946148306619927
LOSS train 0.40181046105542423 valid 0.45937789647715616
LOSS train 0.40181046105542423 valid 0.4593833557775487
LOSS train 0.40181046105542423 valid 0.4593692795855566
EPOCH 8:
  batch 1 loss: 0.36061209440231323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.3767232596874237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.39606528480847675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.39914654940366745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.40247716307640075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4049650579690933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.40007203817367554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.40655071288347244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4044974678092533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.403608563542366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4018665606325323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4001743247111638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.39785733131261974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.39660067217690603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.39886391957600914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.39984987676143646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.40005318557514863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.39995570646391976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.40035270076049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.39898882508277894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.3982865129198347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.3987542458555915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.40027155435603595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40162529175480205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.40206772208213803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.40351850252885085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4036178743397748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.40324881034237997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4042954907335084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.40421903630097705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.40502093492015717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.40528014302253723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.40503693891294074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4049411565065384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.40562831504004343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.40565535095002914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4053106581842577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4053167230204532
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.40577115156711674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4060154721140862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4052756123426484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.40457221227032797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.40564307431842006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.40495170043273404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.405185831255383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4043431586545447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.40459471116674706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4045734715958436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.40457691161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4049650371074677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.40454506640340765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.404590816451953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4047994186293404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4043196031340846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4039793160828677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4042797546301569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.40488981939198676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.40431805211922217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4042847338369337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4042879650990168
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.40401615471136376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.40402938954291806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4038875897725423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.40416881488636136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.40423368353110095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.40442888483856665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4039041079691987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.40371668119640913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4039253307425458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4044302718979972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.40441085461159826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40398744700683487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4040681054330852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4042059461007247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4040748782952627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.40429392339367615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4044139481984176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4042559392177142
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4043073940880691
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.40445723198354244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4045775293568034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40457064494854067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.40442527848553944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.40429869507040295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4044156642521129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4043594155200692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.404226458620751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.40441462194377725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4043181468261762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.40448891785409713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4041178616193625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.40416203471629514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4045067282133205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.40456338575545775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.40435407914613425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4045677011211713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4041526139396982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.40448333170949197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4048011339072025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4049265152215958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4046321222097567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.40456848606175067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.40480339527130127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.40451269998000217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4044664550395239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4043307672694044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.40443542794646503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4046006351709366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4044641546153147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4048928764733401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.40457527970408536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4045061942722116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4041826440169748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4041661256760882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4037479755671128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4035893989534214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4036460134208712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.40346634615275817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40324090233370036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.40330513243873917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.403066548680471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4030183409569693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.40356558779390844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4035546161955403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.40369909834861756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.40359629170289113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.40358044852421976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.40377032733522356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4039117576077927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4038644226697775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4036399198852423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4035386440880371
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4036487495540676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4035607391773765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.40341758551420986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.40346455968478145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4036140985732531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4034897136515465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4037939430140763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4038380346127919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.40343831173071626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.40341408089013164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.40369599349015245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4039452785833014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4041037384806008
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.40405956910897606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.404096906079727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.40423327905906214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4042860787586878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.40428245762983955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.40437327611525326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.40421994775533676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4040268400525735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.40383834749847264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4040849326118346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.40416124826058364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4042475529157432
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.40417498557627957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4044533688692177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.40436112862080337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4041477310361329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.40402129182109126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.40424564261377954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4040648199436141
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.40392498103055086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.40389749335955427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.403513306272244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4033656530082226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.40331631422748226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4033297505448846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.403295285869063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.403068735502487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.40283073269562913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4029052809052084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.40281563435282025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4026987576349215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.40251522330241013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.40234012466468166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4024267997488629
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.40226366188791063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.40234044029567784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.40241762357098715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4022731411326778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4022862010675928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.40238705664067653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4022420716862525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4020383974766349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.40173837019408004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4016585640175633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4016730653612237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.40173766937555444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4016172808284561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.40158660053589185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4015012162247884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4014935566828801
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.40150502080820044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4015922386029045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.40205410995868723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4019480981119913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4019521190226078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4019294685095697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4018690816246637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4020348219155091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.40198804160543516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.40194810759730454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4019121200714296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.40203209444520555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.40182243889340985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.40188025544134626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.40188912124860854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.40190373876648494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4019824771105118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4018038777118558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40156006214217604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4015111101228137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4014464386359409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4015173548102928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4015344322548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4016711370313549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.40173295031894335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.40165959885217484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4016109209608387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.40163238580451416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.40193496538060053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4017675872643789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.40161387398179654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.40169273730416655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4015921878448704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4015757992017738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.40160405480343364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.40167419167308066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.40169644484232214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4015497070269523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4015749062483127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4016441077628034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4017129357335931
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40188226933720744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.40193352967250245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.40205350555635394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.40206335062781967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4020145758059015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4018921123063269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.402051671174328
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4019853641263774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.40207517803931725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.40209175488813137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.40208525937578454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.40212177617415307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.40208477069096393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.40220207571983335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.40220111905341127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4022081724944569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4021399691406446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.40211475646401956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4021860760800979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4021576199447736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4020731867751259
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4021171524312145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.40224151365085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4023858853257619
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4022996375387199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.4023136150745945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.40221998832071687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4021246475026463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.40198715351662545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4020183149136995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.40193547682369246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.40193412119328087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4019997575247598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4019307711610088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4019973336330639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4018473856370239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.40184975423655667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4016982422475397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4015241495045749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4016510515973188
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.40160346224850263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.40146490095330656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4015994046324043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.40151350923946927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4014651819904504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.40133381671939333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.40131496235254377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.40128081827096534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40139675035811306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.40133986981598646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40134323847833825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.40144797569761675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.40163522639076604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4017768027453587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.40184094549454363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40180542126093827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.40182842248128947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.40186925871031626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4019582752454079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4019435934118322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4020587143673239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4019190997085315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4018812943063053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4019298736254374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.40198243228700076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.40186119227614625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.40185948970294233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.40183281849481556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4017032377055434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.401681844899857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4016751375182832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.40148317542943085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.40162442822286615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4016514644507439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.40169253015824835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4016844723851253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.40172932723078864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4016103642002033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.40157028834025066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.40158692851096767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4015958575232172
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4015414590168299
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4015417152250822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.40147654255852105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4014872234558391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.401451296965528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4014875164526535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4014530313419707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.40143550561024594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4014031570747586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4014305235413601
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4014078494979114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4013098866019206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4013394993363005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.40143722799969583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.40132990578211936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4013997564265678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.40136027229046395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4013995617183287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.40135980441811536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.401218464006656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4012974903604688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4012557363088152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4014361068606377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.40136104481311136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4014923409586064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4015397687521342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.40146444919844004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.40146574663079304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4014408163769397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.40146197485992474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.40146574694877385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4013603076039891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.40128349908760613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.40119075223251627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4012128511782397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40129061587809167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4012112426387388
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4012424624302018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.40122957125808417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.40129098070769753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.40129487907420325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.40135693782551374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.40137141280704075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.40136214570655715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.40149990432170213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.40153331779579815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.40156048994797927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4016700385368034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.40164347489674884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4016141129774359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.40163845641781454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.40166768544734655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4017026029728554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4017489142013046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.40176538922773897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.40174151002242164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.40171525025750227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.40167459956804913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4016832730713043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4017390242780235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4017395945610823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.40170895149022107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.40169532173558287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40162984170312954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4016143359750977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.40171323899500677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40176450259362656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.40166350200578765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4017079894097976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4016819454594792
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.40167358225768374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.40161726514600543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4016103262320543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4015792673048766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.40155585399087595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.40164422564227464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4015286816709538
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4014897372903703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4014947753060948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4014113562683615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40148452171428717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.40149561063687605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4016367484629154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4015219210835169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.40136309153405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4012445020616498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4012281442485233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.40124736384109216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.40121487208775114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4011655299757271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4010785281950352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.401121401553632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.401130129215194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4012323938437042
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4011656712849163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4011397324953472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4012161640873278
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4011660554322852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.40119294800723976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.401131818620421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4010893303241456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4011387997140179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4011150490669977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4011791045478857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.40113540396306185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4011495674896466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.40115138276849155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4011281451758216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.40107751641195144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.40116541495926206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4011171854962812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.40098939638037784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.40113653727742127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.40113660527216033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.40115333286424476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4009950571880605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.40098790247594157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4009034359592131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.40094755822365435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.40096369556213135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4009001376149861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.40082615213405026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4008087958124551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4008372045563462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4008663076216279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4009261785188593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4009494449909743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4011276150017642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.40114997414195486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.401089468391683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.40116616358448354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4011823316592151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4011841995186276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.40117771649307793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4011795986278922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4011861519439857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4011672233038537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4011091307624356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4010873978728788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.40101319571031785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4010517790458088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4010795882065052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.40109576479248377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.40107956974728765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4010587604272933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4010717608758749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4011082853479632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.40117460873819166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4012576165117419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4012264851201525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.40114037074849135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4012054885501292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40124837331315305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4011794207835147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.40128279572068637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.40128279572068637 valid 0.4375191926956177
LOSS train 0.40128279572068637 valid 0.4379581809043884
LOSS train 0.40128279572068637 valid 0.4590594371159871
LOSS train 0.40128279572068637 valid 0.4558159410953522
LOSS train 0.40128279572068637 valid 0.45255525708198546
LOSS train 0.40128279572068637 valid 0.4557485232750575
LOSS train 0.40128279572068637 valid 0.45667621067592074
LOSS train 0.40128279572068637 valid 0.4560822919011116
LOSS train 0.40128279572068637 valid 0.4497756361961365
LOSS train 0.40128279572068637 valid 0.4527194112539291
LOSS train 0.40128279572068637 valid 0.4562542194669897
LOSS train 0.40128279572068637 valid 0.4547930434346199
LOSS train 0.40128279572068637 valid 0.4570083182591658
LOSS train 0.40128279572068637 valid 0.4570720429931368
LOSS train 0.40128279572068637 valid 0.4555730005105337
LOSS train 0.40128279572068637 valid 0.4576070252805948
LOSS train 0.40128279572068637 valid 0.46024321983842287
LOSS train 0.40128279572068637 valid 0.46134049197038013
LOSS train 0.40128279572068637 valid 0.46196770668029785
LOSS train 0.40128279572068637 valid 0.4636765122413635
LOSS train 0.40128279572068637 valid 0.4626910218170711
LOSS train 0.40128279572068637 valid 0.45977025817741046
LOSS train 0.40128279572068637 valid 0.46060606318971387
LOSS train 0.40128279572068637 valid 0.4590625079969565
LOSS train 0.40128279572068637 valid 0.4580509340763092
LOSS train 0.40128279572068637 valid 0.457488544858419
LOSS train 0.40128279572068637 valid 0.4568624529573653
LOSS train 0.40128279572068637 valid 0.45760204643011093
LOSS train 0.40128279572068637 valid 0.4568502615238058
LOSS train 0.40128279572068637 valid 0.45766749382019045
LOSS train 0.40128279572068637 valid 0.4594954598334528
LOSS train 0.40128279572068637 valid 0.4594648238271475
LOSS train 0.40128279572068637 valid 0.46083531054583465
LOSS train 0.40128279572068637 valid 0.4601031278862673
LOSS train 0.40128279572068637 valid 0.46094261067254205
LOSS train 0.40128279572068637 valid 0.4611189174983237
LOSS train 0.40128279572068637 valid 0.4614995548854003
LOSS train 0.40128279572068637 valid 0.4627316303943333
LOSS train 0.40128279572068637 valid 0.46227297492516345
LOSS train 0.40128279572068637 valid 0.46377132162451745
LOSS train 0.40128279572068637 valid 0.46363664182221015
LOSS train 0.40128279572068637 valid 0.46473893452258336
LOSS train 0.40128279572068637 valid 0.46478256028751996
LOSS train 0.40128279572068637 valid 0.4652637236497619
LOSS train 0.40128279572068637 valid 0.4654472953743405
LOSS train 0.40128279572068637 valid 0.4659621890472329
LOSS train 0.40128279572068637 valid 0.4652425729213877
LOSS train 0.40128279572068637 valid 0.46555655139187974
LOSS train 0.40128279572068637 valid 0.46611099766225234
LOSS train 0.40128279572068637 valid 0.4657360488176346
LOSS train 0.40128279572068637 valid 0.4663635726068534
LOSS train 0.40128279572068637 valid 0.46606040516724956
LOSS train 0.40128279572068637 valid 0.46550613585508094
LOSS train 0.40128279572068637 valid 0.4655191765891181
LOSS train 0.40128279572068637 valid 0.465007268298756
LOSS train 0.40128279572068637 valid 0.46474553857530865
LOSS train 0.40128279572068637 valid 0.4645974552422239
LOSS train 0.40128279572068637 valid 0.4644095743524617
LOSS train 0.40128279572068637 valid 0.46507965205079416
LOSS train 0.40128279572068637 valid 0.46442384719848634
LOSS train 0.40128279572068637 valid 0.4632624690649939
LOSS train 0.40128279572068637 valid 0.46451094458180087
LOSS train 0.40128279572068637 valid 0.4648246916513594
LOSS train 0.40128279572068637 valid 0.4653807180002332
LOSS train 0.40128279572068637 valid 0.46560750832924475
LOSS train 0.40128279572068637 valid 0.4656115427161708
LOSS train 0.40128279572068637 valid 0.4652047766678369
LOSS train 0.40128279572068637 valid 0.4646289076875238
LOSS train 0.40128279572068637 valid 0.4642599531705829
LOSS train 0.40128279572068637 valid 0.4638192172561373
LOSS train 0.40128279572068637 valid 0.4633832099572034
LOSS train 0.40128279572068637 valid 0.4631391701598962
LOSS train 0.40128279572068637 valid 0.4635109676890177
LOSS train 0.40128279572068637 valid 0.46338644744576635
LOSS train 0.40128279572068637 valid 0.4628127157688141
LOSS train 0.40128279572068637 valid 0.4629780893263064
LOSS train 0.40128279572068637 valid 0.46275213554308015
LOSS train 0.40128279572068637 valid 0.4627022364964852
LOSS train 0.40128279572068637 valid 0.4624024014684218
LOSS train 0.40128279572068637 valid 0.4623480875045061
LOSS train 0.40128279572068637 valid 0.46182814093283664
LOSS train 0.40128279572068637 valid 0.4620617362784176
LOSS train 0.40128279572068637 valid 0.46184920438800947
LOSS train 0.40128279572068637 valid 0.4619267728357088
LOSS train 0.40128279572068637 valid 0.4620420589166529
LOSS train 0.40128279572068637 valid 0.461527289346207
LOSS train 0.40128279572068637 valid 0.4611198354041439
LOSS train 0.40128279572068637 valid 0.46054697849533777
LOSS train 0.40128279572068637 valid 0.46094237150770895
LOSS train 0.40128279572068637 valid 0.4609394060240852
LOSS train 0.40128279572068637 valid 0.4605924719637567
LOSS train 0.40128279572068637 valid 0.4601941154054973
LOSS train 0.40128279572068637 valid 0.45961295212468795
LOSS train 0.40128279572068637 valid 0.458831380973471
LOSS train 0.40128279572068637 valid 0.4583731870902212
LOSS train 0.40128279572068637 valid 0.4586983611807227
LOSS train 0.40128279572068637 valid 0.45911265863585715
LOSS train 0.40128279572068637 valid 0.45906883569396273
LOSS train 0.40128279572068637 valid 0.459335152548973
LOSS train 0.40128279572068637 valid 0.4596883022785187
LOSS train 0.40128279572068637 valid 0.45981792707254393
LOSS train 0.40128279572068637 valid 0.45986930967545975
LOSS train 0.40128279572068637 valid 0.46049532988696423
LOSS train 0.40128279572068637 valid 0.46032012798465216
LOSS train 0.40128279572068637 valid 0.4603365060828981
LOSS train 0.40128279572068637 valid 0.4605044461083862
LOSS train 0.40128279572068637 valid 0.4601839463287425
LOSS train 0.40128279572068637 valid 0.46058475805653465
LOSS train 0.40128279572068637 valid 0.4607349289666622
LOSS train 0.40128279572068637 valid 0.46083182042295284
LOSS train 0.40128279572068637 valid 0.46090687502611866
LOSS train 0.40128279572068637 valid 0.4606938548386097
LOSS train 0.40128279572068637 valid 0.46060698538754896
LOSS train 0.40128279572068637 valid 0.4604050360227886
LOSS train 0.40128279572068637 valid 0.46043538528939953
LOSS train 0.40128279572068637 valid 0.4604120873685541
LOSS train 0.40128279572068637 valid 0.46046310433974635
LOSS train 0.40128279572068637 valid 0.4602337545257504
LOSS train 0.40128279572068637 valid 0.45993796541911214
LOSS train 0.40128279572068637 valid 0.4598366451760133
LOSS train 0.40128279572068637 valid 0.4596919279453183
LOSS train 0.40128279572068637 valid 0.4595938894103785
LOSS train 0.40128279572068637 valid 0.4596789457449099
LOSS train 0.40128279572068637 valid 0.46000154220288797
LOSS train 0.40128279572068637 valid 0.45986502838134763
LOSS train 0.40128279572068637 valid 0.4597816699080997
LOSS train 0.40128279572068637 valid 0.46024582282764703
LOSS train 0.40128279572068637 valid 0.46038014348596334
LOSS train 0.40128279572068637 valid 0.46055480768514234
LOSS train 0.40128279572068637 valid 0.46028829629604634
LOSS train 0.40128279572068637 valid 0.4602663187125257
LOSS train 0.40128279572068637 valid 0.4602006524801254
LOSS train 0.40128279572068637 valid 0.46000047016860846
LOSS train 0.40128279572068637 valid 0.46019929514002444
LOSS train 0.40128279572068637 valid 0.460428285157239
LOSS train 0.40128279572068637 valid 0.4605134990723694
LOSS train 0.40128279572068637 valid 0.4603167328521283
LOSS train 0.40128279572068637 valid 0.4601645594921665
LOSS train 0.40128279572068637 valid 0.459841310120315
LOSS train 0.40128279572068637 valid 0.45999875622136255
LOSS train 0.40128279572068637 valid 0.4600307596913466
LOSS train 0.40128279572068637 valid 0.4603154157668772
LOSS train 0.40128279572068637 valid 0.4599751529993711
LOSS train 0.40128279572068637 valid 0.4599911926521195
LOSS train 0.40128279572068637 valid 0.45979401366464023
LOSS train 0.40128279572068637 valid 0.4601436686025907
LOSS train 0.40128279572068637 valid 0.459710752882925
LOSS train 0.40128279572068637 valid 0.46013681791924144
LOSS train 0.40128279572068637 valid 0.46021483328518453
LOSS train 0.40128279572068637 valid 0.46033434371153514
LOSS train 0.40128279572068637 valid 0.46042684233741255
LOSS train 0.40128279572068637 valid 0.46015079417511034
LOSS train 0.40128279572068637 valid 0.46042172717892266
LOSS train 0.40128279572068637 valid 0.460404096679254
LOSS train 0.40128279572068637 valid 0.46054563310838514
LOSS train 0.40128279572068637 valid 0.46087762006582356
LOSS train 0.40128279572068637 valid 0.460771138121368
LOSS train 0.40128279572068637 valid 0.46070454562012153
LOSS train 0.40128279572068637 valid 0.4603964547691105
LOSS train 0.40128279572068637 valid 0.46042276844382285
LOSS train 0.40128279572068637 valid 0.4602657773109697
LOSS train 0.40128279572068637 valid 0.45987830265068713
LOSS train 0.40128279572068637 valid 0.4598072189494876
LOSS train 0.40128279572068637 valid 0.4596521916185937
LOSS train 0.40128279572068637 valid 0.45951142473654316
LOSS train 0.40128279572068637 valid 0.45932761247617654
LOSS train 0.40128279572068637 valid 0.4594102514361193
LOSS train 0.40128279572068637 valid 0.4596191720948333
LOSS train 0.40128279572068637 valid 0.45977498211804224
LOSS train 0.40128279572068637 valid 0.46024095153107364
LOSS train 0.40128279572068637 valid 0.46011469378108866
LOSS train 0.40128279572068637 valid 0.460154399968857
LOSS train 0.40128279572068637 valid 0.4602785927022813
LOSS train 0.40128279572068637 valid 0.4602769383753853
LOSS train 0.40128279572068637 valid 0.4603725492954254
LOSS train 0.40128279572068637 valid 0.4602456528016112
LOSS train 0.40128279572068637 valid 0.4606051029121808
LOSS train 0.40128279572068637 valid 0.46080862789341576
LOSS train 0.40128279572068637 valid 0.4606502016163405
LOSS train 0.40128279572068637 valid 0.4607098968492614
LOSS train 0.40128279572068637 valid 0.4606925889602682
LOSS train 0.40128279572068637 valid 0.46081583775006807
LOSS train 0.40128279572068637 valid 0.4606983524854066
LOSS train 0.40128279572068637 valid 0.46092606692210486
LOSS train 0.40128279572068637 valid 0.4608590754302772
LOSS train 0.40128279572068637 valid 0.4609540252275364
LOSS train 0.40128279572068637 valid 0.4609815637695598
LOSS train 0.40128279572068637 valid 0.46097116457655074
LOSS train 0.40128279572068637 valid 0.46088689959869183
LOSS train 0.40128279572068637 valid 0.4607216320539776
LOSS train 0.40128279572068637 valid 0.460993725279863
LOSS train 0.40128279572068637 valid 0.46109999530017376
LOSS train 0.40128279572068637 valid 0.4609660492351018
LOSS train 0.40128279572068637 valid 0.4607779569539827
LOSS train 0.40128279572068637 valid 0.4607545053347563
LOSS train 0.40128279572068637 valid 0.460867881014639
LOSS train 0.40128279572068637 valid 0.4611601588992298
LOSS train 0.40128279572068637 valid 0.46119376008558755
LOSS train 0.40128279572068637 valid 0.46123615760899067
LOSS train 0.40128279572068637 valid 0.46116369009017943
LOSS train 0.40128279572068637 valid 0.46086032369836644
LOSS train 0.40128279572068637 valid 0.46102838985400624
LOSS train 0.40128279572068637 valid 0.46085724997990235
LOSS train 0.40128279572068637 valid 0.4608821059558906
LOSS train 0.40128279572068637 valid 0.46087339869359645
LOSS train 0.40128279572068637 valid 0.4606493533525652
LOSS train 0.40128279572068637 valid 0.46088835107531523
LOSS train 0.40128279572068637 valid 0.46089001988562256
LOSS train 0.40128279572068637 valid 0.4607678958388607
LOSS train 0.40128279572068637 valid 0.4608959022022429
LOSS train 0.40128279572068637 valid 0.46095307658633916
LOSS train 0.40128279572068637 valid 0.46101826120097683
LOSS train 0.40128279572068637 valid 0.46105122398322734
LOSS train 0.40128279572068637 valid 0.46101339286732895
LOSS train 0.40128279572068637 valid 0.46103865254757015
LOSS train 0.40128279572068637 valid 0.4610885176117773
LOSS train 0.40128279572068637 valid 0.46114314193000444
LOSS train 0.40128279572068637 valid 0.4612549982213099
LOSS train 0.40128279572068637 valid 0.46123572925454404
LOSS train 0.40128279572068637 valid 0.46143109419129114
LOSS train 0.40128279572068637 valid 0.4616449691051811
LOSS train 0.40128279572068637 valid 0.46163634996156433
LOSS train 0.40128279572068637 valid 0.46166434122307953
LOSS train 0.40128279572068637 valid 0.46171000440205845
LOSS train 0.40128279572068637 valid 0.46174952109654743
LOSS train 0.40128279572068637 valid 0.4617323519381802
LOSS train 0.40128279572068637 valid 0.46180355312540666
LOSS train 0.40128279572068637 valid 0.46176772669219135
LOSS train 0.40128279572068637 valid 0.46188437626351436
LOSS train 0.40128279572068637 valid 0.4620122352372045
LOSS train 0.40128279572068637 valid 0.46209702063432506
LOSS train 0.40128279572068637 valid 0.4621477422529253
LOSS train 0.40128279572068637 valid 0.46205471871748505
LOSS train 0.40128279572068637 valid 0.46199802251962513
LOSS train 0.40128279572068637 valid 0.46218847467544233
LOSS train 0.40128279572068637 valid 0.46207358372413504
LOSS train 0.40128279572068637 valid 0.46196982968708633
LOSS train 0.40128279572068637 valid 0.4619297156063448
LOSS train 0.40128279572068637 valid 0.46176132859046487
LOSS train 0.40128279572068637 valid 0.46160818003118037
LOSS train 0.40128279572068637 valid 0.4618793479881841
LOSS train 0.40128279572068637 valid 0.46177511927017495
LOSS train 0.40128279572068637 valid 0.46171384939440974
LOSS train 0.40128279572068637 valid 0.46183712218628553
LOSS train 0.40128279572068637 valid 0.4618530923006486
LOSS train 0.40128279572068637 valid 0.46184306464544156
LOSS train 0.40128279572068637 valid 0.4619070706579849
LOSS train 0.40128279572068637 valid 0.46186970534824556
LOSS train 0.40128279572068637 valid 0.4618958531613331
LOSS train 0.40128279572068637 valid 0.46216308569908143
LOSS train 0.40128279572068637 valid 0.4622423096719491
LOSS train 0.40128279572068637 valid 0.4625082149628609
LOSS train 0.40128279572068637 valid 0.46236270842816046
LOSS train 0.40128279572068637 valid 0.46256563548497326
LOSS train 0.40128279572068637 valid 0.46257832272380006
LOSS train 0.40128279572068637 valid 0.4625374706229195
LOSS train 0.40128279572068637 valid 0.46252856841347095
LOSS train 0.40128279572068637 valid 0.462568077237107
LOSS train 0.40128279572068637 valid 0.4625414469527462
LOSS train 0.40128279572068637 valid 0.4623908290496239
LOSS train 0.40128279572068637 valid 0.4624253256795964
LOSS train 0.40128279572068637 valid 0.46235308562981264
LOSS train 0.40128279572068637 valid 0.4622942572990751
LOSS train 0.40128279572068637 valid 0.4622149369256063
LOSS train 0.40128279572068637 valid 0.46220474366871817
LOSS train 0.40128279572068637 valid 0.4623561002930304
LOSS train 0.40128279572068637 valid 0.46255134319544733
LOSS train 0.40128279572068637 valid 0.4626976659716065
LOSS train 0.40128279572068637 valid 0.4629417749807294
LOSS train 0.40128279572068637 valid 0.4628662574070471
LOSS train 0.40128279572068637 valid 0.46298570188649024
LOSS train 0.40128279572068637 valid 0.46308646942762766
LOSS train 0.40128279572068637 valid 0.463122994799317
LOSS train 0.40128279572068637 valid 0.4631417522030155
LOSS train 0.40128279572068637 valid 0.4630499352108349
LOSS train 0.40128279572068637 valid 0.46302811920210935
LOSS train 0.40128279572068637 valid 0.4631185132458752
LOSS train 0.40128279572068637 valid 0.46306671652433684
LOSS train 0.40128279572068637 valid 0.46314333277791203
LOSS train 0.40128279572068637 valid 0.4630084374121257
LOSS train 0.40128279572068637 valid 0.46282571808723366
LOSS train 0.40128279572068637 valid 0.46279392365022753
LOSS train 0.40128279572068637 valid 0.4628094108281624
LOSS train 0.40128279572068637 valid 0.46286407092087706
LOSS train 0.40128279572068637 valid 0.4628094223507664
LOSS train 0.40128279572068637 valid 0.4626674090440457
LOSS train 0.40128279572068637 valid 0.46270499921011177
LOSS train 0.40128279572068637 valid 0.46262663923617864
LOSS train 0.40128279572068637 valid 0.46273148668266084
LOSS train 0.40128279572068637 valid 0.46274512790400407
LOSS train 0.40128279572068637 valid 0.46258224234548223
LOSS train 0.40128279572068637 valid 0.46262410150407113
LOSS train 0.40128279572068637 valid 0.4624881908144967
LOSS train 0.40128279572068637 valid 0.46255376154468175
LOSS train 0.40128279572068637 valid 0.4627239323268502
LOSS train 0.40128279572068637 valid 0.46264899209947197
LOSS train 0.40128279572068637 valid 0.4626809912498551
LOSS train 0.40128279572068637 valid 0.46255229493515604
LOSS train 0.40128279572068637 valid 0.4626445146308695
LOSS train 0.40128279572068637 valid 0.4626541503270467
LOSS train 0.40128279572068637 valid 0.46265695499027293
LOSS train 0.40128279572068637 valid 0.46252076890294913
LOSS train 0.40128279572068637 valid 0.46244954207155964
LOSS train 0.40128279572068637 valid 0.462508287182764
LOSS train 0.40128279572068637 valid 0.46247401120232756
LOSS train 0.40128279572068637 valid 0.46249526661205914
LOSS train 0.40128279572068637 valid 0.4624681817398009
LOSS train 0.40128279572068637 valid 0.46236680612548603
LOSS train 0.40128279572068637 valid 0.46237581264239686
LOSS train 0.40128279572068637 valid 0.4624020283260653
LOSS train 0.40128279572068637 valid 0.4623916646483627
LOSS train 0.40128279572068637 valid 0.4624052973320851
LOSS train 0.40128279572068637 valid 0.4625166721237353
LOSS train 0.40128279572068637 valid 0.46247533153576453
LOSS train 0.40128279572068637 valid 0.4624510742369152
LOSS train 0.40128279572068637 valid 0.46233914641639856
LOSS train 0.40128279572068637 valid 0.4623748047118683
LOSS train 0.40128279572068637 valid 0.4623786748955085
LOSS train 0.40128279572068637 valid 0.46239228981041985
LOSS train 0.40128279572068637 valid 0.46235570320859554
LOSS train 0.40128279572068637 valid 0.46236126853669546
LOSS train 0.40128279572068637 valid 0.46238138281410524
LOSS train 0.40128279572068637 valid 0.46237319827817913
LOSS train 0.40128279572068637 valid 0.4623482746106607
LOSS train 0.40128279572068637 valid 0.4622873726257911
LOSS train 0.40128279572068637 valid 0.46238233002782597
LOSS train 0.40128279572068637 valid 0.4625427177010691
LOSS train 0.40128279572068637 valid 0.46251587387992116
LOSS train 0.40128279572068637 valid 0.4625468643602992
LOSS train 0.40128279572068637 valid 0.4624985373381412
LOSS train 0.40128279572068637 valid 0.4624494501471159
LOSS train 0.40128279572068637 valid 0.4623231084411403
LOSS train 0.40128279572068637 valid 0.46236637091493465
LOSS train 0.40128279572068637 valid 0.46241853114016757
LOSS train 0.40128279572068637 valid 0.46243111010807664
LOSS train 0.40128279572068637 valid 0.46238147068236557
LOSS train 0.40128279572068637 valid 0.462387644307196
LOSS train 0.40128279572068637 valid 0.4624199631827823
LOSS train 0.40128279572068637 valid 0.462356351469822
LOSS train 0.40128279572068637 valid 0.46239816949648016
LOSS train 0.40128279572068637 valid 0.46225335835711345
LOSS train 0.40128279572068637 valid 0.46208875081692524
LOSS train 0.40128279572068637 valid 0.46209196985289236
LOSS train 0.40128279572068637 valid 0.4623046356231667
LOSS train 0.40128279572068637 valid 0.4623703508273415
LOSS train 0.40128279572068637 valid 0.46236652799079875
LOSS train 0.40128279572068637 valid 0.46230019281164714
LOSS train 0.40128279572068637 valid 0.46217480139143163
LOSS train 0.40128279572068637 valid 0.46220555611189595
LOSS train 0.40128279572068637 valid 0.4620719108411244
LOSS train 0.40128279572068637 valid 0.46200876528041657
LOSS train 0.40128279572068637 valid 0.46204295568168163
LOSS train 0.40128279572068637 valid 0.4620742577500114
LOSS train 0.40128279572068637 valid 0.4621204179053926
LOSS train 0.40128279572068637 valid 0.4621343736077698
LOSS train 0.40128279572068637 valid 0.4621297615800011
LOSS train 0.40128279572068637 valid 0.46206438516368387
LOSS train 0.40128279572068637 valid 0.4619849960231248
LOSS train 0.40128279572068637 valid 0.4620311205433604
LOSS train 0.40128279572068637 valid 0.4620550029807621
LOSS train 0.40128279572068637 valid 0.4620856484217657
LOSS train 0.40128279572068637 valid 0.4622436549452787
LOSS train 0.40128279572068637 valid 0.4621660215959733
LOSS train 0.40128279572068637 valid 0.4621064204436082
LOSS train 0.40128279572068637 valid 0.46215877369658587
LOSS train 0.40128279572068637 valid 0.4621044711662772
LOSS train 0.40128279572068637 valid 0.4620205832274798
LOSS train 0.40128279572068637 valid 0.4620266576176104
LOSS train 0.40128279572068637 valid 0.4620134861973243
EPOCH 9:
  batch 1 loss: 0.35874468088150024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.38272032141685486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.3980901936690013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.40362391620874405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.408564954996109
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.41011740267276764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.40593374201229643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.41280046477913857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4111334714624617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4100650757551193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.40785958008332684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.40519585957129794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4021245814286746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.4002266377210617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4020305395126343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.40309341810643673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.40257837667184715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4026422318485048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4027110824459477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.40199379324913026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4013413744313376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.40153347768566827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.40195330199987994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40270547320445377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.40287299394607545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4040924883805789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.40409835400404753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4032341944319861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4044542435942025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.40400826235612236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4044091422711649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.40489277616143227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.40454590501207294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4047680584823384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.40512529952185494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.40481770038604736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.40461568896834915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4046383500099182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.40524692565966874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4058251649141312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.40555389189138646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4049812817857379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4061418466789778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4055315364490856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4059295833110809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4050646962031074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4053986560791097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4053907139847676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4054395763241515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.40566552579402926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4053705971614987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.405243718280242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4051296964006604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4047850298660773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4047519201582128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4049250265317304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4054003248089238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.40457410750717954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.40476081229872624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.40463032176097236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4040896887661981
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4040476809586248
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4038215090358068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.40423390502110124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4043148361719572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.40442710573023016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.40401733366411124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.40380937474615436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.40386059880256653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4043431682246072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.40421582695464015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4039531217681037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4039462245490453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.404073127620929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.40392934521039325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.40423181613809184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4043694111433896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.40406388884935623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40413802975340735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.40437812097370623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.40460783647902215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.404516660949079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.40422373651021937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.40410864778927397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4040814189349904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4040210191593614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4039079413331788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.40420814095572993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4041653154941087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.40424871510929533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.40383844257711055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.40391499743513437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.404298758955412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4043220557430957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.40410801956528114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4044695474828283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4041309845201748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.40455948242119383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4048122905119501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4050253722071648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4047377212802962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.40472450677086325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.405093712424769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4049055937391061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.40485333147503083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4046852757345955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.40486338929595234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.40509415721451797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.40501823720582036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.40540011470968074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.40515835408691886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4050557099814926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.404738572318997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4048153988102026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4044535035672395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4043094292283058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.40430380263899124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4041444202095775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40391734342615143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4039696139593919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.40373043112518375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4036548061937582
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.40422178623152943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.40419441365426584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.40430663371086123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.40405063496695626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.40390661241501336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4040449580643326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.40415123035741407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4040583720574012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.40381029543985847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4037092420639414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.40375125923551114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.403674462615554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.40358872126649925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4036724306643009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.40378288456993383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.40360635130301764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4039358333718005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.40403139761516027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.40359329839124747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.40354300972441554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.40387965874238446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4041500304722124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4043041675255216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4042488581513705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.404196233976455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.40430303360964803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.40438159320178446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4044409821430842
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4046030460998712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4044545075218928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.40435558538031735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4041033675531288
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4042706864495431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.404350116275824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.40440936680811984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.40428014646602584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.40460907400779006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.40449773259460925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4042997648997336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.40416985087924534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.40432564411426614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.40413502912695815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.40404987028150846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4039396164288004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.40355892970176516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4034999098096575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.40344932199229855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4033876818769118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.40344235754152485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.40320380742466727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.40297290028175176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.40302907821090744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4030257100718362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.40287520905787294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.40274028623171443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.40260563054111564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4026340083037009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.40244999710056517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.402542928141125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4026652664601148
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4025453086433515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.40253432208429213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4026208999994639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.40249497611676494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4022847871410655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4020143520641834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4019227485177378
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4019364741287733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4019832256888844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.40181293059140444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4017519144814249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.40164485251166154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.401641601171249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4016567207112604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.40176852826539633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4022480776213636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4021674456009314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.40220943674445153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.40221231389994644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4021629480147126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.40231678330252324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.402274784942468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.40223049797662874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.40229482297758457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4023403280599106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.402092727044454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.40215637053599196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.40217693093277157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.40218727438935736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4021961485158722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4019877271193294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40181500123483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4017010601454003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4016344934977867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4017067300284513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.40170882300499383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.40187323175064504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4019071541049264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4018189240904415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.40172789695563615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4017580914657747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4020219901576638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.40185876541667515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.40167293414077926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4017380816033233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4015774036708631
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.40155662602732795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4016072831724001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4016888658979754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.40171761129950656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4015795318609655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4015806010390958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4016325683035749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40171407466217623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40188659218293205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4019636862418231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.40209504824801967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4020711317658424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4019911749234338
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.40191936837740183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4020506008662314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4020094082492297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.40209512856541846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.402162200915135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4021743797821555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4022388207095285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4021953699818577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.40230754840373995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4023216865452162
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.402299564036112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.40226752131352783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4022206003506353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4022841280581904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.40224646613933146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4021388846612626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4021513835173245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4022613667153023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.402415810410793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.40231631953140784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.40226798885651216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.40221362977426767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4020864878865806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.40196823140360277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4020590460614154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.40200931447722044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.40204227626768513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40209854590848476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.40206912248222915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4021506239127409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.40199103743276177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4020199749495957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4018655891401054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4017235820943659
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4018688481571018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4017967744209276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4016293832938448
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4017815404040839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4016986755388124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4016799921454908
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.401587909100749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.40159664474190754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.40157454303452667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40169821810304074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.40166127525426293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40163213305357026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.40165627664989895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4017911405918095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4019193939093886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4019157714450482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4018999601471914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4019062057290061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4018972243378762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4019489997524326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4019277494501423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4020647607267104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.40193982942392364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4019446049047553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.40194158514340717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4019940853910985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.40190794600161495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4018886784712474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4018656368318357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.40174589352529555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.401752519062142
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4017498173814643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4015724832167873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.40170461141947406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.40176356415594777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.40178717888436516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4017940547603827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4018534031538918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.40173277657502776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.40173256245870437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.40178462117910385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.40177718745045105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.40170166618044273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.40167566012813005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.40160819040611384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.40157534223850644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.40151809988925174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.40151274582549884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.40147973716626933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4014935335746178
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.40147758042154136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.40150152470358286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.401475525302131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.40137615790845416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4013780303073652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4014776547149589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4013807929782982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4014295889987602
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4013915143148628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.40143471805017383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.40140964419004466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4012977002459393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.40138298229000274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4013772866191414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40157938152551653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.401531898818058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.40166775664390875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.40173451415651396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4016228045315243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.40160853594973467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4015428231802979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.40156297759295195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.401591082585269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.40152040320344506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.40143933960369654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4013636251460453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.40140826551412995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40151752755256953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4014015031904824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.40141331100128064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.40137951017430656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.40141551626496624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4013875985944737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.40141473855812904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.40143023000823125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.40140097144568065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4015347462826671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.401559749746454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.40151910451087325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.40161657692634894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4015946228647493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4015874182171003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4016339318907779
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4016754466505232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.401718137232033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4017377146331448
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4016927180270995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.40168095937363263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.40168163682368985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4016097266674042
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4016110062440659
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4016382737722574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.40164636942760024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.401612138134823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4015627682209015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4015282284556411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.40150024160664743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4015594392470218
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40160664667685825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.40151854242597307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.40155626223494967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4015077703682951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4015093087842784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.40143930276132794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.40143779722543865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4014147526925177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4013414501535649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4014006381423115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.40129912353409125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4012655360034749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.40124535214419316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4011881518123732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40122834312256855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4012114783576258
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.40136676505208013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.40125511426878097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4010530822905735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.40093546166609295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4009066182788056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.40092476694672197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.400910345497977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4008502957276103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4007716730383097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.40079191225082195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.4008040822860671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4009212142359601
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4008754234290817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.40083140430669806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4008965836342982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.40083233276045466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.400854281651286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4008023806041379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.40078424494802667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.40082057549447037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4007795315413248
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.40086427083207987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4008389089909775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4008451533937567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4008691295419099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4008759462132173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.400867394858123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4009602011227217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4009196446320721
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.40078473459312686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.40092958953491475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4009355993254279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.40097935821999003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4008237275598231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4008692289415043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4007861192884116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.40082577793696605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.40084153693382474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.40078856445610794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4007031810989684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4007056200368838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.40073492062064797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.40074387435459985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4008033797649444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.40082162558226975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.40101781802231007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4010216975292283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4009872654940458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4010541731757777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4010405820568314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4010517016384337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.401039616297724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.40105193945686374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4010617708659856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4010429937015021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.40096938131929755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.40098374657202185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.40092636791569397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.40095573475006885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4010023286399758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.40103565311950184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4009858583162767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.40096062286333606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4009550471928928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.40097845994449893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.40103008330509227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.40112881349647506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.40109069935770053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4010096999187755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4010593403122827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4011505313376163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4010817717341607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.40115546207811875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.40115546207811875 valid 0.4360998868942261
LOSS train 0.40115546207811875 valid 0.43603602051734924
LOSS train 0.40115546207811875 valid 0.4573875864346822
LOSS train 0.40115546207811875 valid 0.45437487959861755
LOSS train 0.40115546207811875 valid 0.451122385263443
LOSS train 0.40115546207811875 valid 0.454279159506162
LOSS train 0.40115546207811875 valid 0.45486534919057575
LOSS train 0.40115546207811875 valid 0.4542858712375164
LOSS train 0.40115546207811875 valid 0.4478536281320784
LOSS train 0.40115546207811875 valid 0.4508810669183731
LOSS train 0.40115546207811875 valid 0.45447426492517645
LOSS train 0.40115546207811875 valid 0.45294837405284244
LOSS train 0.40115546207811875 valid 0.4552083726112659
LOSS train 0.40115546207811875 valid 0.4552916948284422
LOSS train 0.40115546207811875 valid 0.4537629981835683
LOSS train 0.40115546207811875 valid 0.45586943812668324
LOSS train 0.40115546207811875 valid 0.458532699767281
LOSS train 0.40115546207811875 valid 0.4596147785584132
LOSS train 0.40115546207811875 valid 0.4603064170009212
LOSS train 0.40115546207811875 valid 0.4620633825659752
LOSS train 0.40115546207811875 valid 0.46100865801175434
LOSS train 0.40115546207811875 valid 0.4580491361292926
LOSS train 0.40115546207811875 valid 0.4588629512683205
LOSS train 0.40115546207811875 valid 0.4573226658006509
LOSS train 0.40115546207811875 valid 0.45630658030509946
LOSS train 0.40115546207811875 valid 0.4557258119949928
LOSS train 0.40115546207811875 valid 0.4550915713663454
LOSS train 0.40115546207811875 valid 0.45583240368536543
LOSS train 0.40115546207811875 valid 0.45510966921674795
LOSS train 0.40115546207811875 valid 0.4559601664543152
LOSS train 0.40115546207811875 valid 0.45780419726525584
LOSS train 0.40115546207811875 valid 0.4577609049156308
LOSS train 0.40115546207811875 valid 0.4591244612679337
LOSS train 0.40115546207811875 valid 0.4584040413884556
LOSS train 0.40115546207811875 valid 0.45923377445765906
LOSS train 0.40115546207811875 valid 0.45939477284749347
LOSS train 0.40115546207811875 valid 0.4598074925912393
LOSS train 0.40115546207811875 valid 0.4610210845344945
LOSS train 0.40115546207811875 valid 0.4605694397901877
LOSS train 0.40115546207811875 valid 0.462108650803566
LOSS train 0.40115546207811875 valid 0.4619865628277383
LOSS train 0.40115546207811875 valid 0.46310200080985114
LOSS train 0.40115546207811875 valid 0.46313995469448177
LOSS train 0.40115546207811875 valid 0.46358970688147977
LOSS train 0.40115546207811875 valid 0.4637429303593106
LOSS train 0.40115546207811875 valid 0.4642600028411202
LOSS train 0.40115546207811875 valid 0.4635534108953273
LOSS train 0.40115546207811875 valid 0.463903255139788
LOSS train 0.40115546207811875 valid 0.4644488807843656
LOSS train 0.40115546207811875 valid 0.464067724943161
LOSS train 0.40115546207811875 valid 0.4647088132652582
LOSS train 0.40115546207811875 valid 0.46439592712200606
LOSS train 0.40115546207811875 valid 0.46383290414540274
LOSS train 0.40115546207811875 valid 0.4638612772579546
LOSS train 0.40115546207811875 valid 0.4633596046404405
LOSS train 0.40115546207811875 valid 0.4631122536957264
LOSS train 0.40115546207811875 valid 0.4629677199480826
LOSS train 0.40115546207811875 valid 0.46276080094534777
LOSS train 0.40115546207811875 valid 0.46344360557653136
LOSS train 0.40115546207811875 valid 0.46279075543085735
LOSS train 0.40115546207811875 valid 0.4616109640871892
LOSS train 0.40115546207811875 valid 0.4628939003713669
LOSS train 0.40115546207811875 valid 0.463209711370014
LOSS train 0.40115546207811875 valid 0.4637597743421793
LOSS train 0.40115546207811875 valid 0.4639869694526379
LOSS train 0.40115546207811875 valid 0.46400285534786456
LOSS train 0.40115546207811875 valid 0.4635695143422084
LOSS train 0.40115546207811875 valid 0.4629864101024235
LOSS train 0.40115546207811875 valid 0.4626245792361273
LOSS train 0.40115546207811875 valid 0.46217169421059745
LOSS train 0.40115546207811875 valid 0.46174289013298464
LOSS train 0.40115546207811875 valid 0.46151143146885765
LOSS train 0.40115546207811875 valid 0.46187230005656205
LOSS train 0.40115546207811875 valid 0.4617452025413513
LOSS train 0.40115546207811875 valid 0.46114778757095337
LOSS train 0.40115546207811875 valid 0.461314079792876
LOSS train 0.40115546207811875 valid 0.46108516934630156
LOSS train 0.40115546207811875 valid 0.46102766157724917
LOSS train 0.40115546207811875 valid 0.4607385242287117
LOSS train 0.40115546207811875 valid 0.46066900379955766
LOSS train 0.40115546207811875 valid 0.4601534807387693
LOSS train 0.40115546207811875 valid 0.4604012809875535
LOSS train 0.40115546207811875 valid 0.46017944776868247
LOSS train 0.40115546207811875 valid 0.46025964262939634
LOSS train 0.40115546207811875 valid 0.4603656488306382
LOSS train 0.40115546207811875 valid 0.45985516767169154
LOSS train 0.40115546207811875 valid 0.4594628358709401
LOSS train 0.40115546207811875 valid 0.45887335220521147
LOSS train 0.40115546207811875 valid 0.4592794186613533
LOSS train 0.40115546207811875 valid 0.4592560880713993
LOSS train 0.40115546207811875 valid 0.4589220855262253
LOSS train 0.40115546207811875 valid 0.4585210784621861
LOSS train 0.40115546207811875 valid 0.4579232851023315
LOSS train 0.40115546207811875 valid 0.4571466918321366
LOSS train 0.40115546207811875 valid 0.4566912403232173
LOSS train 0.40115546207811875 valid 0.45701607782393694
LOSS train 0.40115546207811875 valid 0.4574266174404891
LOSS train 0.40115546207811875 valid 0.45738877720978793
LOSS train 0.40115546207811875 valid 0.4576546278866855
LOSS train 0.40115546207811875 valid 0.4580039882659912
LOSS train 0.40115546207811875 valid 0.4581405659123222
LOSS train 0.40115546207811875 valid 0.45819108012844534
LOSS train 0.40115546207811875 valid 0.45881952909589974
LOSS train 0.40115546207811875 valid 0.4586319513618946
LOSS train 0.40115546207811875 valid 0.4586453662032173
LOSS train 0.40115546207811875 valid 0.45880153128560985
LOSS train 0.40115546207811875 valid 0.45847705312978443
LOSS train 0.40115546207811875 valid 0.45889229520603464
LOSS train 0.40115546207811875 valid 0.459041946251458
LOSS train 0.40115546207811875 valid 0.45914662344889207
LOSS train 0.40115546207811875 valid 0.459220178223945
LOSS train 0.40115546207811875 valid 0.4590150721903358
LOSS train 0.40115546207811875 valid 0.45893424696626917
LOSS train 0.40115546207811875 valid 0.45873219219216127
LOSS train 0.40115546207811875 valid 0.4587604691152987
LOSS train 0.40115546207811875 valid 0.4587343702542371
LOSS train 0.40115546207811875 valid 0.45878805080030716
LOSS train 0.40115546207811875 valid 0.4585634278038801
LOSS train 0.40115546207811875 valid 0.45827120542526245
LOSS train 0.40115546207811875 valid 0.4581615517536799
LOSS train 0.40115546207811875 valid 0.4580081435274487
LOSS train 0.40115546207811875 valid 0.4578988183228696
LOSS train 0.40115546207811875 valid 0.45798974599295517
LOSS train 0.40115546207811875 valid 0.4583156433316969
LOSS train 0.40115546207811875 valid 0.45818080329895017
LOSS train 0.40115546207811875 valid 0.4580850892123722
LOSS train 0.40115546207811875 valid 0.4585532482684128
LOSS train 0.40115546207811875 valid 0.45869054622016847
LOSS train 0.40115546207811875 valid 0.45886211986689607
LOSS train 0.40115546207811875 valid 0.4585987019997377
LOSS train 0.40115546207811875 valid 0.4585835305789045
LOSS train 0.40115546207811875 valid 0.45852587484952173
LOSS train 0.40115546207811875 valid 0.4583259648398349
LOSS train 0.40115546207811875 valid 0.4585309813716518
LOSS train 0.40115546207811875 valid 0.4587530211166099
LOSS train 0.40115546207811875 valid 0.4588312475996859
LOSS train 0.40115546207811875 valid 0.4586322181416254
LOSS train 0.40115546207811875 valid 0.4584839473599973
LOSS train 0.40115546207811875 valid 0.45816310103848684
LOSS train 0.40115546207811875 valid 0.45832702687808446
LOSS train 0.40115546207811875 valid 0.45836151026664895
LOSS train 0.40115546207811875 valid 0.4586566451569678
LOSS train 0.40115546207811875 valid 0.4583090760491111
LOSS train 0.40115546207811875 valid 0.45833615048064125
LOSS train 0.40115546207811875 valid 0.45814209847614684
LOSS train 0.40115546207811875 valid 0.4584967318462999
LOSS train 0.40115546207811875 valid 0.4580542437073325
LOSS train 0.40115546207811875 valid 0.4584814330210557
LOSS train 0.40115546207811875 valid 0.4585675921216107
LOSS train 0.40115546207811875 valid 0.45867676575978594
LOSS train 0.40115546207811875 valid 0.4587628075618618
LOSS train 0.40115546207811875 valid 0.4584922682689993
LOSS train 0.40115546207811875 valid 0.4587632259901832
LOSS train 0.40115546207811875 valid 0.4587486539181177
LOSS train 0.40115546207811875 valid 0.45888586582676055
LOSS train 0.40115546207811875 valid 0.4592302498909143
LOSS train 0.40115546207811875 valid 0.4591237150939407
LOSS train 0.40115546207811875 valid 0.45906569591805907
LOSS train 0.40115546207811875 valid 0.4587555555802471
LOSS train 0.40115546207811875 valid 0.4587858149781823
LOSS train 0.40115546207811875 valid 0.4586179410078511
LOSS train 0.40115546207811875 valid 0.45822001588933264
LOSS train 0.40115546207811875 valid 0.4581542949369349
LOSS train 0.40115546207811875 valid 0.4579989036045423
LOSS train 0.40115546207811875 valid 0.4578639765580495
LOSS train 0.40115546207811875 valid 0.4576791749302163
LOSS train 0.40115546207811875 valid 0.45775973315010526
LOSS train 0.40115546207811875 valid 0.4579667429484072
LOSS train 0.40115546207811875 valid 0.4581222574739061
LOSS train 0.40115546207811875 valid 0.45859356540090895
LOSS train 0.40115546207811875 valid 0.45846602808662323
LOSS train 0.40115546207811875 valid 0.45850972883230035
LOSS train 0.40115546207811875 valid 0.45863603598120584
LOSS train 0.40115546207811875 valid 0.4586344851159501
LOSS train 0.40115546207811875 valid 0.45873066016605923
LOSS train 0.40115546207811875 valid 0.4585968628525734
LOSS train 0.40115546207811875 valid 0.4589556357954855
LOSS train 0.40115546207811875 valid 0.459164344695177
LOSS train 0.40115546207811875 valid 0.45900873115608815
LOSS train 0.40115546207811875 valid 0.459076356391112
LOSS train 0.40115546207811875 valid 0.4590636636670782
LOSS train 0.40115546207811875 valid 0.45918913103721953
LOSS train 0.40115546207811875 valid 0.45907040860483556
LOSS train 0.40115546207811875 valid 0.45930018923852756
LOSS train 0.40115546207811875 valid 0.45922841461929115
LOSS train 0.40115546207811875 valid 0.4593196996758061
LOSS train 0.40115546207811875 valid 0.45935128828420996
LOSS train 0.40115546207811875 valid 0.4593348387391009
LOSS train 0.40115546207811875 valid 0.4592514842275589
LOSS train 0.40115546207811875 valid 0.45908424305288414
LOSS train 0.40115546207811875 valid 0.45936073261405785
LOSS train 0.40115546207811875 valid 0.4594697318971157
LOSS train 0.40115546207811875 valid 0.4593381137427888
LOSS train 0.40115546207811875 valid 0.4591452539274373
LOSS train 0.40115546207811875 valid 0.45912263897749095
LOSS train 0.40115546207811875 valid 0.4592327876966827
LOSS train 0.40115546207811875 valid 0.45952149363338646
LOSS train 0.40115546207811875 valid 0.45955867944943785
LOSS train 0.40115546207811875 valid 0.45960155983067036
LOSS train 0.40115546207811875 valid 0.4595302926003933
LOSS train 0.40115546207811875 valid 0.45923032051888274
LOSS train 0.40115546207811875 valid 0.45939663864008273
LOSS train 0.40115546207811875 valid 0.4592203942719352
LOSS train 0.40115546207811875 valid 0.4592380209588537
LOSS train 0.40115546207811875 valid 0.45923104315269286
LOSS train 0.40115546207811875 valid 0.45900976773604607
LOSS train 0.40115546207811875 valid 0.45925078242297335
LOSS train 0.40115546207811875 valid 0.45924808729726535
LOSS train 0.40115546207811875 valid 0.45912790312721397
LOSS train 0.40115546207811875 valid 0.45925929773421514
LOSS train 0.40115546207811875 valid 0.4593115787935483
LOSS train 0.40115546207811875 valid 0.4593793770895814
LOSS train 0.40115546207811875 valid 0.4594168840719501
LOSS train 0.40115546207811875 valid 0.45937555694134435
LOSS train 0.40115546207811875 valid 0.45939639224562534
LOSS train 0.40115546207811875 valid 0.45945027760333484
LOSS train 0.40115546207811875 valid 0.45950500248214615
LOSS train 0.40115546207811875 valid 0.4596113974074705
LOSS train 0.40115546207811875 valid 0.45959278886721017
LOSS train 0.40115546207811875 valid 0.4597915797071023
LOSS train 0.40115546207811875 valid 0.46000785053585447
LOSS train 0.40115546207811875 valid 0.45999863435019245
LOSS train 0.40115546207811875 valid 0.46002350821088783
LOSS train 0.40115546207811875 valid 0.4600698133664472
LOSS train 0.40115546207811875 valid 0.4601120267974006
LOSS train 0.40115546207811875 valid 0.46009608443859407
LOSS train 0.40115546207811875 valid 0.46016834997920736
LOSS train 0.40115546207811875 valid 0.460136165613668
LOSS train 0.40115546207811875 valid 0.46025559501356433
LOSS train 0.40115546207811875 valid 0.460388654988745
LOSS train 0.40115546207811875 valid 0.46046586831410724
LOSS train 0.40115546207811875 valid 0.46051746658210096
LOSS train 0.40115546207811875 valid 0.4604218755668837
LOSS train 0.40115546207811875 valid 0.46036217253432316
LOSS train 0.40115546207811875 valid 0.46055219224158755
LOSS train 0.40115546207811875 valid 0.46043900463540677
LOSS train 0.40115546207811875 valid 0.46033134842723733
LOSS train 0.40115546207811875 valid 0.4602921110491793
LOSS train 0.40115546207811875 valid 0.4601241760423493
LOSS train 0.40115546207811875 valid 0.4599700663238764
LOSS train 0.40115546207811875 valid 0.46024090138213763
LOSS train 0.40115546207811875 valid 0.4601382466633458
LOSS train 0.40115546207811875 valid 0.46008366370887915
LOSS train 0.40115546207811875 valid 0.4602052105254814
LOSS train 0.40115546207811875 valid 0.4602196465949623
LOSS train 0.40115546207811875 valid 0.4602098420141189
LOSS train 0.40115546207811875 valid 0.46026934146398474
LOSS train 0.40115546207811875 valid 0.4602336798223757
LOSS train 0.40115546207811875 valid 0.4602586787388507
LOSS train 0.40115546207811875 valid 0.46052695989608766
LOSS train 0.40115546207811875 valid 0.4606072743575412
LOSS train 0.40115546207811875 valid 0.46087706964167335
LOSS train 0.40115546207811875 valid 0.4607348364332448
LOSS train 0.40115546207811875 valid 0.4609404462059652
LOSS train 0.40115546207811875 valid 0.4609535310782638
LOSS train 0.40115546207811875 valid 0.46091689891181886
LOSS train 0.40115546207811875 valid 0.46090728856246294
LOSS train 0.40115546207811875 valid 0.46095181666603385
LOSS train 0.40115546207811875 valid 0.46092929458065846
LOSS train 0.40115546207811875 valid 0.4607796125687086
LOSS train 0.40115546207811875 valid 0.46081395338778297
LOSS train 0.40115546207811875 valid 0.46073910036614835
LOSS train 0.40115546207811875 valid 0.4606828611386593
LOSS train 0.40115546207811875 valid 0.4605993873467951
LOSS train 0.40115546207811875 valid 0.4605885623760943
LOSS train 0.40115546207811875 valid 0.4607390614604591
LOSS train 0.40115546207811875 valid 0.4609377697835701
LOSS train 0.40115546207811875 valid 0.4610793034532177
LOSS train 0.40115546207811875 valid 0.46132904557047283
LOSS train 0.40115546207811875 valid 0.46124905546506245
LOSS train 0.40115546207811875 valid 0.46137879926340164
LOSS train 0.40115546207811875 valid 0.4614766916150556
LOSS train 0.40115546207811875 valid 0.4615113085661179
LOSS train 0.40115546207811875 valid 0.4615304244913324
LOSS train 0.40115546207811875 valid 0.46143630103631456
LOSS train 0.40115546207811875 valid 0.4614081338479899
LOSS train 0.40115546207811875 valid 0.4615014417076799
LOSS train 0.40115546207811875 valid 0.46145044020611603
LOSS train 0.40115546207811875 valid 0.4615305025517727
LOSS train 0.40115546207811875 valid 0.4613928020000458
LOSS train 0.40115546207811875 valid 0.4612139982048727
LOSS train 0.40115546207811875 valid 0.461182343410262
LOSS train 0.40115546207811875 valid 0.46120223645186675
LOSS train 0.40115546207811875 valid 0.46125525550943025
LOSS train 0.40115546207811875 valid 0.4612015762872863
LOSS train 0.40115546207811875 valid 0.4610640510812506
LOSS train 0.40115546207811875 valid 0.46109903211793
LOSS train 0.40115546207811875 valid 0.46102173522942597
LOSS train 0.40115546207811875 valid 0.4611278782666348
LOSS train 0.40115546207811875 valid 0.46114308957395883
LOSS train 0.40115546207811875 valid 0.4609766553357704
LOSS train 0.40115546207811875 valid 0.4610210382570959
LOSS train 0.40115546207811875 valid 0.46088694844636496
LOSS train 0.40115546207811875 valid 0.4609575657820215
LOSS train 0.40115546207811875 valid 0.4611268311233844
LOSS train 0.40115546207811875 valid 0.4610513045981124
LOSS train 0.40115546207811875 valid 0.4610862032532291
LOSS train 0.40115546207811875 valid 0.4609580375004135
LOSS train 0.40115546207811875 valid 0.4610500809141625
LOSS train 0.40115546207811875 valid 0.46106699655453365
LOSS train 0.40115546207811875 valid 0.46107032786176055
LOSS train 0.40115546207811875 valid 0.4609352392668756
LOSS train 0.40115546207811875 valid 0.460866385560618
LOSS train 0.40115546207811875 valid 0.4609236246661136
LOSS train 0.40115546207811875 valid 0.4608893258649795
LOSS train 0.40115546207811875 valid 0.4609124516349992
LOSS train 0.40115546207811875 valid 0.46088969299769944
LOSS train 0.40115546207811875 valid 0.4607883050263702
LOSS train 0.40115546207811875 valid 0.46079915019300766
LOSS train 0.40115546207811875 valid 0.4608216573153773
LOSS train 0.40115546207811875 valid 0.460808520052594
LOSS train 0.40115546207811875 valid 0.4608239818077821
LOSS train 0.40115546207811875 valid 0.4609372592962588
LOSS train 0.40115546207811875 valid 0.46089505219155813
LOSS train 0.40115546207811875 valid 0.46087064326755584
LOSS train 0.40115546207811875 valid 0.4607519086780427
LOSS train 0.40115546207811875 valid 0.46078634647540867
LOSS train 0.40115546207811875 valid 0.460791067038692
LOSS train 0.40115546207811875 valid 0.4608015208782447
LOSS train 0.40115546207811875 valid 0.46075966507196425
LOSS train 0.40115546207811875 valid 0.46076943820510696
LOSS train 0.40115546207811875 valid 0.4607902066492886
LOSS train 0.40115546207811875 valid 0.46078420045206053
LOSS train 0.40115546207811875 valid 0.4607547619092612
LOSS train 0.40115546207811875 valid 0.4606937527656555
LOSS train 0.40115546207811875 valid 0.4607884360968701
LOSS train 0.40115546207811875 valid 0.46095503980595764
LOSS train 0.40115546207811875 valid 0.46092604891192623
LOSS train 0.40115546207811875 valid 0.4609536667181728
LOSS train 0.40115546207811875 valid 0.46090047296249503
LOSS train 0.40115546207811875 valid 0.46085491191224387
LOSS train 0.40115546207811875 valid 0.4607241787465222
LOSS train 0.40115546207811875 valid 0.4607678686713313
LOSS train 0.40115546207811875 valid 0.4608204319270071
LOSS train 0.40115546207811875 valid 0.46082789568758725
LOSS train 0.40115546207811875 valid 0.46077142168013824
LOSS train 0.40115546207811875 valid 0.4607752806531923
LOSS train 0.40115546207811875 valid 0.460809381844024
LOSS train 0.40115546207811875 valid 0.4607451489541383
LOSS train 0.40115546207811875 valid 0.46078739841194716
LOSS train 0.40115546207811875 valid 0.4606372469331512
LOSS train 0.40115546207811875 valid 0.4604714632208584
LOSS train 0.40115546207811875 valid 0.4604688744677051
LOSS train 0.40115546207811875 valid 0.46068026220729186
LOSS train 0.40115546207811875 valid 0.4607455019501672
LOSS train 0.40115546207811875 valid 0.4607417872875412
LOSS train 0.40115546207811875 valid 0.4606723335359557
LOSS train 0.40115546207811875 valid 0.46054840670234853
LOSS train 0.40115546207811875 valid 0.46057736600367594
LOSS train 0.40115546207811875 valid 0.4604395957504
LOSS train 0.40115546207811875 valid 0.46037609276608527
LOSS train 0.40115546207811875 valid 0.46040987087921664
LOSS train 0.40115546207811875 valid 0.46044537560122545
LOSS train 0.40115546207811875 valid 0.4604892349344189
LOSS train 0.40115546207811875 valid 0.46049996757171524
LOSS train 0.40115546207811875 valid 0.4604948657784569
LOSS train 0.40115546207811875 valid 0.4604293612205014
LOSS train 0.40115546207811875 valid 0.4603507708570811
LOSS train 0.40115546207811875 valid 0.46039514704335033
LOSS train 0.40115546207811875 valid 0.46042175806230967
LOSS train 0.40115546207811875 valid 0.4604524828060182
LOSS train 0.40115546207811875 valid 0.46061147527141466
LOSS train 0.40115546207811875 valid 0.4605345363130911
LOSS train 0.40115546207811875 valid 0.4604741285790454
LOSS train 0.40115546207811875 valid 0.46052898233884
LOSS train 0.40115546207811875 valid 0.4604749776463691
LOSS train 0.40115546207811875 valid 0.46038998643124135
LOSS train 0.40115546207811875 valid 0.4603960271924734
LOSS train 0.40115546207811875 valid 0.46037992931962984
EPOCH 10:
  batch 1 loss: 0.3570672869682312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.3795790374279022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.39875175555547077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4034130424261093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4073765158653259
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.40730170408884686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4019507680620466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4083027169108391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.40776003731621635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4079664349555969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.405704376372424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.40478605031967163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4015169327075665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.40008485530103954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.40218696792920433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4030515141785145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4028694419299855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4036597063144048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4036672287865689
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4021794095635414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.40113702984083266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.40158250521529804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4030714993891509
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40355392048756283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.40419253826141355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.405860213133005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.40597133724777784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.40495756587811876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.40585786618035413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.40547352135181425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4058313254387148
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.405851025134325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4056588564858292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.40549250122378855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.40576292702129907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4058585597409142
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4054216041758254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4050098414483823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.40559232464203465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4060207404196262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.40577731772166925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4049856989156632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4061355493789495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.405651870098981
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4059580736690097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.40480973020843836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4051607815509147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4047055374830961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.404790674545327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4048200219869614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4046458385738672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4043280923595795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4041386083611902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.40364134587623457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.40351311672817575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.40380219157252994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.40439506058107344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.40361027984783565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4039671259411311
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.40406780342260995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.40332471835808675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4033271295409049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4032192272799356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.40364916855469346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4035127749809852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.40361449573979236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.40322749249970735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4029958410298123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.40306060987970105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4035614950316293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4034873918748238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4032292866872417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.40315462914231703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4031984439572772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.40288214405377704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4031581827684453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.40329585408235524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.40308273717378956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40327629560156714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4034577030688524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.40370597000475283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4036555562804385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4034236583365015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4032619893550873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4034171889810001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4035077358401099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4033682216172931
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.40356006947430695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.40356421135784537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4036805142958959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4033160727102678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.40323848115361255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.40354443718028327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4035394353435395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4033203639482197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4035938289016485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.40331255345000433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.40376351013475537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4040701220733951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.40427290976047514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.40396736901585417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.403836708150658
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.40414827570174505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4038473138442406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4038404030459268
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.40360563403030614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.40366410345674675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.40391561913269536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4037970192388657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.40421924780715596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.40404566370689116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.40398237641368595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4037121209950574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4037287298001741
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4033630946408147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4032331746200035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.40333949016709614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.40320493331400015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4030622632062736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.40327948903044064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4030090297056624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4029888969952943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.40347692152348963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4034625976797073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4035375154018402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.40337373552814365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.40319520493191996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4033867947291583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4034703838270764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.40345958792246306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4032378064767095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4030984441439311
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.40323750820375026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4031221915536852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4029374043146769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4029117428204593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.40309390708477827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.40296336403791455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.40329184849485217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.40334473848342894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4029302309590874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4029638469219208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.40333331006390233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.40359125783046085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.403712521339285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.40366678491030655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4036073039989082
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4037043164308007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4037756973865048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4037776694695155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4038121954889487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4036486982122848
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.40349588207170073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4032380660245945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.40340564174036825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4034646875583209
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.40354531528843435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4034305776976332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4036572017009903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4036204168573022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.40344970030073796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4033477635663233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4035823880894784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.40335752815008163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4032604273521539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4031676497445049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4027708977639318
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.40269104657428606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4026672337534865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.40271535533315994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.40273709377350164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4025324927859528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4023275234106648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.40237490730039005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4024179572718484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4023043559017507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4021412273921536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4019982709308689
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.40201402509678674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.40186177955733404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4019164214147389
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.40202386939263607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4018806311927858
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.40185076824348903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.40191062398858973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.40182385489504824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.40163131353051906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4013748492332215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4012854821467526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4013355642557144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4013542394051377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.40123353510474163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.40117397441147523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4010492933472407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.40104291515472607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.40108508920791197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4011333256506073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4016317750769432
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.40152138022322154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.40153020739555356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4014696016240476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4014240485606807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.40159668725699627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4015536251313546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4015619011913858
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4015971623288775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4016602246657662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4014560949917023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.40150385282256384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4015181616658256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.40149466940576994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4015781620763383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4014086498061256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4011989036731631
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.40109309096669044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4010396130658962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.40110949080111247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4011350827752997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4013089103513657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.401411802389405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4013389197949371
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.40124906304183305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.40129263799286746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4015683751287205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4014470836851332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4012971093169356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4013820398221457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.40122697515445843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.40123722751067714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4012861881567084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.40137410525119666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4014014308822566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4012134153188042
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.40122262980693424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4013067911279962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40136397731001094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40154222144356255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4015907448630373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4016944627632157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4017095070332289
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4016107141476944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.40155941900635556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4017041150189231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.401621586108794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.40172141024044583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4017263357716847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.40176112545646636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.40179378467221416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4018271795238357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4019492015838623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4019500696326632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.401915422625958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.40188075466589496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4018207214714035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4018643646847968
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.40184316982049495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4017754878979249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4018284730439962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4019712202797525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.40209046671023735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4020045269494769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.401930644425727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.40182472408497744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.40171658857302234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.40158804767536666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4016341685800624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.40158880381994927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4016080896801023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40168918552895017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4016440133253733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4017028148763734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4015304870246088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4015262940209427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.40136924962492754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4012002222104506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.40135898397884506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4012909623044493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4011794054250923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4013388449573175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.40125305695193153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4012277390396892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4010979542706875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.40106453006764603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.40099358390754375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40107067039138394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4010345151165982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40103252102273684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.40110320401274496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.40131338719265686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4014302733643302
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4014320843613025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40138249068635784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4013815852765744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.40138575992211195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.40144036462751487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.40141700067230174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.40154579251703587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.40139372796820316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4014054251753766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4014150467514992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4014585019148069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4013592341285668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4013682660883409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4013436087652257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.40121571470479495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.40120701306785633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4012057950131668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4010114468537368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4011519451936086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.40121219225468174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4012128194237062
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4012522222713018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.401330549019975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4011848002292548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4011923056746286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.40124337082799477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.40125559961382146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.40121071893464094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.40120524719217354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4011321636848152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.40113181126451936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.40108743717211376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.40109793855678927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.40108397170717336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4010797969194559
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4011031889293823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4011359873714797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.401127068916472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4010450629840144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.40104549102710957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.40115869486439987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4010352694306029
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4010944576771768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4010824104269108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.40113480998508966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.40113253545548233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.40102898968433415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.40108572008341725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4010751499714753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40125519028481316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4011532006200807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4012927150691462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4013461151727782
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.40126979836197785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4012751895448436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.40125503102478954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4013019539093765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.401290203648052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.40122372629307745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.40114760151931217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.40109165602939423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.40114988886158576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4012435038096506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.40111582663099643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.40112505420832567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4011287909377827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.40115479419545297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.40113118182680463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4011878054952223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4012189763287703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.40119364098168475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4013234202374411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.401343365838705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.40133753009549866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4014416765676786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4014104945086391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4013624982223199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.401379826600137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.40142019759348735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.40146412543348364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4014806946654204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.40144111776864655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.401442243969792
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.40143404319324594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.401362188577652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.40133168326413377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4013476934610058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.40139132809071315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.40138449871760246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.40134056186989736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40129585583691835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4012529822700311
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.40134586654506216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40139083471149206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4012680759677639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4013315970415896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.40129116970747325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4013206994103402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.40125351140615567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4012240696411866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4011901514152127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.40112784770982607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4012140065204096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.40109441070084645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4010404279714898
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4010433209213344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.40097994077716126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40102190108754526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4010150114396461
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.40117010474205017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.40105960085207687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.40088320223253165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4007510917062499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4007370697684807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.40072403954870905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4007010015801256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4006186856245233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.40055767074227333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.400597886817671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.40060811464379475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4007206544678867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.40068105109108304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4006544993806982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.400715874876953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4006786293294056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4007367715239525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4006682494275576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4006317188009691
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4006889896347301
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.40065398471696034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.40074040445182785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4007295104564649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.40074103831117597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.40077105825239756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4007732624166152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.40072837429986874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.40082743086915384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.40078898010966935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4006359456302403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4007454890151357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4007921902043637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4008392919268873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.40068328077743565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.40070205027331957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.40063457509566996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4007003700377744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4007304014139372
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.40071694845478284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4006323017400598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4006392123346979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.40065971618336615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.40069861635902887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.40075538255291115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4007766751555709
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.40097346707676235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4009630474942682
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.40091549476787813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.40098032175696324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.40100739760228943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4010054916805691
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4010013794555368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4009797989135295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4009609919115408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4009700290825924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.40091603922319935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.40093616703361795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4008984396833299
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.40092310101184264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.40094176785358937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.40098483510639354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.40093084840091864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4008928578653377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.40087305282928515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4008860932984229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4009636605298647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.40104755804006637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.40099787865256853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4009166459242503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4009601416618331
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40103030128681916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4009682875909623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4010456395098719
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4010456395098719 valid 0.44605135917663574
LOSS train 0.4010456395098719 valid 0.44649022817611694
LOSS train 0.4010456395098719 valid 0.46806637446085614
LOSS train 0.4010456395098719 valid 0.4646669253706932
LOSS train 0.4010456395098719 valid 0.4612192213535309
LOSS train 0.4010456395098719 valid 0.4644988824923833
LOSS train 0.4010456395098719 valid 0.46560608063425335
LOSS train 0.4010456395098719 valid 0.46500202640891075
LOSS train 0.4010456395098719 valid 0.45857028828726876
LOSS train 0.4010456395098719 valid 0.4615242540836334
LOSS train 0.4010456395098719 valid 0.4651710716160861
LOSS train 0.4010456395098719 valid 0.4637054403622945
LOSS train 0.4010456395098719 valid 0.46599082763378435
LOSS train 0.4010456395098719 valid 0.46606774841036114
LOSS train 0.4010456395098719 valid 0.4645950675010681
LOSS train 0.4010456395098719 valid 0.46664752066135406
LOSS train 0.4010456395098719 valid 0.46934987516964183
LOSS train 0.4010456395098719 valid 0.47050154209136963
LOSS train 0.4010456395098719 valid 0.47112607014806646
LOSS train 0.4010456395098719 valid 0.47284807860851286
LOSS train 0.4010456395098719 valid 0.4718539459364755
LOSS train 0.4010456395098719 valid 0.46888751875270496
LOSS train 0.4010456395098719 valid 0.46976958409599634
LOSS train 0.4010456395098719 valid 0.4682239716251691
LOSS train 0.4010456395098719 valid 0.4671961259841919
LOSS train 0.4010456395098719 valid 0.46662835203684294
LOSS train 0.4010456395098719 valid 0.4659805949087496
LOSS train 0.4010456395098719 valid 0.46672028622456957
LOSS train 0.4010456395098719 valid 0.4659445604373669
LOSS train 0.4010456395098719 valid 0.4667731742064158
LOSS train 0.4010456395098719 valid 0.4686226825560293
LOSS train 0.4010456395098719 valid 0.4686035718768835
LOSS train 0.4010456395098719 valid 0.4700107718958999
LOSS train 0.4010456395098719 valid 0.4692656020907795
LOSS train 0.4010456395098719 valid 0.4701364781175341
LOSS train 0.4010456395098719 valid 0.47032034231556785
LOSS train 0.4010456395098719 valid 0.4707029268548295
LOSS train 0.4010456395098719 valid 0.4719665050506592
LOSS train 0.4010456395098719 valid 0.4715079413010524
LOSS train 0.4010456395098719 valid 0.4730238772928715
LOSS train 0.4010456395098719 valid 0.4728909985321324
LOSS train 0.4010456395098719 valid 0.474012445126261
LOSS train 0.4010456395098719 valid 0.4740465470524721
LOSS train 0.4010456395098719 valid 0.47453985092314804
LOSS train 0.4010456395098719 valid 0.4747472286224365
LOSS train 0.4010456395098719 valid 0.47526876563611237
LOSS train 0.4010456395098719 valid 0.47452240928690487
LOSS train 0.4010456395098719 valid 0.4748298233995835
LOSS train 0.4010456395098719 valid 0.475404685249134
LOSS train 0.4010456395098719 valid 0.4750188547372818
LOSS train 0.4010456395098719 valid 0.4756537097341874
LOSS train 0.4010456395098719 valid 0.47535189585043836
LOSS train 0.4010456395098719 valid 0.47479161620140076
LOSS train 0.4010456395098719 valid 0.47479604846901363
LOSS train 0.4010456395098719 valid 0.47428085478869353
LOSS train 0.4010456395098719 valid 0.4740105654512133
LOSS train 0.4010456395098719 valid 0.47386746605237323
LOSS train 0.4010456395098719 valid 0.4736849269990263
LOSS train 0.4010456395098719 valid 0.47436735135013774
LOSS train 0.4010456395098719 valid 0.47368874003489814
LOSS train 0.4010456395098719 valid 0.4725083073631662
LOSS train 0.4010456395098719 valid 0.4737711029668008
LOSS train 0.4010456395098719 valid 0.47409099482354666
LOSS train 0.4010456395098719 valid 0.4746565702371299
LOSS train 0.4010456395098719 valid 0.4748885677411006
LOSS train 0.4010456395098719 valid 0.4748873913829977
LOSS train 0.4010456395098719 valid 0.47447677779553543
LOSS train 0.4010456395098719 valid 0.4738984835498473
LOSS train 0.4010456395098719 valid 0.4735140696815822
LOSS train 0.4010456395098719 valid 0.4730636677571705
LOSS train 0.4010456395098719 valid 0.47261077039678334
LOSS train 0.4010456395098719 valid 0.47236095410254264
LOSS train 0.4010456395098719 valid 0.4727504698381032
LOSS train 0.4010456395098719 valid 0.4726234807355984
LOSS train 0.4010456395098719 valid 0.4720523150761922
LOSS train 0.4010456395098719 valid 0.4722214709771307
LOSS train 0.4010456395098719 valid 0.4719877459786155
LOSS train 0.4010456395098719 valid 0.47194279997776717
LOSS train 0.4010456395098719 valid 0.47163646771937984
LOSS train 0.4010456395098719 valid 0.47157545350492003
LOSS train 0.4010456395098719 valid 0.4710455930527346
LOSS train 0.4010456395098719 valid 0.4712765220461822
LOSS train 0.4010456395098719 valid 0.4710595474903842
LOSS train 0.4010456395098719 valid 0.47114859698783784
LOSS train 0.4010456395098719 valid 0.4712611082722159
LOSS train 0.4010456395098719 valid 0.4707304901161859
LOSS train 0.4010456395098719 valid 0.47031302116383084
LOSS train 0.4010456395098719 valid 0.46972661736336624
LOSS train 0.4010456395098719 valid 0.4701317367928751
LOSS train 0.4010456395098719 valid 0.470132925775316
LOSS train 0.4010456395098719 valid 0.4697775103888669
LOSS train 0.4010456395098719 valid 0.4693737350728201
LOSS train 0.4010456395098719 valid 0.46878849178232174
LOSS train 0.4010456395098719 valid 0.46799419091102923
LOSS train 0.4010456395098719 valid 0.46752394876982034
LOSS train 0.4010456395098719 valid 0.46784788991014165
LOSS train 0.4010456395098719 valid 0.46826568768196497
LOSS train 0.4010456395098719 valid 0.4682129457288859
LOSS train 0.4010456395098719 valid 0.46848242752479785
LOSS train 0.4010456395098719 valid 0.46884547650814057
LOSS train 0.4010456395098719 valid 0.4689727254433207
LOSS train 0.4010456395098719 valid 0.469022741504744
LOSS train 0.4010456395098719 valid 0.4696538957577307
LOSS train 0.4010456395098719 valid 0.4694808692886279
LOSS train 0.4010456395098719 valid 0.46949972709019977
LOSS train 0.4010456395098719 valid 0.4696724420448519
LOSS train 0.4010456395098719 valid 0.46935141142283643
LOSS train 0.4010456395098719 valid 0.4697555888582159
LOSS train 0.4010456395098719 valid 0.46991311929641516
LOSS train 0.4010456395098719 valid 0.4700109368020838
LOSS train 0.4010456395098719 valid 0.47008615759041933
LOSS train 0.4010456395098719 valid 0.46986388521535055
LOSS train 0.4010456395098719 valid 0.46977865643205896
LOSS train 0.4010456395098719 valid 0.4695682789672885
LOSS train 0.4010456395098719 valid 0.4696070266806561
LOSS train 0.4010456395098719 valid 0.46958546314773886
LOSS train 0.4010456395098719 valid 0.469634563749672
LOSS train 0.4010456395098719 valid 0.46939934108216885
LOSS train 0.4010456395098719 valid 0.469097071585535
LOSS train 0.4010456395098719 valid 0.4690006519357363
LOSS train 0.4010456395098719 valid 0.46885655143044214
LOSS train 0.4010456395098719 valid 0.46875941851099984
LOSS train 0.4010456395098719 valid 0.46884328369202655
LOSS train 0.4010456395098719 valid 0.46916799631810957
LOSS train 0.4010456395098719 valid 0.4690300621986389
LOSS train 0.4010456395098719 valid 0.4689500532926075
LOSS train 0.4010456395098719 valid 0.4694211940596423
LOSS train 0.4010456395098719 valid 0.4695584352593869
LOSS train 0.4010456395098719 valid 0.4697342413340428
LOSS train 0.4010456395098719 valid 0.46946453681358924
LOSS train 0.4010456395098719 valid 0.4694446944098436
LOSS train 0.4010456395098719 valid 0.46937524369268707
LOSS train 0.4010456395098719 valid 0.4691697040894874
LOSS train 0.4010456395098719 valid 0.46937231319164163
LOSS train 0.4010456395098719 valid 0.4696066478888194
LOSS train 0.4010456395098719 valid 0.4696979248786674
LOSS train 0.4010456395098719 valid 0.4694991442408875
LOSS train 0.4010456395098719 valid 0.46934332558210345
LOSS train 0.4010456395098719 valid 0.46901333439264364
LOSS train 0.4010456395098719 valid 0.46917232125997543
LOSS train 0.4010456395098719 valid 0.4692064445492224
LOSS train 0.4010456395098719 valid 0.46949745168988133
LOSS train 0.4010456395098719 valid 0.46915594097617624
LOSS train 0.4010456395098719 valid 0.4691728043059508
LOSS train 0.4010456395098719 valid 0.46897224311170904
LOSS train 0.4010456395098719 valid 0.46932318439222365
LOSS train 0.4010456395098719 valid 0.4688846720319216
LOSS train 0.4010456395098719 valid 0.4693229097772289
LOSS train 0.4010456395098719 valid 0.46940304768965546
LOSS train 0.4010456395098719 valid 0.46952751219272615
LOSS train 0.4010456395098719 valid 0.46962655439282097
LOSS train 0.4010456395098719 valid 0.4693431273887032
LOSS train 0.4010456395098719 valid 0.4696188666462119
LOSS train 0.4010456395098719 valid 0.4695994511440203
LOSS train 0.4010456395098719 valid 0.46974519471968373
LOSS train 0.4010456395098719 valid 0.47008322236629635
LOSS train 0.4010456395098719 valid 0.4699747674404436
LOSS train 0.4010456395098719 valid 0.4699041622726223
LOSS train 0.4010456395098719 valid 0.4695933633630381
LOSS train 0.4010456395098719 valid 0.46962133757770064
LOSS train 0.4010456395098719 valid 0.46946691541197877
LOSS train 0.4010456395098719 valid 0.4690729405409024
LOSS train 0.4010456395098719 valid 0.4689993571284358
LOSS train 0.4010456395098719 valid 0.46884159689269417
LOSS train 0.4010456395098719 valid 0.46869571028333723
LOSS train 0.4010456395098719 valid 0.4685071494924017
LOSS train 0.4010456395098719 valid 0.46859382084029877
LOSS train 0.4010456395098719 valid 0.4688073999824978
LOSS train 0.4010456395098719 valid 0.4689653743300918
LOSS train 0.4010456395098719 valid 0.4694376708830104
LOSS train 0.4010456395098719 valid 0.4693107552695693
LOSS train 0.4010456395098719 valid 0.46934538698473643
LOSS train 0.4010456395098719 valid 0.46947427171503187
LOSS train 0.4010456395098719 valid 0.4694717238689291
LOSS train 0.4010456395098719 valid 0.4695694615159716
LOSS train 0.4010456395098719 valid 0.4694420925595544
LOSS train 0.4010456395098719 valid 0.4698094533661665
LOSS train 0.4010456395098719 valid 0.4700178946002146
LOSS train 0.4010456395098719 valid 0.4698567713439132
LOSS train 0.4010456395098719 valid 0.4699145696229405
LOSS train 0.4010456395098719 valid 0.4698948262475472
LOSS train 0.4010456395098719 valid 0.47001819738319944
LOSS train 0.4010456395098719 valid 0.46990110688522213
LOSS train 0.4010456395098719 valid 0.4701312966644764
LOSS train 0.4010456395098719 valid 0.4700675618004155
LOSS train 0.4010456395098719 valid 0.4701638361138682
LOSS train 0.4010456395098719 valid 0.4701913615917777
LOSS train 0.4010456395098719 valid 0.47017930273679975
LOSS train 0.4010456395098719 valid 0.47009444630965985
LOSS train 0.4010456395098719 valid 0.4699268196758471
LOSS train 0.4010456395098719 valid 0.4702061495855841
LOSS train 0.4010456395098719 valid 0.4703141280139486
LOSS train 0.4010456395098719 valid 0.47017934686779356
LOSS train 0.4010456395098719 valid 0.46999058188851345
LOSS train 0.4010456395098719 valid 0.4699677773011036
LOSS train 0.4010456395098719 valid 0.4700864250866734
LOSS train 0.4010456395098719 valid 0.47038610559429617
LOSS train 0.4010456395098719 valid 0.470419284671244
LOSS train 0.4010456395098719 valid 0.47046081265013423
LOSS train 0.4010456395098719 valid 0.4703874735534191
LOSS train 0.4010456395098719 valid 0.4700772090634303
LOSS train 0.4010456395098719 valid 0.47024686841091307
LOSS train 0.4010456395098719 valid 0.4700723907043194
LOSS train 0.4010456395098719 valid 0.47009903046430324
LOSS train 0.4010456395098719 valid 0.4700904319926006
LOSS train 0.4010456395098719 valid 0.4698628702209991
LOSS train 0.4010456395098719 valid 0.4701091874624796
LOSS train 0.4010456395098719 valid 0.47011321467848927
LOSS train 0.4010456395098719 valid 0.46998565105730267
LOSS train 0.4010456395098719 valid 0.470117554352397
LOSS train 0.4010456395098719 valid 0.47017798096082786
LOSS train 0.4010456395098719 valid 0.4702431597518471
LOSS train 0.4010456395098719 valid 0.47027787790052206
LOSS train 0.4010456395098719 valid 0.4702366736726226
LOSS train 0.4010456395098719 valid 0.47026282881581505
LOSS train 0.4010456395098719 valid 0.47031359981607507
LOSS train 0.4010456395098719 valid 0.47036657218010197
LOSS train 0.4010456395098719 valid 0.47047914222839776
LOSS train 0.4010456395098719 valid 0.470458187196897
LOSS train 0.4010456395098719 valid 0.4706587539477782
LOSS train 0.4010456395098719 valid 0.4708766875223876
LOSS train 0.4010456395098719 valid 0.4708680574958389
LOSS train 0.4010456395098719 valid 0.47090086020161753
LOSS train 0.4010456395098719 valid 0.47094936296343803
LOSS train 0.4010456395098719 valid 0.470991554790073
LOSS train 0.4010456395098719 valid 0.4709731936454773
LOSS train 0.4010456395098719 valid 0.47104613345099966
LOSS train 0.4010456395098719 valid 0.47100876716145296
LOSS train 0.4010456395098719 valid 0.47112454545549953
LOSS train 0.4010456395098719 valid 0.4712529602258102
LOSS train 0.4010456395098719 valid 0.4713403279389138
LOSS train 0.4010456395098719 valid 0.4713918614233362
LOSS train 0.4010456395098719 valid 0.47129841257574223
LOSS train 0.4010456395098719 valid 0.4712413937872292
LOSS train 0.4010456395098719 valid 0.47143436961985646
LOSS train 0.4010456395098719 valid 0.4713143592668792
LOSS train 0.4010456395098719 valid 0.47121008262352604
LOSS train 0.4010456395098719 valid 0.47116793854897765
LOSS train 0.4010456395098719 valid 0.4709983739892808
LOSS train 0.4010456395098719 valid 0.47084210216999056
LOSS train 0.4010456395098719 valid 0.4711157978817635
LOSS train 0.4010456395098719 valid 0.4710086150602861
LOSS train 0.4010456395098719 valid 0.4709474665147287
LOSS train 0.4010456395098719 valid 0.47107033236104934
LOSS train 0.4010456395098719 valid 0.47108752240940016
LOSS train 0.4010456395098719 valid 0.47107623602316634
LOSS train 0.4010456395098719 valid 0.47114153333038455
LOSS train 0.4010456395098719 valid 0.47110348315008227
LOSS train 0.4010456395098719 valid 0.4711318837112212
LOSS train 0.4010456395098719 valid 0.4714048273563385
LOSS train 0.4010456395098719 valid 0.47148437281528793
LOSS train 0.4010456395098719 valid 0.47175607321754337
LOSS train 0.4010456395098719 valid 0.47160842602432007
LOSS train 0.4010456395098719 valid 0.4718140760275323
LOSS train 0.4010456395098719 valid 0.4718256814807069
LOSS train 0.4010456395098719 valid 0.4717832747846842
LOSS train 0.4010456395098719 valid 0.4717740785287048
LOSS train 0.4010456395098719 valid 0.47181532653265223
LOSS train 0.4010456395098719 valid 0.47178750977092726
LOSS train 0.4010456395098719 valid 0.47163561605490173
LOSS train 0.4010456395098719 valid 0.4716690981981855
LOSS train 0.4010456395098719 valid 0.47159801958171466
LOSS train 0.4010456395098719 valid 0.47153793077051864
LOSS train 0.4010456395098719 valid 0.47145684639161284
LOSS train 0.4010456395098719 valid 0.47144676188253004
LOSS train 0.4010456395098719 valid 0.4715978150304995
LOSS train 0.4010456395098719 valid 0.4717963225162878
LOSS train 0.4010456395098719 valid 0.471948251016994
LOSS train 0.4010456395098719 valid 0.4721948452376965
LOSS train 0.4010456395098719 valid 0.472119446043615
LOSS train 0.4010456395098719 valid 0.47223944054758416
LOSS train 0.4010456395098719 valid 0.47234289161860943
LOSS train 0.4010456395098719 valid 0.4723799736290188
LOSS train 0.4010456395098719 valid 0.47239992957915705
LOSS train 0.4010456395098719 valid 0.47230995254083113
LOSS train 0.4010456395098719 valid 0.4722915367371794
LOSS train 0.4010456395098719 valid 0.47238290030173014
LOSS train 0.4010456395098719 valid 0.4723287327684087
LOSS train 0.4010456395098719 valid 0.4724068148161775
LOSS train 0.4010456395098719 valid 0.47226798736623354
LOSS train 0.4010456395098719 valid 0.4720806147492229
LOSS train 0.4010456395098719 valid 0.47204595624555085
LOSS train 0.4010456395098719 valid 0.4720599238527116
LOSS train 0.4010456395098719 valid 0.4721153880089102
LOSS train 0.4010456395098719 valid 0.47205870967162283
LOSS train 0.4010456395098719 valid 0.47191295194459126
LOSS train 0.4010456395098719 valid 0.4719515889363837
LOSS train 0.4010456395098719 valid 0.47187136858701706
LOSS train 0.4010456395098719 valid 0.47197706641622894
LOSS train 0.4010456395098719 valid 0.47199061451287105
LOSS train 0.4010456395098719 valid 0.47182409050538365
LOSS train 0.4010456395098719 valid 0.4718667975027267
LOSS train 0.4010456395098719 valid 0.47172751565028376
LOSS train 0.4010456395098719 valid 0.4717929420017061
LOSS train 0.4010456395098719 valid 0.47196717060218424
LOSS train 0.4010456395098719 valid 0.4718925900555946
LOSS train 0.4010456395098719 valid 0.4719249632222082
LOSS train 0.4010456395098719 valid 0.4717933975610157
LOSS train 0.4010456395098719 valid 0.47188673529736574
LOSS train 0.4010456395098719 valid 0.47189569254716235
LOSS train 0.4010456395098719 valid 0.4718982955546078
LOSS train 0.4010456395098719 valid 0.47175849490607813
LOSS train 0.4010456395098719 valid 0.471685517739148
LOSS train 0.4010456395098719 valid 0.4717463290220813
LOSS train 0.4010456395098719 valid 0.47171203699268277
LOSS train 0.4010456395098719 valid 0.47173335037979425
LOSS train 0.4010456395098719 valid 0.4717030454342062
LOSS train 0.4010456395098719 valid 0.47159901754809663
LOSS train 0.4010456395098719 valid 0.47160835925815175
LOSS train 0.4010456395098719 valid 0.4716340338030169
LOSS train 0.4010456395098719 valid 0.47162359243803853
LOSS train 0.4010456395098719 valid 0.4716372163249896
LOSS train 0.4010456395098719 valid 0.4717498783486339
LOSS train 0.4010456395098719 valid 0.4717078655009057
LOSS train 0.4010456395098719 valid 0.47168375367210025
LOSS train 0.4010456395098719 valid 0.47157158221625073
LOSS train 0.4010456395098719 valid 0.4716086601985366
LOSS train 0.4010456395098719 valid 0.47161224428212867
LOSS train 0.4010456395098719 valid 0.47162690282241676
LOSS train 0.4010456395098719 valid 0.4715897163376212
LOSS train 0.4010456395098719 valid 0.47159420673349567
LOSS train 0.4010456395098719 valid 0.47161456313192474
LOSS train 0.4010456395098719 valid 0.4716060235404378
LOSS train 0.4010456395098719 valid 0.47158164494199517
LOSS train 0.4010456395098719 valid 0.47151900098874017
LOSS train 0.4010456395098719 valid 0.4716167397842817
LOSS train 0.4010456395098719 valid 0.4717788250621306
LOSS train 0.4010456395098719 valid 0.4717514918344777
LOSS train 0.4010456395098719 valid 0.47178467465026763
LOSS train 0.4010456395098719 valid 0.47173772418137755
LOSS train 0.4010456395098719 valid 0.4716885256443139
LOSS train 0.4010456395098719 valid 0.47156059661184446
LOSS train 0.4010456395098719 valid 0.47160458555808654
LOSS train 0.4010456395098719 valid 0.47165660952736516
LOSS train 0.4010456395098719 valid 0.47167114152837153
LOSS train 0.4010456395098719 valid 0.4716232356925805
LOSS train 0.4010456395098719 valid 0.4716309797162472
LOSS train 0.4010456395098719 valid 0.4716630286189931
LOSS train 0.4010456395098719 valid 0.4715981985439593
LOSS train 0.4010456395098719 valid 0.4716419980806463
LOSS train 0.4010456395098719 valid 0.4714974694587618
LOSS train 0.4010456395098719 valid 0.47132888906880427
LOSS train 0.4010456395098719 valid 0.47133319596855006
LOSS train 0.4010456395098719 valid 0.4715495908329653
LOSS train 0.4010456395098719 valid 0.47161647832911946
LOSS train 0.4010456395098719 valid 0.4716125917917042
LOSS train 0.4010456395098719 valid 0.47154846658624217
LOSS train 0.4010456395098719 valid 0.47142127704346315
LOSS train 0.4010456395098719 valid 0.47145399306086894
LOSS train 0.4010456395098719 valid 0.4713203397818974
LOSS train 0.4010456395098719 valid 0.47125565309470197
LOSS train 0.4010456395098719 valid 0.47129231826825574
LOSS train 0.4010456395098719 valid 0.47132222459944384
LOSS train 0.4010456395098719 valid 0.4713690752363474
LOSS train 0.4010456395098719 valid 0.4713846574366932
LOSS train 0.4010456395098719 valid 0.4713788049274616
LOSS train 0.4010456395098719 valid 0.4713115171224129
LOSS train 0.4010456395098719 valid 0.4712296785922024
LOSS train 0.4010456395098719 valid 0.47127771859049467
LOSS train 0.4010456395098719 valid 0.4713017292320728
LOSS train 0.4010456395098719 valid 0.47133326381857704
LOSS train 0.4010456395098719 valid 0.4714937149161133
LOSS train 0.4010456395098719 valid 0.4714152673387659
LOSS train 0.4010456395098719 valid 0.471355187860164
LOSS train 0.4010456395098719 valid 0.4714074285879527
LOSS train 0.4010456395098719 valid 0.4713509906836546
LOSS train 0.4010456395098719 valid 0.4712653886882096
LOSS train 0.4010456395098719 valid 0.4712707527467738
LOSS train 0.4010456395098719 valid 0.4712591944186668
EPOCH 11:
  batch 1 loss: 0.36249497532844543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.38122156262397766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.39787914355595905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.40369878709316254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.40897072553634645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.40903501212596893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.40406154309000286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.41099441424012184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.40922128160794574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4076976180076599
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4059136022220958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.40481049319108325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4017783059523656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.399969288281032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.40110559860865275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4015220124274492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.40118978304021496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.40167352226045394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4017105729956376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.40047259330749513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.3996050272669111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.40029221773147583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.40108620990877564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40179237599174183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.40229165434837344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.40336179847900683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4031574527422587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4025954838309969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4032540496053367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.40296529630819955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4036078443450312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4036413384601474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.40349655440359405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.40361761082621184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4039689975125449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.404012241297298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4041257371773591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.404033678142648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4045534989772699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4050169803202152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.40474183457653695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4042627492121288
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4052131827487502
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.40439266711473465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.40477452741728887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4039014662089555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4041985698202823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.40400083487232524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.40407806756545084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4042352342605591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4040371372419245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.40393879264593124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.40411606431007385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.40401199570408575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4038785056634383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4039437621831894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.40451095135588394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4036649542635885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.40405886809704666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.40413083632787067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4035506287559134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4037763543667332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4037027491463555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4040221543982625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4041385843203618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.404340922832489
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.40384088523352324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4036906707812758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.40401712448700616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4044169055564063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.40433523898393336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40406331337160534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.40414002619377554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.40421082683511683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4039402159055074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4043268526070996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.40447953382095736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.40437159400719863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40439580211156534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.40449977815151217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.40469363810103615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40461596047006004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4044229556997138
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4044153999005045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.40444580491851356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4044299652410108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.40427430128229075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.40454370934854855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.404422219549672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.404664362139172
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.40427605234659636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4042847231030464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.40462538920423036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.40474963568626565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.40438014551212914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4046080481881897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.40426579209947094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4048761144584539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4050290042703802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4053283601999283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.40500566923972403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.40496424658625735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.40519751246693064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.40500800340221477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.404953871738343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4048543653960498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.40491038087372466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4051104795049738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.40489195984437926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4054252703081478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4051333421522433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4051039492977517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.40480157943953454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4047177049674486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.40424443353777345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4041667691078679
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4042081219008845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.40410018118761354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40393585091879386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.40396280686060587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.40367376508791586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.40360336054543977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.40401575356964176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4039341982814573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4040349595546722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.40379038287533653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.40372135859774794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4038962370250374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4040630531403445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4039304616359564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.40369452115233617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4035411477088928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.40370194087351174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.403663921267239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4035456096684491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4035544515970875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4036750443225359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4035147640152254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.40388279317094267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4039963988321168
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.40358776678430275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4035539205225421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4039111941844433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.40414091468685204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4043108477674682
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.40421273385825224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4041649569459513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4042012939179266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4042722384801647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.40423862556616463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4043800031507252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4042021118496594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.40401721234415094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.40380177792016564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4040040914089449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.40404350138627565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4041239657219808
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4039511484435842
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4042111509626017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4041387477889657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.40397158672350536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.40380377294840636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.40398667725317317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.40381243007212153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.40372926773446977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4036957813673709
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.40326451541420943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4031509132612319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4030850201668824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4030446471536861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.40303385623714383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4027438061528428
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4025274575445693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4025550715882203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4025342404842377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.40240522186187183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4022190678591109
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4020124842946449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4021010753495733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.40193388991885715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.40199663823480764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.40210829789821917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4019756616790438
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4019479840669943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4020379063245412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4018706144184195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4017335405961715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4014849751553637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.40136758565271974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4014135015638251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4013891911319413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.40126223443076015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.40119105747326667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.40103401981063724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4010172432813889
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.40107005819374203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.40115539464853744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.40162965263983214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4015376737069844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4014784881472588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4014273668403056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4014147536294295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.40162889050145456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.401582929287471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4015647068256285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.401588136854681
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4016478398571844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4014435545183145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4014712885806435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4015197795061838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.40154104436178345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4016062653851959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.40142468401523823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40121378143814124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4010727398617323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4010373905852989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.40114701824254156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.40113169679401117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.40130862253441657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4013433296572078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.40131390593709987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4012196745958414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.40126433153323526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4015283813433988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4013565742969513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4011603225912668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4011877511303856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.40105710649176646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.40106695460960856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4011345119579979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.40118274079772814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4012096248053271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.401069347822615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.40108487735956144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4011845108042372
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40127422597448703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40142434106094427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4014824457278773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4016039619635339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4016131700326999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.40157107409105264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.40149490535259247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.401640556354091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4015314097775788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4015820959392859
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4016127672379579
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.40161867759488373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4016540175484073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4016253522122241
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4017717739343643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.40175376470345425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.40176550582760856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4017306032623698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4016857065084412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4017622210231482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.40170127083547413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.401644974367164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.40165345105089884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.40184321470242207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4019948501999562
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.40186938083948304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.40184615302176874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4017778421989412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4016680290753191
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4015301468237391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.40159129849950176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4015436035193754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.401500289231094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40158420612820905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.40155827579674896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4016253492928959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.401533172958914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.40155388300235456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.40139007350824174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.40119137308814307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.40135472861752997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.40130013421124067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.40117549960561794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.40130463125030624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4012089163064957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4011891877736061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.40108633062518234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4010660580948469
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.40104159901679404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40114130273199916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.401100747860395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.401099690576879
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4011437160273393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4013486457118526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.40144571107009364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.40148912508463125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40150224162291176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.40152590592159754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4014807088034494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.40153180643663566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4015436460440223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4016609391580126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4015532877021188
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4015167801077151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.40150715937217074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.40154553578541524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4014053385186669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4013882195792182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4013351478466862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4012303778382598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4012187123298645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40126277938339533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4010710473377983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.401197373577692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.40124573649898654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.40121991688032244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4012394454807807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.40126708149909973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4011668349337426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.40118804697006466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4011905399870269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.40115415730310916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.401072288178048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.40109503269195557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.40101365381851795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.40099760295817416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.40096445964730304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.40098440490270915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4009541584017836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.40094031645701483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4009212432829149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4009541508254655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.40095503210294536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.40084848188339395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4008848998582724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.40098152158843786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.400904798992427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4009832139308746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4009414714967419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.40101125471627536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.40098547988704275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.400862933973884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.40095257388769523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4009177411376199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4011046589297407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.40105335479957266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4011720227219208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4012284695928368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4011162756833919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.40107903722403704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.40103105778639025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.40109253865841143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4010793096546469
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.40098514213603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4008913346699306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.40080980256072474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4008400761099024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40091938447344405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.40082372565053953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.40085791273855825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.40083304131298925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4008785215746455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.40085079833115944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4008981434415642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.40091171231534745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4008816978442702
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4010117637683015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4010550291085046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.40104276965280156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.40112699809139724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.40109960270709677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.40109362215696953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.40113927148606465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.40115118955532064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.40117698899797494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4011781758696564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4012035261238775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.40120575662912056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4011917636196881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.40112207674980166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4011004995950993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4011714882970805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.40118570696739925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4011492520020316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4010932461211556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40104119952895195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4010294519793925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4011115625539585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40113847873484093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4010335927659815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4010882276481915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.40105133501750245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4010595024861011
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.40102350972305534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4010057136034354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4009611307050261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.40092681986945017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4010191123752497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4009221957873572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4008748568311522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4008705909505035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4007994922943019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40083113784466556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.40082918798415584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4009608068317175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.40085860744973373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.40067555477370076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4005414992940633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4005178282461544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4004918693760295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4004665647674664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.40040656653317536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4003742377401567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.40042464999814487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.40042211449727777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.40055758935691665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.40051646364256016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.40048418986018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4005461052276086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.40048971413129786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4005437468966612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4004548737328115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.40042214630323164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4004926247642262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4004400996225221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.40050393774786924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4004753772963845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4004974876735227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.40054913961662436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.40056255733265594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4004994962416904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.40060137348376057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4005532980522263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4004133007465265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.40054762252541476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.40058066300062456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4006205393622319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4005011443315422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.40050005047552045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.40042959999764105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.40048338144744206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.40049575027121015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4004740064546942
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.40037708062517346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.40039168867197905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4004121191647588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.40045140285837166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4005012255220865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.40053616074828413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.40075354616293746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4007492844566636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4007162787770265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.40078383843813625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4007748170260066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4007679498195648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.40072566733392007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.40071707199105117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.40069999547457325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4006895997975891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4006154225422786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.40063343393175227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4006231189165387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.40067026240336323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.40069147158811813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4007228020740592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.40068179834432044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.40064527320139337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4006420736307717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.40066687261749956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.40071325455942464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4007809189000355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4007423066990789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.40066506223291415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4006972395534963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40078710425407327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4007316849920147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4008465243219319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4008465243219319 valid 0.42804428935050964
LOSS train 0.4008465243219319 valid 0.42724384367465973
LOSS train 0.4008465243219319 valid 0.4482739269733429
LOSS train 0.4008465243219319 valid 0.4456024393439293
LOSS train 0.4008465243219319 valid 0.442382150888443
LOSS train 0.4008465243219319 valid 0.4454179008801778
LOSS train 0.4008465243219319 valid 0.44575895156179157
LOSS train 0.4008465243219319 valid 0.4452761895954609
LOSS train 0.4008465243219319 valid 0.43894753522343105
LOSS train 0.4008465243219319 valid 0.4419142991304398
LOSS train 0.4008465243219319 valid 0.4454817392609336
LOSS train 0.4008465243219319 valid 0.4439472258090973
LOSS train 0.4008465243219319 valid 0.44620890800769514
LOSS train 0.4008465243219319 valid 0.44633897287505014
LOSS train 0.4008465243219319 valid 0.4448500633239746
LOSS train 0.4008465243219319 valid 0.44698725640773773
LOSS train 0.4008465243219319 valid 0.4495810182655559
LOSS train 0.4008465243219319 valid 0.4506339265240563
LOSS train 0.4008465243219319 valid 0.45137949993735865
LOSS train 0.4008465243219319 valid 0.4531809791922569
LOSS train 0.4008465243219319 valid 0.45210531921613784
LOSS train 0.4008465243219319 valid 0.44918782196261664
LOSS train 0.4008465243219319 valid 0.4499738695828811
LOSS train 0.4008465243219319 valid 0.44851099078853923
LOSS train 0.4008465243219319 valid 0.44751633882522585
LOSS train 0.4008465243219319 valid 0.44692502113489
LOSS train 0.4008465243219319 valid 0.446292448926855
LOSS train 0.4008465243219319 valid 0.4470204508730343
LOSS train 0.4008465243219319 valid 0.44633199223156633
LOSS train 0.4008465243219319 valid 0.4471926192442576
LOSS train 0.4008465243219319 valid 0.4490327969674141
LOSS train 0.4008465243219319 valid 0.44899022951722145
LOSS train 0.4008465243219319 valid 0.4503264327843984
LOSS train 0.4008465243219319 valid 0.44963783551664915
LOSS train 0.4008465243219319 valid 0.45046399661472863
LOSS train 0.4008465243219319 valid 0.4506076822678248
LOSS train 0.4008465243219319 valid 0.45104060060269124
LOSS train 0.4008465243219319 valid 0.452221984926023
LOSS train 0.4008465243219319 valid 0.45180690441376126
LOSS train 0.4008465243219319 valid 0.45333227664232256
LOSS train 0.4008465243219319 valid 0.45322832247106043
LOSS train 0.4008465243219319 valid 0.45432873637903304
LOSS train 0.4008465243219319 valid 0.45435543878133905
LOSS train 0.4008465243219319 valid 0.4547635547139428
LOSS train 0.4008465243219319 valid 0.4548820243941413
LOSS train 0.4008465243219319 valid 0.45538579057092254
LOSS train 0.4008465243219319 valid 0.4547102007460087
LOSS train 0.4008465243219319 valid 0.4550708942115307
LOSS train 0.4008465243219319 valid 0.45560162347190236
LOSS train 0.4008465243219319 valid 0.45520499169826506
LOSS train 0.4008465243219319 valid 0.4558349970509024
LOSS train 0.4008465243219319 valid 0.4555226925473947
LOSS train 0.4008465243219319 valid 0.45496187626190904
LOSS train 0.4008465243219319 valid 0.45498762914428004
LOSS train 0.4008465243219319 valid 0.45451376817443156
LOSS train 0.4008465243219319 valid 0.45428862954889027
LOSS train 0.4008465243219319 valid 0.45415092560282927
LOSS train 0.4008465243219319 valid 0.45392522369993143
LOSS train 0.4008465243219319 valid 0.45460538692393543
LOSS train 0.4008465243219319 valid 0.45397120316823325
LOSS train 0.4008465243219319 valid 0.45281211860844345
LOSS train 0.4008465243219319 valid 0.454086221033527
LOSS train 0.4008465243219319 valid 0.4543986159657675
LOSS train 0.4008465243219319 valid 0.4549300177022815
LOSS train 0.4008465243219319 valid 0.45515357897831843
LOSS train 0.4008465243219319 valid 0.4551811398881854
LOSS train 0.4008465243219319 valid 0.4547278881072998
LOSS train 0.4008465243219319 valid 0.4541595144306912
LOSS train 0.4008465243219319 valid 0.4538099597329679
LOSS train 0.4008465243219319 valid 0.4533570102282933
LOSS train 0.4008465243219319 valid 0.45295020728044105
LOSS train 0.4008465243219319 valid 0.4527298803958628
LOSS train 0.4008465243219319 valid 0.45307460263983845
LOSS train 0.4008465243219319 valid 0.4529455590087014
LOSS train 0.4008465243219319 valid 0.45234397570292156
LOSS train 0.4008465243219319 valid 0.4525054995166628
LOSS train 0.4008465243219319 valid 0.45228123703560275
LOSS train 0.4008465243219319 valid 0.45222516969228405
LOSS train 0.4008465243219319 valid 0.4519551916967464
LOSS train 0.4008465243219319 valid 0.45187352895736693
LOSS train 0.4008465243219319 valid 0.451374610265096
LOSS train 0.4008465243219319 valid 0.4516259086568181
LOSS train 0.4008465243219319 valid 0.45140166419098177
LOSS train 0.4008465243219319 valid 0.4514906739904767
LOSS train 0.4008465243219319 valid 0.45158266740686753
LOSS train 0.4008465243219319 valid 0.45109623254731646
LOSS train 0.4008465243219319 valid 0.45072800606146624
LOSS train 0.4008465243219319 valid 0.4501380232924765
LOSS train 0.4008465243219319 valid 0.45054534178101613
LOSS train 0.4008465243219319 valid 0.45049886273013223
LOSS train 0.4008465243219319 valid 0.4501896857560336
LOSS train 0.4008465243219319 valid 0.4497965577503909
LOSS train 0.4008465243219319 valid 0.44920364919529165
LOSS train 0.4008465243219319 valid 0.448455754429736
LOSS train 0.4008465243219319 valid 0.44801852232531497
LOSS train 0.4008465243219319 valid 0.4483286505565047
LOSS train 0.4008465243219319 valid 0.4487197638786945
LOSS train 0.4008465243219319 valid 0.44868763733883293
LOSS train 0.4008465243219319 valid 0.44894149899482727
LOSS train 0.4008465243219319 valid 0.4492777931690216
LOSS train 0.4008465243219319 valid 0.44941294724398323
LOSS train 0.4008465243219319 valid 0.4494601894243091
LOSS train 0.4008465243219319 valid 0.4500724224789629
LOSS train 0.4008465243219319 valid 0.4498804549758251
LOSS train 0.4008465243219319 valid 0.44989077619143897
LOSS train 0.4008465243219319 valid 0.4500266296683617
LOSS train 0.4008465243219319 valid 0.4497074356703001
LOSS train 0.4008465243219319 valid 0.4501287873696398
LOSS train 0.4008465243219319 valid 0.45027175381642964
LOSS train 0.4008465243219319 valid 0.4503806355324658
LOSS train 0.4008465243219319 valid 0.45044712682028076
LOSS train 0.4008465243219319 valid 0.45025624866996494
LOSS train 0.4008465243219319 valid 0.4501862576050041
LOSS train 0.4008465243219319 valid 0.44998532063082647
LOSS train 0.4008465243219319 valid 0.4500151302503503
LOSS train 0.4008465243219319 valid 0.44999453091415864
LOSS train 0.4008465243219319 valid 0.45004803680966043
LOSS train 0.4008465243219319 valid 0.4498379202717442
LOSS train 0.4008465243219319 valid 0.44955808650545714
LOSS train 0.4008465243219319 valid 0.4494395114481449
LOSS train 0.4008465243219319 valid 0.44928053119951045
LOSS train 0.4008465243219319 valid 0.44916374712693885
LOSS train 0.4008465243219319 valid 0.4492543763746091
LOSS train 0.4008465243219319 valid 0.4495686165267421
LOSS train 0.4008465243219319 valid 0.44944339752197265
LOSS train 0.4008465243219319 valid 0.4493377447601349
LOSS train 0.4008465243219319 valid 0.44979203146273694
LOSS train 0.4008465243219319 valid 0.44993297499604523
LOSS train 0.4008465243219319 valid 0.45009609872056533
LOSS train 0.4008465243219319 valid 0.44983989527592294
LOSS train 0.4008465243219319 valid 0.4498375078649011
LOSS train 0.4008465243219319 valid 0.4497874205311139
LOSS train 0.4008465243219319 valid 0.449592750995679
LOSS train 0.4008465243219319 valid 0.4497953439826396
LOSS train 0.4008465243219319 valid 0.45000518759091696
LOSS train 0.4008465243219319 valid 0.4500769098453662
LOSS train 0.4008465243219319 valid 0.4498848168954362
LOSS train 0.4008465243219319 valid 0.4497453587642614
LOSS train 0.4008465243219319 valid 0.44943796945132797
LOSS train 0.4008465243219319 valid 0.4496048092842102
LOSS train 0.4008465243219319 valid 0.44964680836555804
LOSS train 0.4008465243219319 valid 0.44994477235095603
LOSS train 0.4008465243219319 valid 0.4496060772375627
LOSS train 0.4008465243219319 valid 0.44964203362663585
LOSS train 0.4008465243219319 valid 0.4494572995037868
LOSS train 0.4008465243219319 valid 0.4498048924828229
LOSS train 0.4008465243219319 valid 0.44936825284341564
LOSS train 0.4008465243219319 valid 0.4497869922905355
LOSS train 0.4008465243219319 valid 0.4498775307364112
LOSS train 0.4008465243219319 valid 0.4499710681041082
LOSS train 0.4008465243219319 valid 0.450052838451815
LOSS train 0.4008465243219319 valid 0.44979039128673703
LOSS train 0.4008465243219319 valid 0.4500538465244318
LOSS train 0.4008465243219319 valid 0.45004346037839915
LOSS train 0.4008465243219319 valid 0.4501726456226841
LOSS train 0.4008465243219319 valid 0.4505169213964389
LOSS train 0.4008465243219319 valid 0.4504159102394323
LOSS train 0.4008465243219319 valid 0.4503681552183779
LOSS train 0.4008465243219319 valid 0.45006701275237704
LOSS train 0.4008465243219319 valid 0.45010115038603543
LOSS train 0.4008465243219319 valid 0.4499240658298042
LOSS train 0.4008465243219319 valid 0.44952723659850935
LOSS train 0.4008465243219319 valid 0.44946812175534256
LOSS train 0.4008465243219319 valid 0.44931714091359115
LOSS train 0.4008465243219319 valid 0.44919153795097816
LOSS train 0.4008465243219319 valid 0.4490145647741226
LOSS train 0.4008465243219319 valid 0.44909347781164205
LOSS train 0.4008465243219319 valid 0.4492956616339229
LOSS train 0.4008465243219319 valid 0.44944848852044733
LOSS train 0.4008465243219319 valid 0.4499140076777514
LOSS train 0.4008465243219319 valid 0.44978904863547164
LOSS train 0.4008465243219319 valid 0.44983207607685133
LOSS train 0.4008465243219319 valid 0.4499599390980825
LOSS train 0.4008465243219319 valid 0.44995424922170313
LOSS train 0.4008465243219319 valid 0.45004451990127564
LOSS train 0.4008465243219319 valid 0.4499148079617457
LOSS train 0.4008465243219319 valid 0.450257276074361
LOSS train 0.4008465243219319 valid 0.45046786679310746
LOSS train 0.4008465243219319 valid 0.45031638784781514
LOSS train 0.4008465243219319 valid 0.45038665897316404
LOSS train 0.4008465243219319 valid 0.45037782620329886
LOSS train 0.4008465243219319 valid 0.4505046632263687
LOSS train 0.4008465243219319 valid 0.4503874417211189
LOSS train 0.4008465243219319 valid 0.450614097163729
LOSS train 0.4008465243219319 valid 0.4505394930775101
LOSS train 0.4008465243219319 valid 0.4506268232099472
LOSS train 0.4008465243219319 valid 0.45066017868684577
LOSS train 0.4008465243219319 valid 0.45064157643850816
LOSS train 0.4008465243219319 valid 0.45056024887574414
LOSS train 0.4008465243219319 valid 0.4503991825015921
LOSS train 0.4008465243219319 valid 0.4506717519298274
LOSS train 0.4008465243219319 valid 0.45078142841036123
LOSS train 0.4008465243219319 valid 0.45065287234251983
LOSS train 0.4008465243219319 valid 0.4504635370883745
LOSS train 0.4008465243219319 valid 0.450441704193751
LOSS train 0.4008465243219319 valid 0.45055022227520847
LOSS train 0.4008465243219319 valid 0.45082694382836974
LOSS train 0.4008465243219319 valid 0.4508645176285445
LOSS train 0.4008465243219319 valid 0.45090437264897715
LOSS train 0.4008465243219319 valid 0.4508371092379093
LOSS train 0.4008465243219319 valid 0.450550708456419
LOSS train 0.4008465243219319 valid 0.45071020102736975
LOSS train 0.4008465243219319 valid 0.4505332720103522
LOSS train 0.4008465243219319 valid 0.4505393919991512
LOSS train 0.4008465243219319 valid 0.4505342041573873
LOSS train 0.4008465243219319 valid 0.4503222970129217
LOSS train 0.4008465243219319 valid 0.45056060273290255
LOSS train 0.4008465243219319 valid 0.450554135040595
LOSS train 0.4008465243219319 valid 0.4504364064435639
LOSS train 0.4008465243219319 valid 0.4505665062438874
LOSS train 0.4008465243219319 valid 0.45061224374160946
LOSS train 0.4008465243219319 valid 0.4506812858975159
LOSS train 0.4008465243219319 valid 0.4507226973352298
LOSS train 0.4008465243219319 valid 0.4506789979255088
LOSS train 0.4008465243219319 valid 0.45069646197696067
LOSS train 0.4008465243219319 valid 0.4507517788421225
LOSS train 0.4008465243219319 valid 0.45080445809847747
LOSS train 0.4008465243219319 valid 0.4509027094469158
LOSS train 0.4008465243219319 valid 0.4508839633366833
LOSS train 0.4008465243219319 valid 0.45108120346611197
LOSS train 0.4008465243219319 valid 0.4512934624069956
LOSS train 0.4008465243219319 valid 0.4512843378223814
LOSS train 0.4008465243219319 valid 0.4513121556006205
LOSS train 0.4008465243219319 valid 0.45135869311967064
LOSS train 0.4008465243219319 valid 0.45140077975061205
LOSS train 0.4008465243219319 valid 0.4513862698742774
LOSS train 0.4008465243219319 valid 0.45145999899519695
LOSS train 0.4008465243219319 valid 0.4514322777589162
LOSS train 0.4008465243219319 valid 0.451548535750943
LOSS train 0.4008465243219319 valid 0.45168146594710973
LOSS train 0.4008465243219319 valid 0.45175034414122117
LOSS train 0.4008465243219319 valid 0.45180087754952497
LOSS train 0.4008465243219319 valid 0.45170513921029576
LOSS train 0.4008465243219319 valid 0.45164383056326807
LOSS train 0.4008465243219319 valid 0.451828337603427
LOSS train 0.4008465243219319 valid 0.4517157918820947
LOSS train 0.4008465243219319 valid 0.45160847298706636
LOSS train 0.4008465243219319 valid 0.4515672507656722
LOSS train 0.4008465243219319 valid 0.4514067116890991
LOSS train 0.4008465243219319 valid 0.4512571763247252
LOSS train 0.4008465243219319 valid 0.45151888545123375
LOSS train 0.4008465243219319 valid 0.4514228600608416
LOSS train 0.4008465243219319 valid 0.4513752056983273
LOSS train 0.4008465243219319 valid 0.45149155119892026
LOSS train 0.4008465243219319 valid 0.45150712910963564
LOSS train 0.4008465243219319 valid 0.45149874941604895
LOSS train 0.4008465243219319 valid 0.45155149070840134
LOSS train 0.4008465243219319 valid 0.45151887161116444
LOSS train 0.4008465243219319 valid 0.45154254946363975
LOSS train 0.4008465243219319 valid 0.45180289041996
LOSS train 0.4008465243219319 valid 0.4518802094744496
LOSS train 0.4008465243219319 valid 0.4521434231409951
LOSS train 0.4008465243219319 valid 0.4520097497423647
LOSS train 0.4008465243219319 valid 0.45221111835457206
LOSS train 0.4008465243219319 valid 0.45222555387253854
LOSS train 0.4008465243219319 valid 0.4521932137431577
LOSS train 0.4008465243219319 valid 0.45218349906257155
LOSS train 0.4008465243219319 valid 0.45223225075607154
LOSS train 0.4008465243219319 valid 0.4522130009520468
LOSS train 0.4008465243219319 valid 0.45207005475576106
LOSS train 0.4008465243219319 valid 0.45210247432591816
LOSS train 0.4008465243219319 valid 0.4520276425448993
LOSS train 0.4008465243219319 valid 0.45197693737287487
LOSS train 0.4008465243219319 valid 0.4518935807952375
LOSS train 0.4008465243219319 valid 0.45188321358752703
LOSS train 0.4008465243219319 valid 0.45202582346317466
LOSS train 0.4008465243219319 valid 0.45222173346562333
LOSS train 0.4008465243219319 valid 0.45235320736668005
LOSS train 0.4008465243219319 valid 0.4525997961099263
LOSS train 0.4008465243219319 valid 0.45251909384021055
LOSS train 0.4008465243219319 valid 0.4526527792325319
LOSS train 0.4008465243219319 valid 0.45274415414999514
LOSS train 0.4008465243219319 valid 0.4527764414256309
LOSS train 0.4008465243219319 valid 0.4527976010402624
LOSS train 0.4008465243219319 valid 0.45270478291945027
LOSS train 0.4008465243219319 valid 0.45267046275346173
LOSS train 0.4008465243219319 valid 0.4527636357593192
LOSS train 0.4008465243219319 valid 0.4527109623384133
LOSS train 0.4008465243219319 valid 0.45279220804091425
LOSS train 0.4008465243219319 valid 0.4526550283389432
LOSS train 0.4008465243219319 valid 0.45248393062170716
LOSS train 0.4008465243219319 valid 0.45245061022170047
LOSS train 0.4008465243219319 valid 0.45247484243379466
LOSS train 0.4008465243219319 valid 0.4525241369092968
LOSS train 0.4008465243219319 valid 0.45247239491395785
LOSS train 0.4008465243219319 valid 0.4523419434582437
LOSS train 0.4008465243219319 valid 0.45237532154192905
LOSS train 0.4008465243219319 valid 0.45229995405922335
LOSS train 0.4008465243219319 valid 0.4524031505246476
LOSS train 0.4008465243219319 valid 0.4524172777759618
LOSS train 0.4008465243219319 valid 0.4522524839619181
LOSS train 0.4008465243219319 valid 0.45229851985222674
LOSS train 0.4008465243219319 valid 0.45217165259371034
LOSS train 0.4008465243219319 valid 0.4522443089355417
LOSS train 0.4008465243219319 valid 0.4524076613329225
LOSS train 0.4008465243219319 valid 0.45233377663267627
LOSS train 0.4008465243219319 valid 0.45236920337082964
LOSS train 0.4008465243219319 valid 0.45224725930082715
LOSS train 0.4008465243219319 valid 0.45233771763119013
LOSS train 0.4008465243219319 valid 0.4523587136467298
LOSS train 0.4008465243219319 valid 0.45236414651142004
LOSS train 0.4008465243219319 valid 0.4522321123555796
LOSS train 0.4008465243219319 valid 0.4521651807988044
LOSS train 0.4008465243219319 valid 0.45221821248139205
LOSS train 0.4008465243219319 valid 0.4521828802882648
LOSS train 0.4008465243219319 valid 0.4522067182788662
LOSS train 0.4008465243219319 valid 0.4521859316367668
LOSS train 0.4008465243219319 valid 0.4520876199587599
LOSS train 0.4008465243219319 valid 0.4521005795032847
LOSS train 0.4008465243219319 valid 0.45211613457049094
LOSS train 0.4008465243219319 valid 0.45210033348518935
LOSS train 0.4008465243219319 valid 0.4521177663252904
LOSS train 0.4008465243219319 valid 0.45222902221801564
LOSS train 0.4008465243219319 valid 0.4521884644866749
LOSS train 0.4008465243219319 valid 0.4521639750117347
LOSS train 0.4008465243219319 valid 0.4520425393800192
LOSS train 0.4008465243219319 valid 0.4520731736620894
LOSS train 0.4008465243219319 valid 0.4520791254515918
LOSS train 0.4008465243219319 valid 0.4520851164402259
LOSS train 0.4008465243219319 valid 0.4520397916436195
LOSS train 0.4008465243219319 valid 0.45205205623234546
LOSS train 0.4008465243219319 valid 0.4520718334994701
LOSS train 0.4008465243219319 valid 0.45206682287133515
LOSS train 0.4008465243219319 valid 0.45203436966295596
LOSS train 0.4008465243219319 valid 0.4519740137687096
LOSS train 0.4008465243219319 valid 0.45206295401772106
LOSS train 0.4008465243219319 valid 0.45223024988757726
LOSS train 0.4008465243219319 valid 0.45220049125392264
LOSS train 0.4008465243219319 valid 0.452224452988355
LOSS train 0.4008465243219319 valid 0.45216544956871957
LOSS train 0.4008465243219319 valid 0.4521231094876085
LOSS train 0.4008465243219319 valid 0.4519904808825757
LOSS train 0.4008465243219319 valid 0.45203376066935314
LOSS train 0.4008465243219319 valid 0.4520843620607239
LOSS train 0.4008465243219319 valid 0.45208774867342477
LOSS train 0.4008465243219319 valid 0.45202749355563093
LOSS train 0.4008465243219319 valid 0.45203035468517494
LOSS train 0.4008465243219319 valid 0.4520639825678436
LOSS train 0.4008465243219319 valid 0.4519987910722209
LOSS train 0.4008465243219319 valid 0.4520390562274877
LOSS train 0.4008465243219319 valid 0.4518904873877327
LOSS train 0.4008465243219319 valid 0.451727742775839
LOSS train 0.4008465243219319 valid 0.45172048205884485
LOSS train 0.4008465243219319 valid 0.4519229219403378
LOSS train 0.4008465243219319 valid 0.45198440396267436
LOSS train 0.4008465243219319 valid 0.4519786374761879
LOSS train 0.4008465243219319 valid 0.4519098562534673
LOSS train 0.4008465243219319 valid 0.45179169316743983
LOSS train 0.4008465243219319 valid 0.4518206840258273
LOSS train 0.4008465243219319 valid 0.45168578701359885
LOSS train 0.4008465243219319 valid 0.4516262710094452
LOSS train 0.4008465243219319 valid 0.4516601466827772
LOSS train 0.4008465243219319 valid 0.45169958421596385
LOSS train 0.4008465243219319 valid 0.4517410805838256
LOSS train 0.4008465243219319 valid 0.45175040347475404
LOSS train 0.4008465243219319 valid 0.45174501183327664
LOSS train 0.4008465243219319 valid 0.4516814939615105
LOSS train 0.4008465243219319 valid 0.4516043084460264
LOSS train 0.4008465243219319 valid 0.4516467427974956
LOSS train 0.4008465243219319 valid 0.4516754266288545
LOSS train 0.4008465243219319 valid 0.4517068353551246
LOSS train 0.4008465243219319 valid 0.45185935983012393
LOSS train 0.4008465243219319 valid 0.45178596088380524
LOSS train 0.4008465243219319 valid 0.45172738488558883
LOSS train 0.4008465243219319 valid 0.4517828783760332
LOSS train 0.4008465243219319 valid 0.4517283074028505
LOSS train 0.4008465243219319 valid 0.45164539719797286
LOSS train 0.4008465243219319 valid 0.4516506814600333
LOSS train 0.4008465243219319 valid 0.4516325966129458
EPOCH 12:
  batch 1 loss: 0.3645309805870056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.38297218084335327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.399239460627238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4053132236003876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4088541865348816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.40832507113615674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4019726812839508
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.40780963748693466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.40697579582532245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4055823415517807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.40235389091751794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.40158724536498386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.39929460562192476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.3982689210346767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.3999623775482178
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.40027741715312004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4009457598714268
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4012865937418408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4016058272437045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4001786336302757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.3989666515872592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.39939300986853515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.40098099475321564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4017130881547928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4023699569702148
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.40361083012360793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.40374352865748936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4031328761151859
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.40420960249571963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4037495364745458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.40407663487618967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4040190326049924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4039372846935735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.404444677864804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4046337800366538
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.405083807806174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.40497994503459417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4046580587562762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.405021010301052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4057028092443943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.405335932970047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.404753463608878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.40588548155718074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4050809781659733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.40546318689982097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.40432100710661517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4044329822063446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.40444201541443664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4046142229012081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.40497129380702973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4047576002046174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4044626813668471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4044007619596877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.40407002634472317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.40384303602305327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4040464051067829
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4047636332219107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4037997326974211
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.40412724119121746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4042075345913569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.40366590120753304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.40370444520827264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4035509153017922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.40378231136128306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4036915774528797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4039003411025712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4033039399047396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.40301497631213246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4031632425992385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.40364842457430705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.40365926270753566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40328091258804005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4031451756823553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.40324284861216675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4031461830933889
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.40344271495154027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4035557504598196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4033475025342061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40352919433690326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4036395750939846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.40380001141701216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4037113880238882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4035118588482041
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.40340920431273325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4035587331827949
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.40350855540397557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.40351382822825993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.40380776809020474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4036837193403351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4038464195198483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.40341734886169434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4034590815072474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4036839722946126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4038406854614298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4034307749647843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.40368864592164755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4032866275802101
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4037018503461565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.40391661783661503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4041061165928841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.40385849493564946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.40375513101325317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.40390065370254147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4035680193740588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.40348569183122546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4032688981519555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4033516575799924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.40357437095156423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4033657110065495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.40391608666289935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4036923697939864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4036804647850139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.40336141570479467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.40335661408148316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.40297954626705335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.40284920560902565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4029052823017805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4027285358663333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40254048339459075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.40260857592026394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.40236005162404587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4022877538790468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.40275327291915086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4027120511858694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.40284618830680846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4027527424078139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4026634805784451
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4028036892414093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4029433036497397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.40287968745598424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.40262343182818583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4024321138858795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4025242088880754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4024698985601539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4022902771278664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.40234023880432634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.40244055990755123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4023083521836046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.40260590066155083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.40261758182729995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.402189793527549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.40220134359010506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.40254632138705754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.40279910527169704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4028399603120212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.40273133879655026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4027445291986271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4029223596727526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.40304252325288403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.40299939274787905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.40308052597456423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.40286441363002123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.40270956746892994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.402473329917177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4026608957398322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4027675837278366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.40293002261477673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4027343895993655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4029387657372457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4028487902134657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.40270912832354905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.40253849419546717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4027429085933358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.402502377222224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4023703416188558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.40233292529381903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4018823943452207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4017812343580382
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.40169149319801106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4016555186580209
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.40165998939185116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.40150867385226624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.40126035840525104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4013029655505871
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4012668195792607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4011594563383948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4009537762504513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4007552374949616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4008159867212093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4006686975558599
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4007697382025956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4008903315106591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.40078174563053526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4007683368804662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4008197028894682
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.40075191486907263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4005332383561262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4002719206061769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.40016283386598817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.40023737910546753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.40021089187467285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4001365681178868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.400114658119765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.40002791260935594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.40002959447029307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.40008008540893086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.40019886051942855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4006400734487206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.40052147366892754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.40053950995206833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.40056893807738575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.40052321346679537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.400713758515607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.40070050969427706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4006620722572978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4006650533201625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.40074225669897695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4005582335476692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.40059986439618195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.40062666620526993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4006518786552393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.40067955387650794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4004999961651547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40029697872210884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.40016276004702545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.40013746751679313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.40026155169109046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.40025846509758484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.40046776524961814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.40048097426241097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4004223288723786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4003460673061577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.40039013372943005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.40070695070815937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4005959106816186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4004545243440476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4005474282781458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4004158452153206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4003718832434525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.40041563316531803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4004688967357982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.40048463103072396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.40034499726070355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4003278942953827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4004147454779199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40049548409247804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.40060894838868316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.400697558241732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4008389183916307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4008109163492918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.40073624278005227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4006608677797081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.40077236601354654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.40072618889026956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.40078735083949807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4007852433658228
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4007559430744001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.40078676840470684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4007656228350827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4009193044900894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4009408782202884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4008717176223558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4008459462949881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.40081070046725237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.40089067886857427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.400881742243655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.40078174047432985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.40080454818500105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4009725029173965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.40106187290870227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4009587885776242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.400945142025256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4009101121144603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4008219362885663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.40066859429737306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4007553181477955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.40067702409033473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.40063642877251354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4007115536906019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4006558296857057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4006804843670328
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.40057259118732286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.40053280587598084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.40041324855202304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.40027424920688975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4003758205883745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.40030826020326854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4001709669828415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.40033377210299176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4002572614167418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.40026814859108567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.40016809919624463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.40017125989860025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.40015037273856957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40026947364472504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4002005482887055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40021005013263183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4003224050005277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4004921706902527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.40062538179857976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4006658567186074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4006434536143525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.40062122377519316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4005914962007886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.40069960305246255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4006747991048001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.40077955303368745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4006453141470083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.40062573781380284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.400640138288339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4006629767409987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4005447927097611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4005165526969205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.40052353473086105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4003929335562909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.40037813509990966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40037787339198083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4002063428233196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.400328741008024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4004283950213463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4004456098056683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4004886469397789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.40051792423946025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.40038297671800965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.40038216558713763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4004001448614688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4004123828576566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4003468046210847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.40032727208257096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.40031949123367666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.40029897023212874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.40027409171835976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.40027986453044523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4002741191674162
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.40027895991618817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4002802808043416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.40033482037917556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.400334286162766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4002627421476196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.400226666078423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4003784464745363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.40026138893452035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.40032202685559476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.40032896497649345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.40038491638738716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.400340123811648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.40024372422376797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.40031907253364135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.40025471568459253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40045113493414486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.40038296772587684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4004912568986067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.40055204384876064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.400452371686697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4004507595214291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.40043986110673474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.40043819388669916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4004648369790494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4003964894822129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.40031494719641547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.40023727600391096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.40027984147044743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40038358084540865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.40024833448525876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4002818838811257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.40023985078160684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.40027964332190547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.400279624252346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4003195864742513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.40031475341982314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4002755010227087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.40043446446321285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4004552202612244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4004441320404902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.40055931553448715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.40055477317890836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.400524148661694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.40057643648722896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4006221473701601
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4006470767227379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.40066168587805445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.40062007283972156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4006050893832148
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.40060621037840205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.40052232233683266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4004926475438666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4005641077968739
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4005892520386075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4005619691670098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4005025355439437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40044820699791894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4004162379896454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4005004964360369
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40052403416484594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.40041831422161744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.40043661886237447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.40040635408049097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4004254964055474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4003621984110393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4003339802607512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.40031226524306684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4002553597852892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4003491916577628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4002170262451704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4001704554769057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4001692837536937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4000954974808681
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40011943330117805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.40009973267266025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4002274268120527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4001127290458156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.3999346481330359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.39983140209472506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.39980862665884564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.39978468403404144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.39973030712804186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.3996742725079417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.39961665423185216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.3996491791420869
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.3996580440823625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.39975925185094496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.39971557143822456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.3996761910274589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.3997666407466511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.3997082889798176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.3997493780289705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.39968415887521613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.399661650569245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.3997085124325354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.3996700747382073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.3997322063972718
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.39971054991557137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.39972171229673614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.39974213342340487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.3997381107947406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.39969448822205056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.39978569752996923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.3997332093732379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.39960700058159015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.3997358229271201
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.3997601685557177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.39978903697596657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.39963484994258397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.39965362524107306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.3995852429291298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.3996629497600258
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.39969061932247346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.39965402100184194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.39955579759319715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.3995590261437676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.3996032527785182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.39961491208270666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.3996968794084295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.3997209004319466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.39991069261947376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.3999224172846619
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.3998910151338684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.39998671918043066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.39998258992133534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.39997582448853386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.3999980139626632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4000092131637894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4000043828887392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.39999687284362473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.39993861880931225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.3999652569100522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.3999388304659261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.39998301700993916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4000121107678008
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.40003884337518525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.3999968103240214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.39995273096220835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.3999501004589814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.3999890584884019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4000199761441959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.40009757134535795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.40005977397557246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.3999896689485281
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.40002370014119504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40011720955371854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4000692459301837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.40016956096988615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.40016956096988615 valid 0.43180641531944275
LOSS train 0.40016956096988615 valid 0.43200284242630005
LOSS train 0.40016956096988615 valid 0.45322059591611225
LOSS train 0.40016956096988615 valid 0.45015546679496765
LOSS train 0.40016956096988615 valid 0.4468782305717468
LOSS train 0.40016956096988615 valid 0.45015356441338855
LOSS train 0.40016956096988615 valid 0.4511226713657379
LOSS train 0.40016956096988615 valid 0.4505937434732914
LOSS train 0.40016956096988615 valid 0.44429239961836076
LOSS train 0.40016956096988615 valid 0.44717698693275454
LOSS train 0.40016956096988615 valid 0.45076810771768744
LOSS train 0.40016956096988615 valid 0.4492690960566203
LOSS train 0.40016956096988615 valid 0.4515134829741258
LOSS train 0.40016956096988615 valid 0.451617568731308
LOSS train 0.40016956096988615 valid 0.45015992323557535
LOSS train 0.40016956096988615 valid 0.45219174586236477
LOSS train 0.40016956096988615 valid 0.4548509804641499
LOSS train 0.40016956096988615 valid 0.4559519605504142
LOSS train 0.40016956096988615 valid 0.4565999303993426
LOSS train 0.40016956096988615 valid 0.4583222970366478
LOSS train 0.40016956096988615 valid 0.45732264859335764
LOSS train 0.40016956096988615 valid 0.4543999054215171
LOSS train 0.40016956096988615 valid 0.45521890080493427
LOSS train 0.40016956096988615 valid 0.45370856920878094
LOSS train 0.40016956096988615 valid 0.4527105402946472
LOSS train 0.40016956096988615 valid 0.45213662202541643
LOSS train 0.40016956096988615 valid 0.45149509884693007
LOSS train 0.40016956096988615 valid 0.45222451112100054
LOSS train 0.40016956096988615 valid 0.45150490259302073
LOSS train 0.40016956096988615 valid 0.45230606297651926
LOSS train 0.40016956096988615 valid 0.45415705154019015
LOSS train 0.40016956096988615 valid 0.4541253689676523
LOSS train 0.40016956096988615 valid 0.4555257938124917
LOSS train 0.40016956096988615 valid 0.4547894526930416
LOSS train 0.40016956096988615 valid 0.45563242180006847
LOSS train 0.40016956096988615 valid 0.45580142653650707
LOSS train 0.40016956096988615 valid 0.4561792604021124
LOSS train 0.40016956096988615 valid 0.45741475177438634
LOSS train 0.40016956096988615 valid 0.4569706924450703
LOSS train 0.40016956096988615 valid 0.458452383428812
LOSS train 0.40016956096988615 valid 0.4583238188813372
LOSS train 0.40016956096988615 valid 0.4594307712146214
LOSS train 0.40016956096988615 valid 0.4594431852185449
LOSS train 0.40016956096988615 valid 0.45991756834767084
LOSS train 0.40016956096988615 valid 0.46008872985839844
LOSS train 0.40016956096988615 valid 0.4606061901735223
LOSS train 0.40016956096988615 valid 0.4598918810803839
LOSS train 0.40016956096988615 valid 0.46019528930385906
LOSS train 0.40016956096988615 valid 0.4607572330504048
LOSS train 0.40016956096988615 valid 0.46037205755710603
LOSS train 0.40016956096988615 valid 0.46099914113680523
LOSS train 0.40016956096988615 valid 0.46070205305631345
LOSS train 0.40016956096988615 valid 0.46013335461886423
LOSS train 0.40016956096988615 valid 0.4601406405369441
LOSS train 0.40016956096988615 valid 0.4596495167775588
LOSS train 0.40016956096988615 valid 0.4594031348824501
LOSS train 0.40016956096988615 valid 0.4592600313195011
LOSS train 0.40016956096988615 valid 0.4590632340003704
LOSS train 0.40016956096988615 valid 0.4597475346872362
LOSS train 0.40016956096988615 valid 0.4590979188680649
LOSS train 0.40016956096988615 valid 0.4579468760334077
LOSS train 0.40016956096988615 valid 0.459209866100742
LOSS train 0.40016956096988615 valid 0.45951780156483724
LOSS train 0.40016956096988615 valid 0.4600627305917442
LOSS train 0.40016956096988615 valid 0.46028341009066653
LOSS train 0.40016956096988615 valid 0.4602860234903567
LOSS train 0.40016956096988615 valid 0.45987805101408885
LOSS train 0.40016956096988615 valid 0.4592997142497231
LOSS train 0.40016956096988615 valid 0.4589296337487041
LOSS train 0.40016956096988615 valid 0.4584851631096431
LOSS train 0.40016956096988615 valid 0.45804959325723243
LOSS train 0.40016956096988615 valid 0.457804827640454
LOSS train 0.40016956096988615 valid 0.45817871983737163
LOSS train 0.40016956096988615 valid 0.45803531319708435
LOSS train 0.40016956096988615 valid 0.4574579119682312
LOSS train 0.40016956096988615 valid 0.45762487226410914
LOSS train 0.40016956096988615 valid 0.45739255477855734
LOSS train 0.40016956096988615 valid 0.45733964710663527
LOSS train 0.40016956096988615 valid 0.45704483759554126
LOSS train 0.40016956096988615 valid 0.4569792978465557
LOSS train 0.40016956096988615 valid 0.4564601731153182
LOSS train 0.40016956096988615 valid 0.4566846224592953
LOSS train 0.40016956096988615 valid 0.45646678539643804
LOSS train 0.40016956096988615 valid 0.4565477839538029
LOSS train 0.40016956096988615 valid 0.45665471834294935
LOSS train 0.40016956096988615 valid 0.45613871549451074
LOSS train 0.40016956096988615 valid 0.4557446227676567
LOSS train 0.40016956096988615 valid 0.455161566761407
LOSS train 0.40016956096988615 valid 0.4555577193753103
LOSS train 0.40016956096988615 valid 0.45554764370123546
LOSS train 0.40016956096988615 valid 0.45520437451509327
LOSS train 0.40016956096988615 valid 0.4547981862788615
LOSS train 0.40016956096988615 valid 0.45421970050822025
LOSS train 0.40016956096988615 valid 0.45345059417663736
LOSS train 0.40016956096988615 valid 0.45299123902069893
LOSS train 0.40016956096988615 valid 0.45331693223367137
LOSS train 0.40016956096988615 valid 0.45372422239215104
LOSS train 0.40016956096988615 valid 0.453672854267821
LOSS train 0.40016956096988615 valid 0.45393576886918807
LOSS train 0.40016956096988615 valid 0.4542920422554016
LOSS train 0.40016956096988615 valid 0.45442425909608897
LOSS train 0.40016956096988615 valid 0.4544689605633418
LOSS train 0.40016956096988615 valid 0.4550952526550848
LOSS train 0.40016956096988615 valid 0.4549131052425274
LOSS train 0.40016956096988615 valid 0.45492135598545985
LOSS train 0.40016956096988615 valid 0.45508428339688284
LOSS train 0.40016956096988615 valid 0.45477026283183947
LOSS train 0.40016956096988615 valid 0.4551732694661176
LOSS train 0.40016956096988615 valid 0.45532611805364626
LOSS train 0.40016956096988615 valid 0.4554229961200194
LOSS train 0.40016956096988615 valid 0.4555037655271925
LOSS train 0.40016956096988615 valid 0.4552933392780168
LOSS train 0.40016956096988615 valid 0.4552113437547093
LOSS train 0.40016956096988615 valid 0.4550067181127113
LOSS train 0.40016956096988615 valid 0.4550392000571541
LOSS train 0.40016956096988615 valid 0.455026775598526
LOSS train 0.40016956096988615 valid 0.4550784734579233
LOSS train 0.40016956096988615 valid 0.4548459320755328
LOSS train 0.40016956096988615 valid 0.45455248716498625
LOSS train 0.40016956096988615 valid 0.4544509706397851
LOSS train 0.40016956096988615 valid 0.4543076815191379
LOSS train 0.40016956096988615 valid 0.4542049074270686
LOSS train 0.40016956096988615 valid 0.4542918333677742
LOSS train 0.40016956096988615 valid 0.4546115492140093
LOSS train 0.40016956096988615 valid 0.4544728734493256
LOSS train 0.40016956096988615 valid 0.4543851531214184
LOSS train 0.40016956096988615 valid 0.45484302996650455
LOSS train 0.40016956096988615 valid 0.4549816974904388
LOSS train 0.40016956096988615 valid 0.4551501410414082
LOSS train 0.40016956096988615 valid 0.45488387392117424
LOSS train 0.40016956096988615 valid 0.4548624592427989
LOSS train 0.40016956096988615 valid 0.45480164592013217
LOSS train 0.40016956096988615 valid 0.4545975320769432
LOSS train 0.40016956096988615 valid 0.4547944200127872
LOSS train 0.40016956096988615 valid 0.4550230990957331
LOSS train 0.40016956096988615 valid 0.45510860203820114
LOSS train 0.40016956096988615 valid 0.45491327356248007
LOSS train 0.40016956096988615 valid 0.4547660707131676
LOSS train 0.40016956096988615 valid 0.45444397446062923
LOSS train 0.40016956096988615 valid 0.4546020228947912
LOSS train 0.40016956096988615 valid 0.4546444904296956
LOSS train 0.40016956096988615 valid 0.45493206717598605
LOSS train 0.40016956096988615 valid 0.45459800500136155
LOSS train 0.40016956096988615 valid 0.45461918289462727
LOSS train 0.40016956096988615 valid 0.4544260357988292
LOSS train 0.40016956096988615 valid 0.45477364814444765
LOSS train 0.40016956096988615 valid 0.4543459772252712
LOSS train 0.40016956096988615 valid 0.45477701602755366
LOSS train 0.40016956096988615 valid 0.4548547999970865
LOSS train 0.40016956096988615 valid 0.4549658209085464
LOSS train 0.40016956096988615 valid 0.45505873079331505
LOSS train 0.40016956096988615 valid 0.45478287986234617
LOSS train 0.40016956096988615 valid 0.4550515033450781
LOSS train 0.40016956096988615 valid 0.4550282157860793
LOSS train 0.40016956096988615 valid 0.45516660328834285
LOSS train 0.40016956096988615 valid 0.455496520950244
LOSS train 0.40016956096988615 valid 0.4553846699796664
LOSS train 0.40016956096988615 valid 0.4553252750936943
LOSS train 0.40016956096988615 valid 0.4550257480744296
LOSS train 0.40016956096988615 valid 0.4550520543009043
LOSS train 0.40016956096988615 valid 0.4548906706134725
LOSS train 0.40016956096988615 valid 0.45450116712370037
LOSS train 0.40016956096988615 valid 0.4544287078951034
LOSS train 0.40016956096988615 valid 0.4542766529612425
LOSS train 0.40016956096988615 valid 0.4541353901227315
LOSS train 0.40016956096988615 valid 0.45395255735121576
LOSS train 0.40016956096988615 valid 0.4540385404032861
LOSS train 0.40016956096988615 valid 0.4542481235805012
LOSS train 0.40016956096988615 valid 0.4544050090411711
LOSS train 0.40016956096988615 valid 0.4548735804417554
LOSS train 0.40016956096988615 valid 0.45474764408423884
LOSS train 0.40016956096988615 valid 0.4547850153473921
LOSS train 0.40016956096988615 valid 0.4549125086709943
LOSS train 0.40016956096988615 valid 0.45490517355929844
LOSS train 0.40016956096988615 valid 0.4549999063355582
LOSS train 0.40016956096988615 valid 0.45487758788195526
LOSS train 0.40016956096988615 valid 0.45523606552242557
LOSS train 0.40016956096988615 valid 0.4554493606425403
LOSS train 0.40016956096988615 valid 0.4552901705217095
LOSS train 0.40016956096988615 valid 0.4553464757071601
LOSS train 0.40016956096988615 valid 0.4553276578695076
LOSS train 0.40016956096988615 valid 0.4554506928383649
LOSS train 0.40016956096988615 valid 0.4553339733777802
LOSS train 0.40016956096988615 valid 0.4555621957001479
LOSS train 0.40016956096988615 valid 0.45549500439618085
LOSS train 0.40016956096988615 valid 0.45558978649236825
LOSS train 0.40016956096988615 valid 0.45561852812129544
LOSS train 0.40016956096988615 valid 0.45560213542999106
LOSS train 0.40016956096988615 valid 0.4555218401093962
LOSS train 0.40016956096988615 valid 0.45535743503194104
LOSS train 0.40016956096988615 valid 0.4556295554987423
LOSS train 0.40016956096988615 valid 0.45573639512682956
LOSS train 0.40016956096988615 valid 0.455602447912483
LOSS train 0.40016956096988615 valid 0.45542068272521813
LOSS train 0.40016956096988615 valid 0.4554001728693644
LOSS train 0.40016956096988615 valid 0.45551372790823175
LOSS train 0.40016956096988615 valid 0.45580485448014313
LOSS train 0.40016956096988615 valid 0.4558359103070365
LOSS train 0.40016956096988615 valid 0.45587897720049375
LOSS train 0.40016956096988615 valid 0.4558065739274025
LOSS train 0.40016956096988615 valid 0.45550614150602425
LOSS train 0.40016956096988615 valid 0.4556709342073686
LOSS train 0.40016956096988615 valid 0.4555000040331498
LOSS train 0.40016956096988615 valid 0.45552049942460715
LOSS train 0.40016956096988615 valid 0.4555087448620215
LOSS train 0.40016956096988615 valid 0.4552869767818636
LOSS train 0.40016956096988615 valid 0.45552909489415117
LOSS train 0.40016956096988615 valid 0.45553041994571686
LOSS train 0.40016956096988615 valid 0.45540515486703537
LOSS train 0.40016956096988615 valid 0.45553414367494127
LOSS train 0.40016956096988615 valid 0.45559118455055203
LOSS train 0.40016956096988615 valid 0.45565600074687096
LOSS train 0.40016956096988615 valid 0.4556942081227549
LOSS train 0.40016956096988615 valid 0.4556559686348817
LOSS train 0.40016956096988615 valid 0.4556810758834661
LOSS train 0.40016956096988615 valid 0.455730725493696
LOSS train 0.40016956096988615 valid 0.45578547831504573
LOSS train 0.40016956096988615 valid 0.4558963566471677
LOSS train 0.40016956096988615 valid 0.4558790158735563
LOSS train 0.40016956096988615 valid 0.4560741883787242
LOSS train 0.40016956096988615 valid 0.45628825531286354
LOSS train 0.40016956096988615 valid 0.4562774896621704
LOSS train 0.40016956096988615 valid 0.4563097555541137
LOSS train 0.40016956096988615 valid 0.45635882924710003
LOSS train 0.40016956096988615 valid 0.4564021199279361
LOSS train 0.40016956096988615 valid 0.4563844366147455
LOSS train 0.40016956096988615 valid 0.4564587624850252
LOSS train 0.40016956096988615 valid 0.45642373031168654
LOSS train 0.40016956096988615 valid 0.45654003523843256
LOSS train 0.40016956096988615 valid 0.4566673385060352
LOSS train 0.40016956096988615 valid 0.45675205255483653
LOSS train 0.40016956096988615 valid 0.456802972174924
LOSS train 0.40016956096988615 valid 0.456711716917963
LOSS train 0.40016956096988615 valid 0.45665355981924594
LOSS train 0.40016956096988615 valid 0.45684310121739163
LOSS train 0.40016956096988615 valid 0.45672410878084474
LOSS train 0.40016956096988615 valid 0.45661949105403593
LOSS train 0.40016956096988615 valid 0.45657802166558115
LOSS train 0.40016956096988615 valid 0.4564103189871401
LOSS train 0.40016956096988615 valid 0.4562565088272095
LOSS train 0.40016956096988615 valid 0.4565230432387704
LOSS train 0.40016956096988615 valid 0.45641912138166507
LOSS train 0.40016956096988615 valid 0.4563620441244463
LOSS train 0.40016956096988615 valid 0.45648171093131673
LOSS train 0.40016956096988615 valid 0.45650039084103644
LOSS train 0.40016956096988615 valid 0.4564878281539049
LOSS train 0.40016956096988615 valid 0.45655125017590853
LOSS train 0.40016956096988615 valid 0.4565136632130992
LOSS train 0.40016956096988615 valid 0.4565403315436888
LOSS train 0.40016956096988615 valid 0.45680813908576967
LOSS train 0.40016956096988615 valid 0.45688322079609117
LOSS train 0.40016956096988615 valid 0.4571477494069508
LOSS train 0.40016956096988615 valid 0.4570034251147108
LOSS train 0.40016956096988615 valid 0.4572027298643833
LOSS train 0.40016956096988615 valid 0.4572154460000057
LOSS train 0.40016956096988615 valid 0.4571741835679859
LOSS train 0.40016956096988615 valid 0.45716739988048716
LOSS train 0.40016956096988615 valid 0.4572068303823471
LOSS train 0.40016956096988615 valid 0.4571838985308717
LOSS train 0.40016956096988615 valid 0.4570342789475734
LOSS train 0.40016956096988615 valid 0.45706753290019275
LOSS train 0.40016956096988615 valid 0.4569949204002628
LOSS train 0.40016956096988615 valid 0.45693559689666835
LOSS train 0.40016956096988615 valid 0.45685488798401575
LOSS train 0.40016956096988615 valid 0.456843737836154
LOSS train 0.40016956096988615 valid 0.4569912021769617
LOSS train 0.40016956096988615 valid 0.45718562000253227
LOSS train 0.40016956096988615 valid 0.45733351382746623
LOSS train 0.40016956096988615 valid 0.4575774840262743
LOSS train 0.40016956096988615 valid 0.45750198596053654
LOSS train 0.40016956096988615 valid 0.45762684567388134
LOSS train 0.40016956096988615 valid 0.45772656853146415
LOSS train 0.40016956096988615 valid 0.4577616049256517
LOSS train 0.40016956096988615 valid 0.4577810956831396
LOSS train 0.40016956096988615 valid 0.45769705284725537
LOSS train 0.40016956096988615 valid 0.45767574584570486
LOSS train 0.40016956096988615 valid 0.45776651224074383
LOSS train 0.40016956096988615 valid 0.4577111020791445
LOSS train 0.40016956096988615 valid 0.45778607574415037
LOSS train 0.40016956096988615 valid 0.45764991800699917
LOSS train 0.40016956096988615 valid 0.4574676643911206
LOSS train 0.40016956096988615 valid 0.4574319033335287
LOSS train 0.40016956096988615 valid 0.4574466718380527
LOSS train 0.40016956096988615 valid 0.4574995865704308
LOSS train 0.40016956096988615 valid 0.45744492390699554
LOSS train 0.40016956096988615 valid 0.4573058698560808
LOSS train 0.40016956096988615 valid 0.45734333452032006
LOSS train 0.40016956096988615 valid 0.45726328115496373
LOSS train 0.40016956096988615 valid 0.4573670558657201
LOSS train 0.40016956096988615 valid 0.45738274383133853
LOSS train 0.40016956096988615 valid 0.4572213385318153
LOSS train 0.40016956096988615 valid 0.457263390699478
LOSS train 0.40016956096988615 valid 0.4571282898199843
LOSS train 0.40016956096988615 valid 0.4571931744311132
LOSS train 0.40016956096988615 valid 0.45736481911045007
LOSS train 0.40016956096988615 valid 0.45728958408172066
LOSS train 0.40016956096988615 valid 0.457320610180447
LOSS train 0.40016956096988615 valid 0.45719218974145465
LOSS train 0.40016956096988615 valid 0.4572860618498812
LOSS train 0.40016956096988615 valid 0.45729714413483935
LOSS train 0.40016956096988615 valid 0.4573011047816356
LOSS train 0.40016956096988615 valid 0.4571636741524501
LOSS train 0.40016956096988615 valid 0.45709454983767894
LOSS train 0.40016956096988615 valid 0.4571531996327011
LOSS train 0.40016956096988615 valid 0.45711761840054244
LOSS train 0.40016956096988615 valid 0.4571388058997447
LOSS train 0.40016956096988615 valid 0.45711070367101736
LOSS train 0.40016956096988615 valid 0.4570099249869198
LOSS train 0.40016956096988615 valid 0.4570214404064475
LOSS train 0.40016956096988615 valid 0.4570443388915831
LOSS train 0.40016956096988615 valid 0.45703275113627073
LOSS train 0.40016956096988615 valid 0.45704644832473534
LOSS train 0.40016956096988615 valid 0.4571560511764246
LOSS train 0.40016956096988615 valid 0.4571130119121758
LOSS train 0.40016956096988615 valid 0.45708804915821744
LOSS train 0.40016956096988615 valid 0.4569746732145925
LOSS train 0.40016956096988615 valid 0.45700968731465025
LOSS train 0.40016956096988615 valid 0.45701363111067117
LOSS train 0.40016956096988615 valid 0.4570271338228148
LOSS train 0.40016956096988615 valid 0.4569885041564703
LOSS train 0.40016956096988615 valid 0.4569925599009077
LOSS train 0.40016956096988615 valid 0.4570137894486789
LOSS train 0.40016956096988615 valid 0.4570077006292786
LOSS train 0.40016956096988615 valid 0.4569811215739191
LOSS train 0.40016956096988615 valid 0.456920689527805
LOSS train 0.40016956096988615 valid 0.457014892273154
LOSS train 0.40016956096988615 valid 0.4571737722701618
LOSS train 0.40016956096988615 valid 0.4571445514334411
LOSS train 0.40016956096988615 valid 0.45717523724837145
LOSS train 0.40016956096988615 valid 0.4571252607938015
LOSS train 0.40016956096988615 valid 0.45707674509088797
LOSS train 0.40016956096988615 valid 0.45694872934416114
LOSS train 0.40016956096988615 valid 0.4569927373447934
LOSS train 0.40016956096988615 valid 0.45704427272259834
LOSS train 0.40016956096988615 valid 0.4570548571757416
LOSS train 0.40016956096988615 valid 0.4570044664045175
LOSS train 0.40016956096988615 valid 0.4570119634757056
LOSS train 0.40016956096988615 valid 0.4570424857400578
LOSS train 0.40016956096988615 valid 0.45697994174155515
LOSS train 0.40016956096988615 valid 0.45702443692614053
LOSS train 0.40016956096988615 valid 0.4568814165081796
LOSS train 0.40016956096988615 valid 0.45671758979384663
LOSS train 0.40016956096988615 valid 0.4567207303061082
LOSS train 0.40016956096988615 valid 0.45693305827850517
LOSS train 0.40016956096988615 valid 0.456998602549235
LOSS train 0.40016956096988615 valid 0.4569936961452396
LOSS train 0.40016956096988615 valid 0.4569292157802527
LOSS train 0.40016956096988615 valid 0.45680646033122624
LOSS train 0.40016956096988615 valid 0.45683793360660957
LOSS train 0.40016956096988615 valid 0.45670696709837233
LOSS train 0.40016956096988615 valid 0.45664296929652876
LOSS train 0.40016956096988615 valid 0.456678322177719
LOSS train 0.40016956096988615 valid 0.45671122472617176
LOSS train 0.40016956096988615 valid 0.4567554625077436
LOSS train 0.40016956096988615 valid 0.4567691614930059
LOSS train 0.40016956096988615 valid 0.45676521437891415
LOSS train 0.40016956096988615 valid 0.456699645986744
LOSS train 0.40016956096988615 valid 0.4566200801780104
LOSS train 0.40016956096988615 valid 0.45666512440174073
LOSS train 0.40016956096988615 valid 0.4566890004608366
LOSS train 0.40016956096988615 valid 0.45672124161944827
LOSS train 0.40016956096988615 valid 0.45687860711503425
LOSS train 0.40016956096988615 valid 0.456803087689003
LOSS train 0.40016956096988615 valid 0.4567431717456042
LOSS train 0.40016956096988615 valid 0.4567940975705238
LOSS train 0.40016956096988615 valid 0.4567387482670487
LOSS train 0.40016956096988615 valid 0.45665436958746947
LOSS train 0.40016956096988615 valid 0.45666025635664875
LOSS train 0.40016956096988615 valid 0.4566494830578646
EPOCH 13:
  batch 1 loss: 0.3628772497177124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.3839229345321655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.3955356478691101
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.40133136510849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4034638822078705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4051935027043025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4005881590502603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.40559349581599236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.40522685647010803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.40400385558605195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4023566950451244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.40175163249174756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.3993837306132683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.39783623601709095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.39942985971768696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4003135096281767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.39970556252142964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.39971984591748977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.3998621498283587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.3990527391433716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.3983936735561916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.39842125231569464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.3999821310457976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40107902387777966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.40154505014419556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4032703087880061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4035779822755743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.40299624523946215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4038617066268263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4033301422993342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4039036968062001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.40401509683579206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4037657181421916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4039565359844881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4041949680873326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.40397530794143677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.40364555088249415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4035667651578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.40430248929904056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4046682119369507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4046785809644839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.40401631948493777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.40483014181602833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4042769501155073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4045609202649858
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.40377888407396234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4037595784410517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.40361183136701584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4036122852442216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.40382699728012084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.40366414014030905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.40357326773496777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4036304489621576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4032124220221131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4030507391149348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4032383662249361
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.40385237963576065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.40306973662869683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4035056728427693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4034282257159551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.40291776422594416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4027903882726546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4027752691791171
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.40332726016640663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4034316603954022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4034672803951032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4030479068186746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.40295289719806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4032271919043168
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4036156943866185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4036280374291917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40324301396807033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.40315482346978904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4031310166056092
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.402830003897349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.40320854673260137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.40339335760512907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.40313386420408887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40329146196570576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4034299701452255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4036795073821221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40362214678671304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4033971827432334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.40331194620756877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4034111377070932
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.40344681019006773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4032486451083216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.40350267561999237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.40328680732277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4035141395197974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.40308174589178064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.40309640084919723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4033258653456165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.40334845159916166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.40302758467824834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4033996316914757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.40305066385220006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.40358188322612215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.40367020501030815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.40389068484306334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.40362606249233285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4036809176790948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4039929104082793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4037478735240606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.403742374976476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.40362297757616583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4038277870026704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4040159384409587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4039550188484542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.404472721435807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.40424585100766774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.40414916670748163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.40378027574150965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.40372204937432943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.40329200107118357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.40311374720828286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4030734532409244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4029449378534899
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40270110664247466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4027854554355145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4024586044559794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.40238812101668997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.40295491446324483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4029568842341823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4030234637260437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.40292106568813324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4027606690023828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4029555784072727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4030686231084572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4029346947486584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4027611617823593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.40260236416802264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.40265170299917236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.40259208519067335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.40246058525862516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4025203136398512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4026569426059723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.40253481355266296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.40285031679722905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.40292699762753076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4024963784725108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4024810950521012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.40286296147566575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4030924058622784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.40317945583113307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4031572001029367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.40309949634837455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4032134216379475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4032815962829846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4032555687427521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.40339835669031204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4032449800717203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4030958649769328
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.40282291696443184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4029343854996466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4029603168750421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.40301311243871213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4028391081698333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4031246077714476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4030374180525541
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.40278019908792484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4026461837836254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4027959384435525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.40251854280146154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.40240855289228034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4023601603077119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.40204584455775644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.40197711029932615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4019144066339414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4019141542560914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.40199770094358434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4018342049662457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4016003925676291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.40164911592828817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4015919368607657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4014326120642098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4012711428653049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4010843041907535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4011981267502854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4010058853361342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.40103393085095107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.40113446984317275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.40103982527399323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4010321974106457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.40109624524374266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4009860271728167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4007757240756948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.40052818824002084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.40045904419409534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4005256706162503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.40054986661017256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.40049253233398
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4003953407156653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4003483533244772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4003528882295657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.40040034466252034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.40053328735574245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.40096670253710315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4009149991088177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4008871519565582
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.40085897932005166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4008120035771096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.40097540249965463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.40093474601413687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4008858330366088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4008594622600426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4010060949314044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.40077917292140997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4007610771359439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4007732212543488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.40074913804000023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4008113812163191
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4006417066278592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4004692655300426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4003379109293915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.40029400283539734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4003625885682172
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4003626261282405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.40054076773935254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.40062510723417455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.40053321765019345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4004504953150277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4004695510383144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.40079576681767193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4006581955485874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4005290546775919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.40062488543304575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.40050913445782244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.40050424173409244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4005541836437972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4006439012624485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4006396687493242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.40046721837551297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.40049489542969274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4006118300113272
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40072647772603115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4009148508687563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.400959987224651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4010473441129948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4010083728780349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4009281568754758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4008409638296474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4009983881756111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4009278034333323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4010341526294241
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4010727294092256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.40107607407125867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.40113668263919894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4011204460538535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.40125671243667604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4012206742962993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4012071089375587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.40115196667169867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4011095720013296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4011726337320664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.40114113688468933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4010631922154111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.40112651549568473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.40132809951038434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4014540338745484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4013715394383646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.40132305082929043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.401250360696488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.40117250800584303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.40105717710728916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.40116274648142936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.40115525492568144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.40115294171803034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40117874054660585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4011466413736343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4011728474354832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.40103866094175505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4010635290172074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.40091313987317745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.40075475400144406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.40090792906889017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4008425397778246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.40071936637806377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4008254225108786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.40077637646879466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4007429889936888
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.40064023995230386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4006440801671032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.40058540143597293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40068290442751164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.40061238970789875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.4006151477011239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.40069449599832296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.400866553032687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4009542814616499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.40098273446879434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40098740303353086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.40100075055307904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4009971209123832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.40108512650101874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4010575343225453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4012030973177566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4010723247224052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4010497878825784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4010746857523918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4011098230597981
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4009888614250335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.40098752578099567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.40098194728948566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4008566378569994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.40083986179890974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40083066211461243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.40064059304339544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4008093160911671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4008984568618959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.40094017244611907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4009295575893842
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.40095072356275857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.40083018068675025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4008067640047225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.40082124573520467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4008009663139608
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.40071858034568764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.40069677211274174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.40064650820568204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.40063412492148975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.40058048717353656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4006037561701547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4005377486716082
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4005363425841698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.40052497277230575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.400571190891645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4006008892887976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4005026830003617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4004701037298549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4005654704534755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.40044709025736314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.40051411320497327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4005147572941409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4005641334982061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.40053007503350574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4004164481375267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.40051276417526266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4004546886524268
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.40062461670707256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.40054842978278915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4006760030636313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.40073206447303816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4006423440783523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.40067581456640494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4006252613543086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4006856301160642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.40069550798199643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.40063837973299543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4005759804589408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.40049354116461555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4005164388905872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40061495324369867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4004923596894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.40052811394275073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4005182183692964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4005294493934354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.40049292305328327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.40056088126801515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4005806037949191
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.40054965952096555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4006728730807647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.40067363877270173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4006690547525228
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4007949475556204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.40076963627924683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4007563269430675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4008157049994106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.40084484736447734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4008774278131691
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.40090714672183736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4008706594987582
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.40086083070202744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4008623092251028
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4008320307731628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.400795902581291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4008270354264611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.40086882857103195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4008411770602959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4007897078206665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40075165260182277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4007381120433358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4008231159912388
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40085844369605184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.40076523686384224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4007978736582198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4007753694396302
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.40077660486255723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4007030607495639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4006501893202464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.40060268780764413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.40052194064673113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4006002217000374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4004785684764688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4004248952563805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.40042226242296625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4003445040669189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.4003752994177929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.40038027672241805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.40051702968776226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.40040395956978836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4002152135716149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4001065253028207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4000716174740602
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4000971883167455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.40009115019748953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.40000752830095315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.39992251502824766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.3999430160504973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.3999381777716846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.40003936141366797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.39997440540385476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.3999263582881946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.3999923001884838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.39993853016072006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.39999799981999856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.39992232638583197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.3998870800414154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.39992975968165156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.3998865966285978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.39993203564097934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.39991406969267046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.3999241729295564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.39995330972772725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.3999470943563125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.399915530508113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.3999954871048134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.3999272077997154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.39980458073960595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.39992722744165465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.3999814593045175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.40001770074444787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.3998406704936787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.39985681012753516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.3997901040247117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.39984569015032656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.3998610504841095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.39979843421069455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.39971652986791517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.3997197117995132
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.39974565631678316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.399775543363925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.399852070730373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.39987537150715924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.400095805894123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.40009754308136053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4000513858976513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.40013316267036964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.40011703211374433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4001349361737569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4001384434969621
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4001523356522079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.40014844165732527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.40015774971850643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4000741274802239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4000988386963543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.40007393874016056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4001193914611267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4001551506825782
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4001638969649439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.40012891121903627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.40010956349052906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4000989163282366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4001083541661501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.400168744402547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.40025225595087455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.40022609256830155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4001493960873693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4001771646267824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40023491991327165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4001592874780076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.40029935305148867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.40029935305148867 valid 0.4370275139808655
LOSS train 0.40029935305148867 valid 0.4375538229942322
LOSS train 0.40029935305148867 valid 0.4588908354441325
LOSS train 0.40029935305148867 valid 0.45564985275268555
LOSS train 0.40029935305148867 valid 0.45232245326042175
LOSS train 0.40029935305148867 valid 0.4556727359692256
LOSS train 0.40029935305148867 valid 0.45687833428382874
LOSS train 0.40029935305148867 valid 0.45634031668305397
LOSS train 0.40029935305148867 valid 0.45001247856352067
LOSS train 0.40029935305148867 valid 0.45285764932632444
LOSS train 0.40029935305148867 valid 0.4564946781505238
LOSS train 0.40029935305148867 valid 0.45503508547941846
LOSS train 0.40029935305148867 valid 0.4572960275870103
LOSS train 0.40029935305148867 valid 0.4573892993586404
LOSS train 0.40029935305148867 valid 0.45594940582911175
LOSS train 0.40029935305148867 valid 0.4579638224095106
LOSS train 0.40029935305148867 valid 0.4606501828221714
LOSS train 0.40029935305148867 valid 0.4617743690808614
LOSS train 0.40029935305148867 valid 0.46239243683062103
LOSS train 0.40029935305148867 valid 0.46409757882356645
LOSS train 0.40029935305148867 valid 0.46312294829459416
LOSS train 0.40029935305148867 valid 0.4601900997486981
LOSS train 0.40029935305148867 valid 0.46104019232418225
LOSS train 0.40029935305148867 valid 0.45952943339943886
LOSS train 0.40029935305148867 valid 0.45852519154548643
LOSS train 0.40029935305148867 valid 0.4579529727880771
LOSS train 0.40029935305148867 valid 0.4573060991587462
LOSS train 0.40029935305148867 valid 0.4580328432576997
LOSS train 0.40029935305148867 valid 0.45728352460367927
LOSS train 0.40029935305148867 valid 0.45807358920574187
LOSS train 0.40029935305148867 valid 0.45993257626410455
LOSS train 0.40029935305148867 valid 0.45991168078035116
LOSS train 0.40029935305148867 valid 0.46133716088352783
LOSS train 0.40029935305148867 valid 0.4605840751353432
LOSS train 0.40029935305148867 valid 0.46144346594810487
LOSS train 0.40029935305148867 valid 0.461627334356308
LOSS train 0.40029935305148867 valid 0.4619866883432543
LOSS train 0.40029935305148867 valid 0.4632456914374703
LOSS train 0.40029935305148867 valid 0.46280285945305455
LOSS train 0.40029935305148867 valid 0.46427060663700104
LOSS train 0.40029935305148867 valid 0.4641372481497323
LOSS train 0.40029935305148867 valid 0.46524536538691746
LOSS train 0.40029935305148867 valid 0.46525315004725787
LOSS train 0.40029935305148867 valid 0.46575285629792645
LOSS train 0.40029935305148867 valid 0.46595317324002583
LOSS train 0.40029935305148867 valid 0.46647545112215955
LOSS train 0.40029935305148867 valid 0.4657358539865372
LOSS train 0.40029935305148867 valid 0.4660152221719424
LOSS train 0.40029935305148867 valid 0.4665951193595419
LOSS train 0.40029935305148867 valid 0.46621273159980775
LOSS train 0.40029935305148867 valid 0.4668387922586179
LOSS train 0.40029935305148867 valid 0.4665443404362752
LOSS train 0.40029935305148867 valid 0.4659763349677032
LOSS train 0.40029935305148867 valid 0.4659712789235292
LOSS train 0.40029935305148867 valid 0.46547733545303344
LOSS train 0.40029935305148867 valid 0.46522258328539984
LOSS train 0.40029935305148867 valid 0.4650794147399434
LOSS train 0.40029935305148867 valid 0.4648893388180897
LOSS train 0.40029935305148867 valid 0.4655779433452477
LOSS train 0.40029935305148867 valid 0.4649154270688693
LOSS train 0.40029935305148867 valid 0.4637631935174348
LOSS train 0.40029935305148867 valid 0.4650199158537772
LOSS train 0.40029935305148867 valid 0.4653317705979423
LOSS train 0.40029935305148867 valid 0.4658808405511081
LOSS train 0.40029935305148867 valid 0.46610369361363924
LOSS train 0.40029935305148867 valid 0.4660957392418023
LOSS train 0.40029935305148867 valid 0.4656997154008097
LOSS train 0.40029935305148867 valid 0.46512114037485686
LOSS train 0.40029935305148867 valid 0.46473687628041144
LOSS train 0.40029935305148867 valid 0.46429490872791834
LOSS train 0.40029935305148867 valid 0.46384345267859983
LOSS train 0.40029935305148867 valid 0.4635912606285678
LOSS train 0.40029935305148867 valid 0.46398229100932814
LOSS train 0.40029935305148867 valid 0.46383592889115616
LOSS train 0.40029935305148867 valid 0.463271195491155
LOSS train 0.40029935305148867 valid 0.4634413401547231
LOSS train 0.40029935305148867 valid 0.4632077832500656
LOSS train 0.40029935305148867 valid 0.46315938501785964
LOSS train 0.40029935305148867 valid 0.46285605619225323
LOSS train 0.40029935305148867 valid 0.4627967294305563
LOSS train 0.40029935305148867 valid 0.46226784586906433
LOSS train 0.40029935305148867 valid 0.46248367247058125
LOSS train 0.40029935305148867 valid 0.4622685553797756
LOSS train 0.40029935305148867 valid 0.4623531990108036
LOSS train 0.40029935305148867 valid 0.46246270011453067
LOSS train 0.40029935305148867 valid 0.4619319494380507
LOSS train 0.40029935305148867 valid 0.4615256615068721
LOSS train 0.40029935305148867 valid 0.4609426232901486
LOSS train 0.40029935305148867 valid 0.46133769763989396
LOSS train 0.40029935305148867 valid 0.4613430692089929
LOSS train 0.40029935305148867 valid 0.4609887128347879
LOSS train 0.40029935305148867 valid 0.4605814856679543
LOSS train 0.40029935305148867 valid 0.4600089484004564
LOSS train 0.40029935305148867 valid 0.4592296950360562
LOSS train 0.40029935305148867 valid 0.4587601900100708
LOSS train 0.40029935305148867 valid 0.4590872296442588
LOSS train 0.40029935305148867 valid 0.459498039840423
LOSS train 0.40029935305148867 valid 0.4594391870255373
LOSS train 0.40029935305148867 valid 0.4597052242418732
LOSS train 0.40029935305148867 valid 0.4600691565871239
LOSS train 0.40029935305148867 valid 0.46019712060984996
LOSS train 0.40029935305148867 valid 0.46024378140767414
LOSS train 0.40029935305148867 valid 0.4608753769143114
LOSS train 0.40029935305148867 valid 0.4606986762239383
LOSS train 0.40029935305148867 valid 0.4607065759953998
LOSS train 0.40029935305148867 valid 0.46087853554284797
LOSS train 0.40029935305148867 valid 0.46056529545338354
LOSS train 0.40029935305148867 valid 0.46096027421730534
LOSS train 0.40029935305148867 valid 0.4611181715212831
LOSS train 0.40029935305148867 valid 0.4612079322338104
LOSS train 0.40029935305148867 valid 0.46128905732352454
LOSS train 0.40029935305148867 valid 0.46106787238802227
LOSS train 0.40029935305148867 valid 0.4609820159663141
LOSS train 0.40029935305148867 valid 0.4607732162663811
LOSS train 0.40029935305148867 valid 0.460811782401541
LOSS train 0.40029935305148867 valid 0.46080458652356576
LOSS train 0.40029935305148867 valid 0.46085336804389954
LOSS train 0.40029935305148867 valid 0.4606131421307386
LOSS train 0.40029935305148867 valid 0.46031370633790475
LOSS train 0.40029935305148867 valid 0.46021792689959207
LOSS train 0.40029935305148867 valid 0.46007904287212154
LOSS train 0.40029935305148867 valid 0.4599818831584493
LOSS train 0.40029935305148867 valid 0.4600659041869931
LOSS train 0.40029935305148867 valid 0.4603867158293724
LOSS train 0.40029935305148867 valid 0.46024551153182985
LOSS train 0.40029935305148867 valid 0.46016643775833976
LOSS train 0.40029935305148867 valid 0.46062653412030435
LOSS train 0.40029935305148867 valid 0.46076714573428035
LOSS train 0.40029935305148867 valid 0.4609371576198312
LOSS train 0.40029935305148867 valid 0.46066599648732404
LOSS train 0.40029935305148867 valid 0.46064145169185317
LOSS train 0.40029935305148867 valid 0.46057485540707904
LOSS train 0.40029935305148867 valid 0.46036484658269955
LOSS train 0.40029935305148867 valid 0.4605595015767795
LOSS train 0.40029935305148867 valid 0.4607947345133181
LOSS train 0.40029935305148867 valid 0.4608894527396735
LOSS train 0.40029935305148867 valid 0.46069370025265827
LOSS train 0.40029935305148867 valid 0.4605422397886497
LOSS train 0.40029935305148867 valid 0.46021503403032427
LOSS train 0.40029935305148867 valid 0.4603694775274822
LOSS train 0.40029935305148867 valid 0.46041222075198557
LOSS train 0.40029935305148867 valid 0.4606983913502223
LOSS train 0.40029935305148867 valid 0.46036811808606126
LOSS train 0.40029935305148867 valid 0.4603839090300931
LOSS train 0.40029935305148867 valid 0.4601864004957265
LOSS train 0.40029935305148867 valid 0.460532935106591
LOSS train 0.40029935305148867 valid 0.4601059243792579
LOSS train 0.40029935305148867 valid 0.4605440030226836
LOSS train 0.40029935305148867 valid 0.46061896977808653
LOSS train 0.40029935305148867 valid 0.46073708494504295
LOSS train 0.40029935305148867 valid 0.4608368721624084
LOSS train 0.40029935305148867 valid 0.4605527267252144
LOSS train 0.40029935305148867 valid 0.4608237484311746
LOSS train 0.40029935305148867 valid 0.460796959794961
LOSS train 0.40029935305148867 valid 0.460939105672221
LOSS train 0.40029935305148867 valid 0.4612642326034032
LOSS train 0.40029935305148867 valid 0.46114925726963457
LOSS train 0.40029935305148867 valid 0.4610835998495923
LOSS train 0.40029935305148867 valid 0.4607833183411532
LOSS train 0.40029935305148867 valid 0.46080869529396296
LOSS train 0.40029935305148867 valid 0.46065374727574937
LOSS train 0.40029935305148867 valid 0.46026557555169234
LOSS train 0.40029935305148867 valid 0.4601883242832371
LOSS train 0.40029935305148867 valid 0.4600342085085264
LOSS train 0.40029935305148867 valid 0.45988668582656167
LOSS train 0.40029935305148867 valid 0.4597012942813965
LOSS train 0.40029935305148867 valid 0.4597914900608405
LOSS train 0.40029935305148867 valid 0.4600047635890189
LOSS train 0.40029935305148867 valid 0.46016320956529244
LOSS train 0.40029935305148867 valid 0.4606321005260243
LOSS train 0.40029935305148867 valid 0.4605058384569068
LOSS train 0.40029935305148867 valid 0.46053968664518624
LOSS train 0.40029935305148867 valid 0.4606687559213252
LOSS train 0.40029935305148867 valid 0.4606609702452846
LOSS train 0.40029935305148867 valid 0.4607577642372676
LOSS train 0.40029935305148867 valid 0.46063922633501614
LOSS train 0.40029935305148867 valid 0.4610028655852302
LOSS train 0.40029935305148867 valid 0.4612168164065715
LOSS train 0.40029935305148867 valid 0.46105475915210875
LOSS train 0.40029935305148867 valid 0.46110539535681405
LOSS train 0.40029935305148867 valid 0.46108268687079623
LOSS train 0.40029935305148867 valid 0.46120468453391567
LOSS train 0.40029935305148867 valid 0.4610881106775315
LOSS train 0.40029935305148867 valid 0.4613172847615636
LOSS train 0.40029935305148867 valid 0.46125410811321155
LOSS train 0.40029935305148867 valid 0.46135186283819135
LOSS train 0.40029935305148867 valid 0.46137922428508493
LOSS train 0.40029935305148867 valid 0.4613637166454437
LOSS train 0.40029935305148867 valid 0.4612834992862883
LOSS train 0.40029935305148867 valid 0.4611184837002503
LOSS train 0.40029935305148867 valid 0.4613919880689751
LOSS train 0.40029935305148867 valid 0.4614989293428759
LOSS train 0.40029935305148867 valid 0.4613636190100655
LOSS train 0.40029935305148867 valid 0.461183705587977
LOSS train 0.40029935305148867 valid 0.46116287280351687
LOSS train 0.40029935305148867 valid 0.46128089178581627
LOSS train 0.40029935305148867 valid 0.46157828623873326
LOSS train 0.40029935305148867 valid 0.4616072743830055
LOSS train 0.40029935305148867 valid 0.4616508298183805
LOSS train 0.40029935305148867 valid 0.46157735466957095
LOSS train 0.40029935305148867 valid 0.4612712652529057
LOSS train 0.40029935305148867 valid 0.46143833879787144
LOSS train 0.40029935305148867 valid 0.4612687506111972
LOSS train 0.40029935305148867 valid 0.46129392715645773
LOSS train 0.40029935305148867 valid 0.46128098441333304
LOSS train 0.40029935305148867 valid 0.4610549972473996
LOSS train 0.40029935305148867 valid 0.46129960109646195
LOSS train 0.40029935305148867 valid 0.4613049984551393
LOSS train 0.40029935305148867 valid 0.4611753730112286
LOSS train 0.40029935305148867 valid 0.46130392012142
LOSS train 0.40029935305148867 valid 0.46136532236614497
LOSS train 0.40029935305148867 valid 0.4614286127517808
LOSS train 0.40029935305148867 valid 0.46146586103618426
LOSS train 0.40029935305148867 valid 0.461428415552478
LOSS train 0.40029935305148867 valid 0.4614573470381803
LOSS train 0.40029935305148867 valid 0.46150385133094257
LOSS train 0.40029935305148867 valid 0.461557157440669
LOSS train 0.40029935305148867 valid 0.46167239205006066
LOSS train 0.40029935305148867 valid 0.46165376833584754
LOSS train 0.40029935305148867 valid 0.46184976385398346
LOSS train 0.40029935305148867 valid 0.46206474641329565
LOSS train 0.40029935305148867 valid 0.4620539909816003
LOSS train 0.40029935305148867 valid 0.4620898017166976
LOSS train 0.40029935305148867 valid 0.4621407964399883
LOSS train 0.40029935305148867 valid 0.46218353033065795
LOSS train 0.40029935305148867 valid 0.4621645673713853
LOSS train 0.40029935305148867 valid 0.4622393776929326
LOSS train 0.40029935305148867 valid 0.4622018775134756
LOSS train 0.40029935305148867 valid 0.46231732943693105
LOSS train 0.40029935305148867 valid 0.46244307186292566
LOSS train 0.40029935305148867 valid 0.46253458168599515
LOSS train 0.40029935305148867 valid 0.4625860875279739
LOSS train 0.40029935305148867 valid 0.4624967970305758
LOSS train 0.40029935305148867 valid 0.4624390935795939
LOSS train 0.40029935305148867 valid 0.46262993051650675
LOSS train 0.40029935305148867 valid 0.4625071462685779
LOSS train 0.40029935305148867 valid 0.4624043920623602
LOSS train 0.40029935305148867 valid 0.46236102020039277
LOSS train 0.40029935305148867 valid 0.46219143907395366
LOSS train 0.40029935305148867 valid 0.46203671768307686
LOSS train 0.40029935305148867 valid 0.46230428273252433
LOSS train 0.40029935305148867 valid 0.46219701880265857
LOSS train 0.40029935305148867 valid 0.46213620680349843
LOSS train 0.40029935305148867 valid 0.4622563931052802
LOSS train 0.40029935305148867 valid 0.46227743881089345
LOSS train 0.40029935305148867 valid 0.4622637049211719
LOSS train 0.40029935305148867 valid 0.46233072128855746
LOSS train 0.40029935305148867 valid 0.4622910694489556
LOSS train 0.40029935305148867 valid 0.46231976558405713
LOSS train 0.40029935305148867 valid 0.46259081304073335
LOSS train 0.40029935305148867 valid 0.4626658564782238
LOSS train 0.40029935305148867 valid 0.4629321068761841
LOSS train 0.40029935305148867 valid 0.4627840991312336
LOSS train 0.40029935305148867 valid 0.4629826162039764
LOSS train 0.40029935305148867 valid 0.46299445781053283
LOSS train 0.40029935305148867 valid 0.4629494952969253
LOSS train 0.40029935305148867 valid 0.4629431364601224
LOSS train 0.40029935305148867 valid 0.4629804671041725
LOSS train 0.40029935305148867 valid 0.46295533309111725
LOSS train 0.40029935305148867 valid 0.4628047429598295
LOSS train 0.40029935305148867 valid 0.4628378526232709
LOSS train 0.40029935305148867 valid 0.46276683297776083
LOSS train 0.40029935305148867 valid 0.46270519902950913
LOSS train 0.40029935305148867 valid 0.4626247088114421
LOSS train 0.40029935305148867 valid 0.46261345935317705
LOSS train 0.40029935305148867 valid 0.4627617671525568
LOSS train 0.40029935305148867 valid 0.4629560856336958
LOSS train 0.40029935305148867 valid 0.46310942342032246
LOSS train 0.40029935305148867 valid 0.46335219760809687
LOSS train 0.40029935305148867 valid 0.463278317672235
LOSS train 0.40029935305148867 valid 0.4633993882534689
LOSS train 0.40029935305148867 valid 0.46350220547002907
LOSS train 0.40029935305148867 valid 0.4635384598057785
LOSS train 0.40029935305148867 valid 0.4635578820305149
LOSS train 0.40029935305148867 valid 0.46347640958699315
LOSS train 0.40029935305148867 valid 0.46346002611993015
LOSS train 0.40029935305148867 valid 0.463550263578711
LOSS train 0.40029935305148867 valid 0.4634927350411312
LOSS train 0.40029935305148867 valid 0.4635663193827462
LOSS train 0.40029935305148867 valid 0.4634293738220419
LOSS train 0.40029935305148867 valid 0.4632420451827745
LOSS train 0.40029935305148867 valid 0.4632047334461347
LOSS train 0.40029935305148867 valid 0.4632159194550329
LOSS train 0.40029935305148867 valid 0.4632705581230177
LOSS train 0.40029935305148867 valid 0.4632153602022874
LOSS train 0.40029935305148867 valid 0.46307225316971334
LOSS train 0.40029935305148867 valid 0.4631124874025272
LOSS train 0.40029935305148867 valid 0.46303058457043433
LOSS train 0.40029935305148867 valid 0.4631352183315581
LOSS train 0.40029935305148867 valid 0.46315073298996895
LOSS train 0.40029935305148867 valid 0.4629894169335513
LOSS train 0.40029935305148867 valid 0.4630295311751431
LOSS train 0.40029935305148867 valid 0.4628909159032151
LOSS train 0.40029935305148867 valid 0.4629529916307553
LOSS train 0.40029935305148867 valid 0.4631289196216454
LOSS train 0.40029935305148867 valid 0.4630548030742117
LOSS train 0.40029935305148867 valid 0.4630849501902006
LOSS train 0.40029935305148867 valid 0.46295382652506734
LOSS train 0.40029935305148867 valid 0.46304882429913935
LOSS train 0.40029935305148867 valid 0.46305560717980065
LOSS train 0.40029935305148867 valid 0.46305877386137495
LOSS train 0.40029935305148867 valid 0.46291834402163295
LOSS train 0.40029935305148867 valid 0.4628464913997713
LOSS train 0.40029935305148867 valid 0.46290751977970723
LOSS train 0.40029935305148867 valid 0.46287244812386935
LOSS train 0.40029935305148867 valid 0.4628926050039678
LOSS train 0.40029935305148867 valid 0.46286031399953637
LOSS train 0.40029935305148867 valid 0.46275800176255116
LOSS train 0.40029935305148867 valid 0.4627685182302901
LOSS train 0.40029935305148867 valid 0.46279328907689743
LOSS train 0.40029935305148867 valid 0.46278265051519757
LOSS train 0.40029935305148867 valid 0.4627946824408494
LOSS train 0.40029935305148867 valid 0.4629044493737693
LOSS train 0.40029935305148867 valid 0.46286035352831434
LOSS train 0.40029935305148867 valid 0.4628352735723768
LOSS train 0.40029935305148867 valid 0.462724965584429
LOSS train 0.40029935305148867 valid 0.4627612329055834
LOSS train 0.40029935305148867 valid 0.4627656066942515
LOSS train 0.40029935305148867 valid 0.4627825133852824
LOSS train 0.40029935305148867 valid 0.4627469262108207
LOSS train 0.40029935305148867 valid 0.46274795933304547
LOSS train 0.40029935305148867 valid 0.4627690149575287
LOSS train 0.40029935305148867 valid 0.4627618421526516
LOSS train 0.40029935305148867 valid 0.46273746488638867
LOSS train 0.40029935305148867 valid 0.46267627734404343
LOSS train 0.40029935305148867 valid 0.46277213142327733
LOSS train 0.40029935305148867 valid 0.4629279525454985
LOSS train 0.40029935305148867 valid 0.46289928729941204
LOSS train 0.40029935305148867 valid 0.46293286521746396
LOSS train 0.40029935305148867 valid 0.4628860334555308
LOSS train 0.40029935305148867 valid 0.46283498181317145
LOSS train 0.40029935305148867 valid 0.4627084039061902
LOSS train 0.40029935305148867 valid 0.4627530889826136
LOSS train 0.40029935305148867 valid 0.4628047410421029
LOSS train 0.40029935305148867 valid 0.46281879989068897
LOSS train 0.40029935305148867 valid 0.4627723976792324
LOSS train 0.40029935305148867 valid 0.46278209555396693
LOSS train 0.40029935305148867 valid 0.46281140346146193
LOSS train 0.40029935305148867 valid 0.4627489149570465
LOSS train 0.40029935305148867 valid 0.4627949997782707
LOSS train 0.40029935305148867 valid 0.4626545240976943
LOSS train 0.40029935305148867 valid 0.4624891518152248
LOSS train 0.40029935305148867 valid 0.46249523915285273
LOSS train 0.40029935305148867 valid 0.4627104958649291
LOSS train 0.40029935305148867 valid 0.46277745417926625
LOSS train 0.40029935305148867 valid 0.46277261581379553
LOSS train 0.40029935305148867 valid 0.4627109012789273
LOSS train 0.40029935305148867 valid 0.462585853519796
LOSS train 0.40029935305148867 valid 0.4626198891753112
LOSS train 0.40029935305148867 valid 0.46249083374227795
LOSS train 0.40029935305148867 valid 0.46242555975914
LOSS train 0.40029935305148867 valid 0.46246267609636893
LOSS train 0.40029935305148867 valid 0.4624931900089253
LOSS train 0.40029935305148867 valid 0.46253899211263927
LOSS train 0.40029935305148867 valid 0.46255509567932346
LOSS train 0.40029935305148867 valid 0.46255115737740915
LOSS train 0.40029935305148867 valid 0.4624846334717855
LOSS train 0.40029935305148867 valid 0.4624033518676651
LOSS train 0.40029935305148867 valid 0.46245064003221836
LOSS train 0.40029935305148867 valid 0.4624727458589607
LOSS train 0.40029935305148867 valid 0.46250500606367795
LOSS train 0.40029935305148867 valid 0.4626634358042511
LOSS train 0.40029935305148867 valid 0.46258741937393
LOSS train 0.40029935305148867 valid 0.4625271569405283
LOSS train 0.40029935305148867 valid 0.4625766365495447
LOSS train 0.40029935305148867 valid 0.4625202283018925
LOSS train 0.40029935305148867 valid 0.4624349814344817
LOSS train 0.40029935305148867 valid 0.46244086713894555
LOSS train 0.40029935305148867 valid 0.4624327853281647
EPOCH 14:
  batch 1 loss: 0.3516303598880768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.37675540149211884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.3960986038049062
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.40226346999406815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.40629667043685913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4059934765100479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.40219223499298096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.40879707783460617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.40775373246934676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4061936497688293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.40401785752990027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.40190397451321286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4000359292213733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.3989136112587793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4005054255326589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.40168137289583683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.401911982718636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4021364384227329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.40226893989663376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4008356273174286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.3997779701437269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.40015987239100714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.401706091735674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4023060202598572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4023218762874603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.40343057306913227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.40381984688617567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4031220791595323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.40393473362100535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.40355295638243355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.40400819720760467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.40399797167629004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.40387318260741956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4040379480404012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.40438431416239057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4043792014320691
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.40424370685139216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4034969665502247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.40415607736660886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4045658506453037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4045367197292607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.40398635324977694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.40489022676334824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.40452325208620593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4048203236526913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.40388926993245666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.40396311118247663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.40375122614204884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4037392461786465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4040478187799454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4036984239138809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.40358222275972366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.40364472539919727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4033498521204348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4030097159472379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4031668081879616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.40357680383481476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4027686894967638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4031160317235074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.40312043726444247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4025236065270471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4025908439390121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4023019103776841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4026059489697218
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4025538352819589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.40264149416576733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4022045073224537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4019603475051768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4021910446277563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.40271674735205515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4027173657652358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4023810190459092
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.40230679226248234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4024018762079445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4022905536492666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4026111736893654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4028092789185512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4026683473434204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40284370659272883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4030296828597784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4032032530248901
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40328471762378043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.40301504910710345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.40300709647791727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.40307961667285247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.40305622060631596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4030013012474981
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4033616188574921
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4032671729500374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4033835003773371
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4030689151732476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4029933424747508
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4032377014237066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.40332380127399525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4029933678476434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4032861025383075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.40300746000919146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4033555126920038
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.40357900538829844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4038106369972229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.40359901467172227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.40357556325547833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.40393021529160655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4037129357457161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.40366265915689015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4034553178638782
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.40350808356409873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4036910023402285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.40365399652664813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4040736764669418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.40377127399315704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.403700570708939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.40333423809667607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.40322414145135044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4028342620186184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.40272025404305295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.40278136220752686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.40264530732470044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40245155401590493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.40248336469133694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.402153464141956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.402102425205903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.40266717061763857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.40261440700100315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4027677230834961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.40255643687550985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.40244824867548906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.40272314194589853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.40292665963025054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.40284394896947423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4026281396851285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.40248126514030225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4026168652046892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4026036934176488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.40240376039787573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.40241551925154295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4025154842512451
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.40237264659093774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.40277357281540793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.40279226047652106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.402355450687679
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4023287149382309
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.40268183588148
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.40294342881275547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4030009730108853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.402948089862523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4028625538965472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4029658154861347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4030315215955645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.40306400140126547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4031771650377488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.402934099498548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4027727067080978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4025398252846359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4028052476144606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4028813028946901
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.40294463106781053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.40290126015868366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.40321488725314353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4031890332698822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.40300366523102943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.402864067826742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.40315381826067265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.40296507626771927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4028407315413157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.40280848974923056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.40242924376162226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4023478531411716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4022726751643525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4022166041766896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4022437510086082
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.40196762372588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4017632467553795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4018038500999582
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4017530504294804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.40162894993343135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4014761702152295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4012742896428269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.40132037537723947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4012131310171551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.40129393141572645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.40144612042458505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.40134507352537147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.40130746137836704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.40140258557087666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.40130989301589226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4011348481165534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.40088994277918594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4008404156833729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4008721980609392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.40090374188273364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.40080290799960494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.40072578361614997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.40065605047437336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.40064302667593343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4006826398628099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.40083862727668684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4013264909236118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.40124502328772044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4011788846552372
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4011987593043503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.40117870699061026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.40134080025950086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4013020232612011
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.40127267997439314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4013561717804196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4014271012538873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.40122000514887846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.40125363138303805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.40130336653618587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4013588004767612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.40143852638748456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.40126452003846147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.40108186117956574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.40094550875730295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4009078151925846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.40099328412987667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.40100389267873326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.40116708286821023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.40119168812578376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4011613880347343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4010903914501001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4010715138484544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.40138776334268705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.40122966474956934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.40106282613973704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4011263513880154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.40105328290608894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4010406942086449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4010863396136657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4011670523907715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.401171765193857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.401053094301101
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.40109999363238996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4011729232808377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40123325864137227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.401415510896892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4014734941370347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.40156162071926327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4015660802523295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.40147453051879695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.40139540586589784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.40155731871294875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.40148262044445415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4015540444121069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4015626190154533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.40152356149213997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.401624538124569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4016029232716465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.40170857059955595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4017137031393697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.40168279681413893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4016754458779874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4015745082943458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.40163852560753915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4016855437075719
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4016296245476615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4016260847795841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.401774721371161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.40189065417418113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4017676958864219
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.401736332828762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4016146149925406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4015561983440862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4014988853121704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.40154626618202466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4014975724372078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4015039655922064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40153766708746275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.40146984755992887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.40150340731733397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.40137877589201226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.40138741126863947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.40124377205859135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4010903292352503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.40120877552291623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4012346570027004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.40107658516160016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.401260139801169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4011976163302149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.40120392359024265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.40108129498383677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4010568232713234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4010575005496052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40114422346416273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4011176044082308
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.40110045796072025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4011916975594229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.40132056573683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.40142832871141104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.40144265640232574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.40138618362276524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4013991213495821
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4013985561675766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4014748785455348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.40145944179715337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4015842010878553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4014397584551933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.40143787342569104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4014830348889033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4015046341276644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4013712973586771
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.40133880614840944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4013299287149781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4012342465705559
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.40122932507321724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40123746886315487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.40107335140565775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.40119246371741435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4012681134285465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4012602469928778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4013020172715187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.40136137119116494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.40121823852988564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.401178030551426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4012232442634015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4011985137823628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4011490017925418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4011409242511917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.40107466345652937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.40106378546756377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.40104825905761365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4010721953476177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.40106110697911107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4010477993121514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4010364809102076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.40100061465111714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.40099805021067947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4009082606317062
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4008895840608712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.401003901151732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4008754992700485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.40095863023677747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4009479390468426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.40103101241054817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4010026187059425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4009196695481988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4009615760406799
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.40093770675954565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4011369723607512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.40108604681107307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4012441334494373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.40132625535695265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.40120449021112087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.40117983887161035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4011277406546422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4011784355647282
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4012073328097661
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4011074455727137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.40101318878786907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.40094152228784696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.40097366518933664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40106135682749006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4009521115297652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4009860362805111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.40094004713752296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4010090756983984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.40098118790368126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.40101450532259714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4010180652141571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.40099362042471975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4010970237670024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4011608592899049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4011582792787762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4012679046963992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.40124589416498696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4012280436237761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.40127400389831996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4013095975406771
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4013158463948482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.40133612167160465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4012784189594689
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.401280041274692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.40126351374674607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.40117155798276266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.40113189031786106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4011580042086482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.40116707255285255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4011353061664702
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4010953603606475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.40106765937617445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4010426421596118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4010948988538498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4011129556844632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.40098804119345427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.40102153144043345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4009902556583247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4010025524755114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4009341668806836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.40092093295011766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4008780532633252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4008475392296606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4009332846442555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.400780152699669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4007555541358417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.40074314335078903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.40070210153269825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.40075769518787535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4007634253131417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.40087869472801685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.40075183843733964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.40057772027319344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4004682543555797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.40043728628961167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.40043817243458313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.40042414064771437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.40038365462488273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.400309925131938
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.40034886473256975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.40036639861944245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4004627890395422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4004154440413401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.40041607798733375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.40048318043135217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4004206877156913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.40048203975535357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.40042392262737814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4003934602132825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.40045510115088595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.40044239716870444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.40046979002035143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4004161650253133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.40045783642335986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4004965051305744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4004961335659027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.40044594013914814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4005572148871366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.40050425784331617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4003565651831371
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4004895978195723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4005042831056909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4005490354503746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4004124071939438
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.40041960611046734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.40034321498596803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4003962536060482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.40042041518322663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.40040448961192615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.40030589489295976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4002997349609028
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4003137721090901
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.40034528737424185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4003874478571571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4004112614301948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4006059467792511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.40059943096252837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.40056573437897686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4006434105602758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.40063992414814326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4006047705809275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4005931878830007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.40060195313618246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.400606377103734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4005829971529839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4005350771841112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4005455413931294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.40052465921679525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4005506745982899
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.40058987222465814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4006195414973342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4005890806688404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.40052111653280464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4005051670398877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.40054138852604504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.40059486627578733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.40065929575027825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.40062687343397285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4005313648754715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4005650598992671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.40063902171368293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.40057931236147626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4006937473886094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4006937473886094 valid 0.43762171268463135
LOSS train 0.4006937473886094 valid 0.4388619363307953
LOSS train 0.4006937473886094 valid 0.4598807096481323
LOSS train 0.4006937473886094 valid 0.4562842771410942
LOSS train 0.4006937473886094 valid 0.4528400480747223
LOSS train 0.4006937473886094 valid 0.456279123822848
LOSS train 0.4006937473886094 valid 0.4579779463154929
LOSS train 0.4006937473886094 valid 0.457445215433836
LOSS train 0.4006937473886094 valid 0.45125441749890643
LOSS train 0.4006937473886094 valid 0.4539955496788025
LOSS train 0.4006937473886094 valid 0.45759222182360565
LOSS train 0.4006937473886094 valid 0.4562150885661443
LOSS train 0.4006937473886094 valid 0.45845429255412173
LOSS train 0.4006937473886094 valid 0.45851963332721163
LOSS train 0.4006937473886094 valid 0.4571436146895091
LOSS train 0.4006937473886094 valid 0.45905477926135063
LOSS train 0.4006937473886094 valid 0.4617198845919441
LOSS train 0.4006937473886094 valid 0.4628618558247884
LOSS train 0.4006937473886094 valid 0.4633952818418804
LOSS train 0.4006937473886094 valid 0.4650248110294342
LOSS train 0.4006937473886094 valid 0.4641456972985041
LOSS train 0.4006937473886094 valid 0.461252209815112
LOSS train 0.4006937473886094 valid 0.46212261137755023
LOSS train 0.4006937473886094 valid 0.46063486983378726
LOSS train 0.4006937473886094 valid 0.45963775157928466
LOSS train 0.4006937473886094 valid 0.4590869454237131
LOSS train 0.4006937473886094 valid 0.4584405344945413
LOSS train 0.4006937473886094 valid 0.4591651122484888
LOSS train 0.4006937473886094 valid 0.45838729163696024
LOSS train 0.4006937473886094 valid 0.45912987887859347
LOSS train 0.4006937473886094 valid 0.46096426921506084
LOSS train 0.4006937473886094 valid 0.46096198819577694
LOSS train 0.4006937473886094 valid 0.46240302288171015
LOSS train 0.4006937473886094 valid 0.4616268399883719
LOSS train 0.4006937473886094 valid 0.4625029802322388
LOSS train 0.4006937473886094 valid 0.4627280905842781
LOSS train 0.4006937473886094 valid 0.46304037603172093
LOSS train 0.4006937473886094 valid 0.46432112235771983
LOSS train 0.4006937473886094 valid 0.4638807850006299
LOSS train 0.4006937473886094 valid 0.46528814882040026
LOSS train 0.4006937473886094 valid 0.4651389892508344
LOSS train 0.4006937473886094 valid 0.4662440930094038
LOSS train 0.4006937473886094 valid 0.4662488380143809
LOSS train 0.4006937473886094 valid 0.46678372675722296
LOSS train 0.4006937473886094 valid 0.4670321292347378
LOSS train 0.4006937473886094 valid 0.46755077657492267
LOSS train 0.4006937473886094 valid 0.466793011477653
LOSS train 0.4006937473886094 valid 0.467021028821667
LOSS train 0.4006937473886094 valid 0.4676100125118178
LOSS train 0.4006937473886094 valid 0.46722780525684354
LOSS train 0.4006937473886094 valid 0.46782899253508625
LOSS train 0.4006937473886094 valid 0.4675473186832208
LOSS train 0.4006937473886094 valid 0.4669928949958873
LOSS train 0.4006937473886094 valid 0.4669630295700497
LOSS train 0.4006937473886094 valid 0.4664684284817089
LOSS train 0.4006937473886094 valid 0.4661976173520088
LOSS train 0.4006937473886094 valid 0.46605161459822403
LOSS train 0.4006937473886094 valid 0.4658798025599841
LOSS train 0.4006937473886094 valid 0.4665604784327038
LOSS train 0.4006937473886094 valid 0.46588880916436515
LOSS train 0.4006937473886094 valid 0.46476002697084773
LOSS train 0.4006937473886094 valid 0.46597591234791663
LOSS train 0.4006937473886094 valid 0.4662828398129297
LOSS train 0.4006937473886094 valid 0.4668323704972863
LOSS train 0.4006937473886094 valid 0.4670544881087083
LOSS train 0.4006937473886094 valid 0.4670286869460886
LOSS train 0.4006937473886094 valid 0.4666674586374368
LOSS train 0.4006937473886094 valid 0.4661065765163478
LOSS train 0.4006937473886094 valid 0.4657115180423294
LOSS train 0.4006937473886094 valid 0.46528188841683527
LOSS train 0.4006937473886094 valid 0.4648152929796299
LOSS train 0.4006937473886094 valid 0.4645492873258061
LOSS train 0.4006937473886094 valid 0.4649604975360714
LOSS train 0.4006937473886094 valid 0.4648122497507044
LOSS train 0.4006937473886094 valid 0.46428061127662656
LOSS train 0.4006937473886094 valid 0.4644513047839466
LOSS train 0.4006937473886094 valid 0.4642193449008
LOSS train 0.4006937473886094 valid 0.4641803426620288
LOSS train 0.4006937473886094 valid 0.4638641514355623
LOSS train 0.4006937473886094 valid 0.4638179004192352
LOSS train 0.4006937473886094 valid 0.46328221132725844
LOSS train 0.4006937473886094 valid 0.4634753720062535
LOSS train 0.4006937473886094 valid 0.4632706656513444
LOSS train 0.4006937473886094 valid 0.463354980306966
LOSS train 0.4006937473886094 valid 0.4634710876380696
LOSS train 0.4006937473886094 valid 0.46293408614258436
LOSS train 0.4006937473886094 valid 0.46251082934182264
LOSS train 0.4006937473886094 valid 0.46194203570485115
LOSS train 0.4006937473886094 valid 0.46232561047157544
LOSS train 0.4006937473886094 valid 0.4623584184381697
LOSS train 0.4006937473886094 valid 0.46198648050591185
LOSS train 0.4006937473886094 valid 0.4615815826084303
LOSS train 0.4006937473886094 valid 0.461032106671282
LOSS train 0.4006937473886094 valid 0.4602500358794598
LOSS train 0.4006937473886094 valid 0.45977332341043575
LOSS train 0.4006937473886094 valid 0.46009965520352125
LOSS train 0.4006937473886094 valid 0.46051202268944574
LOSS train 0.4006937473886094 valid 0.460442913734183
LOSS train 0.4006937473886094 valid 0.46070916453997296
LOSS train 0.4006937473886094 valid 0.46107685983181
LOSS train 0.4006937473886094 valid 0.46119687993927755
LOSS train 0.4006937473886094 valid 0.46124095601194043
LOSS train 0.4006937473886094 valid 0.46187490687786953
LOSS train 0.4006937473886094 valid 0.46171235751647216
LOSS train 0.4006937473886094 valid 0.4617212990919749
LOSS train 0.4006937473886094 valid 0.46190502030669517
LOSS train 0.4006937473886094 valid 0.4615997981245273
LOSS train 0.4006937473886094 valid 0.461972872140231
LOSS train 0.4006937473886094 valid 0.462134009380953
LOSS train 0.4006937473886094 valid 0.462215413830497
LOSS train 0.4006937473886094 valid 0.4622981556364008
LOSS train 0.4006937473886094 valid 0.462064410426787
LOSS train 0.4006937473886094 valid 0.4619707040554654
LOSS train 0.4006937473886094 valid 0.4617581163582049
LOSS train 0.4006937473886094 valid 0.4618017201838286
LOSS train 0.4006937473886094 valid 0.4618098617627703
LOSS train 0.4006937473886094 valid 0.46185668436889976
LOSS train 0.4006937473886094 valid 0.4616091157925331
LOSS train 0.4006937473886094 valid 0.4613070543072805
LOSS train 0.4006937473886094 valid 0.4612216129899025
LOSS train 0.4006937473886094 valid 0.4610943680952403
LOSS train 0.4006937473886094 valid 0.46100984538187745
LOSS train 0.4006937473886094 valid 0.4610853282416739
LOSS train 0.4006937473886094 valid 0.46140255370447714
LOSS train 0.4006937473886094 valid 0.4612583150863647
LOSS train 0.4006937473886094 valid 0.4611946382219829
LOSS train 0.4006937473886094 valid 0.4616484229020246
LOSS train 0.4006937473886094 valid 0.46178661729209125
LOSS train 0.4006937473886094 valid 0.4619581941948381
LOSS train 0.4006937473886094 valid 0.46168247713492466
LOSS train 0.4006937473886094 valid 0.4616507198519379
LOSS train 0.4006937473886094 valid 0.4615731903097846
LOSS train 0.4006937473886094 valid 0.4613597478185381
LOSS train 0.4006937473886094 valid 0.4615448373022364
LOSS train 0.4006937473886094 valid 0.4617887560968046
LOSS train 0.4006937473886094 valid 0.46189160601181145
LOSS train 0.4006937473886094 valid 0.4616986038911082
LOSS train 0.4006937473886094 valid 0.4615439504816912
LOSS train 0.4006937473886094 valid 0.46121542316546543
LOSS train 0.4006937473886094 valid 0.4613600890551295
LOSS train 0.4006937473886094 valid 0.46140145283218814
LOSS train 0.4006937473886094 valid 0.46167647964517833
LOSS train 0.4006937473886094 valid 0.46135821959355494
LOSS train 0.4006937473886094 valid 0.4613598535458247
LOSS train 0.4006937473886094 valid 0.46115918529444727
LOSS train 0.4006937473886094 valid 0.46149586202347115
LOSS train 0.4006937473886094 valid 0.46108412620972616
LOSS train 0.4006937473886094 valid 0.46152564722138484
LOSS train 0.4006937473886094 valid 0.46159042828035035
LOSS train 0.4006937473886094 valid 0.46172252694765725
LOSS train 0.4006937473886094 valid 0.4618314326993677
LOSS train 0.4006937473886094 valid 0.46153758662311656
LOSS train 0.4006937473886094 valid 0.461809501149296
LOSS train 0.4006937473886094 valid 0.4617756802540321
LOSS train 0.4006937473886094 valid 0.4619227716999669
LOSS train 0.4006937473886094 valid 0.4622302437439943
LOSS train 0.4006937473886094 valid 0.462113330698317
LOSS train 0.4006937473886094 valid 0.4620371730644492
LOSS train 0.4006937473886094 valid 0.46174264722650155
LOSS train 0.4006937473886094 valid 0.4617618707939982
LOSS train 0.4006937473886094 valid 0.46161924071193483
LOSS train 0.4006937473886094 valid 0.46124307958432187
LOSS train 0.4006937473886094 valid 0.4611581276896541
LOSS train 0.4006937473886094 valid 0.46100566608876714
LOSS train 0.4006937473886094 valid 0.4608480886979537
LOSS train 0.4006937473886094 valid 0.4606642882867032
LOSS train 0.4006937473886094 valid 0.4607580459403421
LOSS train 0.4006937473886094 valid 0.4609723025489421
LOSS train 0.4006937473886094 valid 0.4611298743437028
LOSS train 0.4006937473886094 valid 0.4615934868069256
LOSS train 0.4006937473886094 valid 0.46146900978004723
LOSS train 0.4006937473886094 valid 0.46149490444466124
LOSS train 0.4006937473886094 valid 0.4616219354847263
LOSS train 0.4006937473886094 valid 0.46161255805656826
LOSS train 0.4006937473886094 valid 0.4617084210259574
LOSS train 0.4006937473886094 valid 0.4615999644791538
LOSS train 0.4006937473886094 valid 0.4619647575973791
LOSS train 0.4006937473886094 valid 0.46217454049024687
LOSS train 0.4006937473886094 valid 0.4620083322405149
LOSS train 0.4006937473886094 valid 0.4620470757285754
LOSS train 0.4006937473886094 valid 0.46201692052309024
LOSS train 0.4006937473886094 valid 0.4621349276749642
LOSS train 0.4006937473886094 valid 0.46202112856458444
LOSS train 0.4006937473886094 valid 0.46224614929245866
LOSS train 0.4006937473886094 valid 0.46219067815187814
LOSS train 0.4006937473886094 valid 0.46229319466698554
LOSS train 0.4006937473886094 valid 0.46231561437010127
LOSS train 0.4006937473886094 valid 0.46230485321993525
LOSS train 0.4006937473886094 valid 0.46222456312053417
LOSS train 0.4006937473886094 valid 0.4620630935618752
LOSS train 0.4006937473886094 valid 0.4623302049661806
LOSS train 0.4006937473886094 valid 0.46243418380618095
LOSS train 0.4006937473886094 valid 0.4622963104841005
LOSS train 0.4006937473886094 valid 0.4621243968452375
LOSS train 0.4006937473886094 valid 0.4621040335068336
LOSS train 0.4006937473886094 valid 0.4622282651918275
LOSS train 0.4006937473886094 valid 0.4625299816506768
LOSS train 0.4006937473886094 valid 0.4625524106350812
LOSS train 0.4006937473886094 valid 0.4625938122895495
LOSS train 0.4006937473886094 valid 0.4625186623632908
LOSS train 0.4006937473886094 valid 0.46220828511228607
LOSS train 0.4006937473886094 valid 0.4623759121883034
LOSS train 0.4006937473886094 valid 0.4622137649305936
LOSS train 0.4006937473886094 valid 0.4622475788289425
LOSS train 0.4006937473886094 valid 0.4622322867556316
LOSS train 0.4006937473886094 valid 0.4620033343440121
LOSS train 0.4006937473886094 valid 0.462248500706493
LOSS train 0.4006937473886094 valid 0.46226054344039696
LOSS train 0.4006937473886094 valid 0.46212734018216295
LOSS train 0.4006937473886094 valid 0.46225127237183705
LOSS train 0.4006937473886094 valid 0.4623194637739263
LOSS train 0.4006937473886094 valid 0.4623782981960279
LOSS train 0.4006937473886094 valid 0.4624122620468408
LOSS train 0.4006937473886094 valid 0.46237944790693086
LOSS train 0.4006937473886094 valid 0.4624146972977838
LOSS train 0.4006937473886094 valid 0.4624554221000936
LOSS train 0.4006937473886094 valid 0.4625074125929362
LOSS train 0.4006937473886094 valid 0.4626288695619741
LOSS train 0.4006937473886094 valid 0.46260833413633584
LOSS train 0.4006937473886094 valid 0.46280207417228003
LOSS train 0.4006937473886094 valid 0.4630137806025026
LOSS train 0.4006937473886094 valid 0.4630030911784988
LOSS train 0.4006937473886094 valid 0.4630447990958466
LOSS train 0.4006937473886094 valid 0.46309712595705477
LOSS train 0.4006937473886094 valid 0.46313846906026207
LOSS train 0.4006937473886094 valid 0.4631178019057333
LOSS train 0.4006937473886094 valid 0.46319306461296417
LOSS train 0.4006937473886094 valid 0.46315184431640727
LOSS train 0.4006937473886094 valid 0.46326270634430466
LOSS train 0.4006937473886094 valid 0.46338094006414
LOSS train 0.4006937473886094 valid 0.4634836870870549
LOSS train 0.4006937473886094 valid 0.4635336612319124
LOSS train 0.4006937473886094 valid 0.4634498618703032
LOSS train 0.4006937473886094 valid 0.4633947880859049
LOSS train 0.4006937473886094 valid 0.4635858865494424
LOSS train 0.4006937473886094 valid 0.4634599665463981
LOSS train 0.4006937473886094 valid 0.46336220148243484
LOSS train 0.4006937473886094 valid 0.46331764682501303
LOSS train 0.4006937473886094 valid 0.46314831508253407
LOSS train 0.4006937473886094 valid 0.462995637084047
LOSS train 0.4006937473886094 valid 0.46326223930877275
LOSS train 0.4006937473886094 valid 0.4631528643783459
LOSS train 0.4006937473886094 valid 0.463086223160779
LOSS train 0.4006937473886094 valid 0.46320586688205845
LOSS train 0.4006937473886094 valid 0.4632310340599138
LOSS train 0.4006937473886094 valid 0.46321657614979317
LOSS train 0.4006937473886094 valid 0.4632893803148617
LOSS train 0.4006937473886094 valid 0.4632479519613327
LOSS train 0.4006937473886094 valid 0.46327857619308566
LOSS train 0.4006937473886094 valid 0.4635486079454422
LOSS train 0.4006937473886094 valid 0.46361960346005354
LOSS train 0.4006937473886094 valid 0.46388138605961726
LOSS train 0.4006937473886094 valid 0.46372888493443665
LOSS train 0.4006937473886094 valid 0.4639230309508917
LOSS train 0.4006937473886094 valid 0.46393446571686686
LOSS train 0.4006937473886094 valid 0.4638821096159518
LOSS train 0.4006937473886094 valid 0.46387618559807653
LOSS train 0.4006937473886094 valid 0.4639074569062669
LOSS train 0.4006937473886094 valid 0.46387810987855477
LOSS train 0.4006937473886094 valid 0.46373013647703026
LOSS train 0.4006937473886094 valid 0.4637615437480225
LOSS train 0.4006937473886094 valid 0.46369409822780666
LOSS train 0.4006937473886094 valid 0.4636289426355761
LOSS train 0.4006937473886094 valid 0.46355188208999054
LOSS train 0.4006937473886094 valid 0.46353930639770796
LOSS train 0.4006937473886094 valid 0.46368638577317833
LOSS train 0.4006937473886094 valid 0.46387610564964094
LOSS train 0.4006937473886094 valid 0.46403674292030617
LOSS train 0.4006937473886094 valid 0.46427224271802653
LOSS train 0.4006937473886094 valid 0.46420440475145974
LOSS train 0.4006937473886094 valid 0.46431457721439234
LOSS train 0.4006937473886094 valid 0.4644218905664542
LOSS train 0.4006937473886094 valid 0.46446033209671467
LOSS train 0.4006937473886094 valid 0.46447999634011816
LOSS train 0.4006937473886094 valid 0.46440629265525124
LOSS train 0.4006937473886094 valid 0.46439920678950736
LOSS train 0.4006937473886094 valid 0.4644862363915151
LOSS train 0.4006937473886094 valid 0.4644262383310057
LOSS train 0.4006937473886094 valid 0.4644952048964825
LOSS train 0.4006937473886094 valid 0.46436065467340604
LOSS train 0.4006937473886094 valid 0.4641670417106873
LOSS train 0.4006937473886094 valid 0.46412815956781944
LOSS train 0.4006937473886094 valid 0.4641320426346135
LOSS train 0.4006937473886094 valid 0.46418816407381647
LOSS train 0.4006937473886094 valid 0.4641314955134141
LOSS train 0.4006937473886094 valid 0.4639830175604854
LOSS train 0.4006937473886094 valid 0.4640275541082907
LOSS train 0.4006937473886094 valid 0.4639436343891753
LOSS train 0.4006937473886094 valid 0.46404532680874466
LOSS train 0.4006937473886094 valid 0.4640602227942697
LOSS train 0.4006937473886094 valid 0.46390412671049847
LOSS train 0.4006937473886094 valid 0.46394123096172124
LOSS train 0.4006937473886094 valid 0.46379942047718037
LOSS train 0.4006937473886094 valid 0.46385437006853064
LOSS train 0.4006937473886094 valid 0.4640321666911497
LOSS train 0.4006937473886094 valid 0.4639599597131884
LOSS train 0.4006937473886094 valid 0.46398626834856543
LOSS train 0.4006937473886094 valid 0.46385424349132
LOSS train 0.4006937473886094 valid 0.463950089886037
LOSS train 0.4006937473886094 valid 0.46394798119862873
LOSS train 0.4006937473886094 valid 0.4639497163683869
LOSS train 0.4006937473886094 valid 0.46380763071657016
LOSS train 0.4006937473886094 valid 0.46373356539424104
LOSS train 0.4006937473886094 valid 0.4637969018597352
LOSS train 0.4006937473886094 valid 0.4637615330883714
LOSS train 0.4006937473886094 valid 0.4637788160174501
LOSS train 0.4006937473886094 valid 0.4637404274474526
LOSS train 0.4006937473886094 valid 0.46363848428447524
LOSS train 0.4006937473886094 valid 0.4636481600093224
LOSS train 0.4006937473886094 valid 0.46367606232243197
LOSS train 0.4006937473886094 valid 0.4636676025927258
LOSS train 0.4006937473886094 valid 0.4636773349573979
LOSS train 0.4006937473886094 valid 0.46378355275708644
LOSS train 0.4006937473886094 valid 0.4637396530171109
LOSS train 0.4006937473886094 valid 0.4637146394404154
LOSS train 0.4006937473886094 valid 0.46361313364173795
LOSS train 0.4006937473886094 valid 0.4636513242022096
LOSS train 0.4006937473886094 valid 0.4636565203186851
LOSS train 0.4006937473886094 valid 0.4636778653975938
LOSS train 0.4006937473886094 valid 0.4636483467184007
LOSS train 0.4006937473886094 valid 0.4636435863384948
LOSS train 0.4006937473886094 valid 0.4636636020048805
LOSS train 0.4006937473886094 valid 0.46365447005620314
LOSS train 0.4006937473886094 valid 0.4636356180280815
LOSS train 0.4006937473886094 valid 0.4635750213953165
LOSS train 0.4006937473886094 valid 0.46367102779128067
LOSS train 0.4006937473886094 valid 0.46381837120479036
LOSS train 0.4006937473886094 valid 0.46379068303035526
LOSS train 0.4006937473886094 valid 0.46382848497219725
LOSS train 0.4006937473886094 valid 0.4637878740375692
LOSS train 0.4006937473886094 valid 0.4637324754204995
LOSS train 0.4006937473886094 valid 0.46361171301588955
LOSS train 0.4006937473886094 valid 0.46365603097566255
LOSS train 0.4006937473886094 valid 0.46370616974587925
LOSS train 0.4006937473886094 valid 0.463725995394721
LOSS train 0.4006937473886094 valid 0.4636881054334697
LOSS train 0.4006937473886094 valid 0.4637017109450671
LOSS train 0.4006937473886094 valid 0.46372807352147866
LOSS train 0.4006937473886094 valid 0.4636670408171538
LOSS train 0.4006937473886094 valid 0.46371313324745966
LOSS train 0.4006937473886094 valid 0.4635812836833014
LOSS train 0.4006937473886094 valid 0.46341708311211993
LOSS train 0.4006937473886094 valid 0.46342922099825246
LOSS train 0.4006937473886094 valid 0.4636458731148132
LOSS train 0.4006937473886094 valid 0.4637137782746467
LOSS train 0.4006937473886094 valid 0.4637078410283679
LOSS train 0.4006937473886094 valid 0.4636518845297074
LOSS train 0.4006937473886094 valid 0.4635258327270376
LOSS train 0.4006937473886094 valid 0.4635626094730672
LOSS train 0.4006937473886094 valid 0.46344002527850015
LOSS train 0.4006937473886094 valid 0.4633749122293586
LOSS train 0.4006937473886094 valid 0.46341411693190987
LOSS train 0.4006937473886094 valid 0.463439719535136
LOSS train 0.4006937473886094 valid 0.4634871673954409
LOSS train 0.4006937473886094 valid 0.46350694735285264
LOSS train 0.4006937473886094 valid 0.46350263494454075
LOSS train 0.4006937473886094 valid 0.46343825452801896
LOSS train 0.4006937473886094 valid 0.46335543567241905
LOSS train 0.4006937473886094 valid 0.4634053116887393
LOSS train 0.4006937473886094 valid 0.4634236112236977
LOSS train 0.4006937473886094 valid 0.46345632351996824
LOSS train 0.4006937473886094 valid 0.46361321927104865
LOSS train 0.4006937473886094 valid 0.4635374185631755
LOSS train 0.4006937473886094 valid 0.4634779893926212
LOSS train 0.4006937473886094 valid 0.4635235257344703
LOSS train 0.4006937473886094 valid 0.4634656604847621
LOSS train 0.4006937473886094 valid 0.46338112469590004
LOSS train 0.4006937473886094 valid 0.4633868294565574
LOSS train 0.4006937473886094 valid 0.46338304150395276
EPOCH 15:
  batch 1 loss: 0.35357069969177246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.375348836183548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.3935757080713908
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.40022335946559906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.40697047114372253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.40705270568529767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.40209308692387175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.40717054158449173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.405500849088033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4045043408870697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.40208354592323303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.39976244419813156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.3970555319235875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.3952197794403349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.3986236492792765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.3989359512925148
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.3987661652705249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.399730212158627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.39964662413848073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.39848675578832626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.39753424411728266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.3983557413924824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.39947071282759955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.40034718066453934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4009033143520355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4020511507987976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.40209713026329325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4015127101114818
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4026641794319811
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.402360408504804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4028973810134395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4028836488723755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4026617714852998
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.40320440250284534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4036536650998252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.40371434804466033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.40362325632894364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4029819706552907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.40340202511885226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.40382439121603964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4038132429122925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4032179848069236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4045795028985933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4037612276998433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4042350537247128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.40322207108787866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.40315223247446913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.40306356549263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.40288143681020155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4032051134109497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.40298327336124345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.40270679616011107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4029878557852979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4027669887851786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4024638040499254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4025946067912238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4032271797196907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4025767260584338
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.40288759742752983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4030004029472669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4024218638412288
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.402458353388694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4022525567857046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4027377376332879
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4027008056640625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.40281555869362573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4023512161489743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.40205636313732934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.40213217726652173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.40260770278317587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.40251028537750244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.40222085350089604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4021010558082633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.40236203614118937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4022139243284861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.40251936881165756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4027563937298663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4026786860747215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.40273840819733053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.40291321128606794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4031089452313788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.40312771063025404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.40282796987568037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4027464059846742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4027456841048072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4026593694160151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4025675678390196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4029412347484719
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4030082476942727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4031914403041204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.402783201618509
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4027593106679294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4030987931195126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.40320084196455935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4028795599937439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.40325275746484596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4029390003877817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4034309025321688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4035432624696481
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.40375802397727967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.403671005279711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4037127281520881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4039512895843358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.40373329990185225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.40370826976639884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4036266182391149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4036798596939194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.40390923867623013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4037732889346026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.40417498377236455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4038641380297171
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.403741880985243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.40336461958632003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4033202061004806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.40288017729054326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4026979845145653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4026853668893504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.40244193223573393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.40222608316846253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.40226300433278084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.401999111017905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.40196623054684183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4025322998442301
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.40258891544034403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4028107404708862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.40264514088630676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4024815798744442
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.40272701485082507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.40278706947962445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4026068531549894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.402398377429438
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4022492594791181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.40233714150306876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4022864688243439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4021593219704098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.40224330302547007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.40235381165560147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4022585227005724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.40265291393232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4026546120643616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4022330407132494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4021732041113813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4025314594065393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4028336312621832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4029421261672316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4028121818826623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4027722962454063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4028749063208297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.40291674705159747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4028958491484324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.402992532742734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4027692256005187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.40261679673506545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4024007984183051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.40260667493266444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4026571863736862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.40270890798538356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4025977874481225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.40284865326101676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4027997383847833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4025941119060753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4023673359626605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.40252760016113703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.40235662478499296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4022408012187842
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.40222655541925545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4018637573647642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4017557931088266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.40169950208720373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4017359526718364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.40175372588704206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4015920035714327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4013598671538292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.401408472109115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.40137954456465585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.40126919086006557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4010352729740789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4008083659946249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4007994785655144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4006327509880066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.40071896360724013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4008429302619054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.40072935998765497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.40070542563562805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4007496975563668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4006744744957134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4005098146869537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4002351790983626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.40008701423488596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4000937581062317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4001125771337779
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.40000059517721337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.3999715234331516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.39986104203253675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.39984107323181933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.3998178815355106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.3999106201726168
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4004379717087505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4003278951549051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4002693589031696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.40032706272542773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4002835260759486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4004073753732766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.40037720577389585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4003228335845761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.40031987312927986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4003722667694092
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.40014019866402334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.40017931469889917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.400169493612789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.40015071630477905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4001618748847044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4000017764702649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.3998298625522685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.39975760953370915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.39973775849298193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.39986249667158874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.39989099849801546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.400080921307002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.40012713752009654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4000840895046476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.39993825997855215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.3999667004619479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.40026586622531923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.40007838712798227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.3998969958155556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.39999257796136295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.39984906229533645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.3998627593683884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.3999144313128098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.39997881341290165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.39999978603987857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.39983468557120394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.3998805427143716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.40004701043697116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.40012538395190644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4002814731768918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4003132153458956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4004496627771705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.40047753006219866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4004015487259354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.40035352911338334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4005419711271922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.40048529085565787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.40055367241100387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.40055640562763056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4005542658118584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4005756288045837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.40058730991489916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4007145240306854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.40069473905867314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.40064078380191137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.400626732780057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.40057363789381945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.40059112088353027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.40058662823867053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.40050171101139675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.40056441423966904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.40069783631438916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4008535105448503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4007351449851332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.40069033546757155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4005934660652291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4005266052078117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4004167836792064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.40046572618018417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4003662934687254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4003557414928479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.40042240236328436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4003782049373344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.40043392480519424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.40028163560611363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.40030614742429266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.40015316553359487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.39998064810579476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4001158529865569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.40007553731061063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.39995810335917437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4000925777419921
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4000140800007752
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.3999879132174088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.3999157416905072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.39991294242467984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.3998937498725636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.40000123486184236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.39997305413642964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.3999880973885699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4000795829213328
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4002365845297447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.40033848984488124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4003455497554897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4003270462359468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4003452273155642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.40034496713252293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.40040612028816996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4004015019415198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.40052803989612695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.40036272072552037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.40035313258202976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.40034902314345044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4003548740944593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4002132121695588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.400189735118312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4001803548124276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4000504645167804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.40006276672961666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.40005911212014067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.39985955893606334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4000260359261028
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.40012058759889296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4001395506874158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.40013986099988985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4002177263981999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.40007575017631436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4000510815590147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.400101558317112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.40007756354304896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.40002563530169194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4000228938637856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.40000069700181484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.40002403192431013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.39998911904252094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.399985939448832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4000086965568272
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.3999938762187958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4000123189819371
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4000604691308573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.40005522030519275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.3999648519018863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.39998332596186437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4000759836950331
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.39998778287904807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4000581408048177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.40002595753726844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4000584367495864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.40001630650034975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.3999338517026307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.39998865577243486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.39996020517869685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4001310087302152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.40004966772896106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4001652787477649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.40018854970139595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.40010090232935064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4000935583010964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4000765361710091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.40011719513351707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4001141255614401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.40004322368299383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.3999752705437796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.3999170647387491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.3999428583139723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.40003567596332884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.39991942586871865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.3999665084019513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.39992807437194866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.3999965131616726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.39997717222021945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.40001892063943123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.40002027534776263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4000151930093105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.40014614123665826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.40017273898952266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.40018676663493064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.40029515215795336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.40026519915770964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.40024486557664274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.400302062863889
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.400358257335699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.40039869297195124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4004269961237586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4004081194439242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.400416716573705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4003786572160568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4003088402748108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4002859650298636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.40031757634577764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4003328376661533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4003143653391534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4002867762979708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4002155515309081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4001972162754748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4002562493630551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.40026936974997324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4002005049934635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4002318726611261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4001829021198805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.40018877394727825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4001589890157655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.40014615708436724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4001013576374639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.40004012323155697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4000964125300788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.3999610854889536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.3999318142480488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.3999317161964648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.39989500937593975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.3999710242502653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.39996162998048884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4001147534698248
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.40000153717554715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.3998030920823415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.3996773839884301
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.3996690645961478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.3996986966074249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.39969061579316706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.3996012417338697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.3995482207221143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.3995952644091655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.3995622198029262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.39964483609454765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.3995984174238825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.3995638867123075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.3996440252100212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.39962185384279275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.39967600686045796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.3996034906350737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.399555305117055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.3996006295902917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.3995662464981987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.3996334603308499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.39961306397666296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.3996007267042255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.3996262047791256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.39963219053605026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.3995879240718806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.3996636235881466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.3996157535464964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.3994687981122024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.3996044040419335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.3996481269667154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.3996832973013322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.3995249030496452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.399528986504001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.3994802914131647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.39954285938805395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.39954778545235603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.39949104244306205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.3993980241663635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.39939166354862127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.3994384591136119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.3994503731910999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.3995138852106529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.39953090868017693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.3997333090626792
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.399714385113374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.399684584980843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.39976294338703156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.3997929203749234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.39978040827645195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.39976114021436604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.39975058887384635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.39974729910854734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.3997362791047747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.3996693174262623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.3996910299909742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.3996485371297507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.39970302106771927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.39973126108350315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.39974473928627763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.39971853239934513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.39969644653590725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.39967590267920855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.3997358509564194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.3997989139890158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.39988675265864754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.39985177897283813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.39979476844653106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.39983363846726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.3999206927862573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.39985237424034475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.3999484797655526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.3999484797655526 valid 0.4453790783882141
LOSS train 0.3999484797655526 valid 0.44616425037384033
LOSS train 0.3999484797655526 valid 0.4677013158798218
LOSS train 0.3999484797655526 valid 0.46421340107917786
LOSS train 0.3999484797655526 valid 0.46078355312347413
LOSS train 0.3999484797655526 valid 0.4642322013775508
LOSS train 0.3999484797655526 valid 0.46566017610686167
LOSS train 0.3999484797655526 valid 0.4651246555149555
LOSS train 0.3999484797655526 valid 0.45872775713602704
LOSS train 0.3999484797655526 valid 0.46155214309692383
LOSS train 0.3999484797655526 valid 0.4652655666524714
LOSS train 0.3999484797655526 valid 0.4638427197933197
LOSS train 0.3999484797655526 valid 0.46614837646484375
LOSS train 0.3999484797655526 valid 0.46623886270182474
LOSS train 0.3999484797655526 valid 0.46483702858289083
LOSS train 0.3999484797655526 valid 0.4668440092355013
LOSS train 0.3999484797655526 valid 0.46957021776367636
LOSS train 0.3999484797655526 valid 0.47072860101858777
LOSS train 0.3999484797655526 valid 0.4713250665288222
LOSS train 0.3999484797655526 valid 0.47302453964948654
LOSS train 0.3999484797655526 valid 0.4720672851517087
LOSS train 0.3999484797655526 valid 0.46910570697350934
LOSS train 0.3999484797655526 valid 0.469997050969497
LOSS train 0.3999484797655526 valid 0.4684941867987315
LOSS train 0.3999484797655526 valid 0.46747055172920227
LOSS train 0.3999484797655526 valid 0.46689633337350994
LOSS train 0.3999484797655526 valid 0.46623916096157497
LOSS train 0.3999484797655526 valid 0.4669689152921949
LOSS train 0.3999484797655526 valid 0.4661763803712253
LOSS train 0.3999484797655526 valid 0.46696870227654774
LOSS train 0.3999484797655526 valid 0.4688445435416314
LOSS train 0.3999484797655526 valid 0.46883951500058174
LOSS train 0.3999484797655526 valid 0.47029857563249994
LOSS train 0.3999484797655526 valid 0.46952491823364706
LOSS train 0.3999484797655526 valid 0.4704169852393014
LOSS train 0.3999484797655526 valid 0.4706225097179413
LOSS train 0.3999484797655526 valid 0.47097105512747894
LOSS train 0.3999484797655526 valid 0.4722635895013809
LOSS train 0.3999484797655526 valid 0.4718184921986017
LOSS train 0.3999484797655526 valid 0.47327792569994925
LOSS train 0.3999484797655526 valid 0.4731382095232243
LOSS train 0.3999484797655526 valid 0.4742586946203595
LOSS train 0.3999484797655526 valid 0.474262758049854
LOSS train 0.3999484797655526 valid 0.47479125518690457
LOSS train 0.3999484797655526 valid 0.4750259021917979
LOSS train 0.3999484797655526 valid 0.47555555856746173
LOSS train 0.3999484797655526 valid 0.47477792742404534
LOSS train 0.3999484797655526 valid 0.47503333166241646
LOSS train 0.3999484797655526 valid 0.4756377096078834
LOSS train 0.3999484797655526 valid 0.4752511245012283
LOSS train 0.3999484797655526 valid 0.4758742212080488
LOSS train 0.3999484797655526 valid 0.47558370117957777
LOSS train 0.3999484797655526 valid 0.4750128354666368
LOSS train 0.3999484797655526 valid 0.4749958206106115
LOSS train 0.3999484797655526 valid 0.47449791431427
LOSS train 0.3999484797655526 valid 0.474230663052627
LOSS train 0.3999484797655526 valid 0.4740907157722272
LOSS train 0.3999484797655526 valid 0.47390542307804373
LOSS train 0.3999484797655526 valid 0.4746043050693253
LOSS train 0.3999484797655526 valid 0.47392290234565737
LOSS train 0.3999484797655526 valid 0.4727621044291825
LOSS train 0.3999484797655526 valid 0.47401771285841543
LOSS train 0.3999484797655526 valid 0.4743348019463675
LOSS train 0.3999484797655526 valid 0.4748893901705742
LOSS train 0.3999484797655526 valid 0.47511802499110883
LOSS train 0.3999484797655526 valid 0.475097834612384
LOSS train 0.3999484797655526 valid 0.4747087470631101
LOSS train 0.3999484797655526 valid 0.47413328158504825
LOSS train 0.3999484797655526 valid 0.4737324952215388
LOSS train 0.3999484797655526 valid 0.47329295320170267
LOSS train 0.3999484797655526 valid 0.4728208138069636
LOSS train 0.3999484797655526 valid 0.4725589905348089
LOSS train 0.3999484797655526 valid 0.4729719737621203
LOSS train 0.3999484797655526 valid 0.472822041527645
LOSS train 0.3999484797655526 valid 0.4722706115245819
LOSS train 0.3999484797655526 valid 0.47244257558333247
LOSS train 0.3999484797655526 valid 0.4722032152213059
LOSS train 0.3999484797655526 valid 0.4721624614336552
LOSS train 0.3999484797655526 valid 0.4718503944481475
LOSS train 0.3999484797655526 valid 0.4717964239418507
LOSS train 0.3999484797655526 valid 0.4712569146980474
LOSS train 0.3999484797655526 valid 0.47146540516760294
LOSS train 0.3999484797655526 valid 0.4712518920381385
LOSS train 0.3999484797655526 valid 0.47134291380643845
LOSS train 0.3999484797655526 valid 0.4714550684480106
LOSS train 0.3999484797655526 valid 0.470908964789191
LOSS train 0.3999484797655526 valid 0.47048818379983137
LOSS train 0.3999484797655526 valid 0.4699013917283578
LOSS train 0.3999484797655526 valid 0.47029995181587303
LOSS train 0.3999484797655526 valid 0.4703229082955254
LOSS train 0.3999484797655526 valid 0.46995616810662405
LOSS train 0.3999484797655526 valid 0.4695480423777
LOSS train 0.3999484797655526 valid 0.4689809907508153
LOSS train 0.3999484797655526 valid 0.46818863489526386
LOSS train 0.3999484797655526 valid 0.4677068719738408
LOSS train 0.3999484797655526 valid 0.46803709398955107
LOSS train 0.3999484797655526 valid 0.4684513263481179
LOSS train 0.3999484797655526 valid 0.4683820723879094
LOSS train 0.3999484797655526 valid 0.4686508455661812
LOSS train 0.3999484797655526 valid 0.469023140668869
LOSS train 0.3999484797655526 valid 0.46914711329016356
LOSS train 0.3999484797655526 valid 0.4691939979207282
LOSS train 0.3999484797655526 valid 0.4698347680777022
LOSS train 0.3999484797655526 valid 0.46966289986784643
LOSS train 0.3999484797655526 valid 0.4696704785029093
LOSS train 0.3999484797655526 valid 0.4698519897910784
LOSS train 0.3999484797655526 valid 0.4695365186606612
LOSS train 0.3999484797655526 valid 0.4699237216953878
LOSS train 0.3999484797655526 valid 0.47008931910226104
LOSS train 0.3999484797655526 valid 0.4701737487857992
LOSS train 0.3999484797655526 valid 0.4702550865508415
LOSS train 0.3999484797655526 valid 0.47002252962972435
LOSS train 0.3999484797655526 valid 0.4699335992336273
LOSS train 0.3999484797655526 valid 0.46971641219498816
LOSS train 0.3999484797655526 valid 0.46976205343785493
LOSS train 0.3999484797655526 valid 0.4697622911169611
LOSS train 0.3999484797655526 valid 0.46980741925728625
LOSS train 0.3999484797655526 valid 0.4695594063249685
LOSS train 0.3999484797655526 valid 0.4692526399588385
LOSS train 0.3999484797655526 valid 0.4691620394587517
LOSS train 0.3999484797655526 valid 0.4690278113380937
LOSS train 0.3999484797655526 valid 0.4689357952504862
LOSS train 0.3999484797655526 valid 0.469015382169708
LOSS train 0.3999484797655526 valid 0.4693384141691269
LOSS train 0.3999484797655526 valid 0.4691950855255127
LOSS train 0.3999484797655526 valid 0.4691249926884969
LOSS train 0.3999484797655526 valid 0.46958727489306235
LOSS train 0.3999484797655526 valid 0.46972938859835267
LOSS train 0.3999484797655526 valid 0.4699024567308352
LOSS train 0.3999484797655526 valid 0.46962477152164167
LOSS train 0.3999484797655526 valid 0.46959823460979316
LOSS train 0.3999484797655526 valid 0.46952392454400205
LOSS train 0.3999484797655526 valid 0.4693069012093365
LOSS train 0.3999484797655526 valid 0.4694999667690761
LOSS train 0.3999484797655526 valid 0.46974250983308863
LOSS train 0.3999484797655526 valid 0.46984588815008893
LOSS train 0.3999484797655526 valid 0.46964962138746774
LOSS train 0.3999484797655526 valid 0.4694924957078436
LOSS train 0.3999484797655526 valid 0.4691595803919456
LOSS train 0.3999484797655526 valid 0.46931191086769103
LOSS train 0.3999484797655526 valid 0.4693557197320546
LOSS train 0.3999484797655526 valid 0.469643856857864
LOSS train 0.3999484797655526 valid 0.4693165396476959
LOSS train 0.3999484797655526 valid 0.4693288178079658
LOSS train 0.3999484797655526 valid 0.46912534401334566
LOSS train 0.3999484797655526 valid 0.4694707777402172
LOSS train 0.3999484797655526 valid 0.46904157740729197
LOSS train 0.3999484797655526 valid 0.4694895051621102
LOSS train 0.3999484797655526 valid 0.4695631587665353
LOSS train 0.3999484797655526 valid 0.46969101289908094
LOSS train 0.3999484797655526 valid 0.46979913707600524
LOSS train 0.3999484797655526 valid 0.4695035621131721
LOSS train 0.3999484797655526 valid 0.46977803578563765
LOSS train 0.3999484797655526 valid 0.46974714061656553
LOSS train 0.3999484797655526 valid 0.4698935799060329
LOSS train 0.3999484797655526 valid 0.4702160310668823
LOSS train 0.3999484797655526 valid 0.47009828553837574
LOSS train 0.3999484797655526 valid 0.47002556505082527
LOSS train 0.3999484797655526 valid 0.46972282015302647
LOSS train 0.3999484797655526 valid 0.46974772922694685
LOSS train 0.3999484797655526 valid 0.4695986020639076
LOSS train 0.3999484797655526 valid 0.469208847961308
LOSS train 0.3999484797655526 valid 0.46912633056289577
LOSS train 0.3999484797655526 valid 0.468968746865668
LOSS train 0.3999484797655526 valid 0.468814940886064
LOSS train 0.3999484797655526 valid 0.46862559433443
LOSS train 0.3999484797655526 valid 0.4687198048937107
LOSS train 0.3999484797655526 valid 0.4689382809613432
LOSS train 0.3999484797655526 valid 0.4690980870695509
LOSS train 0.3999484797655526 valid 0.4695697779164595
LOSS train 0.3999484797655526 valid 0.4694446421157547
LOSS train 0.3999484797655526 valid 0.4694735581098601
LOSS train 0.3999484797655526 valid 0.4696058410440566
LOSS train 0.3999484797655526 valid 0.46959778067024277
LOSS train 0.3999484797655526 valid 0.4696964839526585
LOSS train 0.3999484797655526 valid 0.4695803038775921
LOSS train 0.3999484797655526 valid 0.4699512043241727
LOSS train 0.3999484797655526 valid 0.4701666132117925
LOSS train 0.3999484797655526 valid 0.4700005335847759
LOSS train 0.3999484797655526 valid 0.4700455213586489
LOSS train 0.3999484797655526 valid 0.4700189381014576
LOSS train 0.3999484797655526 valid 0.47013968458542454
LOSS train 0.3999484797655526 valid 0.4700238092349527
LOSS train 0.3999484797655526 valid 0.47025481935428537
LOSS train 0.3999484797655526 valid 0.47019549350480777
LOSS train 0.3999484797655526 valid 0.4702966764409055
LOSS train 0.3999484797655526 valid 0.4703227979614135
LOSS train 0.3999484797655526 valid 0.4703067205053695
LOSS train 0.3999484797655526 valid 0.47022623880199654
LOSS train 0.3999484797655526 valid 0.47006055446047534
LOSS train 0.3999484797655526 valid 0.4703366748637554
LOSS train 0.3999484797655526 valid 0.4704443090595305
LOSS train 0.3999484797655526 valid 0.47030723079498565
LOSS train 0.3999484797655526 valid 0.4701292593147337
LOSS train 0.3999484797655526 valid 0.47010915478070575
LOSS train 0.3999484797655526 valid 0.4702336211897889
LOSS train 0.3999484797655526 valid 0.47053840151293025
LOSS train 0.3999484797655526 valid 0.47056505038882745
LOSS train 0.3999484797655526 valid 0.47060783873850376
LOSS train 0.3999484797655526 valid 0.47053333148360255
LOSS train 0.3999484797655526 valid 0.47021963228633745
LOSS train 0.3999484797655526 valid 0.4703901955986967
LOSS train 0.3999484797655526 valid 0.4702205201381533
LOSS train 0.3999484797655526 valid 0.47024939778973074
LOSS train 0.3999484797655526 valid 0.470236400133226
LOSS train 0.3999484797655526 valid 0.47000614951536496
LOSS train 0.3999484797655526 valid 0.4702542140575999
LOSS train 0.3999484797655526 valid 0.4702638747313848
LOSS train 0.3999484797655526 valid 0.47012839904812537
LOSS train 0.3999484797655526 valid 0.4702557820649374
LOSS train 0.3999484797655526 valid 0.4703231260392338
LOSS train 0.3999484797655526 valid 0.4703845184928966
LOSS train 0.3999484797655526 valid 0.470421250857098
LOSS train 0.3999484797655526 valid 0.47038417093664686
LOSS train 0.3999484797655526 valid 0.4704164419063302
LOSS train 0.3999484797655526 valid 0.4704596880409453
LOSS train 0.3999484797655526 valid 0.4705106245207896
LOSS train 0.3999484797655526 valid 0.4706302990607165
LOSS train 0.3999484797655526 valid 0.4706104019461157
LOSS train 0.3999484797655526 valid 0.47080861871892754
LOSS train 0.3999484797655526 valid 0.47102617543207576
LOSS train 0.3999484797655526 valid 0.4710157450523462
LOSS train 0.3999484797655526 valid 0.471055895624674
LOSS train 0.3999484797655526 valid 0.4711093557998538
LOSS train 0.3999484797655526 valid 0.4711529256237878
LOSS train 0.3999484797655526 valid 0.47113266666378595
LOSS train 0.3999484797655526 valid 0.47120902073540877
LOSS train 0.3999484797655526 valid 0.4711698572102346
LOSS train 0.3999484797655526 valid 0.4712844682312428
LOSS train 0.3999484797655526 valid 0.47140942928583723
LOSS train 0.3999484797655526 valid 0.47150792162139693
LOSS train 0.3999484797655526 valid 0.4715599448516451
LOSS train 0.3999484797655526 valid 0.47147191542924216
LOSS train 0.3999484797655526 valid 0.47141346972212833
LOSS train 0.3999484797655526 valid 0.4716070205607313
LOSS train 0.3999484797655526 valid 0.4714799083895602
LOSS train 0.3999484797655526 valid 0.47137932058125104
LOSS train 0.3999484797655526 valid 0.47133386686068623
LOSS train 0.3999484797655526 valid 0.47116222341689107
LOSS train 0.3999484797655526 valid 0.4710057164231936
LOSS train 0.3999484797655526 valid 0.4712763450947045
LOSS train 0.3999484797655526 valid 0.47116472947696025
LOSS train 0.3999484797655526 valid 0.4711002366533005
LOSS train 0.3999484797655526 valid 0.47122041905512574
LOSS train 0.3999484797655526 valid 0.47124430257446914
LOSS train 0.3999484797655526 valid 0.47122927216010363
LOSS train 0.3999484797655526 valid 0.4712990819201296
LOSS train 0.3999484797655526 valid 0.47125803018289225
LOSS train 0.3999484797655526 valid 0.4712889413517642
LOSS train 0.3999484797655526 valid 0.47156502640247344
LOSS train 0.3999484797655526 valid 0.47163973588392555
LOSS train 0.3999484797655526 valid 0.471908736678343
LOSS train 0.3999484797655526 valid 0.471756504929584
LOSS train 0.3999484797655526 valid 0.4719549208644807
LOSS train 0.3999484797655526 valid 0.4719658811887105
LOSS train 0.3999484797655526 valid 0.4719167178263888
LOSS train 0.3999484797655526 valid 0.4719100138788557
LOSS train 0.3999484797655526 valid 0.47194691718548765
LOSS train 0.3999484797655526 valid 0.47191894537693746
LOSS train 0.3999484797655526 valid 0.4717671827628062
LOSS train 0.3999484797655526 valid 0.47179906692541423
LOSS train 0.3999484797655526 valid 0.4717305384519446
LOSS train 0.3999484797655526 valid 0.4716666053003231
LOSS train 0.3999484797655526 valid 0.47158581041025394
LOSS train 0.3999484797655526 valid 0.4715750842724206
LOSS train 0.3999484797655526 valid 0.4717244124950323
LOSS train 0.3999484797655526 valid 0.4719196294577381
LOSS train 0.3999484797655526 valid 0.47207946808480505
LOSS train 0.3999484797655526 valid 0.47232254685965613
LOSS train 0.3999484797655526 valid 0.47225075584870796
LOSS train 0.3999484797655526 valid 0.4723689136030049
LOSS train 0.3999484797655526 valid 0.4724748728468138
LOSS train 0.3999484797655526 valid 0.4725124226821648
LOSS train 0.3999484797655526 valid 0.4725330197898141
LOSS train 0.3999484797655526 valid 0.47245350794358687
LOSS train 0.3999484797655526 valid 0.4724422795833021
LOSS train 0.3999484797655526 valid 0.4725319516142353
LOSS train 0.3999484797655526 valid 0.47247111207718473
LOSS train 0.3999484797655526 valid 0.47254446394554606
LOSS train 0.3999484797655526 valid 0.47240617339100155
LOSS train 0.3999484797655526 valid 0.47221288922842714
LOSS train 0.3999484797655526 valid 0.4721733498657849
LOSS train 0.3999484797655526 valid 0.4721810694507491
LOSS train 0.3999484797655526 valid 0.47223816171918115
LOSS train 0.3999484797655526 valid 0.4721822536828225
LOSS train 0.3999484797655526 valid 0.4720334217890159
LOSS train 0.3999484797655526 valid 0.4720762388631442
LOSS train 0.3999484797655526 valid 0.47199073371787864
LOSS train 0.3999484797655526 valid 0.47209603708095615
LOSS train 0.3999484797655526 valid 0.4721110510415044
LOSS train 0.3999484797655526 valid 0.4719485200147858
LOSS train 0.3999484797655526 valid 0.47198674684926256
LOSS train 0.3999484797655526 valid 0.4718431473388607
LOSS train 0.3999484797655526 valid 0.47190242894247275
LOSS train 0.3999484797655526 valid 0.47208247962644545
LOSS train 0.3999484797655526 valid 0.47201027922533656
LOSS train 0.3999484797655526 valid 0.4720391875967032
LOSS train 0.3999484797655526 valid 0.47190487364794587
LOSS train 0.3999484797655526 valid 0.47200096949287085
LOSS train 0.3999484797655526 valid 0.4720039528608322
LOSS train 0.3999484797655526 valid 0.4720068568011059
LOSS train 0.3999484797655526 valid 0.4718624518209735
LOSS train 0.3999484797655526 valid 0.4717879601240945
LOSS train 0.3999484797655526 valid 0.47185078586794826
LOSS train 0.3999484797655526 valid 0.4718160222788326
LOSS train 0.3999484797655526 valid 0.4718354128155054
LOSS train 0.3999484797655526 valid 0.4717973152278689
LOSS train 0.3999484797655526 valid 0.47169287947865274
LOSS train 0.3999484797655526 valid 0.4717024221389425
LOSS train 0.3999484797655526 valid 0.4717282489422829
LOSS train 0.3999484797655526 valid 0.47171871215584193
LOSS train 0.3999484797655526 valid 0.4717284452456694
LOSS train 0.3999484797655526 valid 0.47183929159999277
LOSS train 0.3999484797655526 valid 0.4717944709548525
LOSS train 0.3999484797655526 valid 0.47176895870102775
LOSS train 0.3999484797655526 valid 0.471661250142357
LOSS train 0.3999484797655526 valid 0.4716987097488969
LOSS train 0.3999484797655526 valid 0.4717044085264206
LOSS train 0.3999484797655526 valid 0.4717243625826223
LOSS train 0.3999484797655526 valid 0.4716916872188449
LOSS train 0.3999484797655526 valid 0.47168979382960596
LOSS train 0.3999484797655526 valid 0.47171052364829164
LOSS train 0.3999484797655526 valid 0.4717021530995797
LOSS train 0.3999484797655526 valid 0.47168100873629254
LOSS train 0.3999484797655526 valid 0.4716183858651381
LOSS train 0.3999484797655526 valid 0.47171693418654925
LOSS train 0.3999484797655526 valid 0.4718710989762519
LOSS train 0.3999484797655526 valid 0.4718433449544558
LOSS train 0.3999484797655526 valid 0.4718799976954707
LOSS train 0.3999484797655526 valid 0.47183665669325625
LOSS train 0.3999484797655526 valid 0.4717829375108563
LOSS train 0.3999484797655526 valid 0.4716567621532693
LOSS train 0.3999484797655526 valid 0.4717019203904871
LOSS train 0.3999484797655526 valid 0.47175379338378676
LOSS train 0.3999484797655526 valid 0.4717709552885881
LOSS train 0.3999484797655526 valid 0.4717285552372535
LOSS train 0.3999484797655526 valid 0.4717410618898069
LOSS train 0.3999484797655526 valid 0.471769353958982
LOSS train 0.3999484797655526 valid 0.47170607574218143
LOSS train 0.3999484797655526 valid 0.47175356211031183
LOSS train 0.3999484797655526 valid 0.47161548097462247
LOSS train 0.3999484797655526 valid 0.47144779170814316
LOSS train 0.3999484797655526 valid 0.47145708960972443
LOSS train 0.3999484797655526 valid 0.47167539778490397
LOSS train 0.3999484797655526 valid 0.4717437194741291
LOSS train 0.3999484797655526 valid 0.47173872409183853
LOSS train 0.3999484797655526 valid 0.47167958392189974
LOSS train 0.3999484797655526 valid 0.4715515339169009
LOSS train 0.3999484797655526 valid 0.471588731751401
LOSS train 0.3999484797655526 valid 0.4714614067758833
LOSS train 0.3999484797655526 valid 0.47139567799038357
LOSS train 0.3999484797655526 valid 0.4714356402612545
LOSS train 0.3999484797655526 valid 0.4714628985684587
LOSS train 0.3999484797655526 valid 0.47151043514410657
LOSS train 0.3999484797655526 valid 0.47152962625866207
LOSS train 0.3999484797655526 valid 0.47152530083830435
LOSS train 0.3999484797655526 valid 0.4714582519037049
LOSS train 0.3999484797655526 valid 0.4713745691589803
LOSS train 0.3999484797655526 valid 0.4714248122279026
LOSS train 0.3999484797655526 valid 0.4714454859495163
LOSS train 0.3999484797655526 valid 0.47147888655147396
LOSS train 0.3999484797655526 valid 0.47163873663923356
LOSS train 0.3999484797655526 valid 0.47156176849501846
LOSS train 0.3999484797655526 valid 0.47150160183945855
LOSS train 0.3999484797655526 valid 0.4715502534010639
LOSS train 0.3999484797655526 valid 0.47149176692050665
LOSS train 0.3999484797655526 valid 0.4714059650248338
LOSS train 0.3999484797655526 valid 0.47141094562476094
LOSS train 0.3999484797655526 valid 0.4714058164335525
Selected network (scan_genome.py) = bimodal
bimodal selected
bichrom_seq(
  (conv1d): Conv1d(4, 256, kernel_size=(24,), stride=(1,))
  (relu): ReLU()
  (batchNorm1d): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (maxPool1d): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=True)
  (lstm): LSTM(256, 32, batch_first=True)
  (tanh): Tanh()
  (model_dense_repeat): Sequential(
    (0): Linear(in_features=32, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=512, out_features=512, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.5, inplace=False)
  )
  (linear): Linear(in_features=512, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
bimodal_network(
  (base_model): bichrom_seq(
    (conv1d): Conv1d(4, 256, kernel_size=(24,), stride=(1,))
    (relu): ReLU()
    (batchNorm1d): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (maxPool1d): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=True)
    (lstm): LSTM(256, 32, batch_first=True)
    (tanh): Tanh()
    (model_dense_repeat): Sequential(
      (0): Linear(in_features=32, out_features=512, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=512, out_features=512, bias=True)
      (4): ReLU()
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=512, out_features=512, bias=True)
      (7): ReLU()
      (8): Dropout(p=0.5, inplace=False)
    )
    (linear): Linear(in_features=512, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
  (linear): Linear(in_features=512, out_features=1, bias=True)
  (tanh): Tanh()
  (model): bichrom_chrom(
    (_reshape): _reshape()
    (conv1d): Conv1d(12, 15, kernel_size=(1,), stride=(1,), padding=valid)
    (relu): ReLU()
    (lstm): LSTM(15, 5, batch_first=True)
    (relu2): ReLU()
    (linear): Linear(in_features=5, out_features=1, bias=True)
    (tanh): Tanh()
  )
  (linear2): Linear(in_features=2, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
0.2026578073089701
0.2101328903654485
	4h11m3.05s real		5h33m4.13s user		1h25m16.42s sys
