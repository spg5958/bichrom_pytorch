Training seq
DEVICE = mps
####################
Total Parameters = 605185
Total Trainable Parameters = 605185
bichrom_seq(
  (conv1d): Conv1d(4, 256, kernel_size=(24,), stride=(1,))
  (relu): ReLU()
  (batchNorm1d): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (maxPool1d): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=True)
  (lstm): LSTM(256, 32, batch_first=True)
  (tanh): Tanh()
  (model_dense_repeat): Sequential(
    (0): Linear(in_features=32, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=512, out_features=512, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.5, inplace=False)
  )
  (linear): Linear(in_features=512, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
####################
EPOCH 1:
  batch 1 loss: 0.6942312121391296
  batch 2 loss: 0.6933141648769379
  batch 3 loss: 0.694541354974111
  batch 4 loss: 0.6939951330423355
  batch 5 loss: 0.6945032477378845
  batch 6 loss: 0.6942918399969736
  batch 7 loss: 0.6942000985145569
  batch 8 loss: 0.6944807320833206
  batch 9 loss: 0.6942922804090712
  batch 10 loss: 0.6943651020526886
  batch 11 loss: 0.6942437616261569
  batch 12 loss: 0.6942598174015681
  batch 13 loss: 0.6941322455039391
  batch 14 loss: 0.6941158388342176
  batch 15 loss: 0.6940271099408467
  batch 16 loss: 0.6937993876636028
  batch 17 loss: 0.6935937439694124
  batch 18 loss: 0.6935092442565494
  batch 19 loss: 0.6932992213650754
  batch 20 loss: 0.6933856099843979
  batch 21 loss: 0.6934645828746614
  batch 22 loss: 0.693451548164541
  batch 23 loss: 0.6934990234996962
  batch 24 loss: 0.6935723250110944
  batch 25 loss: 0.6935060954093933
  batch 26 loss: 0.6933947434792151
  batch 27 loss: 0.6933400277738218
  batch 28 loss: 0.6933474029813494
  batch 29 loss: 0.6933572723947722
  batch 30 loss: 0.6933038771152497
  batch 31 loss: 0.6932479085460785
  batch 32 loss: 0.6930980440229177
  batch 33 loss: 0.6929028630256653
  batch 34 loss: 0.693055287880056
  batch 35 loss: 0.692967849118369
  batch 36 loss: 0.6928112192286385
  batch 37 loss: 0.6927130528398462
  batch 38 loss: 0.6926260198417463
  batch 39 loss: 0.6924783266507663
  batch 40 loss: 0.6923709943890571
  batch 41 loss: 0.6923306904188017
  batch 42 loss: 0.6921425986857641
  batch 43 loss: 0.6921461501786875
  batch 44 loss: 0.691943882541223
  batch 45 loss: 0.6918111708429124
  batch 46 loss: 0.6918502566607102
  batch 47 loss: 0.6920803113186613
  batch 48 loss: 0.6919299811124802
  batch 49 loss: 0.6918677286225923
  batch 50 loss: 0.6916522431373596
  batch 51 loss: 0.6915136914627225
  batch 52 loss: 0.6913916376920847
  batch 53 loss: 0.6912989076578392
  batch 54 loss: 0.6910785127569128
  batch 55 loss: 0.6907332225279375
  batch 56 loss: 0.6903964344944272
  batch 57 loss: 0.6903608922372785
  batch 58 loss: 0.6903649363024481
  batch 59 loss: 0.6899774882753017
  batch 60 loss: 0.6899005889892578
  batch 61 loss: 0.6897789728446085
  batch 62 loss: 0.6895199552659066
  batch 63 loss: 0.6891802341218979
  batch 64 loss: 0.6889031687751412
  batch 65 loss: 0.6886210835897005
  batch 66 loss: 0.6884379540428971
  batch 67 loss: 0.6881918809307155
  batch 68 loss: 0.6881596410975737
  batch 69 loss: 0.687902153402135
  batch 70 loss: 0.6875558776514871
  batch 71 loss: 0.6872011910022144
  batch 72 loss: 0.6870380424790912
  batch 73 loss: 0.6869873739268682
  batch 74 loss: 0.686748934758676
  batch 75 loss: 0.6868398507436116
  batch 76 loss: 0.6871290991180822
  batch 77 loss: 0.6867987730286338
  batch 78 loss: 0.6864102200055734
  batch 79 loss: 0.6861098672770247
  batch 80 loss: 0.6862491279840469
  batch 81 loss: 0.6859371941766621
  batch 82 loss: 0.6858309143927039
  batch 83 loss: 0.6856864877493984
  batch 84 loss: 0.6856949315184638
  batch 85 loss: 0.6856414247961605
  batch 86 loss: 0.6855780510015266
  batch 87 loss: 0.6854454950354565
  batch 88 loss: 0.6851154294880953
  batch 89 loss: 0.6849488575806778
  batch 90 loss: 0.68479702340232
  batch 91 loss: 0.6847094978604998
  batch 92 loss: 0.6845984141463819
  batch 93 loss: 0.6844343543052673
  batch 94 loss: 0.6841783764514517
  batch 95 loss: 0.6840466323651766
  batch 96 loss: 0.6837399248033762
  batch 97 loss: 0.6833618062058675
  batch 98 loss: 0.6830935654591541
  batch 99 loss: 0.6829153967626167
  batch 100 loss: 0.6827558028697968
  batch 101 loss: 0.6826736171646873
  batch 102 loss: 0.6824930018069697
  batch 103 loss: 0.6823086703865273
  batch 104 loss: 0.6821516700662099
  batch 105 loss: 0.6818496488389515
  batch 106 loss: 0.6815997440859957
  batch 107 loss: 0.6816270139729865
  batch 108 loss: 0.6813316256911667
  batch 109 loss: 0.6812253698296503
  batch 110 loss: 0.6811510216106068
  batch 111 loss: 0.6810577968219379
  batch 112 loss: 0.6808052169425147
  batch 113 loss: 0.6805185912984663
  batch 114 loss: 0.6804103950659434
  batch 115 loss: 0.6802464936090552
  batch 116 loss: 0.6803609908654772
  batch 117 loss: 0.6801237953014863
  batch 118 loss: 0.6800509479086277
  batch 119 loss: 0.6798197171267342
  batch 120 loss: 0.6795800139506658
  batch 121 loss: 0.67935592675012
  batch 122 loss: 0.6792154263277523
  batch 123 loss: 0.6790328985307275
  batch 124 loss: 0.6788553326360641
  batch 125 loss: 0.6787579936981201
  batch 126 loss: 0.6785018817772941
  batch 127 loss: 0.6782666125635463
  batch 128 loss: 0.6781441634520888
  batch 129 loss: 0.6778365216513936
  batch 130 loss: 0.6775550718490894
  batch 131 loss: 0.6778013838156489
  batch 132 loss: 0.6775899190794338
  batch 133 loss: 0.6774395327819022
  batch 134 loss: 0.6772246307401515
  batch 135 loss: 0.6770637150164004
  batch 136 loss: 0.6770063270540798
  batch 137 loss: 0.6769983202871614
  batch 138 loss: 0.676855496738268
  batch 139 loss: 0.6768159909214048
  batch 140 loss: 0.6765302236591066
  batch 141 loss: 0.6763055354145402
  batch 142 loss: 0.6761019863712956
  batch 143 loss: 0.6758141392594451
  batch 144 loss: 0.6757174308101336
  batch 145 loss: 0.6754822044536986
  batch 146 loss: 0.6754957645723264
  batch 147 loss: 0.675375513884486
  batch 148 loss: 0.6751901261709832
  batch 149 loss: 0.675026313970553
  batch 150 loss: 0.6748981527487437
  batch 151 loss: 0.6750900417763666
  batch 152 loss: 0.6751353701478556
  batch 153 loss: 0.6751012248930588
  batch 154 loss: 0.6750168978393852
  batch 155 loss: 0.6749536495054922
  batch 156 loss: 0.6749328928880203
  batch 157 loss: 0.6749077818955586
  batch 158 loss: 0.6748911659174328
  batch 159 loss: 0.6747440856957586
  batch 160 loss: 0.6746990144252777
  batch 161 loss: 0.6745874259782874
  batch 162 loss: 0.674409803049064
  batch 163 loss: 0.6743715657778313
  batch 164 loss: 0.6744408302190827
  batch 165 loss: 0.6743247097188776
  batch 166 loss: 0.6743008099406599
  batch 167 loss: 0.674150833826579
  batch 168 loss: 0.6740716784482911
  batch 169 loss: 0.6739831644402453
  batch 170 loss: 0.6739500855698305
  batch 171 loss: 0.6738782936369466
  batch 172 loss: 0.6737745546324309
  batch 173 loss: 0.6737519637008623
  batch 174 loss: 0.6736838851851978
  batch 175 loss: 0.6735253749574934
  batch 176 loss: 0.673472037030892
  batch 177 loss: 0.6732598357954941
  batch 178 loss: 0.673224063066954
  batch 179 loss: 0.6730829410712812
  batch 180 loss: 0.6729256007406447
  batch 181 loss: 0.6728166203472495
  batch 182 loss: 0.6726858642075088
  batch 183 loss: 0.6726331085455223
  batch 184 loss: 0.6725143712499867
  batch 185 loss: 0.672392705646721
  batch 186 loss: 0.672288393141121
  batch 187 loss: 0.672179361078191
  batch 188 loss: 0.6720825332276364
  batch 189 loss: 0.6718793615462288
  batch 190 loss: 0.6717407841431468
  batch 191 loss: 0.6716972592613459
  batch 192 loss: 0.6715142279863358
  batch 193 loss: 0.6714082344826021
  batch 194 loss: 0.6712686468645469
  batch 195 loss: 0.6711627840995789
  batch 196 loss: 0.6711121207597305
  batch 197 loss: 0.6711178485512128
  batch 198 loss: 0.6711248538710854
  batch 199 loss: 0.6710825316870033
  batch 200 loss: 0.670986732840538
  batch 201 loss: 0.670847650191084
  batch 202 loss: 0.6707785507239917
  batch 203 loss: 0.6706902311353261
  batch 204 loss: 0.6706476725784003
  batch 205 loss: 0.6705631197952643
  batch 206 loss: 0.6704775002396223
  batch 207 loss: 0.6704946940647807
  batch 208 loss: 0.6703851383465987
  batch 209 loss: 0.6702851881250811
  batch 210 loss: 0.670146803344999
  batch 211 loss: 0.6701200943422544
  batch 212 loss: 0.6700119772609675
  batch 213 loss: 0.669853731220317
  batch 214 loss: 0.6697291403173287
  batch 215 loss: 0.669552507788636
  batch 216 loss: 0.669409234766607
  batch 217 loss: 0.6692865161302453
  batch 218 loss: 0.669173989547502
  batch 219 loss: 0.6690374735283525
  batch 220 loss: 0.668904257091609
  batch 221 loss: 0.6689275090511029
  batch 222 loss: 0.6688660670508135
  batch 223 loss: 0.668789863051855
  batch 224 loss: 0.6686802719320569
  batch 225 loss: 0.6685180642869737
  batch 226 loss: 0.6683483308395454
  batch 227 loss: 0.6681635752648509
  batch 228 loss: 0.6680641352084645
  batch 229 loss: 0.6679589704134579
  batch 230 loss: 0.6678815149742624
  batch 231 loss: 0.6678710595353857
  batch 232 loss: 0.6678337942937325
  batch 233 loss: 0.6678011355993574
  batch 234 loss: 0.6676789122259515
  batch 235 loss: 0.66763387309744
  batch 236 loss: 0.6674820247848156
  batch 237 loss: 0.6675080164072382
  batch 238 loss: 0.6674780762996995
  batch 239 loss: 0.6673890958271266
  batch 240 loss: 0.6672992584606011
  batch 241 loss: 0.6672676576618337
  batch 242 loss: 0.667068263715949
  batch 243 loss: 0.6669792133103672
  batch 244 loss: 0.666964555128676
  batch 245 loss: 0.6668533505225668
  batch 246 loss: 0.6668290200272227
  batch 247 loss: 0.6667587081430412
  batch 248 loss: 0.6666873419477094
  batch 249 loss: 0.6666653539282251
  batch 250 loss: 0.6666018731594086
  batch 251 loss: 0.6665764959209943
  batch 252 loss: 0.6664373659425311
  batch 253 loss: 0.6663270371233522
  batch 254 loss: 0.6662065302293132
  batch 255 loss: 0.6661075884220646
  batch 256 loss: 0.6660226902458817
  batch 257 loss: 0.6659686361305445
  batch 258 loss: 0.6658493751703307
  batch 259 loss: 0.6656856704862881
  batch 260 loss: 0.6656155852171091
  batch 261 loss: 0.6654695272445679
  batch 262 loss: 0.6653568266912271
  batch 263 loss: 0.6651840321011416
  batch 264 loss: 0.6650910429430731
  batch 265 loss: 0.6650390611504609
  batch 266 loss: 0.6648972948691002
  batch 267 loss: 0.6647580315111282
  batch 268 loss: 0.6645484368747739
  batch 269 loss: 0.6644466585829355
  batch 270 loss: 0.664272646330021
  batch 271 loss: 0.6640282132528805
  batch 272 loss: 0.6638978360330358
  batch 273 loss: 0.6637437415646983
  batch 274 loss: 0.6636275403255963
  batch 275 loss: 0.6636356737396933
  batch 276 loss: 0.6634820045336433
  batch 277 loss: 0.663384458648599
  batch 278 loss: 0.6632254333804837
  batch 279 loss: 0.6630991996402809
  batch 280 loss: 0.6628902750355857
  batch 281 loss: 0.6627759978016076
  batch 282 loss: 0.6625857359551369
  batch 283 loss: 0.6625024596288431
  batch 284 loss: 0.6625341987106163
  batch 285 loss: 0.66233962711535
  batch 286 loss: 0.6621876229773035
  batch 287 loss: 0.6621127153522877
  batch 288 loss: 0.6619087194816934
  batch 289 loss: 0.6618847378809972
  batch 290 loss: 0.6616747258038357
  batch 291 loss: 0.6615945278983755
  batch 292 loss: 0.661585249517062
  batch 293 loss: 0.6614493784644091
  batch 294 loss: 0.661361392055239
  batch 295 loss: 0.6612708966610795
  batch 296 loss: 0.6611428085613895
  batch 297 loss: 0.6610216315747913
  batch 298 loss: 0.6608646412023762
  batch 299 loss: 0.6608654376256426
  batch 300 loss: 0.6607895918687184
  batch 301 loss: 0.6606971936368466
  batch 302 loss: 0.6606139963036342
  batch 303 loss: 0.6604888868017165
  batch 304 loss: 0.6603851890877673
  batch 305 loss: 0.6601807559122804
  batch 306 loss: 0.6600983078573265
  batch 307 loss: 0.6599286350054538
  batch 308 loss: 0.6598198940227558
  batch 309 loss: 0.6597244230288903
  batch 310 loss: 0.6596708947612393
  batch 311 loss: 0.6595835467243502
  batch 312 loss: 0.6595828439562749
  batch 313 loss: 0.6595864040783038
  batch 314 loss: 0.6595205956963217
  batch 315 loss: 0.6594374955646576
  batch 316 loss: 0.6593408086631871
  batch 317 loss: 0.6593266985017795
  batch 318 loss: 0.6592227953409998
  batch 319 loss: 0.6591458847530209
  batch 320 loss: 0.6590508662164212
  batch 321 loss: 0.6589618184113428
  batch 322 loss: 0.6588441290840599
  batch 323 loss: 0.6587612911274559
  batch 324 loss: 0.6586590841596509
  batch 325 loss: 0.6586252549978403
  batch 326 loss: 0.6584570056821671
  batch 327 loss: 0.6583292724889352
  batch 328 loss: 0.6582288714807208
  batch 329 loss: 0.6581932934946565
  batch 330 loss: 0.6580200164607077
  batch 331 loss: 0.6579062344444483
  batch 332 loss: 0.6578227597546865
  batch 333 loss: 0.6577250191399285
  batch 334 loss: 0.6575873699373828
  batch 335 loss: 0.6574518911874117
  batch 336 loss: 0.6573068293787184
  batch 337 loss: 0.6571428170897486
  batch 338 loss: 0.6570371960747171
  batch 339 loss: 0.6569362164950301
  batch 340 loss: 0.656840861194274
  batch 341 loss: 0.6566816571870507
  batch 342 loss: 0.6566004756598445
  batch 343 loss: 0.6564936655255865
  batch 344 loss: 0.6564206413404886
  batch 345 loss: 0.6564675875332044
  batch 346 loss: 0.6563533549708438
  batch 347 loss: 0.6563254094948343
  batch 348 loss: 0.6562956684622271
  batch 349 loss: 0.65622221330517
  batch 350 loss: 0.6561526376860483
  batch 351 loss: 0.6561071524592886
  batch 352 loss: 0.656013473360376
  batch 353 loss: 0.6558791745148029
  batch 354 loss: 0.6557805846303196
  batch 355 loss: 0.6557351503573673
  batch 356 loss: 0.6556630523017283
  batch 357 loss: 0.6556436805164113
  batch 358 loss: 0.6555453082702679
  batch 359 loss: 0.6555056063909717
  batch 360 loss: 0.6554497255219354
  batch 361 loss: 0.6553389709081676
  batch 362 loss: 0.6552641576166311
  batch 363 loss: 0.6552190618081526
  batch 364 loss: 0.6550757208695779
  batch 365 loss: 0.6549988519655515
  batch 366 loss: 0.6549174215624242
  batch 367 loss: 0.6548219149379054
  batch 368 loss: 0.654759567392909
  batch 369 loss: 0.654714503908545
  batch 370 loss: 0.6546545457195592
  batch 371 loss: 0.6546071097857226
  batch 372 loss: 0.6544971256166376
  batch 373 loss: 0.6544528375042667
  batch 374 loss: 0.6543865178358108
  batch 375 loss: 0.6542870155970255
  batch 376 loss: 0.6542308023001285
  batch 377 loss: 0.6541429007084996
  batch 378 loss: 0.6540707335585639
  batch 379 loss: 0.6539797600466847
  batch 380 loss: 0.6539529527488508
  batch 381 loss: 0.6538029478916659
  batch 382 loss: 0.6536603863326667
  batch 383 loss: 0.6535561143885082
  batch 384 loss: 0.6534789355161289
  batch 385 loss: 0.6534170619853131
  batch 386 loss: 0.6533423892265774
  batch 387 loss: 0.6532638057565813
  batch 388 loss: 0.6532681971481166
  batch 389 loss: 0.6531865579916456
  batch 390 loss: 0.6530516332540757
  batch 391 loss: 0.6529425481701141
  batch 392 loss: 0.6528724576441609
  batch 393 loss: 0.6528052663378436
  batch 394 loss: 0.6526733822931493
  batch 395 loss: 0.6525540428825571
  batch 396 loss: 0.6524601145224138
  batch 397 loss: 0.652339910980436
  batch 398 loss: 0.6521637604464239
  batch 399 loss: 0.6520730646929347
  batch 400 loss: 0.6519752551615238
  batch 401 loss: 0.6518604704864007
  batch 402 loss: 0.6517966361484717
  batch 403 loss: 0.6516762256030705
  batch 404 loss: 0.6515615042483452
  batch 405 loss: 0.6515091504579709
  batch 406 loss: 0.6514363332922235
  batch 407 loss: 0.6513992386895258
  batch 408 loss: 0.6513482904901692
  batch 409 loss: 0.6512778551479423
  batch 410 loss: 0.6511848753545343
  batch 411 loss: 0.6510947213265728
  batch 412 loss: 0.6510037332773209
  batch 413 loss: 0.6509187124831913
  batch 414 loss: 0.6508466666159423
  batch 415 loss: 0.6507629213562931
  batch 416 loss: 0.6506817082946117
  batch 417 loss: 0.6506367530182398
  batch 418 loss: 0.6505114724191182
  batch 419 loss: 0.6504405987291176
  batch 420 loss: 0.6503785691090993
  batch 421 loss: 0.6502983741409138
  batch 422 loss: 0.6502970781936465
  batch 423 loss: 0.6502190398549921
  batch 424 loss: 0.6501084798068371
  batch 425 loss: 0.6500503124910243
  batch 426 loss: 0.64992940369906
  batch 427 loss: 0.6498740420129316
  batch 428 loss: 0.649743522021258
  batch 429 loss: 0.6496262365565711
  batch 430 loss: 0.6496070519436238
  batch 431 loss: 0.6495611146265282
  batch 432 loss: 0.6494692195620801
  batch 433 loss: 0.6493659062143287
  batch 434 loss: 0.6493374728662078
  batch 435 loss: 0.6492237569271833
  batch 436 loss: 0.6491755865035801
  batch 437 loss: 0.6491007476158491
  batch 438 loss: 0.6490374521849906
  batch 439 loss: 0.6489794394149867
  batch 440 loss: 0.648932514407418
  batch 441 loss: 0.6489006683669664
  batch 442 loss: 0.6487084287324103
  batch 443 loss: 0.6486488357354502
  batch 444 loss: 0.6485354255985569
  batch 445 loss: 0.6484597323985583
  batch 446 loss: 0.6483554126435865
  batch 447 loss: 0.6482564678928197
  batch 448 loss: 0.6481692007343683
  batch 449 loss: 0.6481258982008443
  batch 450 loss: 0.6480356438954671
  batch 451 loss: 0.6479426154540542
  batch 452 loss: 0.6478481891408431
  batch 453 loss: 0.6477991310965936
  batch 454 loss: 0.6477505287672455
  batch 455 loss: 0.6476981583532396
  batch 456 loss: 0.6475713744498136
  batch 457 loss: 0.6475282460125061
  batch 458 loss: 0.6474764426462515
  batch 459 loss: 0.6474760837025113
  batch 460 loss: 0.6474338615718095
  batch 461 loss: 0.6473578646488148
  batch 462 loss: 0.6472913181626951
  batch 463 loss: 0.6472483427941671
  batch 464 loss: 0.647271486191914
  batch 465 loss: 0.6471398912450319
  batch 466 loss: 0.6470028456188578
  batch 467 loss: 0.6469449989290258
  batch 468 loss: 0.6468446792190911
  batch 469 loss: 0.646789744718751
  batch 470 loss: 0.6466810075526542
  batch 471 loss: 0.6466641029987619
  batch 472 loss: 0.6465706762115834
LOSS train 0.6465706762115834 valid 0.5062761306762695
LOSS train 0.6465706762115834 valid 0.5043627023696899
LOSS train 0.6465706762115834 valid 0.5173118313153585
LOSS train 0.6465706762115834 valid 0.5163454860448837
LOSS train 0.6465706762115834 valid 0.5102869689464569
LOSS train 0.6465706762115834 valid 0.5118227352698644
LOSS train 0.6465706762115834 valid 0.5159570021288735
LOSS train 0.6465706762115834 valid 0.51841014996171
LOSS train 0.6465706762115834 valid 0.5165953801737891
LOSS train 0.6465706762115834 valid 0.5174536973237991
LOSS train 0.6465706762115834 valid 0.5199998969381506
LOSS train 0.6465706762115834 valid 0.5192227587103844
LOSS train 0.6465706762115834 valid 0.5214834740528693
LOSS train 0.6465706762115834 valid 0.5217008611985615
LOSS train 0.6465706762115834 valid 0.5214958449204763
LOSS train 0.6465706762115834 valid 0.5230546649545431
LOSS train 0.6465706762115834 valid 0.5250732355258044
LOSS train 0.6465706762115834 valid 0.5250049216879739
LOSS train 0.6465706762115834 valid 0.5256684124469757
LOSS train 0.6465706762115834 valid 0.5257656708359718
LOSS train 0.6465706762115834 valid 0.5247565862678346
LOSS train 0.6465706762115834 valid 0.523837535218759
LOSS train 0.6465706762115834 valid 0.5256145091160483
LOSS train 0.6465706762115834 valid 0.5260632075369358
LOSS train 0.6465706762115834 valid 0.5255337631702424
LOSS train 0.6465706762115834 valid 0.5252330360504297
LOSS train 0.6465706762115834 valid 0.5252623944370834
LOSS train 0.6465706762115834 valid 0.5257143282464573
LOSS train 0.6465706762115834 valid 0.5255415141582489
LOSS train 0.6465706762115834 valid 0.525776132941246
LOSS train 0.6465706762115834 valid 0.5260711341134964
LOSS train 0.6465706762115834 valid 0.52535389829427
LOSS train 0.6465706762115834 valid 0.5262185777678634
LOSS train 0.6465706762115834 valid 0.5260134102667079
LOSS train 0.6465706762115834 valid 0.5263344092028481
LOSS train 0.6465706762115834 valid 0.5266817915770743
LOSS train 0.6465706762115834 valid 0.5272568343458949
LOSS train 0.6465706762115834 valid 0.5279242623793451
LOSS train 0.6465706762115834 valid 0.5278596243797204
LOSS train 0.6465706762115834 valid 0.5285460732877254
LOSS train 0.6465706762115834 valid 0.5290169723150207
LOSS train 0.6465706762115834 valid 0.5294586583262398
LOSS train 0.6465706762115834 valid 0.5288887446702912
LOSS train 0.6465706762115834 valid 0.5290177728642117
LOSS train 0.6465706762115834 valid 0.5287663929992252
LOSS train 0.6465706762115834 valid 0.5289506283791169
LOSS train 0.6465706762115834 valid 0.5284629267580966
LOSS train 0.6465706762115834 valid 0.5286595169454813
LOSS train 0.6465706762115834 valid 0.5290749431872854
LOSS train 0.6465706762115834 valid 0.5281679433584213
LOSS train 0.6465706762115834 valid 0.5286093570438086
LOSS train 0.6465706762115834 valid 0.5281663806392596
LOSS train 0.6465706762115834 valid 0.528431976178907
LOSS train 0.6465706762115834 valid 0.5282748479534078
LOSS train 0.6465706762115834 valid 0.5279229472983967
LOSS train 0.6465706762115834 valid 0.5276108517178467
LOSS train 0.6465706762115834 valid 0.5278081376301614
LOSS train 0.6465706762115834 valid 0.527572228476919
LOSS train 0.6465706762115834 valid 0.5280591638411506
LOSS train 0.6465706762115834 valid 0.5279944246013959
LOSS train 0.6465706762115834 valid 0.5273914317615697
LOSS train 0.6465706762115834 valid 0.5279540794510995
LOSS train 0.6465706762115834 valid 0.5285096802408733
LOSS train 0.6465706762115834 valid 0.5288845533505082
LOSS train 0.6465706762115834 valid 0.5293108380757845
LOSS train 0.6465706762115834 valid 0.5294814010461172
LOSS train 0.6465706762115834 valid 0.5290355735750341
LOSS train 0.6465706762115834 valid 0.5289550660287633
LOSS train 0.6465706762115834 valid 0.5287573069765947
LOSS train 0.6465706762115834 valid 0.5284893121038164
LOSS train 0.6465706762115834 valid 0.5281842502070145
LOSS train 0.6465706762115834 valid 0.5278042513463232
LOSS train 0.6465706762115834 valid 0.5278014018111032
LOSS train 0.6465706762115834 valid 0.5277025345209483
LOSS train 0.6465706762115834 valid 0.5276153302192688
LOSS train 0.6465706762115834 valid 0.5277282305453953
LOSS train 0.6465706762115834 valid 0.527818982477312
LOSS train 0.6465706762115834 valid 0.5275312578066801
LOSS train 0.6465706762115834 valid 0.5273293822626525
LOSS train 0.6465706762115834 valid 0.5274473764002323
LOSS train 0.6465706762115834 valid 0.527189913355274
LOSS train 0.6465706762115834 valid 0.527156074599522
LOSS train 0.6465706762115834 valid 0.5269162504069776
LOSS train 0.6465706762115834 valid 0.5271248661336445
LOSS train 0.6465706762115834 valid 0.526993862320395
LOSS train 0.6465706762115834 valid 0.5267711531284244
LOSS train 0.6465706762115834 valid 0.5267273269850632
LOSS train 0.6465706762115834 valid 0.5262881876392798
LOSS train 0.6465706762115834 valid 0.5264778746647781
LOSS train 0.6465706762115834 valid 0.5263590150409274
LOSS train 0.6465706762115834 valid 0.5264216576303754
LOSS train 0.6465706762115834 valid 0.5265634014554645
LOSS train 0.6465706762115834 valid 0.5265423629873542
LOSS train 0.6465706762115834 valid 0.5264831064863408
LOSS train 0.6465706762115834 valid 0.5263609503444873
LOSS train 0.6465706762115834 valid 0.5260841979955634
LOSS train 0.6465706762115834 valid 0.5261451088890587
LOSS train 0.6465706762115834 valid 0.5260729385273797
LOSS train 0.6465706762115834 valid 0.5262059740947954
LOSS train 0.6465706762115834 valid 0.526357488334179
LOSS train 0.6465706762115834 valid 0.5263954421671311
LOSS train 0.6465706762115834 valid 0.5263306957249548
LOSS train 0.6465706762115834 valid 0.5265500073872723
LOSS train 0.6465706762115834 valid 0.5264787608041213
LOSS train 0.6465706762115834 valid 0.5265141331014179
LOSS train 0.6465706762115834 valid 0.5264440755236823
LOSS train 0.6465706762115834 valid 0.5263812477900603
LOSS train 0.6465706762115834 valid 0.5265051990195557
LOSS train 0.6465706762115834 valid 0.5265261807026119
LOSS train 0.6465706762115834 valid 0.526649876887148
LOSS train 0.6465706762115834 valid 0.5267233346496616
LOSS train 0.6465706762115834 valid 0.5265497504068273
LOSS train 0.6465706762115834 valid 0.5265724920066057
LOSS train 0.6465706762115834 valid 0.5264485894065154
LOSS train 0.6465706762115834 valid 0.5264449583447498
LOSS train 0.6465706762115834 valid 0.5264817078051895
LOSS train 0.6465706762115834 valid 0.526518378757004
LOSS train 0.6465706762115834 valid 0.5262665756173053
LOSS train 0.6465706762115834 valid 0.5260816058691811
LOSS train 0.6465706762115834 valid 0.5260213839511076
LOSS train 0.6465706762115834 valid 0.5259205716207993
LOSS train 0.6465706762115834 valid 0.5259385150475581
LOSS train 0.6465706762115834 valid 0.5258006528625644
LOSS train 0.6465706762115834 valid 0.5259923259577444
LOSS train 0.6465706762115834 valid 0.526002780675888
LOSS train 0.6465706762115834 valid 0.5259319612431148
LOSS train 0.6465706762115834 valid 0.5260700895561008
LOSS train 0.6465706762115834 valid 0.5262997418176383
LOSS train 0.6465706762115834 valid 0.5264981359012367
LOSS train 0.6465706762115834 valid 0.5263343015542397
LOSS train 0.6465706762115834 valid 0.5264766655350459
LOSS train 0.6465706762115834 valid 0.5264728261214314
LOSS train 0.6465706762115834 valid 0.5263931430820236
LOSS train 0.6465706762115834 valid 0.5264119285700927
LOSS train 0.6465706762115834 valid 0.5263907589294292
LOSS train 0.6465706762115834 valid 0.5264524657498387
LOSS train 0.6465706762115834 valid 0.5263181139517875
LOSS train 0.6465706762115834 valid 0.5262727769820587
LOSS train 0.6465706762115834 valid 0.5260879991294669
LOSS train 0.6465706762115834 valid 0.5260746340666499
LOSS train 0.6465706762115834 valid 0.5261628050753411
LOSS train 0.6465706762115834 valid 0.5264488674805198
LOSS train 0.6465706762115834 valid 0.5263916677111512
LOSS train 0.6465706762115834 valid 0.5264256751785675
LOSS train 0.6465706762115834 valid 0.5262666174050035
LOSS train 0.6465706762115834 valid 0.52640405766768
LOSS train 0.6465706762115834 valid 0.5262948779427276
LOSS train 0.6465706762115834 valid 0.5265535222920211
LOSS train 0.6465706762115834 valid 0.5265456652081253
LOSS train 0.6465706762115834 valid 0.5265020471811295
LOSS train 0.6465706762115834 valid 0.526531904541104
LOSS train 0.6465706762115834 valid 0.5263638016032545
LOSS train 0.6465706762115834 valid 0.5263928063944274
LOSS train 0.6465706762115834 valid 0.5264195910134872
LOSS train 0.6465706762115834 valid 0.5264738561645631
LOSS train 0.6465706762115834 valid 0.5266685350201069
LOSS train 0.6465706762115834 valid 0.5267130537017896
LOSS train 0.6465706762115834 valid 0.5267208684471589
LOSS train 0.6465706762115834 valid 0.526509628918186
LOSS train 0.6465706762115834 valid 0.5266022911295295
LOSS train 0.6465706762115834 valid 0.5264931367421002
LOSS train 0.6465706762115834 valid 0.5261992133326001
LOSS train 0.6465706762115834 valid 0.5262107072066675
LOSS train 0.6465706762115834 valid 0.5261298765133067
LOSS train 0.6465706762115834 valid 0.5260386111158313
LOSS train 0.6465706762115834 valid 0.52590224847018
LOSS train 0.6465706762115834 valid 0.5260423127405658
LOSS train 0.6465706762115834 valid 0.5262387123491082
LOSS train 0.6465706762115834 valid 0.526298605655072
LOSS train 0.6465706762115834 valid 0.5264304492403479
LOSS train 0.6465706762115834 valid 0.5265060525540023
LOSS train 0.6465706762115834 valid 0.5264216150308765
LOSS train 0.6465706762115834 valid 0.5265147804869392
LOSS train 0.6465706762115834 valid 0.5264175135171276
LOSS train 0.6465706762115834 valid 0.5264740744658879
LOSS train 0.6465706762115834 valid 0.526553014293313
LOSS train 0.6465706762115834 valid 0.5266312032432879
LOSS train 0.6465706762115834 valid 0.5266950189062719
LOSS train 0.6465706762115834 valid 0.5266579021621682
LOSS train 0.6465706762115834 valid 0.5266617813044124
LOSS train 0.6465706762115834 valid 0.5266603190266625
LOSS train 0.6465706762115834 valid 0.5266485163471201
LOSS train 0.6465706762115834 valid 0.5266613733898746
LOSS train 0.6465706762115834 valid 0.526868278403645
LOSS train 0.6465706762115834 valid 0.5267011963032388
LOSS train 0.6465706762115834 valid 0.5267387787180562
LOSS train 0.6465706762115834 valid 0.5267835503274744
LOSS train 0.6465706762115834 valid 0.5268401368818385
LOSS train 0.6465706762115834 valid 0.5267695868141437
LOSS train 0.6465706762115834 valid 0.5266169584111163
LOSS train 0.6465706762115834 valid 0.5267990685570303
LOSS train 0.6465706762115834 valid 0.5267422719237705
LOSS train 0.6465706762115834 valid 0.5267711048607999
LOSS train 0.6465706762115834 valid 0.5265877411230323
LOSS train 0.6465706762115834 valid 0.5265490126915467
LOSS train 0.6465706762115834 valid 0.5267473013729466
LOSS train 0.6465706762115834 valid 0.5269090722357561
LOSS train 0.6465706762115834 valid 0.5269630610039739
LOSS train 0.6465706762115834 valid 0.5269077790142903
LOSS train 0.6465706762115834 valid 0.5269973649084568
LOSS train 0.6465706762115834 valid 0.5269305556271207
LOSS train 0.6465706762115834 valid 0.5270052355999993
LOSS train 0.6465706762115834 valid 0.5269173646501719
LOSS train 0.6465706762115834 valid 0.5270108818715694
LOSS train 0.6465706762115834 valid 0.5269972008902852
LOSS train 0.6465706762115834 valid 0.5269821912628933
LOSS train 0.6465706762115834 valid 0.5270759015555543
LOSS train 0.6465706762115834 valid 0.5270798835330285
LOSS train 0.6465706762115834 valid 0.5269532510253231
LOSS train 0.6465706762115834 valid 0.5269901274215607
LOSS train 0.6465706762115834 valid 0.5269514253071699
LOSS train 0.6465706762115834 valid 0.5268956210534528
LOSS train 0.6465706762115834 valid 0.5268368649650628
LOSS train 0.6465706762115834 valid 0.5267151821160985
LOSS train 0.6465706762115834 valid 0.5267299295857896
LOSS train 0.6465706762115834 valid 0.526871474114833
LOSS train 0.6465706762115834 valid 0.5269046836459692
LOSS train 0.6465706762115834 valid 0.5268090729593137
LOSS train 0.6465706762115834 valid 0.5267770392437504
LOSS train 0.6465706762115834 valid 0.5268439781936732
LOSS train 0.6465706762115834 valid 0.5269170995481414
LOSS train 0.6465706762115834 valid 0.5270317203558244
LOSS train 0.6465706762115834 valid 0.5271866322900147
LOSS train 0.6465706762115834 valid 0.5272042233762997
LOSS train 0.6465706762115834 valid 0.527149508661694
LOSS train 0.6465706762115834 valid 0.5270769610605409
LOSS train 0.6465706762115834 valid 0.5272115026539118
LOSS train 0.6465706762115834 valid 0.5272164223225493
LOSS train 0.6465706762115834 valid 0.5271478179500613
LOSS train 0.6465706762115834 valid 0.5270758251781049
LOSS train 0.6465706762115834 valid 0.5271313485903141
LOSS train 0.6465706762115834 valid 0.52716898982381
LOSS train 0.6465706762115834 valid 0.5270937462477213
LOSS train 0.6465706762115834 valid 0.5269907204768597
LOSS train 0.6465706762115834 valid 0.5270580549189385
LOSS train 0.6465706762115834 valid 0.5268721450435914
LOSS train 0.6465706762115834 valid 0.5268584460900303
LOSS train 0.6465706762115834 valid 0.5268075928217223
LOSS train 0.6465706762115834 valid 0.5267839542742054
LOSS train 0.6465706762115834 valid 0.5267573444793622
LOSS train 0.6465706762115834 valid 0.526782469507075
LOSS train 0.6465706762115834 valid 0.5267921103672548
LOSS train 0.6465706762115834 valid 0.5267891855642138
LOSS train 0.6465706762115834 valid 0.5268293539764451
LOSS train 0.6465706762115834 valid 0.5268215380152877
LOSS train 0.6465706762115834 valid 0.5268604868068928
LOSS train 0.6465706762115834 valid 0.5268448688964612
LOSS train 0.6465706762115834 valid 0.5267773403996422
LOSS train 0.6465706762115834 valid 0.5267183066132557
LOSS train 0.6465706762115834 valid 0.5267836292982101
LOSS train 0.6465706762115834 valid 0.5267925755198734
LOSS train 0.6465706762115834 valid 0.5269629471595325
LOSS train 0.6465706762115834 valid 0.5270100109897583
LOSS train 0.6465706762115834 valid 0.5271470242832589
LOSS train 0.6465706762115834 valid 0.5270980656147003
LOSS train 0.6465706762115834 valid 0.5270830775843933
LOSS train 0.6465706762115834 valid 0.5270421575711395
LOSS train 0.6465706762115834 valid 0.5270534394554389
LOSS train 0.6465706762115834 valid 0.5270323027284909
LOSS train 0.6465706762115834 valid 0.5270568949671892
LOSS train 0.6465706762115834 valid 0.5270641367325838
LOSS train 0.6465706762115834 valid 0.5271088520761664
LOSS train 0.6465706762115834 valid 0.5271727276165675
LOSS train 0.6465706762115834 valid 0.5271542698822238
LOSS train 0.6465706762115834 valid 0.5271918736538797
LOSS train 0.6465706762115834 valid 0.5272408366427386
LOSS train 0.6465706762115834 valid 0.527216616306412
LOSS train 0.6465706762115834 valid 0.5271885009176696
LOSS train 0.6465706762115834 valid 0.5272891965718961
LOSS train 0.6465706762115834 valid 0.5272541287872526
LOSS train 0.6465706762115834 valid 0.5273260996570447
LOSS train 0.6465706762115834 valid 0.5274356100708246
LOSS train 0.6465706762115834 valid 0.5275613572789636
LOSS train 0.6465706762115834 valid 0.5276227951267339
LOSS train 0.6465706762115834 valid 0.5275689993121407
LOSS train 0.6465706762115834 valid 0.527607478633307
LOSS train 0.6465706762115834 valid 0.5275903089166979
LOSS train 0.6465706762115834 valid 0.5275026406529996
LOSS train 0.6465706762115834 valid 0.527549967864081
LOSS train 0.6465706762115834 valid 0.52747007768069
LOSS train 0.6465706762115834 valid 0.5274301499022284
LOSS train 0.6465706762115834 valid 0.527360016889606
LOSS train 0.6465706762115834 valid 0.5273209230006795
LOSS train 0.6465706762115834 valid 0.527391442425654
LOSS train 0.6465706762115834 valid 0.5274243249182116
LOSS train 0.6465706762115834 valid 0.5273596405774563
LOSS train 0.6465706762115834 valid 0.5272887061489584
LOSS train 0.6465706762115834 valid 0.5272713995849093
LOSS train 0.6465706762115834 valid 0.5272801195667689
LOSS train 0.6465706762115834 valid 0.5272687781473686
LOSS train 0.6465706762115834 valid 0.5271431039698755
LOSS train 0.6465706762115834 valid 0.5271783324137126
LOSS train 0.6465706762115834 valid 0.5271509110724153
LOSS train 0.6465706762115834 valid 0.5272169796382489
LOSS train 0.6465706762115834 valid 0.5272509382942976
LOSS train 0.6465706762115834 valid 0.5272799986037048
LOSS train 0.6465706762115834 valid 0.5272626521611454
LOSS train 0.6465706762115834 valid 0.5272984686713891
LOSS train 0.6465706762115834 valid 0.5274026712845001
LOSS train 0.6465706762115834 valid 0.5273876257737478
LOSS train 0.6465706762115834 valid 0.5273693752447236
LOSS train 0.6465706762115834 valid 0.5273081468825309
LOSS train 0.6465706762115834 valid 0.5273209918450208
LOSS train 0.6465706762115834 valid 0.5272185999507967
LOSS train 0.6465706762115834 valid 0.5271535858756206
LOSS train 0.6465706762115834 valid 0.5271449705549315
LOSS train 0.6465706762115834 valid 0.5271619539889917
LOSS train 0.6465706762115834 valid 0.5271402406808617
LOSS train 0.6465706762115834 valid 0.5271605476013665
LOSS train 0.6465706762115834 valid 0.5271091531361303
LOSS train 0.6465706762115834 valid 0.5270857675857482
LOSS train 0.6465706762115834 valid 0.5270975724053688
LOSS train 0.6465706762115834 valid 0.5271847020513334
LOSS train 0.6465706762115834 valid 0.5273184287510101
LOSS train 0.6465706762115834 valid 0.5273009711787814
LOSS train 0.6465706762115834 valid 0.52722955815777
LOSS train 0.6465706762115834 valid 0.527221248446955
LOSS train 0.6465706762115834 valid 0.5272552518162338
LOSS train 0.6465706762115834 valid 0.5272570983930067
LOSS train 0.6465706762115834 valid 0.5272107514552772
LOSS train 0.6465706762115834 valid 0.5272305885393671
LOSS train 0.6465706762115834 valid 0.5272401207537385
LOSS train 0.6465706762115834 valid 0.5271881500449342
LOSS train 0.6465706762115834 valid 0.5271920119354754
LOSS train 0.6465706762115834 valid 0.5271440897538112
LOSS train 0.6465706762115834 valid 0.5271687195893445
LOSS train 0.6465706762115834 valid 0.5272083832036465
LOSS train 0.6465706762115834 valid 0.5271645263746018
LOSS train 0.6465706762115834 valid 0.5271355568637964
LOSS train 0.6465706762115834 valid 0.5271020303169887
LOSS train 0.6465706762115834 valid 0.52711494586619
LOSS train 0.6465706762115834 valid 0.5270556616316359
LOSS train 0.6465706762115834 valid 0.5270784267255136
LOSS train 0.6465706762115834 valid 0.5270647955333402
LOSS train 0.6465706762115834 valid 0.5269827334738489
LOSS train 0.6465706762115834 valid 0.5270335119927213
LOSS train 0.6465706762115834 valid 0.5270431047907923
LOSS train 0.6465706762115834 valid 0.5271549864104513
LOSS train 0.6465706762115834 valid 0.5270948036406244
LOSS train 0.6465706762115834 valid 0.5270078016554608
LOSS train 0.6465706762115834 valid 0.5270486441700339
LOSS train 0.6465706762115834 valid 0.527064054768685
LOSS train 0.6465706762115834 valid 0.5270447036789041
LOSS train 0.6465706762115834 valid 0.5271269867066727
LOSS train 0.6465706762115834 valid 0.5271266497563625
LOSS train 0.6465706762115834 valid 0.5271156791145402
LOSS train 0.6465706762115834 valid 0.5271462417645139
LOSS train 0.6465706762115834 valid 0.5271417816308723
LOSS train 0.6465706762115834 valid 0.5271671920758605
LOSS train 0.6465706762115834 valid 0.5272022203888211
LOSS train 0.6465706762115834 valid 0.5271831948702831
LOSS train 0.6465706762115834 valid 0.527208635837517
LOSS train 0.6465706762115834 valid 0.5272217533912604
LOSS train 0.6465706762115834 valid 0.5272599136256902
LOSS train 0.6465706762115834 valid 0.5273071897701478
LOSS train 0.6465706762115834 valid 0.5273522524518913
LOSS train 0.6465706762115834 valid 0.5273732318430722
LOSS train 0.6465706762115834 valid 0.5272673194468355
LOSS train 0.6465706762115834 valid 0.527292986517165
LOSS train 0.6465706762115834 valid 0.5273412109249168
LOSS train 0.6465706762115834 valid 0.5273352976155743
LOSS train 0.6465706762115834 valid 0.5273525911635457
LOSS train 0.6465706762115834 valid 0.5273424579913294
LOSS train 0.6465706762115834 valid 0.5273096721087184
LOSS train 0.6465706762115834 valid 0.5273791060872274
LOSS train 0.6465706762115834 valid 0.5273589647369958
LOSS train 0.6465706762115834 valid 0.5273139495453327
LOSS train 0.6465706762115834 valid 0.5273147201894418
LOSS train 0.6465706762115834 valid 0.527261452542411
EPOCH 2:
  batch 1 loss: 0.6197861433029175
  batch 2 loss: 0.6106989085674286
  batch 3 loss: 0.6112121939659119
  batch 4 loss: 0.6171208322048187
  batch 5 loss: 0.6165371656417846
  batch 6 loss: 0.616551399230957
  batch 7 loss: 0.6204040816852024
  batch 8 loss: 0.6214877143502235
  batch 9 loss: 0.6216173503133986
  batch 10 loss: 0.6218160450458526
  batch 11 loss: 0.6223626190965826
  batch 12 loss: 0.6245873967806498
  batch 13 loss: 0.6262059532679044
  batch 14 loss: 0.627528075660978
  batch 15 loss: 0.6278197964032491
  batch 16 loss: 0.627393338829279
  batch 17 loss: 0.627416260102216
  batch 18 loss: 0.62888193792767
  batch 19 loss: 0.6313319394462987
  batch 20 loss: 0.6323034882545471
  batch 21 loss: 0.6332882557596479
  batch 22 loss: 0.6344992897727273
  batch 23 loss: 0.6352475648340972
  batch 24 loss: 0.6362502674261729
  batch 25 loss: 0.6369677782058716
  batch 26 loss: 0.6373496949672699
  batch 27 loss: 0.6378160825482121
  batch 28 loss: 0.6382836380175182
  batch 29 loss: 0.6388983130455017
  batch 30 loss: 0.6398001889387767
  batch 31 loss: 0.6399215479050914
  batch 32 loss: 0.6406780909746885
  batch 33 loss: 0.6411849802190607
  batch 34 loss: 0.642543771687676
  batch 35 loss: 0.6426760946001325
  batch 36 loss: 0.6429771780967712
  batch 37 loss: 0.6432792882661562
  batch 38 loss: 0.6432733755362662
  batch 39 loss: 0.6435458568426279
  batch 40 loss: 0.6438738912343979
  batch 41 loss: 0.644289304570454
  batch 42 loss: 0.6447501877943674
  batch 43 loss: 0.645231772300809
  batch 44 loss: 0.6448172466321425
  batch 45 loss: 0.6451457685894436
  batch 46 loss: 0.6453361977701602
  batch 47 loss: 0.6456672714111653
  batch 48 loss: 0.6457682363688946
  batch 49 loss: 0.64554441705042
  batch 50 loss: 0.645507105588913
  batch 51 loss: 0.6458635575631085
  batch 52 loss: 0.6461722174516091
  batch 53 loss: 0.6468697572654148
  batch 54 loss: 0.6470407611793942
  batch 55 loss: 0.6468795657157898
  batch 56 loss: 0.6470846512487957
  batch 57 loss: 0.6471475289579023
  batch 58 loss: 0.6475853930259573
  batch 59 loss: 0.6479330679117623
  batch 60 loss: 0.6481210122505824
  batch 61 loss: 0.6484848622415886
  batch 62 loss: 0.6486523295602491
  batch 63 loss: 0.648679618797605
  batch 64 loss: 0.6486592385917902
  batch 65 loss: 0.648717267696674
  batch 66 loss: 0.6487884810476592
  batch 67 loss: 0.6489112982109412
  batch 68 loss: 0.6489900140201345
  batch 69 loss: 0.6488790840342424
  batch 70 loss: 0.6488437856946673
  batch 71 loss: 0.6491136685223646
  batch 72 loss: 0.6491081830528047
  batch 73 loss: 0.6493597667511195
  batch 74 loss: 0.6492442851131027
  batch 75 loss: 0.649179896513621
  batch 76 loss: 0.6494905689829275
  batch 77 loss: 0.6495374774003958
  batch 78 loss: 0.6492623602732633
  batch 79 loss: 0.6493900674807874
  batch 80 loss: 0.6497124440968036
  batch 81 loss: 0.6498703434143538
  batch 82 loss: 0.6502122522854223
  batch 83 loss: 0.6502326274492655
  batch 84 loss: 0.650274498122079
  batch 85 loss: 0.6503067956251256
  batch 86 loss: 0.6505811616431835
  batch 87 loss: 0.6507718275333273
  batch 88 loss: 0.6508094654841856
  batch 89 loss: 0.6508494240514348
  batch 90 loss: 0.6509102953804864
  batch 91 loss: 0.6509442905803303
  batch 92 loss: 0.6511037557021432
  batch 93 loss: 0.6512036387638379
  batch 94 loss: 0.6511618057464031
  batch 95 loss: 0.6511645906849911
  batch 96 loss: 0.6511931084096432
  batch 97 loss: 0.6513370533579403
  batch 98 loss: 0.6514698236572499
  batch 99 loss: 0.6515078454306631
  batch 100 loss: 0.6517764842510223
  batch 101 loss: 0.6518695820676218
  batch 102 loss: 0.6520240283479878
  batch 103 loss: 0.6520462927309055
  batch 104 loss: 0.6522412615326735
  batch 105 loss: 0.6522133918035597
  batch 106 loss: 0.6522986360316007
  batch 107 loss: 0.6521440270905182
  batch 108 loss: 0.6521851127898252
  batch 109 loss: 0.6524405293508407
  batch 110 loss: 0.6526977013457905
  batch 111 loss: 0.6527346093375404
  batch 112 loss: 0.6528411842882633
  batch 113 loss: 0.6528351422959724
  batch 114 loss: 0.6528980836533663
  batch 115 loss: 0.652998051436051
  batch 116 loss: 0.6531408984085609
  batch 117 loss: 0.653128347845159
  batch 118 loss: 0.6530741533990634
  batch 119 loss: 0.6531353888391447
  batch 120 loss: 0.6530320763587951
  batch 121 loss: 0.6529779375092057
  batch 122 loss: 0.6527935886969332
  batch 123 loss: 0.6527868572289381
  batch 124 loss: 0.6528109754285505
  batch 125 loss: 0.6528485012054444
  batch 126 loss: 0.6528222948785812
  batch 127 loss: 0.6528751512212078
  batch 128 loss: 0.6528685018420219
  batch 129 loss: 0.6529052396153294
  batch 130 loss: 0.6528749319223257
  batch 131 loss: 0.6531302692325971
  batch 132 loss: 0.6532079220721216
  batch 133 loss: 0.653258302606138
  batch 134 loss: 0.6532459948489915
  batch 135 loss: 0.6532387163903978
  batch 136 loss: 0.6533173677675864
  batch 137 loss: 0.6533751988062894
  batch 138 loss: 0.6533078076182932
  batch 139 loss: 0.6532801029493482
  batch 140 loss: 0.6533018533672605
  batch 141 loss: 0.6533194750758773
  batch 142 loss: 0.6532551931663299
  batch 143 loss: 0.6531334440191309
  batch 144 loss: 0.6530921860701508
  batch 145 loss: 0.65293850035503
  batch 146 loss: 0.6530245440463497
  batch 147 loss: 0.6531464149351833
  batch 148 loss: 0.6530059616307955
  batch 149 loss: 0.6529569337832047
  batch 150 loss: 0.6528735466798147
  batch 151 loss: 0.6528610871327634
  batch 152 loss: 0.6529243906077585
  batch 153 loss: 0.652882429898954
  batch 154 loss: 0.652880156582052
  batch 155 loss: 0.6529725843860257
  batch 156 loss: 0.6529249713206903
  batch 157 loss: 0.6529959694595094
  batch 158 loss: 0.6529234764696676
  batch 159 loss: 0.6528679271164181
  batch 160 loss: 0.6529453720897436
  batch 161 loss: 0.652885961976851
  batch 162 loss: 0.6527577064655445
  batch 163 loss: 0.6527133445066908
  batch 164 loss: 0.652846023440361
  batch 165 loss: 0.6527838898427558
  batch 166 loss: 0.652816016630954
  batch 167 loss: 0.6528460961615968
  batch 168 loss: 0.652887534172762
  batch 169 loss: 0.6527268897146868
  batch 170 loss: 0.6529216938159045
  batch 171 loss: 0.6529201492231492
  batch 172 loss: 0.6529018026451732
  batch 173 loss: 0.6530725645881168
  batch 174 loss: 0.65310449744093
  batch 175 loss: 0.6532091767447336
  batch 176 loss: 0.6532873010093515
  batch 177 loss: 0.6532061396345581
  batch 178 loss: 0.65322240316466
  batch 179 loss: 0.65321201119343
  batch 180 loss: 0.653107492129008
  batch 181 loss: 0.6531731097737729
  batch 182 loss: 0.6531703956834563
  batch 183 loss: 0.6532137260410955
  batch 184 loss: 0.6531518121128497
  batch 185 loss: 0.6531896987476864
  batch 186 loss: 0.6532039107174001
  batch 187 loss: 0.6532341423519155
  batch 188 loss: 0.6532202800537678
  batch 189 loss: 0.6531086050013386
  batch 190 loss: 0.6531062756714068
  batch 191 loss: 0.6532549727025456
  batch 192 loss: 0.653230898703138
  batch 193 loss: 0.6532059932619797
  batch 194 loss: 0.6530896652605116
  batch 195 loss: 0.6531656931608151
  batch 196 loss: 0.6532748037455033
  batch 197 loss: 0.65331841301797
  batch 198 loss: 0.6531918545564016
  batch 199 loss: 0.6533605719930563
  batch 200 loss: 0.6534587773680687
  batch 201 loss: 0.653429912393959
  batch 202 loss: 0.6533931791782379
  batch 203 loss: 0.6534707508063669
  batch 204 loss: 0.6534681393235338
  batch 205 loss: 0.653550892632182
  batch 206 loss: 0.6535599489235183
  batch 207 loss: 0.6535078085563033
  batch 208 loss: 0.6534207509114192
  batch 209 loss: 0.6534861685556658
  batch 210 loss: 0.6535073802584693
  batch 211 loss: 0.653548250266161
  batch 212 loss: 0.6535649035336837
  batch 213 loss: 0.6534983859935277
  batch 214 loss: 0.653495605025336
  batch 215 loss: 0.6535309833149577
  batch 216 loss: 0.6534873790763043
  batch 217 loss: 0.6534094346283768
  batch 218 loss: 0.6534937847098079
  batch 219 loss: 0.6535064202465423
  batch 220 loss: 0.6534703384746204
  batch 221 loss: 0.6534773683116447
  batch 222 loss: 0.6534903017250268
  batch 223 loss: 0.6534243274162703
  batch 224 loss: 0.6533437791679587
  batch 225 loss: 0.6532009058528476
  batch 226 loss: 0.6532015792563953
  batch 227 loss: 0.6531132155052891
  batch 228 loss: 0.6530184460836544
  batch 229 loss: 0.6530090927036568
  batch 230 loss: 0.6530262177405151
  batch 231 loss: 0.6530131398341357
  batch 232 loss: 0.6531398563549436
  batch 233 loss: 0.6531761659573077
  batch 234 loss: 0.6530306145676181
  batch 235 loss: 0.653112050066603
  batch 236 loss: 0.6531719908875934
  batch 237 loss: 0.6531485148120028
  batch 238 loss: 0.6531185339979765
  batch 239 loss: 0.6531483822786658
  batch 240 loss: 0.6531375586986542
  batch 241 loss: 0.6531450993292559
  batch 242 loss: 0.653147453118947
  batch 243 loss: 0.6531763562449703
  batch 244 loss: 0.6531553014380033
  batch 245 loss: 0.6531842295004398
  batch 246 loss: 0.6531464045609885
  batch 247 loss: 0.6530998274382309
  batch 248 loss: 0.6531213372945786
  batch 249 loss: 0.65310532070068
  batch 250 loss: 0.6531830749511719
  batch 251 loss: 0.6531101607706442
  batch 252 loss: 0.653177369208563
  batch 253 loss: 0.6531104165103596
  batch 254 loss: 0.6531042315828519
  batch 255 loss: 0.6530099146506365
  batch 256 loss: 0.652956209378317
  batch 257 loss: 0.6529870889066258
  batch 258 loss: 0.6529364213925
  batch 259 loss: 0.6528963359166297
  batch 260 loss: 0.652807768033101
  batch 261 loss: 0.6527495217506
  batch 262 loss: 0.6527497886701394
  batch 263 loss: 0.6526902730474
  batch 264 loss: 0.6526579421126482
  batch 265 loss: 0.6526284595705428
  batch 266 loss: 0.652579711344009
  batch 267 loss: 0.6525902091787102
  batch 268 loss: 0.6525023214852632
  batch 269 loss: 0.6524364912820129
  batch 270 loss: 0.6523701195363645
  batch 271 loss: 0.6523409681566527
  batch 272 loss: 0.6523363892646397
  batch 273 loss: 0.6523321460891556
  batch 274 loss: 0.6522693829814883
  batch 275 loss: 0.6523400662162088
  batch 276 loss: 0.6523678332999132
  batch 277 loss: 0.6524123654899184
  batch 278 loss: 0.6523292364834024
  batch 279 loss: 0.6522883915986639
  batch 280 loss: 0.6523173813308988
  batch 281 loss: 0.6523889803801567
  batch 282 loss: 0.6523475266517477
  batch 283 loss: 0.6523487513141161
  batch 284 loss: 0.6523892669610574
  batch 285 loss: 0.652359298028444
  batch 286 loss: 0.652346489937989
  batch 287 loss: 0.652337079056464
  batch 288 loss: 0.6523013456414143
  batch 289 loss: 0.6523030623020185
  batch 290 loss: 0.6522698897739937
  batch 291 loss: 0.6521975332519033
  batch 292 loss: 0.6522008088761813
  batch 293 loss: 0.6521718072809863
  batch 294 loss: 0.6521371282687803
  batch 295 loss: 0.6522181848348197
  batch 296 loss: 0.6521217686098975
  batch 297 loss: 0.6521031388931403
  batch 298 loss: 0.652025262581422
  batch 299 loss: 0.6519896730930111
  batch 300 loss: 0.6520673696200053
  batch 301 loss: 0.6521705090009493
  batch 302 loss: 0.6520996703612094
  batch 303 loss: 0.6521503614513787
  batch 304 loss: 0.652086171076486
  batch 305 loss: 0.652032416570382
  batch 306 loss: 0.6520248972902111
  batch 307 loss: 0.6519880820951555
  batch 308 loss: 0.6519918039247588
  batch 309 loss: 0.6519578440675458
  batch 310 loss: 0.6519304137076101
  batch 311 loss: 0.6518868414918709
  batch 312 loss: 0.6519540857810241
  batch 313 loss: 0.6520357269067734
  batch 314 loss: 0.6521005398908238
  batch 315 loss: 0.6520982513352046
  batch 316 loss: 0.6521131737699991
  batch 317 loss: 0.652116226285038
  batch 318 loss: 0.6520500031282317
  batch 319 loss: 0.6520492486819205
  batch 320 loss: 0.6519758440554142
  batch 321 loss: 0.6519521857347815
  batch 322 loss: 0.6519237630855963
  batch 323 loss: 0.6519374053913742
  batch 324 loss: 0.6519342651705683
  batch 325 loss: 0.6518921534831708
  batch 326 loss: 0.6518889385864047
  batch 327 loss: 0.651864775277059
  batch 328 loss: 0.6518459663521953
  batch 329 loss: 0.6519103537576901
  batch 330 loss: 0.6519490232973387
  batch 331 loss: 0.6519163495824416
  batch 332 loss: 0.6518606473523451
  batch 333 loss: 0.6518462205434347
  batch 334 loss: 0.6518346892145579
  batch 335 loss: 0.6517312131710906
  batch 336 loss: 0.6517579605182012
  batch 337 loss: 0.651696642004064
  batch 338 loss: 0.6517121289256056
  batch 339 loss: 0.6517585468503226
  batch 340 loss: 0.6517283295883852
  batch 341 loss: 0.6517071024763269
  batch 342 loss: 0.6516953640513949
  batch 343 loss: 0.6517083205217523
  batch 344 loss: 0.6517012550733811
  batch 345 loss: 0.6517268669778022
  batch 346 loss: 0.6516828452576102
  batch 347 loss: 0.6516220768865316
  batch 348 loss: 0.6516667416040924
  batch 349 loss: 0.6516515342758856
  batch 350 loss: 0.6516092070511409
  batch 351 loss: 0.6516292387264067
  batch 352 loss: 0.651661182669076
  batch 353 loss: 0.651630091937338
  batch 354 loss: 0.6516590503986273
  batch 355 loss: 0.6516338758065667
  batch 356 loss: 0.6516353655397222
  batch 357 loss: 0.6516249450314947
  batch 358 loss: 0.6516659664375156
  batch 359 loss: 0.651630320256799
  batch 360 loss: 0.6516629301839405
  batch 361 loss: 0.6516016457549753
  batch 362 loss: 0.6515519538307717
  batch 363 loss: 0.6515374620427113
  batch 364 loss: 0.651509702533156
  batch 365 loss: 0.651482374537481
  batch 366 loss: 0.6514250357620052
  batch 367 loss: 0.6514805984107285
  batch 368 loss: 0.6514770453390868
  batch 369 loss: 0.6514926807990242
  batch 370 loss: 0.6515046556253691
  batch 371 loss: 0.651574758827847
  batch 372 loss: 0.6515077403796616
  batch 373 loss: 0.651458507568523
  batch 374 loss: 0.6514423789187549
  batch 375 loss: 0.6514334502220154
  batch 376 loss: 0.6514334356848229
  batch 377 loss: 0.6513804356994932
  batch 378 loss: 0.6513625542638163
  batch 379 loss: 0.6513183785302658
  batch 380 loss: 0.6513242450199629
  batch 381 loss: 0.6513241853300981
  batch 382 loss: 0.6513291781485393
  batch 383 loss: 0.6513123672562542
  batch 384 loss: 0.6512972501417001
  batch 385 loss: 0.6513192392014838
  batch 386 loss: 0.6512647044164529
  batch 387 loss: 0.6512530624712468
  batch 388 loss: 0.6512763192973186
  batch 389 loss: 0.651301614423031
  batch 390 loss: 0.6512847234041262
  batch 391 loss: 0.6512417922849241
  batch 392 loss: 0.6512572003566489
  batch 393 loss: 0.651277523459369
  batch 394 loss: 0.6512569889501871
  batch 395 loss: 0.6512426905994174
  batch 396 loss: 0.6512711836834146
  batch 397 loss: 0.6512118857213172
  batch 398 loss: 0.6511215278551207
  batch 399 loss: 0.6510810145459378
  batch 400 loss: 0.651036826223135
  batch 401 loss: 0.6510054051430149
  batch 402 loss: 0.6509722601715012
  batch 403 loss: 0.6509545401071496
  batch 404 loss: 0.650900749434339
  batch 405 loss: 0.6508710365236542
  batch 406 loss: 0.6508677500515736
  batch 407 loss: 0.6509017649973933
  batch 408 loss: 0.6508941156607048
  batch 409 loss: 0.6508432622352265
  batch 410 loss: 0.6508166541413563
  batch 411 loss: 0.6507854033850695
  batch 412 loss: 0.6507732603445794
  batch 413 loss: 0.6507719382824101
  batch 414 loss: 0.6506952067504183
  batch 415 loss: 0.6507051775254399
  batch 416 loss: 0.6506959379005891
  batch 417 loss: 0.6507017685355042
  batch 418 loss: 0.6506282021269274
  batch 419 loss: 0.6506326840145775
  batch 420 loss: 0.6506427259672256
  batch 421 loss: 0.650621803101338
  batch 422 loss: 0.6506854355052749
  batch 423 loss: 0.6506837888248705
  batch 424 loss: 0.6506903382404795
  batch 425 loss: 0.6506825750014361
  batch 426 loss: 0.650669299940548
  batch 427 loss: 0.6506539470138818
  batch 428 loss: 0.6506582445630403
  batch 429 loss: 0.6506447789274451
  batch 430 loss: 0.6506619608679484
  batch 431 loss: 0.6506911008651185
  batch 432 loss: 0.6507080711976245
  batch 433 loss: 0.6507727996581697
  batch 434 loss: 0.6508104247706277
  batch 435 loss: 0.6508082221294271
  batch 436 loss: 0.6508108280394056
  batch 437 loss: 0.6508521228960504
  batch 438 loss: 0.6509118510163538
  batch 439 loss: 0.6509314262242415
  batch 440 loss: 0.6509226757017049
  batch 441 loss: 0.6509092136575522
  batch 442 loss: 0.6508984893425558
  batch 443 loss: 0.6508809741140757
  batch 444 loss: 0.6508581004701219
  batch 445 loss: 0.6508046294865983
  batch 446 loss: 0.6507920030788455
  batch 447 loss: 0.6507489662575775
  batch 448 loss: 0.650707737675735
  batch 449 loss: 0.6507230843095844
  batch 450 loss: 0.6506910420788659
  batch 451 loss: 0.650654445862823
  batch 452 loss: 0.650675348080365
  batch 453 loss: 0.6506450248606684
  batch 454 loss: 0.6506365882930252
  batch 455 loss: 0.650632885655204
  batch 456 loss: 0.6505829595160066
  batch 457 loss: 0.6505502780626327
  batch 458 loss: 0.6505337508484786
  batch 459 loss: 0.6505434453357538
  batch 460 loss: 0.6505540225816809
  batch 461 loss: 0.6505456079371322
  batch 462 loss: 0.6505522766670624
  batch 463 loss: 0.6505935950361627
  batch 464 loss: 0.6506238041509842
  batch 465 loss: 0.6505498233661857
  batch 466 loss: 0.6504710522588231
  batch 467 loss: 0.6504799648321671
  batch 468 loss: 0.6504218010311453
  batch 469 loss: 0.6504324799153343
  batch 470 loss: 0.6504244770141359
  batch 471 loss: 0.6504505132413974
  batch 472 loss: 0.6504243176619885
LOSS train 0.6504243176619885 valid 0.6108165979385376
LOSS train 0.6504243176619885 valid 0.6092392802238464
LOSS train 0.6504243176619885 valid 0.6172098318735758
LOSS train 0.6504243176619885 valid 0.6167445182800293
LOSS train 0.6504243176619885 valid 0.6143743634223938
LOSS train 0.6504243176619885 valid 0.6149696807066599
LOSS train 0.6504243176619885 valid 0.6176822100366864
LOSS train 0.6504243176619885 valid 0.6210275217890739
LOSS train 0.6504243176619885 valid 0.6188207798533969
LOSS train 0.6504243176619885 valid 0.6187255322933197
LOSS train 0.6504243176619885 valid 0.6207172924822028
LOSS train 0.6504243176619885 valid 0.6205191165208817
LOSS train 0.6504243176619885 valid 0.6221588620772729
LOSS train 0.6504243176619885 valid 0.6220615122999463
LOSS train 0.6504243176619885 valid 0.6230806907018026
LOSS train 0.6504243176619885 valid 0.6234261766076088
LOSS train 0.6504243176619885 valid 0.6248975220848533
LOSS train 0.6504243176619885 valid 0.6249570780330234
LOSS train 0.6504243176619885 valid 0.6247986366874293
LOSS train 0.6504243176619885 valid 0.626137301325798
LOSS train 0.6504243176619885 valid 0.6254275497936067
LOSS train 0.6504243176619885 valid 0.6245243576439944
LOSS train 0.6504243176619885 valid 0.6258577082468115
LOSS train 0.6504243176619885 valid 0.6265851383407911
LOSS train 0.6504243176619885 valid 0.6259062218666077
LOSS train 0.6504243176619885 valid 0.6262665047095373
LOSS train 0.6504243176619885 valid 0.6272769570350647
LOSS train 0.6504243176619885 valid 0.626827712569918
LOSS train 0.6504243176619885 valid 0.6266819896369145
LOSS train 0.6504243176619885 valid 0.6273013075192769
LOSS train 0.6504243176619885 valid 0.6276934666018332
LOSS train 0.6504243176619885 valid 0.6275696288794279
LOSS train 0.6504243176619885 valid 0.6278335018591448
LOSS train 0.6504243176619885 valid 0.6277416751665228
LOSS train 0.6504243176619885 valid 0.6279262730053493
LOSS train 0.6504243176619885 valid 0.6279327819744746
LOSS train 0.6504243176619885 valid 0.6285377499219533
LOSS train 0.6504243176619885 valid 0.6284724724920172
LOSS train 0.6504243176619885 valid 0.6280933771377954
LOSS train 0.6504243176619885 valid 0.6282624423503875
LOSS train 0.6504243176619885 valid 0.6281831468023905
LOSS train 0.6504243176619885 valid 0.6282112002372742
LOSS train 0.6504243176619885 valid 0.6273900561554487
LOSS train 0.6504243176619885 valid 0.6274386332793669
LOSS train 0.6504243176619885 valid 0.6271927369965448
LOSS train 0.6504243176619885 valid 0.6275386849175328
LOSS train 0.6504243176619885 valid 0.6270981316870832
LOSS train 0.6504243176619885 valid 0.6273185610771179
LOSS train 0.6504243176619885 valid 0.6273444805826459
LOSS train 0.6504243176619885 valid 0.6268867003917694
LOSS train 0.6504243176619885 valid 0.6270575207822463
LOSS train 0.6504243176619885 valid 0.6270310649505029
LOSS train 0.6504243176619885 valid 0.6272266068548527
LOSS train 0.6504243176619885 valid 0.6270691995267514
LOSS train 0.6504243176619885 valid 0.6270514531569047
LOSS train 0.6504243176619885 valid 0.6268707545740264
LOSS train 0.6504243176619885 valid 0.6271197963179204
LOSS train 0.6504243176619885 valid 0.6270817127721063
LOSS train 0.6504243176619885 valid 0.6270688630766788
LOSS train 0.6504243176619885 valid 0.6273051887750626
LOSS train 0.6504243176619885 valid 0.6268426414395942
LOSS train 0.6504243176619885 valid 0.6272850930690765
LOSS train 0.6504243176619885 valid 0.6274187006647625
LOSS train 0.6504243176619885 valid 0.6280396608635783
LOSS train 0.6504243176619885 valid 0.6282792861645038
LOSS train 0.6504243176619885 valid 0.6281541838790431
LOSS train 0.6504243176619885 valid 0.6278697234481129
LOSS train 0.6504243176619885 valid 0.6277251243591309
LOSS train 0.6504243176619885 valid 0.6278191260669542
LOSS train 0.6504243176619885 valid 0.6277915673596518
LOSS train 0.6504243176619885 valid 0.6277709939110447
LOSS train 0.6504243176619885 valid 0.627496545513471
LOSS train 0.6504243176619885 valid 0.6272671982033612
LOSS train 0.6504243176619885 valid 0.6270775754709501
LOSS train 0.6504243176619885 valid 0.6270144995053609
LOSS train 0.6504243176619885 valid 0.6270103619286889
LOSS train 0.6504243176619885 valid 0.6267896433929344
LOSS train 0.6504243176619885 valid 0.6266170640786489
LOSS train 0.6504243176619885 valid 0.6264856171004379
LOSS train 0.6504243176619885 valid 0.6263700164854527
LOSS train 0.6504243176619885 valid 0.6261568827393614
LOSS train 0.6504243176619885 valid 0.6262110449918886
LOSS train 0.6504243176619885 valid 0.6261925970215395
LOSS train 0.6504243176619885 valid 0.6262494900396892
LOSS train 0.6504243176619885 valid 0.6261021319557639
LOSS train 0.6504243176619885 valid 0.6258516575014869
LOSS train 0.6504243176619885 valid 0.6259466676876463
LOSS train 0.6504243176619885 valid 0.6257831203666601
LOSS train 0.6504243176619885 valid 0.6258784626307112
LOSS train 0.6504243176619885 valid 0.6256102098359002
LOSS train 0.6504243176619885 valid 0.6255816116437807
LOSS train 0.6504243176619885 valid 0.6258426341025726
LOSS train 0.6504243176619885 valid 0.6259632507960001
LOSS train 0.6504243176619885 valid 0.625807800191514
LOSS train 0.6504243176619885 valid 0.625567260541414
LOSS train 0.6504243176619885 valid 0.6254469578464826
LOSS train 0.6504243176619885 valid 0.6255208585680145
LOSS train 0.6504243176619885 valid 0.6253759544722888
LOSS train 0.6504243176619885 valid 0.6254211290918216
LOSS train 0.6504243176619885 valid 0.6255394637584686
LOSS train 0.6504243176619885 valid 0.6257387635731461
LOSS train 0.6504243176619885 valid 0.6258038177209742
LOSS train 0.6504243176619885 valid 0.625993842638812
LOSS train 0.6504243176619885 valid 0.6259169572821031
LOSS train 0.6504243176619885 valid 0.6258798372177851
LOSS train 0.6504243176619885 valid 0.6259267673177539
LOSS train 0.6504243176619885 valid 0.6257782433634607
LOSS train 0.6504243176619885 valid 0.6258572323454751
LOSS train 0.6504243176619885 valid 0.6258352081710046
LOSS train 0.6504243176619885 valid 0.6258770081129941
LOSS train 0.6504243176619885 valid 0.6258372986638868
LOSS train 0.6504243176619885 valid 0.6258423828652927
LOSS train 0.6504243176619885 valid 0.6258962502521751
LOSS train 0.6504243176619885 valid 0.6259019573529562
LOSS train 0.6504243176619885 valid 0.6257849879886793
LOSS train 0.6504243176619885 valid 0.6259224486762079
LOSS train 0.6504243176619885 valid 0.6260617044236925
LOSS train 0.6504243176619885 valid 0.6260750758445869
LOSS train 0.6504243176619885 valid 0.6260604673073071
LOSS train 0.6504243176619885 valid 0.6260937228798866
LOSS train 0.6504243176619885 valid 0.6261538089799487
LOSS train 0.6504243176619885 valid 0.6260483440805654
LOSS train 0.6504243176619885 valid 0.6259793401733647
LOSS train 0.6504243176619885 valid 0.6259946808699639
LOSS train 0.6504243176619885 valid 0.6261087574958801
LOSS train 0.6504243176619885 valid 0.6260685958559551
LOSS train 0.6504243176619885 valid 0.6261919046950153
LOSS train 0.6504243176619885 valid 0.6262817368842661
LOSS train 0.6504243176619885 valid 0.6263837597166845
LOSS train 0.6504243176619885 valid 0.6262418765288132
LOSS train 0.6504243176619885 valid 0.6264515823990334
LOSS train 0.6504243176619885 valid 0.6264744997024536
LOSS train 0.6504243176619885 valid 0.6263572197211417
LOSS train 0.6504243176619885 valid 0.626276808888165
LOSS train 0.6504243176619885 valid 0.6262479684970997
LOSS train 0.6504243176619885 valid 0.626247697893311
LOSS train 0.6504243176619885 valid 0.62614436828307
LOSS train 0.6504243176619885 valid 0.6261229074519613
LOSS train 0.6504243176619885 valid 0.6260135902775278
LOSS train 0.6504243176619885 valid 0.6260234994547708
LOSS train 0.6504243176619885 valid 0.6261368626398398
LOSS train 0.6504243176619885 valid 0.6263181319538976
LOSS train 0.6504243176619885 valid 0.6263183351163264
LOSS train 0.6504243176619885 valid 0.6262979292207294
LOSS train 0.6504243176619885 valid 0.6262976457332743
LOSS train 0.6504243176619885 valid 0.6262667554698579
LOSS train 0.6504243176619885 valid 0.6261465476483715
LOSS train 0.6504243176619885 valid 0.6262326208320824
LOSS train 0.6504243176619885 valid 0.6261577842219564
LOSS train 0.6504243176619885 valid 0.6261395951112111
LOSS train 0.6504243176619885 valid 0.6263227229876234
LOSS train 0.6504243176619885 valid 0.6262755233206247
LOSS train 0.6504243176619885 valid 0.626352827143825
LOSS train 0.6504243176619885 valid 0.6263396658680656
LOSS train 0.6504243176619885 valid 0.6264325910998929
LOSS train 0.6504243176619885 valid 0.62652587890625
LOSS train 0.6504243176619885 valid 0.6265752566088537
LOSS train 0.6504243176619885 valid 0.6265978375567666
LOSS train 0.6504243176619885 valid 0.6264310404189728
LOSS train 0.6504243176619885 valid 0.6264028739184141
LOSS train 0.6504243176619885 valid 0.6263781045534595
LOSS train 0.6504243176619885 valid 0.6262169745233324
LOSS train 0.6504243176619885 valid 0.6262979043042002
LOSS train 0.6504243176619885 valid 0.6262326832951569
LOSS train 0.6504243176619885 valid 0.626236227425662
LOSS train 0.6504243176619885 valid 0.6261946052671915
LOSS train 0.6504243176619885 valid 0.626352713850444
LOSS train 0.6504243176619885 valid 0.6263914959771293
LOSS train 0.6504243176619885 valid 0.6263919045939248
LOSS train 0.6504243176619885 valid 0.626479532438166
LOSS train 0.6504243176619885 valid 0.6265663379117062
LOSS train 0.6504243176619885 valid 0.6265154456676438
LOSS train 0.6504243176619885 valid 0.6266154991408993
LOSS train 0.6504243176619885 valid 0.6266525720042744
LOSS train 0.6504243176619885 valid 0.6265868629728045
LOSS train 0.6504243176619885 valid 0.6266606047072194
LOSS train 0.6504243176619885 valid 0.6267596937842288
LOSS train 0.6504243176619885 valid 0.626798829335845
LOSS train 0.6504243176619885 valid 0.6267792106340717
LOSS train 0.6504243176619885 valid 0.6269362380107244
LOSS train 0.6504243176619885 valid 0.6268810392743316
LOSS train 0.6504243176619885 valid 0.6269241862899655
LOSS train 0.6504243176619885 valid 0.6269792455141662
LOSS train 0.6504243176619885 valid 0.6270354370708051
LOSS train 0.6504243176619885 valid 0.6269486517519565
LOSS train 0.6504243176619885 valid 0.6268983137223029
LOSS train 0.6504243176619885 valid 0.6268941948120607
LOSS train 0.6504243176619885 valid 0.6269969642162323
LOSS train 0.6504243176619885 valid 0.6269594724216159
LOSS train 0.6504243176619885 valid 0.6268768740327735
LOSS train 0.6504243176619885 valid 0.6268391119247956
LOSS train 0.6504243176619885 valid 0.6269156870742639
LOSS train 0.6504243176619885 valid 0.6269849600569571
LOSS train 0.6504243176619885 valid 0.6268460775159069
LOSS train 0.6504243176619885 valid 0.6267846391751216
LOSS train 0.6504243176619885 valid 0.6268392749586884
LOSS train 0.6504243176619885 valid 0.6268699511053598
LOSS train 0.6504243176619885 valid 0.6269389616720604
LOSS train 0.6504243176619885 valid 0.6269211361755678
LOSS train 0.6504243176619885 valid 0.6270133051276207
LOSS train 0.6504243176619885 valid 0.6269564418057304
LOSS train 0.6504243176619885 valid 0.6269308160437216
LOSS train 0.6504243176619885 valid 0.6268337304368982
LOSS train 0.6504243176619885 valid 0.6268181520349839
LOSS train 0.6504243176619885 valid 0.6268528156164216
LOSS train 0.6504243176619885 valid 0.6268770674478661
LOSS train 0.6504243176619885 valid 0.6269409564382212
LOSS train 0.6504243176619885 valid 0.6269427171120276
LOSS train 0.6504243176619885 valid 0.6268853901676014
LOSS train 0.6504243176619885 valid 0.6268858784721011
LOSS train 0.6504243176619885 valid 0.6268986313828925
LOSS train 0.6504243176619885 valid 0.6268785938901721
LOSS train 0.6504243176619885 valid 0.6267639913469413
LOSS train 0.6504243176619885 valid 0.6267172114871372
LOSS train 0.6504243176619885 valid 0.626789387991262
LOSS train 0.6504243176619885 valid 0.6269063392171154
LOSS train 0.6504243176619885 valid 0.6269260400451273
LOSS train 0.6504243176619885 valid 0.6269442299637226
LOSS train 0.6504243176619885 valid 0.6269636086132973
LOSS train 0.6504243176619885 valid 0.6269568213007667
LOSS train 0.6504243176619885 valid 0.6270468458870417
LOSS train 0.6504243176619885 valid 0.6271353788204022
LOSS train 0.6504243176619885 valid 0.6273301262492021
LOSS train 0.6504243176619885 valid 0.6272921679275376
LOSS train 0.6504243176619885 valid 0.6272361911667718
LOSS train 0.6504243176619885 valid 0.6271946374821452
LOSS train 0.6504243176619885 valid 0.6272075021319452
LOSS train 0.6504243176619885 valid 0.6272893493112764
LOSS train 0.6504243176619885 valid 0.6273167758008799
LOSS train 0.6504243176619885 valid 0.6273000219593877
LOSS train 0.6504243176619885 valid 0.6273116482284679
LOSS train 0.6504243176619885 valid 0.6273039106664986
LOSS train 0.6504243176619885 valid 0.627276423151401
LOSS train 0.6504243176619885 valid 0.6272705925835503
LOSS train 0.6504243176619885 valid 0.6273122150847252
LOSS train 0.6504243176619885 valid 0.6272253111257391
LOSS train 0.6504243176619885 valid 0.6272798847045576
LOSS train 0.6504243176619885 valid 0.6273024347649903
LOSS train 0.6504243176619885 valid 0.627243952771111
LOSS train 0.6504243176619885 valid 0.6272480055689812
LOSS train 0.6504243176619885 valid 0.6272637604183181
LOSS train 0.6504243176619885 valid 0.6271713383434233
LOSS train 0.6504243176619885 valid 0.6271647217342392
LOSS train 0.6504243176619885 valid 0.6272080787381188
LOSS train 0.6504243176619885 valid 0.6271499974387033
LOSS train 0.6504243176619885 valid 0.6271833859808077
LOSS train 0.6504243176619885 valid 0.6272572307934162
LOSS train 0.6504243176619885 valid 0.6271989754130763
LOSS train 0.6504243176619885 valid 0.6271374747456318
LOSS train 0.6504243176619885 valid 0.6271721558570862
LOSS train 0.6504243176619885 valid 0.6271306656271338
LOSS train 0.6504243176619885 valid 0.6272148925160604
LOSS train 0.6504243176619885 valid 0.6272154558788646
LOSS train 0.6504243176619885 valid 0.6273174630844687
LOSS train 0.6504243176619885 valid 0.6272798872461506
LOSS train 0.6504243176619885 valid 0.6272165111731738
LOSS train 0.6504243176619885 valid 0.6271062326338505
LOSS train 0.6504243176619885 valid 0.6271227013695148
LOSS train 0.6504243176619885 valid 0.6271395363402643
LOSS train 0.6504243176619885 valid 0.627172575547145
LOSS train 0.6504243176619885 valid 0.6272166565460263
LOSS train 0.6504243176619885 valid 0.6272073146951107
LOSS train 0.6504243176619885 valid 0.6272274917522764
LOSS train 0.6504243176619885 valid 0.6272309824372783
LOSS train 0.6504243176619885 valid 0.6272634542213296
LOSS train 0.6504243176619885 valid 0.6272819649456138
LOSS train 0.6504243176619885 valid 0.6273601972654964
LOSS train 0.6504243176619885 valid 0.62734565806033
LOSS train 0.6504243176619885 valid 0.6273483824552657
LOSS train 0.6504243176619885 valid 0.6273676088562719
LOSS train 0.6504243176619885 valid 0.6273835835861544
LOSS train 0.6504243176619885 valid 0.6274243553771692
LOSS train 0.6504243176619885 valid 0.6275563152718456
LOSS train 0.6504243176619885 valid 0.6275324495169368
LOSS train 0.6504243176619885 valid 0.6275457657467235
LOSS train 0.6504243176619885 valid 0.6276110760543657
LOSS train 0.6504243176619885 valid 0.6275621017824442
LOSS train 0.6504243176619885 valid 0.6275373390681452
LOSS train 0.6504243176619885 valid 0.6276260706258932
LOSS train 0.6504243176619885 valid 0.6275842357959066
LOSS train 0.6504243176619885 valid 0.6275512414894918
LOSS train 0.6504243176619885 valid 0.6274592290956078
LOSS train 0.6504243176619885 valid 0.6274477262379002
LOSS train 0.6504243176619885 valid 0.6274508924131662
LOSS train 0.6504243176619885 valid 0.6274687961528176
LOSS train 0.6504243176619885 valid 0.6274136236080756
LOSS train 0.6504243176619885 valid 0.6273920463352669
LOSS train 0.6504243176619885 valid 0.6274252641532156
LOSS train 0.6504243176619885 valid 0.6273782814250273
LOSS train 0.6504243176619885 valid 0.6274191430930434
LOSS train 0.6504243176619885 valid 0.6273403853894919
LOSS train 0.6504243176619885 valid 0.6273968997475219
LOSS train 0.6504243176619885 valid 0.6273507193086904
LOSS train 0.6504243176619885 valid 0.6274080175120814
LOSS train 0.6504243176619885 valid 0.6274965546898923
LOSS train 0.6504243176619885 valid 0.6274905007433247
LOSS train 0.6504243176619885 valid 0.6274686887208059
LOSS train 0.6504243176619885 valid 0.6274626189030257
LOSS train 0.6504243176619885 valid 0.6275159778403598
LOSS train 0.6504243176619885 valid 0.6274957420428594
LOSS train 0.6504243176619885 valid 0.6274797954036548
LOSS train 0.6504243176619885 valid 0.6273945761437447
LOSS train 0.6504243176619885 valid 0.6274147818584254
LOSS train 0.6504243176619885 valid 0.6273765665920157
LOSS train 0.6504243176619885 valid 0.6273505613452098
LOSS train 0.6504243176619885 valid 0.6273420172579148
LOSS train 0.6504243176619885 valid 0.6273176503103797
LOSS train 0.6504243176619885 valid 0.6272576762871309
LOSS train 0.6504243176619885 valid 0.6272552794623143
LOSS train 0.6504243176619885 valid 0.6272756274669401
LOSS train 0.6504243176619885 valid 0.6272596701548414
LOSS train 0.6504243176619885 valid 0.6273027683297793
LOSS train 0.6504243176619885 valid 0.6273388093271957
LOSS train 0.6504243176619885 valid 0.6273871825379171
LOSS train 0.6504243176619885 valid 0.6273463239745488
LOSS train 0.6504243176619885 valid 0.6272845504027379
LOSS train 0.6504243176619885 valid 0.6272510088956694
LOSS train 0.6504243176619885 valid 0.6272704100833749
LOSS train 0.6504243176619885 valid 0.6272502197740968
LOSS train 0.6504243176619885 valid 0.6273056473582983
LOSS train 0.6504243176619885 valid 0.62733743383877
LOSS train 0.6504243176619885 valid 0.6273471268807879
LOSS train 0.6504243176619885 valid 0.627310055512762
LOSS train 0.6504243176619885 valid 0.6273068919961835
LOSS train 0.6504243176619885 valid 0.6273268728989821
LOSS train 0.6504243176619885 valid 0.6273163864217652
LOSS train 0.6504243176619885 valid 0.6273327730482142
LOSS train 0.6504243176619885 valid 0.6273576769886947
LOSS train 0.6504243176619885 valid 0.6273217980260183
LOSS train 0.6504243176619885 valid 0.6272780212489042
LOSS train 0.6504243176619885 valid 0.6272334004456903
LOSS train 0.6504243176619885 valid 0.6271613425160029
LOSS train 0.6504243176619885 valid 0.6271248713985935
LOSS train 0.6504243176619885 valid 0.6271803166694984
LOSS train 0.6504243176619885 valid 0.6271997087037385
LOSS train 0.6504243176619885 valid 0.6272769809833595
LOSS train 0.6504243176619885 valid 0.62726651189589
LOSS train 0.6504243176619885 valid 0.6273109509042029
LOSS train 0.6504243176619885 valid 0.6273143891036335
LOSS train 0.6504243176619885 valid 0.6272803697515936
LOSS train 0.6504243176619885 valid 0.6273071009043025
LOSS train 0.6504243176619885 valid 0.6273306114980352
LOSS train 0.6504243176619885 valid 0.6273211831601646
LOSS train 0.6504243176619885 valid 0.6273166921942733
LOSS train 0.6504243176619885 valid 0.6273263205652652
LOSS train 0.6504243176619885 valid 0.6273396959194558
LOSS train 0.6504243176619885 valid 0.6272911917235734
LOSS train 0.6504243176619885 valid 0.62731025684839
LOSS train 0.6504243176619885 valid 0.6273138835641922
LOSS train 0.6504243176619885 valid 0.6273304722990308
LOSS train 0.6504243176619885 valid 0.6273786614083836
LOSS train 0.6504243176619885 valid 0.6274326585910537
LOSS train 0.6504243176619885 valid 0.6274696347058326
LOSS train 0.6504243176619885 valid 0.6275069540166586
LOSS train 0.6504243176619885 valid 0.6275327821852456
LOSS train 0.6504243176619885 valid 0.6275424970669693
LOSS train 0.6504243176619885 valid 0.6275384249139566
LOSS train 0.6504243176619885 valid 0.6274705572501241
LOSS train 0.6504243176619885 valid 0.6274773430359397
LOSS train 0.6504243176619885 valid 0.6274593916204241
LOSS train 0.6504243176619885 valid 0.6275120167851118
LOSS train 0.6504243176619885 valid 0.6274949162375203
LOSS train 0.6504243176619885 valid 0.627503550249683
LOSS train 0.6504243176619885 valid 0.6274524422792288
LOSS train 0.6504243176619885 valid 0.6274527827354327
LOSS train 0.6504243176619885 valid 0.6274183741032752
LOSS train 0.6504243176619885 valid 0.6273793774664564
LOSS train 0.6504243176619885 valid 0.6274206526577473
LOSS train 0.6504243176619885 valid 0.6274229007038644
EPOCH 3:
  batch 1 loss: 0.6461969614028931
  batch 2 loss: 0.6422802209854126
  batch 3 loss: 0.6395509044329325
  batch 4 loss: 0.6499710232019424
  batch 5 loss: 0.6489074468612671
  batch 6 loss: 0.6476108431816101
  batch 7 loss: 0.6470840743609837
  batch 8 loss: 0.6463212594389915
  batch 9 loss: 0.6461933056513468
  batch 10 loss: 0.6478022336959839
  batch 11 loss: 0.6482131047682329
  batch 12 loss: 0.6480592687924703
  batch 13 loss: 0.6487117593105023
  batch 14 loss: 0.6489965277058738
  batch 15 loss: 0.6503530343373617
  batch 16 loss: 0.6500312983989716
  batch 17 loss: 0.6507149233537561
  batch 18 loss: 0.6503253314230177
  batch 19 loss: 0.6497931856858102
  batch 20 loss: 0.6496178776025772
  batch 21 loss: 0.6496910197394234
  batch 22 loss: 0.6498810052871704
  batch 23 loss: 0.6491788262906282
  batch 24 loss: 0.6488635838031769
  batch 25 loss: 0.6496785283088684
  batch 26 loss: 0.6490461321977469
  batch 27 loss: 0.6480366874624182
  batch 28 loss: 0.647329751934324
  batch 29 loss: 0.6477954839837963
  batch 30 loss: 0.6479871849219004
  batch 31 loss: 0.6475421824762898
  batch 32 loss: 0.6470180545002222
  batch 33 loss: 0.6469863562872915
  batch 34 loss: 0.6469909461105571
  batch 35 loss: 0.6472475068909781
  batch 36 loss: 0.6473247061173121
  batch 37 loss: 0.6465977011500178
  batch 38 loss: 0.6459234388251054
  batch 39 loss: 0.6458716881580842
  batch 40 loss: 0.6458350747823716
  batch 41 loss: 0.6452031295473982
  batch 42 loss: 0.6453091005484263
  batch 43 loss: 0.6454962810804677
  batch 44 loss: 0.6446827243674885
  batch 45 loss: 0.6447023391723633
  batch 46 loss: 0.644052259300066
  batch 47 loss: 0.6443128535088073
  batch 48 loss: 0.6435847307244936
  batch 49 loss: 0.6432155224741721
  batch 50 loss: 0.6427457654476165
  batch 51 loss: 0.6428246568231022
  batch 52 loss: 0.642664760351181
  batch 53 loss: 0.6430650375924021
  batch 54 loss: 0.6428441460485812
  batch 55 loss: 0.642675058408217
  batch 56 loss: 0.6424900580729757
  batch 57 loss: 0.6424545216978642
  batch 58 loss: 0.6425998118417017
  batch 59 loss: 0.6421789486529463
  batch 60 loss: 0.6421664456526438
  batch 61 loss: 0.6421368190499602
  batch 62 loss: 0.6418929388446193
  batch 63 loss: 0.6414752157907637
  batch 64 loss: 0.6412663646042347
  batch 65 loss: 0.6408094176879295
  batch 66 loss: 0.6404879219604261
  batch 67 loss: 0.6403954046875683
  batch 68 loss: 0.6404968114460216
  batch 69 loss: 0.6408603640570156
  batch 70 loss: 0.6408873983791896
  batch 71 loss: 0.640749390696136
  batch 72 loss: 0.6406220603320334
  batch 73 loss: 0.6407292240286526
  batch 74 loss: 0.6408419488249598
  batch 75 loss: 0.6406210652987162
  batch 76 loss: 0.6409943872376492
  batch 77 loss: 0.640478384185147
  batch 78 loss: 0.6403185717570476
  batch 79 loss: 0.6403879221481613
  batch 80 loss: 0.6403085947036743
  batch 81 loss: 0.6404683957865209
  batch 82 loss: 0.6404519546322707
  batch 83 loss: 0.6400669181203268
  batch 84 loss: 0.6399021574429103
  batch 85 loss: 0.6396572793231291
  batch 86 loss: 0.6399251756279968
  batch 87 loss: 0.6396844263734489
  batch 88 loss: 0.6393853751095858
  batch 89 loss: 0.6392445088772292
  batch 90 loss: 0.6390001773834229
  batch 91 loss: 0.6387868995194906
  batch 92 loss: 0.6386797343907149
  batch 93 loss: 0.6388769476644455
  batch 94 loss: 0.6388098718004024
  batch 95 loss: 0.6388003443416796
  batch 96 loss: 0.6385223002483448
  batch 97 loss: 0.6384188397643492
  batch 98 loss: 0.6384418144518015
  batch 99 loss: 0.6383822584393049
  batch 100 loss: 0.638372318148613
  batch 101 loss: 0.6380587001838306
  batch 102 loss: 0.6381509467667225
  batch 103 loss: 0.6382082955351154
  batch 104 loss: 0.6382266856156863
  batch 105 loss: 0.6380988268625168
  batch 106 loss: 0.6380592146009769
  batch 107 loss: 0.637733398753906
  batch 108 loss: 0.6379049414837802
  batch 109 loss: 0.63778079649724
  batch 110 loss: 0.6379874413663691
  batch 111 loss: 0.6378131584004239
  batch 112 loss: 0.6378148921898433
  batch 113 loss: 0.6376900514670177
  batch 114 loss: 0.63785082310961
  batch 115 loss: 0.6376825260079425
  batch 116 loss: 0.6378301649258055
  batch 117 loss: 0.6377403573093251
  batch 118 loss: 0.6378155436556218
  batch 119 loss: 0.6377282077524843
  batch 120 loss: 0.6376732890804608
  batch 121 loss: 0.6375576528635892
  batch 122 loss: 0.637553335701833
  batch 123 loss: 0.6373524525301243
  batch 124 loss: 0.6375628272371907
  batch 125 loss: 0.6375567202568054
  batch 126 loss: 0.6373411762335944
  batch 127 loss: 0.6373724674615334
  batch 128 loss: 0.6373429060913622
  batch 129 loss: 0.6372528108515481
  batch 130 loss: 0.6373521552636073
  batch 131 loss: 0.6373466480779284
  batch 132 loss: 0.6373019832553286
  batch 133 loss: 0.6373889473147858
  batch 134 loss: 0.63732251391482
  batch 135 loss: 0.6373139814094261
  batch 136 loss: 0.6373909435728017
  batch 137 loss: 0.637576773218865
  batch 138 loss: 0.6374484810276307
  batch 139 loss: 0.6375115736782979
  batch 140 loss: 0.637436323080744
  batch 141 loss: 0.6374131047979315
  batch 142 loss: 0.6372565836973594
  batch 143 loss: 0.6370529507423615
  batch 144 loss: 0.6369018401536677
  batch 145 loss: 0.6367447133721976
  batch 146 loss: 0.6368475233855313
  batch 147 loss: 0.6369513999037191
  batch 148 loss: 0.6367599347958693
  batch 149 loss: 0.6368292806132528
  batch 150 loss: 0.6368470517794291
  batch 151 loss: 0.6369087514498376
  batch 152 loss: 0.6369741586478133
  batch 153 loss: 0.6369401672307182
  batch 154 loss: 0.6369626599472838
  batch 155 loss: 0.6368946959895473
  batch 156 loss: 0.6368383337289859
  batch 157 loss: 0.6368875066945507
  batch 158 loss: 0.636904652737364
  batch 159 loss: 0.6367478704302566
  batch 160 loss: 0.6367585059255362
  batch 161 loss: 0.6366884615850745
  batch 162 loss: 0.6365903067735978
  batch 163 loss: 0.6365979467432923
  batch 164 loss: 0.6365913828698601
  batch 165 loss: 0.6362823804219564
  batch 166 loss: 0.6363330864044557
  batch 167 loss: 0.6362634622408244
  batch 168 loss: 0.6365514557276454
  batch 169 loss: 0.6364458175100518
  batch 170 loss: 0.636615724773968
  batch 171 loss: 0.6365660327916954
  batch 172 loss: 0.6365140565606051
  batch 173 loss: 0.6365365427353479
  batch 174 loss: 0.6365099799358982
  batch 175 loss: 0.636510146345411
  batch 176 loss: 0.6364640671421181
  batch 177 loss: 0.6363280469414878
  batch 178 loss: 0.6363091780228561
  batch 179 loss: 0.6362790685126235
  batch 180 loss: 0.6361761573288176
  batch 181 loss: 0.6361945205630518
  batch 182 loss: 0.6360662464912121
  batch 183 loss: 0.6360513743807058
  batch 184 loss: 0.6359168553481931
  batch 185 loss: 0.6359478186916661
  batch 186 loss: 0.6359961824391478
  batch 187 loss: 0.6359555628847948
  batch 188 loss: 0.6359559522664293
  batch 189 loss: 0.6358492705557082
  batch 190 loss: 0.6357751410258444
  batch 191 loss: 0.6356679173040141
  batch 192 loss: 0.6356548583135009
  batch 193 loss: 0.63563472032547
  batch 194 loss: 0.6355711255491394
  batch 195 loss: 0.6356506271240039
  batch 196 loss: 0.6357061428074934
  batch 197 loss: 0.6358302296115662
  batch 198 loss: 0.6357451529815944
  batch 199 loss: 0.6357934651662357
  batch 200 loss: 0.6358733090758324
  batch 201 loss: 0.6357214323323758
  batch 202 loss: 0.6356838307168224
  batch 203 loss: 0.6356581652105735
  batch 204 loss: 0.6355080981464947
  batch 205 loss: 0.6355184092754271
  batch 206 loss: 0.6355180534922961
  batch 207 loss: 0.6354196906665673
  batch 208 loss: 0.6354294803280097
  batch 209 loss: 0.6354290985604792
  batch 210 loss: 0.6354063252607981
  batch 211 loss: 0.6354697719569454
  batch 212 loss: 0.635425552163484
  batch 213 loss: 0.6354547613103625
  batch 214 loss: 0.6354134071653135
  batch 215 loss: 0.6352768823157909
  batch 216 loss: 0.6352186796289904
  batch 217 loss: 0.6351669433479485
  batch 218 loss: 0.6351553529774377
  batch 219 loss: 0.6350873768601788
  batch 220 loss: 0.6350575094873255
  batch 221 loss: 0.6350371886162737
  batch 222 loss: 0.6350883530066894
  batch 223 loss: 0.6350511937932584
  batch 224 loss: 0.6349870357662439
  batch 225 loss: 0.6348705903689067
  batch 226 loss: 0.634806690226614
  batch 227 loss: 0.63474270136871
  batch 228 loss: 0.634625671986948
  batch 229 loss: 0.6345606240643163
  batch 230 loss: 0.6345747973607934
  batch 231 loss: 0.6345987639901958
  batch 232 loss: 0.6345732242896639
  batch 233 loss: 0.6346336582699559
  batch 234 loss: 0.6344885874507774
  batch 235 loss: 0.634438979625702
  batch 236 loss: 0.6344741974341668
  batch 237 loss: 0.6344728253561737
  batch 238 loss: 0.6344912032119366
  batch 239 loss: 0.6344789745418596
  batch 240 loss: 0.6345215298235416
  batch 241 loss: 0.6345364307961523
  batch 242 loss: 0.6345503389342757
  batch 243 loss: 0.634546233793345
  batch 244 loss: 0.634524973933814
  batch 245 loss: 0.6345114131363071
  batch 246 loss: 0.6345878837069845
  batch 247 loss: 0.634565366665844
  batch 248 loss: 0.634536532384734
  batch 249 loss: 0.6345024235756043
  batch 250 loss: 0.6346270303726196
  batch 251 loss: 0.634558510495372
  batch 252 loss: 0.6346056906003801
  batch 253 loss: 0.6344711596786741
  batch 254 loss: 0.6344405112304087
  batch 255 loss: 0.6344132900238038
  batch 256 loss: 0.634405393851921
  batch 257 loss: 0.6344587972191985
  batch 258 loss: 0.6345134583092475
  batch 259 loss: 0.6344508155892714
  batch 260 loss: 0.6343873413709494
  batch 261 loss: 0.6343617046473127
  batch 262 loss: 0.634312822846056
  batch 263 loss: 0.634187689072279
  batch 264 loss: 0.6340601439728881
  batch 265 loss: 0.6341256330598075
  batch 266 loss: 0.6340658279289877
  batch 267 loss: 0.6340563091892428
  batch 268 loss: 0.6340107762101871
  batch 269 loss: 0.6339124729199037
  batch 270 loss: 0.6338730918036567
  batch 271 loss: 0.6338693123462016
  batch 272 loss: 0.6338678806581918
  batch 273 loss: 0.6338333830291971
  batch 274 loss: 0.6337415223574117
  batch 275 loss: 0.6337741023843939
  batch 276 loss: 0.6338616657084313
  batch 277 loss: 0.6338776836326406
  batch 278 loss: 0.6338232176766979
  batch 279 loss: 0.6337879178344562
  batch 280 loss: 0.6337291943175453
  batch 281 loss: 0.63373092103259
  batch 282 loss: 0.6336524232904962
  batch 283 loss: 0.6335425823400382
  batch 284 loss: 0.6335428972059572
  batch 285 loss: 0.6333992397576048
  batch 286 loss: 0.6333445664885995
  batch 287 loss: 0.633293048845351
  batch 288 loss: 0.6331217599411806
  batch 289 loss: 0.6331157550267282
  batch 290 loss: 0.6329977132123092
  batch 291 loss: 0.6328805005017835
  batch 292 loss: 0.6328684612088007
  batch 293 loss: 0.6328243841083383
  batch 294 loss: 0.6327863021367262
  batch 295 loss: 0.6328427114729154
  batch 296 loss: 0.6327412593606356
  batch 297 loss: 0.6327026753313212
  batch 298 loss: 0.6325861847640684
  batch 299 loss: 0.6326265087893177
  batch 300 loss: 0.6326639127731323
  batch 301 loss: 0.632645981454374
  batch 302 loss: 0.6325909738114338
  batch 303 loss: 0.6326188203131798
  batch 304 loss: 0.6325338080917534
  batch 305 loss: 0.6324143560206303
  batch 306 loss: 0.6324355360729242
  batch 307 loss: 0.6324318266846847
  batch 308 loss: 0.6323882602639013
  batch 309 loss: 0.6323611610915668
  batch 310 loss: 0.6323282137993843
  batch 311 loss: 0.632242539304629
  batch 312 loss: 0.632329958371627
  batch 313 loss: 0.6323225593414551
  batch 314 loss: 0.6323029945610436
  batch 315 loss: 0.6323180039723714
  batch 316 loss: 0.6323436562773548
  batch 317 loss: 0.6323970727363971
  batch 318 loss: 0.6323089728940208
  batch 319 loss: 0.6322869284773321
  batch 320 loss: 0.6321516314521431
  batch 321 loss: 0.6320361747548587
  batch 322 loss: 0.631987482494449
  batch 323 loss: 0.631926414029148
  batch 324 loss: 0.6319196489122179
  batch 325 loss: 0.6319058385262123
  batch 326 loss: 0.631892950074073
  batch 327 loss: 0.6318342423220293
  batch 328 loss: 0.6318868224213763
  batch 329 loss: 0.6319554815901086
  batch 330 loss: 0.6319522456689315
  batch 331 loss: 0.6319725043463923
  batch 332 loss: 0.6319226173751326
  batch 333 loss: 0.6318619333587967
  batch 334 loss: 0.6318346822333193
  batch 335 loss: 0.6317439170026068
  batch 336 loss: 0.6317455685209661
  batch 337 loss: 0.6317155074648758
  batch 338 loss: 0.6317786683697673
  batch 339 loss: 0.6318716688142062
  batch 340 loss: 0.6318763480466955
  batch 341 loss: 0.6318290296537785
  batch 342 loss: 0.6318797413368671
  batch 343 loss: 0.6319294153080042
  batch 344 loss: 0.6318997813518658
  batch 345 loss: 0.6319473299427308
  batch 346 loss: 0.6319127508326073
  batch 347 loss: 0.631906446874657
  batch 348 loss: 0.6319404110826295
  batch 349 loss: 0.6319287366375199
  batch 350 loss: 0.6318843378339495
  batch 351 loss: 0.6319057364069838
  batch 352 loss: 0.6319445566358891
  batch 353 loss: 0.6318975016685788
  batch 354 loss: 0.6318669647483502
  batch 355 loss: 0.6319225967769891
  batch 356 loss: 0.6318882613369589
  batch 357 loss: 0.6319003692862033
  batch 358 loss: 0.6319162905549204
  batch 359 loss: 0.6319259959675143
  batch 360 loss: 0.6319704946544435
  batch 361 loss: 0.631872005740031
  batch 362 loss: 0.6318842200613812
  batch 363 loss: 0.6318264160274474
  batch 364 loss: 0.6317650479274791
  batch 365 loss: 0.6317526167386198
  batch 366 loss: 0.6317357528405111
  batch 367 loss: 0.6317160592416976
  batch 368 loss: 0.6316686070159726
  batch 369 loss: 0.6317057478718642
  batch 370 loss: 0.6317892491817474
  batch 371 loss: 0.6318351796695164
  batch 372 loss: 0.6317383946590526
  batch 373 loss: 0.6316706161077157
  batch 374 loss: 0.6316191450478559
  batch 375 loss: 0.6316035528182984
  batch 376 loss: 0.6316824033856392
  batch 377 loss: 0.6315953250905247
  batch 378 loss: 0.6316212649067874
  batch 379 loss: 0.6315784421319383
  batch 380 loss: 0.6315603176229878
  batch 381 loss: 0.6315452024692626
  batch 382 loss: 0.6314657815775946
  batch 383 loss: 0.6314631165163324
  batch 384 loss: 0.6314325441295902
  batch 385 loss: 0.6314606908079866
  batch 386 loss: 0.6314006186828712
  batch 387 loss: 0.6313793480550288
  batch 388 loss: 0.6313883852712887
  batch 389 loss: 0.6314068482590212
  batch 390 loss: 0.6313685871087588
  batch 391 loss: 0.6313321098037388
  batch 392 loss: 0.6313252727292022
  batch 393 loss: 0.6313345861495603
  batch 394 loss: 0.6313527881494029
  batch 395 loss: 0.6312717013721225
  batch 396 loss: 0.6312847834343862
  batch 397 loss: 0.6312201279837178
  batch 398 loss: 0.6311005753787917
  batch 399 loss: 0.6310807103501227
  batch 400 loss: 0.6310162155330181
  batch 401 loss: 0.6309463702829698
  batch 402 loss: 0.6309149103674723
  batch 403 loss: 0.6308442962080906
  batch 404 loss: 0.6307685506520885
  batch 405 loss: 0.6307435360955603
  batch 406 loss: 0.6307460520361444
  batch 407 loss: 0.6307714927108633
  batch 408 loss: 0.630789134286198
  batch 409 loss: 0.6307106692808473
  batch 410 loss: 0.6306694815798504
  batch 411 loss: 0.6306357177794705
  batch 412 loss: 0.6305982537061265
  batch 413 loss: 0.6305575575724641
  batch 414 loss: 0.6305147688745877
  batch 415 loss: 0.6304804442876792
  batch 416 loss: 0.6304494089518602
  batch 417 loss: 0.6304876102532129
  batch 418 loss: 0.6304727407733789
  batch 419 loss: 0.630451411079962
  batch 420 loss: 0.6304454267024994
  batch 421 loss: 0.6304282329427942
  batch 422 loss: 0.6305434902979864
  batch 423 loss: 0.6305241481914025
  batch 424 loss: 0.6305088908323702
  batch 425 loss: 0.6305012035369874
  batch 426 loss: 0.6304951300363586
  batch 427 loss: 0.6304503677879619
  batch 428 loss: 0.6304521406086806
  batch 429 loss: 0.6304406126340231
  batch 430 loss: 0.6304188194663025
  batch 431 loss: 0.6303975060755028
  batch 432 loss: 0.6304111796672698
  batch 433 loss: 0.6304181746742742
  batch 434 loss: 0.6304447552026142
  batch 435 loss: 0.6304291722418248
  batch 436 loss: 0.6304159760475159
  batch 437 loss: 0.63042815530873
  batch 438 loss: 0.6304794533611977
  batch 439 loss: 0.6304445589864988
  batch 440 loss: 0.6304065530950372
  batch 441 loss: 0.6303728307996478
  batch 442 loss: 0.6303144402094016
  batch 443 loss: 0.6302500527276411
  batch 444 loss: 0.6302274068196615
  batch 445 loss: 0.6301764876654978
  batch 446 loss: 0.6301331302242963
  batch 447 loss: 0.6300550569890596
  batch 448 loss: 0.6299959832270231
  batch 449 loss: 0.629982198134297
  batch 450 loss: 0.6299326724476284
  batch 451 loss: 0.6298242696373003
  batch 452 loss: 0.6297985559279939
  batch 453 loss: 0.629788212823552
  batch 454 loss: 0.629800077183131
  batch 455 loss: 0.6298579631270943
  batch 456 loss: 0.6297873672947549
  batch 457 loss: 0.6297747778422984
  batch 458 loss: 0.6297334981797564
  batch 459 loss: 0.6297330233006696
  batch 460 loss: 0.6296858502470929
  batch 461 loss: 0.6296196812662799
  batch 462 loss: 0.6296174870683001
  batch 463 loss: 0.6296662030415711
  batch 464 loss: 0.6296996790273436
  batch 465 loss: 0.6296123163674467
  batch 466 loss: 0.6295251999801832
  batch 467 loss: 0.6295547809539567
  batch 468 loss: 0.6295018290352618
  batch 469 loss: 0.6295368621852606
  batch 470 loss: 0.6294944999065805
  batch 471 loss: 0.6294978824137629
  batch 472 loss: 0.6295075225880591
LOSS train 0.6295075225880591 valid 0.5350134372711182
LOSS train 0.6295075225880591 valid 0.5284056961536407
LOSS train 0.6295075225880591 valid 0.5342660744984945
LOSS train 0.6295075225880591 valid 0.530262365937233
LOSS train 0.6295075225880591 valid 0.5294894099235534
LOSS train 0.6295075225880591 valid 0.5276670058568319
LOSS train 0.6295075225880591 valid 0.5288681132452828
LOSS train 0.6295075225880591 valid 0.5318938046693802
LOSS train 0.6295075225880591 valid 0.5317147970199585
LOSS train 0.6295075225880591 valid 0.5315273463726043
LOSS train 0.6295075225880591 valid 0.5334265448830344
LOSS train 0.6295075225880591 valid 0.533368726571401
LOSS train 0.6295075225880591 valid 0.5351010652688833
LOSS train 0.6295075225880591 valid 0.5352178130831037
LOSS train 0.6295075225880591 valid 0.5361582199732463
LOSS train 0.6295075225880591 valid 0.5378925018012524
LOSS train 0.6295075225880591 valid 0.5388820416787091
LOSS train 0.6295075225880591 valid 0.538290970855289
LOSS train 0.6295075225880591 valid 0.537790806669938
LOSS train 0.6295075225880591 valid 0.53902368247509
LOSS train 0.6295075225880591 valid 0.5384588695707775
LOSS train 0.6295075225880591 valid 0.5374874933199449
LOSS train 0.6295075225880591 valid 0.5386254243228746
LOSS train 0.6295075225880591 valid 0.5389678676923116
LOSS train 0.6295075225880591 valid 0.5386960434913636
LOSS train 0.6295075225880591 valid 0.5391436448464026
LOSS train 0.6295075225880591 valid 0.5398461355103387
LOSS train 0.6295075225880591 valid 0.5395191311836243
LOSS train 0.6295075225880591 valid 0.5387936172814205
LOSS train 0.6295075225880591 valid 0.5396571238835652
LOSS train 0.6295075225880591 valid 0.5402953932362218
LOSS train 0.6295075225880591 valid 0.5398089457303286
LOSS train 0.6295075225880591 valid 0.5400694951866613
LOSS train 0.6295075225880591 valid 0.5397801732315737
LOSS train 0.6295075225880591 valid 0.5400109870093209
LOSS train 0.6295075225880591 valid 0.5403179079294205
LOSS train 0.6295075225880591 valid 0.5413902450252224
LOSS train 0.6295075225880591 valid 0.5415888365946318
LOSS train 0.6295075225880591 valid 0.5411305396984785
LOSS train 0.6295075225880591 valid 0.5414251431822776
LOSS train 0.6295075225880591 valid 0.5414326060109023
LOSS train 0.6295075225880591 valid 0.5410926583267394
LOSS train 0.6295075225880591 valid 0.5402147492697073
LOSS train 0.6295075225880591 valid 0.5398204570466821
LOSS train 0.6295075225880591 valid 0.5394841247134738
LOSS train 0.6295075225880591 valid 0.5401748807533927
LOSS train 0.6295075225880591 valid 0.5398740007522258
LOSS train 0.6295075225880591 valid 0.5401845599214236
LOSS train 0.6295075225880591 valid 0.5404042735391733
LOSS train 0.6295075225880591 valid 0.5399850654602051
LOSS train 0.6295075225880591 valid 0.5403249544255874
LOSS train 0.6295075225880591 valid 0.5402141488515414
LOSS train 0.6295075225880591 valid 0.5406333545468888
LOSS train 0.6295075225880591 valid 0.5406405462159051
LOSS train 0.6295075225880591 valid 0.540785037387501
LOSS train 0.6295075225880591 valid 0.540913211447852
LOSS train 0.6295075225880591 valid 0.5410547570178383
LOSS train 0.6295075225880591 valid 0.5407018846478956
LOSS train 0.6295075225880591 valid 0.5406601065296238
LOSS train 0.6295075225880591 valid 0.5410306205352148
LOSS train 0.6295075225880591 valid 0.5403811785041309
LOSS train 0.6295075225880591 valid 0.5407399698611228
LOSS train 0.6295075225880591 valid 0.5410487661286006
LOSS train 0.6295075225880591 valid 0.5415994459763169
LOSS train 0.6295075225880591 valid 0.5417768781001752
LOSS train 0.6295075225880591 valid 0.5418022898110476
LOSS train 0.6295075225880591 valid 0.5414443807815438
LOSS train 0.6295075225880591 valid 0.5414000109714621
LOSS train 0.6295075225880591 valid 0.5415436651395715
LOSS train 0.6295075225880591 valid 0.5416477578026908
LOSS train 0.6295075225880591 valid 0.5416153509851912
LOSS train 0.6295075225880591 valid 0.5412083839376768
LOSS train 0.6295075225880591 valid 0.541028908670765
LOSS train 0.6295075225880591 valid 0.5406333618872875
LOSS train 0.6295075225880591 valid 0.5403781898816427
LOSS train 0.6295075225880591 valid 0.5404601622568933
LOSS train 0.6295075225880591 valid 0.540245695547624
LOSS train 0.6295075225880591 valid 0.5401235108192151
LOSS train 0.6295075225880591 valid 0.5399145453791075
LOSS train 0.6295075225880591 valid 0.5396763615310192
LOSS train 0.6295075225880591 valid 0.5393921423841406
LOSS train 0.6295075225880591 valid 0.5393624094928183
LOSS train 0.6295075225880591 valid 0.5395129150654896
LOSS train 0.6295075225880591 valid 0.5395717415071669
LOSS train 0.6295075225880591 valid 0.5393624410909765
LOSS train 0.6295075225880591 valid 0.5391425913156465
LOSS train 0.6295075225880591 valid 0.5392640986661802
LOSS train 0.6295075225880591 valid 0.5391663035208528
LOSS train 0.6295075225880591 valid 0.5394452066903703
LOSS train 0.6295075225880591 valid 0.5392845624023014
LOSS train 0.6295075225880591 valid 0.5391027514751141
LOSS train 0.6295075225880591 valid 0.5394028924081636
LOSS train 0.6295075225880591 valid 0.5393399544941482
LOSS train 0.6295075225880591 valid 0.5393034847492867
LOSS train 0.6295075225880591 valid 0.5390553292475249
LOSS train 0.6295075225880591 valid 0.5392342284321785
LOSS train 0.6295075225880591 valid 0.5392769329326669
LOSS train 0.6295075225880591 valid 0.5393803679213232
LOSS train 0.6295075225880591 valid 0.5393766056407582
LOSS train 0.6295075225880591 valid 0.539342207312584
LOSS train 0.6295075225880591 valid 0.5395933985710144
LOSS train 0.6295075225880591 valid 0.5397006080431097
LOSS train 0.6295075225880591 valid 0.5400675263219666
LOSS train 0.6295075225880591 valid 0.540125331053367
LOSS train 0.6295075225880591 valid 0.5402134293601626
LOSS train 0.6295075225880591 valid 0.5401262539737629
LOSS train 0.6295075225880591 valid 0.5400723218917847
LOSS train 0.6295075225880591 valid 0.5402567474930374
LOSS train 0.6295075225880591 valid 0.5402357266583574
LOSS train 0.6295075225880591 valid 0.540240650285374
LOSS train 0.6295075225880591 valid 0.5402842153300036
LOSS train 0.6295075225880591 valid 0.5402373953589371
LOSS train 0.6295075225880591 valid 0.540398594024962
LOSS train 0.6295075225880591 valid 0.5402974685033163
LOSS train 0.6295075225880591 valid 0.5402762086495109
LOSS train 0.6295075225880591 valid 0.5402289284714337
LOSS train 0.6295075225880591 valid 0.540235570862762
LOSS train 0.6295075225880591 valid 0.5402947027804488
LOSS train 0.6295075225880591 valid 0.5403308317440898
LOSS train 0.6295075225880591 valid 0.5403934816519419
LOSS train 0.6295075225880591 valid 0.5402683600906498
LOSS train 0.6295075225880591 valid 0.5401736405052122
LOSS train 0.6295075225880591 valid 0.5401483808106523
LOSS train 0.6295075225880591 valid 0.5402436443874913
LOSS train 0.6295075225880591 valid 0.5404012160301208
LOSS train 0.6295075225880591 valid 0.5403596295250787
LOSS train 0.6295075225880591 valid 0.5407375932678463
LOSS train 0.6295075225880591 valid 0.5408780379220843
LOSS train 0.6295075225880591 valid 0.5409235908079517
LOSS train 0.6295075225880591 valid 0.5408403025223658
LOSS train 0.6295075225880591 valid 0.5409253694628942
LOSS train 0.6295075225880591 valid 0.5408357594049338
LOSS train 0.6295075225880591 valid 0.5408281831813038
LOSS train 0.6295075225880591 valid 0.540793417549845
LOSS train 0.6295075225880591 valid 0.5407542626063029
LOSS train 0.6295075225880591 valid 0.5406427997000077
LOSS train 0.6295075225880591 valid 0.5405536367945427
LOSS train 0.6295075225880591 valid 0.5405610320360764
LOSS train 0.6295075225880591 valid 0.540334318610404
LOSS train 0.6295075225880591 valid 0.5403285763093404
LOSS train 0.6295075225880591 valid 0.5404570491601389
LOSS train 0.6295075225880591 valid 0.5406088396696977
LOSS train 0.6295075225880591 valid 0.5407093625802261
LOSS train 0.6295075225880591 valid 0.5406919887496365
LOSS train 0.6295075225880591 valid 0.5407075396899519
LOSS train 0.6295075225880591 valid 0.5407468496936642
LOSS train 0.6295075225880591 valid 0.5404961165927705
LOSS train 0.6295075225880591 valid 0.5407446473836899
LOSS train 0.6295075225880591 valid 0.5407181206165544
LOSS train 0.6295075225880591 valid 0.5407550732294718
LOSS train 0.6295075225880591 valid 0.5408545424606627
LOSS train 0.6295075225880591 valid 0.5408516008602945
LOSS train 0.6295075225880591 valid 0.5409322299209296
LOSS train 0.6295075225880591 valid 0.54085394043427
LOSS train 0.6295075225880591 valid 0.5409809754740807
LOSS train 0.6295075225880591 valid 0.54113452289349
LOSS train 0.6295075225880591 valid 0.541265857067837
LOSS train 0.6295075225880591 valid 0.5413221584845193
LOSS train 0.6295075225880591 valid 0.5409936297614619
LOSS train 0.6295075225880591 valid 0.5409561585634947
LOSS train 0.6295075225880591 valid 0.5409533126013619
LOSS train 0.6295075225880591 valid 0.5407448550801218
LOSS train 0.6295075225880591 valid 0.5407779783558991
LOSS train 0.6295075225880591 valid 0.5406266752539611
LOSS train 0.6295075225880591 valid 0.5405452731883887
LOSS train 0.6295075225880591 valid 0.5404552095625774
LOSS train 0.6295075225880591 valid 0.540657542779774
LOSS train 0.6295075225880591 valid 0.5406530126929283
LOSS train 0.6295075225880591 valid 0.5406525293750876
LOSS train 0.6295075225880591 valid 0.5406497559126686
LOSS train 0.6295075225880591 valid 0.5408197122010571
LOSS train 0.6295075225880591 valid 0.5407780966786451
LOSS train 0.6295075225880591 valid 0.5409087990060707
LOSS train 0.6295075225880591 valid 0.5408496733369499
LOSS train 0.6295075225880591 valid 0.5408165413992746
LOSS train 0.6295075225880591 valid 0.5408884974365885
LOSS train 0.6295075225880591 valid 0.540993017328661
LOSS train 0.6295075225880591 valid 0.5410482300801224
LOSS train 0.6295075225880591 valid 0.5409617677081231
LOSS train 0.6295075225880591 valid 0.5411300665802425
LOSS train 0.6295075225880591 valid 0.541174553046569
LOSS train 0.6295075225880591 valid 0.5411646411969111
LOSS train 0.6295075225880591 valid 0.5411750993442014
LOSS train 0.6295075225880591 valid 0.5412274910056073
LOSS train 0.6295075225880591 valid 0.5411397444235312
LOSS train 0.6295075225880591 valid 0.5411489150857413
LOSS train 0.6295075225880591 valid 0.5412244981622951
LOSS train 0.6295075225880591 valid 0.541366457939148
LOSS train 0.6295075225880591 valid 0.5413343613109891
LOSS train 0.6295075225880591 valid 0.5412584872622239
LOSS train 0.6295075225880591 valid 0.5412233128597599
LOSS train 0.6295075225880591 valid 0.5413060570135713
LOSS train 0.6295075225880591 valid 0.5414025014546251
LOSS train 0.6295075225880591 valid 0.5412859495767613
LOSS train 0.6295075225880591 valid 0.5412212656094477
LOSS train 0.6295075225880591 valid 0.5412962920203501
LOSS train 0.6295075225880591 valid 0.54142743107026
LOSS train 0.6295075225880591 valid 0.5414570542899045
LOSS train 0.6295075225880591 valid 0.5414730226574231
LOSS train 0.6295075225880591 valid 0.5416674074530602
LOSS train 0.6295075225880591 valid 0.5415626467756964
LOSS train 0.6295075225880591 valid 0.5415695613563651
LOSS train 0.6295075225880591 valid 0.5414960830669685
LOSS train 0.6295075225880591 valid 0.54151205163376
LOSS train 0.6295075225880591 valid 0.5415152727103815
LOSS train 0.6295075225880591 valid 0.5415261879708003
LOSS train 0.6295075225880591 valid 0.5416220026315698
LOSS train 0.6295075225880591 valid 0.5416003591739215
LOSS train 0.6295075225880591 valid 0.5415139660310517
LOSS train 0.6295075225880591 valid 0.5415656620547885
LOSS train 0.6295075225880591 valid 0.5415616552411663
LOSS train 0.6295075225880591 valid 0.5415435694860962
LOSS train 0.6295075225880591 valid 0.5414866715529715
LOSS train 0.6295075225880591 valid 0.5414285657004775
LOSS train 0.6295075225880591 valid 0.5414170755896457
LOSS train 0.6295075225880591 valid 0.5414560263355573
LOSS train 0.6295075225880591 valid 0.5414873548367056
LOSS train 0.6295075225880591 valid 0.5414306751084984
LOSS train 0.6295075225880591 valid 0.5413867207966983
LOSS train 0.6295075225880591 valid 0.541393290866505
LOSS train 0.6295075225880591 valid 0.5414749270650596
LOSS train 0.6295075225880591 valid 0.5415687211998949
LOSS train 0.6295075225880591 valid 0.5417362355330599
LOSS train 0.6295075225880591 valid 0.541724714317492
LOSS train 0.6295075225880591 valid 0.5416707640224033
LOSS train 0.6295075225880591 valid 0.541581971982939
LOSS train 0.6295075225880591 valid 0.5417026160572069
LOSS train 0.6295075225880591 valid 0.5417615190932625
LOSS train 0.6295075225880591 valid 0.5417745649554323
LOSS train 0.6295075225880591 valid 0.5417570438074029
LOSS train 0.6295075225880591 valid 0.5417390321240281
LOSS train 0.6295075225880591 valid 0.5417149357240776
LOSS train 0.6295075225880591 valid 0.5417301729001712
LOSS train 0.6295075225880591 valid 0.541711029333946
LOSS train 0.6295075225880591 valid 0.5416824401693141
LOSS train 0.6295075225880591 valid 0.5416401627205186
LOSS train 0.6295075225880591 valid 0.5416980898832973
LOSS train 0.6295075225880591 valid 0.5416887925953424
LOSS train 0.6295075225880591 valid 0.5416947201704879
LOSS train 0.6295075225880591 valid 0.5417214619616667
LOSS train 0.6295075225880591 valid 0.5417000577162905
LOSS train 0.6295075225880591 valid 0.5416623235734042
LOSS train 0.6295075225880591 valid 0.5416775321273647
LOSS train 0.6295075225880591 valid 0.5417391479503914
LOSS train 0.6295075225880591 valid 0.5417210907352213
LOSS train 0.6295075225880591 valid 0.541718869189906
LOSS train 0.6295075225880591 valid 0.5417663751826113
LOSS train 0.6295075225880591 valid 0.5416735477985875
LOSS train 0.6295075225880591 valid 0.5416457801458826
LOSS train 0.6295075225880591 valid 0.5417036006450653
LOSS train 0.6295075225880591 valid 0.5416838854432581
LOSS train 0.6295075225880591 valid 0.5417136762823377
LOSS train 0.6295075225880591 valid 0.5417345908319526
LOSS train 0.6295075225880591 valid 0.5418438869198476
LOSS train 0.6295075225880591 valid 0.5417883110981362
LOSS train 0.6295075225880591 valid 0.5417672502808273
LOSS train 0.6295075225880591 valid 0.5417162314463219
LOSS train 0.6295075225880591 valid 0.5417038234629372
LOSS train 0.6295075225880591 valid 0.541750151678402
LOSS train 0.6295075225880591 valid 0.5418258036558444
LOSS train 0.6295075225880591 valid 0.5418676455358893
LOSS train 0.6295075225880591 valid 0.5418176462177102
LOSS train 0.6295075225880591 valid 0.5418581307614257
LOSS train 0.6295075225880591 valid 0.5418889104868426
LOSS train 0.6295075225880591 valid 0.5419356217924154
LOSS train 0.6295075225880591 valid 0.5419268045658455
LOSS train 0.6295075225880591 valid 0.5420269544204969
LOSS train 0.6295075225880591 valid 0.5420222822854768
LOSS train 0.6295075225880591 valid 0.542122899599678
LOSS train 0.6295075225880591 valid 0.5421177415936081
LOSS train 0.6295075225880591 valid 0.5421533063329014
LOSS train 0.6295075225880591 valid 0.5422611808513894
LOSS train 0.6295075225880591 valid 0.542381050604167
LOSS train 0.6295075225880591 valid 0.5423797640922295
LOSS train 0.6295075225880591 valid 0.5424030152234164
LOSS train 0.6295075225880591 valid 0.542491139277168
LOSS train 0.6295075225880591 valid 0.5424741560371343
LOSS train 0.6295075225880591 valid 0.5424614379303061
LOSS train 0.6295075225880591 valid 0.5425215504502737
LOSS train 0.6295075225880591 valid 0.5424826249480248
LOSS train 0.6295075225880591 valid 0.5424126503306351
LOSS train 0.6295075225880591 valid 0.5423325769444729
LOSS train 0.6295075225880591 valid 0.5423321096298973
LOSS train 0.6295075225880591 valid 0.5423543356673818
LOSS train 0.6295075225880591 valid 0.5423119913067734
LOSS train 0.6295075225880591 valid 0.5422327239196617
LOSS train 0.6295075225880591 valid 0.5422076175852519
LOSS train 0.6295075225880591 valid 0.5422447406583362
LOSS train 0.6295075225880591 valid 0.5421986683017243
LOSS train 0.6295075225880591 valid 0.5422727461518912
LOSS train 0.6295075225880591 valid 0.5421345123310679
LOSS train 0.6295075225880591 valid 0.5421842489748785
LOSS train 0.6295075225880591 valid 0.5421238970837903
LOSS train 0.6295075225880591 valid 0.5421780619491525
LOSS train 0.6295075225880591 valid 0.5422736361875372
LOSS train 0.6295075225880591 valid 0.5422848706712594
LOSS train 0.6295075225880591 valid 0.5422405070728726
LOSS train 0.6295075225880591 valid 0.5422219380036296
LOSS train 0.6295075225880591 valid 0.542244651046485
LOSS train 0.6295075225880591 valid 0.5422063438097636
LOSS train 0.6295075225880591 valid 0.5421950997308244
LOSS train 0.6295075225880591 valid 0.5421552679791356
LOSS train 0.6295075225880591 valid 0.5421730685155384
LOSS train 0.6295075225880591 valid 0.5421025674594077
LOSS train 0.6295075225880591 valid 0.5421125372902291
LOSS train 0.6295075225880591 valid 0.5421067748973573
LOSS train 0.6295075225880591 valid 0.5420851451177938
LOSS train 0.6295075225880591 valid 0.5420061001529941
LOSS train 0.6295075225880591 valid 0.5420275706689335
LOSS train 0.6295075225880591 valid 0.5420279575932411
LOSS train 0.6295075225880591 valid 0.5419720533959735
LOSS train 0.6295075225880591 valid 0.5420320744697864
LOSS train 0.6295075225880591 valid 0.5420603755944834
LOSS train 0.6295075225880591 valid 0.5420882343106969
LOSS train 0.6295075225880591 valid 0.5420749832713415
LOSS train 0.6295075225880591 valid 0.5420172022113318
LOSS train 0.6295075225880591 valid 0.5419968359101834
LOSS train 0.6295075225880591 valid 0.5419457091850305
LOSS train 0.6295075225880591 valid 0.54190930191626
LOSS train 0.6295075225880591 valid 0.5419232547283173
LOSS train 0.6295075225880591 valid 0.5419319444727675
LOSS train 0.6295075225880591 valid 0.5419776321197889
LOSS train 0.6295075225880591 valid 0.541916945770429
LOSS train 0.6295075225880591 valid 0.541927609178755
LOSS train 0.6295075225880591 valid 0.5419380321869484
LOSS train 0.6295075225880591 valid 0.5419603728809239
LOSS train 0.6295075225880591 valid 0.5420247695497052
LOSS train 0.6295075225880591 valid 0.5420171434922916
LOSS train 0.6295075225880591 valid 0.5420082479624763
LOSS train 0.6295075225880591 valid 0.5419552638675227
LOSS train 0.6295075225880591 valid 0.5419146735502514
LOSS train 0.6295075225880591 valid 0.5418265575026892
LOSS train 0.6295075225880591 valid 0.541808304664967
LOSS train 0.6295075225880591 valid 0.541885819977629
LOSS train 0.6295075225880591 valid 0.5418544751494678
LOSS train 0.6295075225880591 valid 0.541912125512248
LOSS train 0.6295075225880591 valid 0.5419063785663344
LOSS train 0.6295075225880591 valid 0.5419565440987694
LOSS train 0.6295075225880591 valid 0.5419552612796997
LOSS train 0.6295075225880591 valid 0.5419592922224717
LOSS train 0.6295075225880591 valid 0.5419335429969072
LOSS train 0.6295075225880591 valid 0.5419620575263486
LOSS train 0.6295075225880591 valid 0.5419801675195944
LOSS train 0.6295075225880591 valid 0.5420557936263639
LOSS train 0.6295075225880591 valid 0.5420713191447051
LOSS train 0.6295075225880591 valid 0.5421100114122291
LOSS train 0.6295075225880591 valid 0.5421157446649645
LOSS train 0.6295075225880591 valid 0.5421167999163441
LOSS train 0.6295075225880591 valid 0.5421712142348631
LOSS train 0.6295075225880591 valid 0.5421751396996635
LOSS train 0.6295075225880591 valid 0.5422061569670327
LOSS train 0.6295075225880591 valid 0.5422337766398083
LOSS train 0.6295075225880591 valid 0.5422663626184544
LOSS train 0.6295075225880591 valid 0.5422925051659514
LOSS train 0.6295075225880591 valid 0.5422867417335511
LOSS train 0.6295075225880591 valid 0.5422845507940549
LOSS train 0.6295075225880591 valid 0.5422337667948726
LOSS train 0.6295075225880591 valid 0.5421373043313372
LOSS train 0.6295075225880591 valid 0.5421754385767541
LOSS train 0.6295075225880591 valid 0.5421245147784551
LOSS train 0.6295075225880591 valid 0.5421582143392589
LOSS train 0.6295075225880591 valid 0.5421416341270531
LOSS train 0.6295075225880591 valid 0.5421848801213519
LOSS train 0.6295075225880591 valid 0.5421591258638507
LOSS train 0.6295075225880591 valid 0.5421852894025306
LOSS train 0.6295075225880591 valid 0.542156370122576
LOSS train 0.6295075225880591 valid 0.5420850175927705
LOSS train 0.6295075225880591 valid 0.5421544755606548
LOSS train 0.6295075225880591 valid 0.5421755246030606
EPOCH 4:
  batch 1 loss: 0.6187130808830261
  batch 2 loss: 0.6183560192584991
  batch 3 loss: 0.6229591766993204
  batch 4 loss: 0.626611739397049
  batch 5 loss: 0.6231664061546326
  batch 6 loss: 0.6235014100869497
  batch 7 loss: 0.624751627445221
  batch 8 loss: 0.6206851974129677
  batch 9 loss: 0.6214133964644538
  batch 10 loss: 0.622445410490036
  batch 11 loss: 0.6250141750682484
  batch 12 loss: 0.6238071322441101
  batch 13 loss: 0.6249017348656287
  batch 14 loss: 0.6244516287531171
  batch 15 loss: 0.6268637259801229
  batch 16 loss: 0.6257006227970123
  batch 17 loss: 0.6265775561332703
  batch 18 loss: 0.6272840135627322
  batch 19 loss: 0.627225355098122
  batch 20 loss: 0.6279236972332001
  batch 21 loss: 0.627481514499301
  batch 22 loss: 0.6273383091796528
  batch 23 loss: 0.625700927299002
  batch 24 loss: 0.6250982781251272
  batch 25 loss: 0.6252349948883057
  batch 26 loss: 0.6247816406763517
  batch 27 loss: 0.6235138486932825
  batch 28 loss: 0.622191248195512
  batch 29 loss: 0.6224931499053692
  batch 30 loss: 0.6219435969988505
  batch 31 loss: 0.6209814856129308
  batch 32 loss: 0.6206823959946632
  batch 33 loss: 0.6204896478941946
  batch 34 loss: 0.6204645072712618
  batch 35 loss: 0.6215326155935015
  batch 36 loss: 0.6214825461308161
  batch 37 loss: 0.6209072921727155
  batch 38 loss: 0.6205740037717318
  batch 39 loss: 0.6205333440731733
  batch 40 loss: 0.6204105034470558
  batch 41 loss: 0.6200199098121829
  batch 42 loss: 0.620150150287719
  batch 43 loss: 0.6203058057053145
  batch 44 loss: 0.6200497123328123
  batch 45 loss: 0.6200576808717516
  batch 46 loss: 0.6193043421144071
  batch 47 loss: 0.6198162373076094
  batch 48 loss: 0.619302841524283
  batch 49 loss: 0.6189813613891602
  batch 50 loss: 0.6186698198318481
  batch 51 loss: 0.6188528046888464
  batch 52 loss: 0.6188266884822112
  batch 53 loss: 0.6188560195688931
  batch 54 loss: 0.6187132939144417
  batch 55 loss: 0.6185529492118141
  batch 56 loss: 0.618256002664566
  batch 57 loss: 0.6182644565900167
  batch 58 loss: 0.618423537961368
  batch 59 loss: 0.6179984777660693
  batch 60 loss: 0.6181355526049932
  batch 61 loss: 0.6177757509419175
  batch 62 loss: 0.6179420621164383
  batch 63 loss: 0.6175634615005009
  batch 64 loss: 0.6175594963133335
  batch 65 loss: 0.6170873045921326
  batch 66 loss: 0.6168343551231154
  batch 67 loss: 0.6168752090254827
  batch 68 loss: 0.6171749453334248
  batch 69 loss: 0.6172179648841637
  batch 70 loss: 0.6169447796685356
  batch 71 loss: 0.6171598182597631
  batch 72 loss: 0.6169015922480159
  batch 73 loss: 0.6170079340673473
  batch 74 loss: 0.6170705669635052
  batch 75 loss: 0.6167640296618143
  batch 76 loss: 0.6173234801543387
  batch 77 loss: 0.6169907172004898
  batch 78 loss: 0.6165997385978699
  batch 79 loss: 0.6167720269553268
  batch 80 loss: 0.6167619518935681
  batch 81 loss: 0.6166392770814307
  batch 82 loss: 0.6165957763427641
  batch 83 loss: 0.6163940558950585
  batch 84 loss: 0.6162657879647755
  batch 85 loss: 0.6158020692713121
  batch 86 loss: 0.6163635143013888
  batch 87 loss: 0.6162242505742216
  batch 88 loss: 0.6158475022424351
  batch 89 loss: 0.6158160828472523
  batch 90 loss: 0.61573702428076
  batch 91 loss: 0.6154847079580956
  batch 92 loss: 0.6154134603946105
  batch 93 loss: 0.6157302580853944
  batch 94 loss: 0.6156823451214648
  batch 95 loss: 0.6156034632732994
  batch 96 loss: 0.6155951327333847
  batch 97 loss: 0.6154245648187461
  batch 98 loss: 0.615414463135661
  batch 99 loss: 0.6154997384909427
  batch 100 loss: 0.61546326816082
  batch 101 loss: 0.6153218946834602
  batch 102 loss: 0.6154503249654583
  batch 103 loss: 0.6154650085180708
  batch 104 loss: 0.6155365974857256
  batch 105 loss: 0.6154700001080831
  batch 106 loss: 0.6154376791333253
  batch 107 loss: 0.6150629069203528
  batch 108 loss: 0.6151229225926929
  batch 109 loss: 0.6150565645016661
  batch 110 loss: 0.6154308958487077
  batch 111 loss: 0.6152917152052527
  batch 112 loss: 0.6152612135878631
  batch 113 loss: 0.6152493188866471
  batch 114 loss: 0.6155709195555302
  batch 115 loss: 0.6153885592585024
  batch 116 loss: 0.6154225314485615
  batch 117 loss: 0.6153736837908753
  batch 118 loss: 0.6153605787430779
  batch 119 loss: 0.615194765960469
  batch 120 loss: 0.6151053269704183
  batch 121 loss: 0.6148161533450293
  batch 122 loss: 0.6147142541213114
  batch 123 loss: 0.6145615742458561
  batch 124 loss: 0.6149645515026585
  batch 125 loss: 0.6150187082290649
  batch 126 loss: 0.6146377646733844
  batch 127 loss: 0.6145235483101973
  batch 128 loss: 0.6144130858592689
  batch 129 loss: 0.6140598543854647
  batch 130 loss: 0.6140597898226517
  batch 131 loss: 0.6141800625633648
  batch 132 loss: 0.6141794789018054
  batch 133 loss: 0.6143539834739571
  batch 134 loss: 0.61421615908395
  batch 135 loss: 0.6142820433334067
  batch 136 loss: 0.6143121281090904
  batch 137 loss: 0.6145263792824571
  batch 138 loss: 0.6144535468108412
  batch 139 loss: 0.6144894803170677
  batch 140 loss: 0.6144477699484144
  batch 141 loss: 0.6143165771842848
  batch 142 loss: 0.6141986783961175
  batch 143 loss: 0.61392008508002
  batch 144 loss: 0.6139418797360526
  batch 145 loss: 0.6138958166385519
  batch 146 loss: 0.613963148365282
  batch 147 loss: 0.6139654768567507
  batch 148 loss: 0.6139302910179705
  batch 149 loss: 0.6139229980091121
  batch 150 loss: 0.6138769233226776
  batch 151 loss: 0.6139453298208729
  batch 152 loss: 0.6139019723785551
  batch 153 loss: 0.6139460615083283
  batch 154 loss: 0.6140331432416841
  batch 155 loss: 0.6139784589890511
  batch 156 loss: 0.6139333851826496
  batch 157 loss: 0.6139375009354512
  batch 158 loss: 0.6139791117438788
  batch 159 loss: 0.6138939760016195
  batch 160 loss: 0.6139401957392693
  batch 161 loss: 0.6139495983627272
  batch 162 loss: 0.6138820320735743
  batch 163 loss: 0.6139032383637926
  batch 164 loss: 0.6138558438638362
  batch 165 loss: 0.6137083768844604
  batch 166 loss: 0.6137789742774274
  batch 167 loss: 0.6136541063200214
  batch 168 loss: 0.6138985231518745
  batch 169 loss: 0.6138196827391901
  batch 170 loss: 0.6140034773770501
  batch 171 loss: 0.6139252977064479
  batch 172 loss: 0.6137847293948018
  batch 173 loss: 0.6137884872497161
  batch 174 loss: 0.6137793965038212
  batch 175 loss: 0.6137120543207442
  batch 176 loss: 0.613666661422361
  batch 177 loss: 0.6135824060035964
  batch 178 loss: 0.6134957527176718
  batch 179 loss: 0.6134035630599081
  batch 180 loss: 0.61337741083569
  batch 181 loss: 0.6134975746850282
  batch 182 loss: 0.6132798253834902
  batch 183 loss: 0.6133940636785955
  batch 184 loss: 0.6132206414704737
  batch 185 loss: 0.6133213426615741
  batch 186 loss: 0.613369115898686
  batch 187 loss: 0.6133566970493705
  batch 188 loss: 0.613377109804052
  batch 189 loss: 0.6132116566890131
  batch 190 loss: 0.6131169027403781
  batch 191 loss: 0.6129951267966425
  batch 192 loss: 0.6130383942897121
  batch 193 loss: 0.6130048552325352
  batch 194 loss: 0.6129463966359797
  batch 195 loss: 0.613000020919702
  batch 196 loss: 0.6129052994810805
  batch 197 loss: 0.6131178609610815
  batch 198 loss: 0.6131585776203811
  batch 199 loss: 0.613131913707484
  batch 200 loss: 0.6132593762874603
  batch 201 loss: 0.6134166106655823
  batch 202 loss: 0.6134338305138125
  batch 203 loss: 0.6134548243043458
  batch 204 loss: 0.6133246567903781
  batch 205 loss: 0.6134596897334588
  batch 206 loss: 0.6134856106008141
  batch 207 loss: 0.613446609409535
  batch 208 loss: 0.6134248524904251
  batch 209 loss: 0.6133765746531874
  batch 210 loss: 0.6134345440637498
  batch 211 loss: 0.6134219937979892
  batch 212 loss: 0.613400639790409
  batch 213 loss: 0.6134675089182429
  batch 214 loss: 0.6134396771961284
  batch 215 loss: 0.6133060247399086
  batch 216 loss: 0.6132007235730136
  batch 217 loss: 0.6132988951722598
  batch 218 loss: 0.6134238155609971
  batch 219 loss: 0.6132314575317244
  batch 220 loss: 0.6131948400627483
  batch 221 loss: 0.6131965787702016
  batch 222 loss: 0.6133797783572394
  batch 223 loss: 0.6134632740320112
  batch 224 loss: 0.613443805703095
  batch 225 loss: 0.6134155564837985
  batch 226 loss: 0.6134206420552414
  batch 227 loss: 0.6133407406869964
  batch 228 loss: 0.6132841653991163
  batch 229 loss: 0.61325687091944
  batch 230 loss: 0.6133054515589839
  batch 231 loss: 0.613387639904435
  batch 232 loss: 0.6133008948687849
  batch 233 loss: 0.6133113879502587
  batch 234 loss: 0.6131977711477851
  batch 235 loss: 0.6131603897886073
  batch 236 loss: 0.6131247143119068
  batch 237 loss: 0.6132225172932138
  batch 238 loss: 0.6132523224634283
  batch 239 loss: 0.6132660316124122
  batch 240 loss: 0.6132602701584499
  batch 241 loss: 0.6132684226352644
  batch 242 loss: 0.6132460209456357
  batch 243 loss: 0.6132608845891285
  batch 244 loss: 0.6132650827286673
  batch 245 loss: 0.613307020372274
  batch 246 loss: 0.6135123909973517
  batch 247 loss: 0.6134904063182322
  batch 248 loss: 0.6135348206566226
  batch 249 loss: 0.6135177741567772
  batch 250 loss: 0.613582270860672
  batch 251 loss: 0.6134997247699723
  batch 252 loss: 0.6135096400976181
  batch 253 loss: 0.6134241279877222
  batch 254 loss: 0.6134285070295409
  batch 255 loss: 0.6134507462090137
  batch 256 loss: 0.6133936753030866
  batch 257 loss: 0.613406375456413
  batch 258 loss: 0.6135043102179387
  batch 259 loss: 0.6134026227770625
  batch 260 loss: 0.6133679270744323
  batch 261 loss: 0.6133451934518486
  batch 262 loss: 0.6132905030523548
  batch 263 loss: 0.6132129961093569
  batch 264 loss: 0.6131085843750925
  batch 265 loss: 0.6131370198051884
  batch 266 loss: 0.6131277315150526
  batch 267 loss: 0.6131494913654827
  batch 268 loss: 0.6131294038313538
  batch 269 loss: 0.6130244058304116
  batch 270 loss: 0.6130288380163688
  batch 271 loss: 0.6131029289586958
  batch 272 loss: 0.6131399541216738
  batch 273 loss: 0.6130989519231048
  batch 274 loss: 0.6130258464900247
  batch 275 loss: 0.6130600181492892
  batch 276 loss: 0.6131246737811876
  batch 277 loss: 0.61312081495347
  batch 278 loss: 0.6130692873069709
  batch 279 loss: 0.6130941813564642
  batch 280 loss: 0.6131124909435
  batch 281 loss: 0.613114256875795
  batch 282 loss: 0.6130329330339499
  batch 283 loss: 0.6128862763462134
  batch 284 loss: 0.6128645318914467
  batch 285 loss: 0.6128394681110717
  batch 286 loss: 0.6126905239962198
  batch 287 loss: 0.6126606113403932
  batch 288 loss: 0.6124906902097993
  batch 289 loss: 0.6124857121685384
  batch 290 loss: 0.612381617159679
  batch 291 loss: 0.6122523959969327
  batch 292 loss: 0.612282441903467
  batch 293 loss: 0.6122178319371194
  batch 294 loss: 0.6122306078469673
  batch 295 loss: 0.6122362740969254
  batch 296 loss: 0.6121220252401119
  batch 297 loss: 0.6120938815251745
  batch 298 loss: 0.6119879526179909
  batch 299 loss: 0.6119834469712299
  batch 300 loss: 0.6120068361361821
  batch 301 loss: 0.6119082506708925
  batch 302 loss: 0.6118177082759655
  batch 303 loss: 0.6118459435972837
  batch 304 loss: 0.6118115345506292
  batch 305 loss: 0.6116504632058691
  batch 306 loss: 0.6116932790263806
  batch 307 loss: 0.6116905344425662
  batch 308 loss: 0.611701744717437
  batch 309 loss: 0.6117179713974493
  batch 310 loss: 0.6116988631986803
  batch 311 loss: 0.6117207770178938
  batch 312 loss: 0.6117899295611259
  batch 313 loss: 0.6117347189412711
  batch 314 loss: 0.6116685183944216
  batch 315 loss: 0.6117084232587663
  batch 316 loss: 0.6117048061723951
  batch 317 loss: 0.6116564347164865
  batch 318 loss: 0.6115664627941899
  batch 319 loss: 0.6115465999396991
  batch 320 loss: 0.6113997247070074
  batch 321 loss: 0.611334989746783
  batch 322 loss: 0.6113449288821369
  batch 323 loss: 0.6112788024332502
  batch 324 loss: 0.6112171718735754
  batch 325 loss: 0.6112310792849615
  batch 326 loss: 0.6112679502715362
  batch 327 loss: 0.6112306786968803
  batch 328 loss: 0.6112566795654413
  batch 329 loss: 0.6113133501136919
  batch 330 loss: 0.6113331684560487
  batch 331 loss: 0.6113382903830883
  batch 332 loss: 0.6113305660974548
  batch 333 loss: 0.6113391937436284
  batch 334 loss: 0.611366199697563
  batch 335 loss: 0.6112720498398169
  batch 336 loss: 0.6112620193688643
  batch 337 loss: 0.6112017629762078
  batch 338 loss: 0.6112467690685092
  batch 339 loss: 0.6113053778279848
  batch 340 loss: 0.6112322954570546
  batch 341 loss: 0.6111245917434917
  batch 342 loss: 0.6111617607679981
  batch 343 loss: 0.6112290135973049
  batch 344 loss: 0.6111243062241133
  batch 345 loss: 0.6111508614775063
  batch 346 loss: 0.6110701605763739
  batch 347 loss: 0.6110881494857392
  batch 348 loss: 0.6111064745091844
  batch 349 loss: 0.6110333882293592
  batch 350 loss: 0.6109869767938342
  batch 351 loss: 0.6109970685763236
  batch 352 loss: 0.610958877612244
  batch 353 loss: 0.6109579953525964
  batch 354 loss: 0.6109459758815119
  batch 355 loss: 0.6110216513485975
  batch 356 loss: 0.611035067378805
  batch 357 loss: 0.611061430778824
  batch 358 loss: 0.6110483241480822
  batch 359 loss: 0.6110102381546849
  batch 360 loss: 0.6110315803024504
  batch 361 loss: 0.6109612592369565
  batch 362 loss: 0.6109633735530284
  batch 363 loss: 0.6109181701644393
  batch 364 loss: 0.6108029851546655
  batch 365 loss: 0.610802675926522
  batch 366 loss: 0.6107906370215077
  batch 367 loss: 0.6107836896782025
  batch 368 loss: 0.6107598290495251
  batch 369 loss: 0.6108505816317509
  batch 370 loss: 0.6109228379017598
  batch 371 loss: 0.6109202287267803
  batch 372 loss: 0.6108319788209854
  batch 373 loss: 0.6107367734167595
  batch 374 loss: 0.6107144355773926
  batch 375 loss: 0.6106175524393718
  batch 376 loss: 0.6106607818857153
  batch 377 loss: 0.610564610369958
  batch 378 loss: 0.6104986872622575
  batch 379 loss: 0.6104639152109151
  batch 380 loss: 0.6104322129174282
  batch 381 loss: 0.6103996407641513
  batch 382 loss: 0.6103130703821232
  batch 383 loss: 0.6103316315160408
  batch 384 loss: 0.6103126540159186
  batch 385 loss: 0.6103858012657661
  batch 386 loss: 0.6103552074938858
  batch 387 loss: 0.6103617277872346
  batch 388 loss: 0.6103660444316176
  batch 389 loss: 0.6103698980532453
  batch 390 loss: 0.6103244307713631
  batch 391 loss: 0.6103132322926046
  batch 392 loss: 0.6102779684018116
  batch 393 loss: 0.6103123569003195
  batch 394 loss: 0.61035329315263
  batch 395 loss: 0.6102330296854429
  batch 396 loss: 0.6101875237443231
  batch 397 loss: 0.6101267192165557
  batch 398 loss: 0.6100875621464983
  batch 399 loss: 0.6100698584004453
  batch 400 loss: 0.6100034090876579
  batch 401 loss: 0.6099344866531449
  batch 402 loss: 0.609925717560213
  batch 403 loss: 0.6098945328674601
  batch 404 loss: 0.6098190391122704
  batch 405 loss: 0.6097942271350343
  batch 406 loss: 0.6098271834439245
  batch 407 loss: 0.6099083189296488
  batch 408 loss: 0.6099813111564693
  batch 409 loss: 0.6099492356654775
  batch 410 loss: 0.6099177440492118
  batch 411 loss: 0.6099006611935414
  batch 412 loss: 0.6098526023255969
  batch 413 loss: 0.6097870855874068
  batch 414 loss: 0.6097839859084807
  batch 415 loss: 0.6097322000078408
  batch 416 loss: 0.6097084199293301
  batch 417 loss: 0.6097367294400716
  batch 418 loss: 0.6096970831093035
  batch 419 loss: 0.6096959579246994
  batch 420 loss: 0.60971787131968
  batch 421 loss: 0.6097366290251036
  batch 422 loss: 0.6098700042866982
  batch 423 loss: 0.6098470100274322
  batch 424 loss: 0.6098670474482033
  batch 425 loss: 0.6098759088796728
  batch 426 loss: 0.609874276627957
  batch 427 loss: 0.6098417759779187
  batch 428 loss: 0.6098346355083947
  batch 429 loss: 0.6098207393726269
  batch 430 loss: 0.6098439510478529
  batch 431 loss: 0.609863334631422
  batch 432 loss: 0.6099144798462037
  batch 433 loss: 0.60992230457742
  batch 434 loss: 0.6099430447624575
  batch 435 loss: 0.609959894076161
  batch 436 loss: 0.6099283604993733
  batch 437 loss: 0.6099272542196226
  batch 438 loss: 0.609997911404257
  batch 439 loss: 0.6099798456682974
  batch 440 loss: 0.6099579074166038
  batch 441 loss: 0.6099239247185844
  batch 442 loss: 0.609834152379187
  batch 443 loss: 0.609780896328911
  batch 444 loss: 0.6097463768076252
  batch 445 loss: 0.6097362983092833
  batch 446 loss: 0.6096931912439286
  batch 447 loss: 0.6096197322711049
  batch 448 loss: 0.6095718215884907
  batch 449 loss: 0.6096235473862204
  batch 450 loss: 0.6096150390307109
  batch 451 loss: 0.6095539746421932
  batch 452 loss: 0.6095246725377783
  batch 453 loss: 0.6095322065269184
  batch 454 loss: 0.6095871050977497
  batch 455 loss: 0.6096040136211521
  batch 456 loss: 0.6095741226484901
  batch 457 loss: 0.6095657092998013
  batch 458 loss: 0.609577611674388
  batch 459 loss: 0.6096098434691336
  batch 460 loss: 0.6096355206292609
  batch 461 loss: 0.6095992907267589
  batch 462 loss: 0.6095995211498045
  batch 463 loss: 0.609661104612165
  batch 464 loss: 0.6096965249242454
  batch 465 loss: 0.6096388839906262
  batch 466 loss: 0.6096060800450043
  batch 467 loss: 0.609661736120759
  batch 468 loss: 0.6096135389346343
  batch 469 loss: 0.6096006645830964
  batch 470 loss: 0.6095721920754047
  batch 471 loss: 0.609593005317032
  batch 472 loss: 0.6095350772394972
LOSS train 0.6095350772394972 valid 0.5047681927680969
LOSS train 0.6095350772394972 valid 0.4961247593164444
LOSS train 0.6095350772394972 valid 0.5013580024242401
LOSS train 0.6095350772394972 valid 0.49776383489370346
LOSS train 0.6095350772394972 valid 0.49655218720436095
LOSS train 0.6095350772394972 valid 0.4967392335335414
LOSS train 0.6095350772394972 valid 0.4984947655882154
LOSS train 0.6095350772394972 valid 0.5002717860043049
LOSS train 0.6095350772394972 valid 0.4993162353833516
LOSS train 0.6095350772394972 valid 0.49811103343963625
LOSS train 0.6095350772394972 valid 0.5005866289138794
LOSS train 0.6095350772394972 valid 0.5007879336675009
LOSS train 0.6095350772394972 valid 0.5022941736074594
LOSS train 0.6095350772394972 valid 0.5021612388747079
LOSS train 0.6095350772394972 valid 0.5018138845761617
LOSS train 0.6095350772394972 valid 0.5023904927074909
LOSS train 0.6095350772394972 valid 0.5034968046581044
LOSS train 0.6095350772394972 valid 0.5030727287133535
LOSS train 0.6095350772394972 valid 0.5015460927235452
LOSS train 0.6095350772394972 valid 0.5035835012793541
LOSS train 0.6095350772394972 valid 0.5027367969353994
LOSS train 0.6095350772394972 valid 0.5010896650227633
LOSS train 0.6095350772394972 valid 0.5017444698706918
LOSS train 0.6095350772394972 valid 0.5017756298184395
LOSS train 0.6095350772394972 valid 0.5013723015785218
LOSS train 0.6095350772394972 valid 0.5015233502938197
LOSS train 0.6095350772394972 valid 0.5017278150275901
LOSS train 0.6095350772394972 valid 0.5017563019480024
LOSS train 0.6095350772394972 valid 0.5013386052230309
LOSS train 0.6095350772394972 valid 0.5024476706981659
LOSS train 0.6095350772394972 valid 0.50317164967137
LOSS train 0.6095350772394972 valid 0.5025624800473452
LOSS train 0.6095350772394972 valid 0.5032526019847754
LOSS train 0.6095350772394972 valid 0.5031942514812245
LOSS train 0.6095350772394972 valid 0.5034645029476711
LOSS train 0.6095350772394972 valid 0.5035327590174146
LOSS train 0.6095350772394972 valid 0.5045554943986841
LOSS train 0.6095350772394972 valid 0.5047395135227003
LOSS train 0.6095350772394972 valid 0.5042204925647149
LOSS train 0.6095350772394972 valid 0.5047214888036251
LOSS train 0.6095350772394972 valid 0.5046825721496488
LOSS train 0.6095350772394972 valid 0.5043014209894907
LOSS train 0.6095350772394972 valid 0.5039496997068095
LOSS train 0.6095350772394972 valid 0.5035440224138173
LOSS train 0.6095350772394972 valid 0.5036431557602352
LOSS train 0.6095350772394972 valid 0.5043492090442906
LOSS train 0.6095350772394972 valid 0.5040399635091741
LOSS train 0.6095350772394972 valid 0.5042607175807158
LOSS train 0.6095350772394972 valid 0.5043802711428428
LOSS train 0.6095350772394972 valid 0.5040123635530471
LOSS train 0.6095350772394972 valid 0.5043973531208786
LOSS train 0.6095350772394972 valid 0.5043300911784172
LOSS train 0.6095350772394972 valid 0.5048855042682504
LOSS train 0.6095350772394972 valid 0.5047253469626108
LOSS train 0.6095350772394972 valid 0.5045913967219267
LOSS train 0.6095350772394972 valid 0.5049145040767533
LOSS train 0.6095350772394972 valid 0.5050036332063508
LOSS train 0.6095350772394972 valid 0.50467146316479
LOSS train 0.6095350772394972 valid 0.504623923766411
LOSS train 0.6095350772394972 valid 0.5049786562720935
LOSS train 0.6095350772394972 valid 0.5043451136252919
LOSS train 0.6095350772394972 valid 0.5046156543877817
LOSS train 0.6095350772394972 valid 0.5048036125917283
LOSS train 0.6095350772394972 valid 0.5055675976909697
LOSS train 0.6095350772394972 valid 0.5056754887104035
LOSS train 0.6095350772394972 valid 0.5057029990535794
LOSS train 0.6095350772394972 valid 0.5055799337465372
LOSS train 0.6095350772394972 valid 0.5055975795668715
LOSS train 0.6095350772394972 valid 0.5055924502835758
LOSS train 0.6095350772394972 valid 0.5054621070623397
LOSS train 0.6095350772394972 valid 0.5051798220251648
LOSS train 0.6095350772394972 valid 0.5048997282154031
LOSS train 0.6095350772394972 valid 0.5048032635695314
LOSS train 0.6095350772394972 valid 0.5043933903043335
LOSS train 0.6095350772394972 valid 0.5042670444647471
LOSS train 0.6095350772394972 valid 0.5041034970628587
LOSS train 0.6095350772394972 valid 0.5040394985056543
LOSS train 0.6095350772394972 valid 0.5039353301891913
LOSS train 0.6095350772394972 valid 0.5038850662074511
LOSS train 0.6095350772394972 valid 0.5037233743816614
LOSS train 0.6095350772394972 valid 0.5034428492740348
LOSS train 0.6095350772394972 valid 0.5033135217864338
LOSS train 0.6095350772394972 valid 0.5034944515630423
LOSS train 0.6095350772394972 valid 0.5034121707791374
LOSS train 0.6095350772394972 valid 0.5033442830338197
LOSS train 0.6095350772394972 valid 0.5031766877617947
LOSS train 0.6095350772394972 valid 0.5032395987675108
LOSS train 0.6095350772394972 valid 0.5031647011637688
LOSS train 0.6095350772394972 valid 0.5034729463330815
LOSS train 0.6095350772394972 valid 0.5034107473161485
LOSS train 0.6095350772394972 valid 0.5030291722371028
LOSS train 0.6095350772394972 valid 0.5030779514623724
LOSS train 0.6095350772394972 valid 0.5029795272375948
LOSS train 0.6095350772394972 valid 0.5028272093610561
LOSS train 0.6095350772394972 valid 0.5027224393267381
LOSS train 0.6095350772394972 valid 0.502870497914652
LOSS train 0.6095350772394972 valid 0.5030950286339239
LOSS train 0.6095350772394972 valid 0.503237391917073
LOSS train 0.6095350772394972 valid 0.5033257787275796
LOSS train 0.6095350772394972 valid 0.5032529786229134
LOSS train 0.6095350772394972 valid 0.5034500239509168
LOSS train 0.6095350772394972 valid 0.5034425027814566
LOSS train 0.6095350772394972 valid 0.5037337081524932
LOSS train 0.6095350772394972 valid 0.5039174169875108
LOSS train 0.6095350772394972 valid 0.5040071830863044
LOSS train 0.6095350772394972 valid 0.5038560013163764
LOSS train 0.6095350772394972 valid 0.503731277779998
LOSS train 0.6095350772394972 valid 0.5037752326439928
LOSS train 0.6095350772394972 valid 0.5038466850005159
LOSS train 0.6095350772394972 valid 0.5038695798678832
LOSS train 0.6095350772394972 valid 0.5038765956152667
LOSS train 0.6095350772394972 valid 0.5037517068641526
LOSS train 0.6095350772394972 valid 0.5038848187016175
LOSS train 0.6095350772394972 valid 0.5038994446135404
LOSS train 0.6095350772394972 valid 0.5038823728976043
LOSS train 0.6095350772394972 valid 0.5038951234570865
LOSS train 0.6095350772394972 valid 0.503819474297711
LOSS train 0.6095350772394972 valid 0.5038000087616807
LOSS train 0.6095350772394972 valid 0.5038877379994432
LOSS train 0.6095350772394972 valid 0.5040457720557848
LOSS train 0.6095350772394972 valid 0.5039901250650075
LOSS train 0.6095350772394972 valid 0.5038083640278362
LOSS train 0.6095350772394972 valid 0.5037724918466273
LOSS train 0.6095350772394972 valid 0.5039993913904313
LOSS train 0.6095350772394972 valid 0.5040511145591736
LOSS train 0.6095350772394972 valid 0.5040139276829977
LOSS train 0.6095350772394972 valid 0.5043493330947996
LOSS train 0.6095350772394972 valid 0.5044465288519859
LOSS train 0.6095350772394972 valid 0.5044799576434054
LOSS train 0.6095350772394972 valid 0.5044950833687416
LOSS train 0.6095350772394972 valid 0.5045389100795484
LOSS train 0.6095350772394972 valid 0.5043315819718621
LOSS train 0.6095350772394972 valid 0.5042794949578163
LOSS train 0.6095350772394972 valid 0.5042657071529929
LOSS train 0.6095350772394972 valid 0.5043033650627843
LOSS train 0.6095350772394972 valid 0.5042720154366073
LOSS train 0.6095350772394972 valid 0.5041719540192263
LOSS train 0.6095350772394972 valid 0.5042757016161213
LOSS train 0.6095350772394972 valid 0.5040345637918376
LOSS train 0.6095350772394972 valid 0.5040951132774353
LOSS train 0.6095350772394972 valid 0.5042291668289942
LOSS train 0.6095350772394972 valid 0.5044265334874811
LOSS train 0.6095350772394972 valid 0.504536519100616
LOSS train 0.6095350772394972 valid 0.5045830545326074
LOSS train 0.6095350772394972 valid 0.5045810859778832
LOSS train 0.6095350772394972 valid 0.504584400212928
LOSS train 0.6095350772394972 valid 0.5042028897473602
LOSS train 0.6095350772394972 valid 0.5044826675911207
LOSS train 0.6095350772394972 valid 0.5045067615957068
LOSS train 0.6095350772394972 valid 0.504612249135971
LOSS train 0.6095350772394972 valid 0.504785011540975
LOSS train 0.6095350772394972 valid 0.504752744381365
LOSS train 0.6095350772394972 valid 0.5048481017545937
LOSS train 0.6095350772394972 valid 0.5047458189648467
LOSS train 0.6095350772394972 valid 0.5047896681293365
LOSS train 0.6095350772394972 valid 0.5049369212908622
LOSS train 0.6095350772394972 valid 0.5050784470928702
LOSS train 0.6095350772394972 valid 0.505114457275294
LOSS train 0.6095350772394972 valid 0.5047994962653274
LOSS train 0.6095350772394972 valid 0.504800826497376
LOSS train 0.6095350772394972 valid 0.5047795008058134
LOSS train 0.6095350772394972 valid 0.5046196419883657
LOSS train 0.6095350772394972 valid 0.5045903354334685
LOSS train 0.6095350772394972 valid 0.5044453176783352
LOSS train 0.6095350772394972 valid 0.5043241730242064
LOSS train 0.6095350772394972 valid 0.5042219199689038
LOSS train 0.6095350772394972 valid 0.5043893633131495
LOSS train 0.6095350772394972 valid 0.5043668599710578
LOSS train 0.6095350772394972 valid 0.5043957027105185
LOSS train 0.6095350772394972 valid 0.5044001595062368
LOSS train 0.6095350772394972 valid 0.504553900301805
LOSS train 0.6095350772394972 valid 0.5045577140395031
LOSS train 0.6095350772394972 valid 0.5047453157819075
LOSS train 0.6095350772394972 valid 0.5046449802045164
LOSS train 0.6095350772394972 valid 0.5046140692915235
LOSS train 0.6095350772394972 valid 0.5046212403950366
LOSS train 0.6095350772394972 valid 0.5046280098836974
LOSS train 0.6095350772394972 valid 0.5046935451499531
LOSS train 0.6095350772394972 valid 0.504632861421095
LOSS train 0.6095350772394972 valid 0.5048199125462108
LOSS train 0.6095350772394972 valid 0.5048217722394849
LOSS train 0.6095350772394972 valid 0.5048302118922328
LOSS train 0.6095350772394972 valid 0.5048103806425314
LOSS train 0.6095350772394972 valid 0.5048763076572315
LOSS train 0.6095350772394972 valid 0.5048303918258564
LOSS train 0.6095350772394972 valid 0.5048990020508407
LOSS train 0.6095350772394972 valid 0.5050624922953825
LOSS train 0.6095350772394972 valid 0.5053008764665178
LOSS train 0.6095350772394972 valid 0.5052482622956472
LOSS train 0.6095350772394972 valid 0.505279605482754
LOSS train 0.6095350772394972 valid 0.5053128105495612
LOSS train 0.6095350772394972 valid 0.5054355203174055
LOSS train 0.6095350772394972 valid 0.5054662250793042
LOSS train 0.6095350772394972 valid 0.5053820728333955
LOSS train 0.6095350772394972 valid 0.505316688769903
LOSS train 0.6095350772394972 valid 0.5054502697015295
LOSS train 0.6095350772394972 valid 0.5055747410367588
LOSS train 0.6095350772394972 valid 0.505544718467828
LOSS train 0.6095350772394972 valid 0.5055812456499991
LOSS train 0.6095350772394972 valid 0.5057440683245659
LOSS train 0.6095350772394972 valid 0.5056573262262107
LOSS train 0.6095350772394972 valid 0.5056969579493645
LOSS train 0.6095350772394972 valid 0.5056956944794491
LOSS train 0.6095350772394972 valid 0.505750455400523
LOSS train 0.6095350772394972 valid 0.5057709769504827
LOSS train 0.6095350772394972 valid 0.505767461744327
LOSS train 0.6095350772394972 valid 0.5059080077830144
LOSS train 0.6095350772394972 valid 0.5058951303362846
LOSS train 0.6095350772394972 valid 0.505750297644492
LOSS train 0.6095350772394972 valid 0.5057724981080918
LOSS train 0.6095350772394972 valid 0.5058713832172738
LOSS train 0.6095350772394972 valid 0.5058115661706565
LOSS train 0.6095350772394972 valid 0.5057944554678151
LOSS train 0.6095350772394972 valid 0.5057464478728927
LOSS train 0.6095350772394972 valid 0.5057128354560497
LOSS train 0.6095350772394972 valid 0.505710210789133
LOSS train 0.6095350772394972 valid 0.505763671090526
LOSS train 0.6095350772394972 valid 0.5056769972274063
LOSS train 0.6095350772394972 valid 0.5056582195301579
LOSS train 0.6095350772394972 valid 0.505675830217925
LOSS train 0.6095350772394972 valid 0.5057671810437112
LOSS train 0.6095350772394972 valid 0.5058528803758793
LOSS train 0.6095350772394972 valid 0.50596398556179
LOSS train 0.6095350772394972 valid 0.5059412487649492
LOSS train 0.6095350772394972 valid 0.5059448670016394
LOSS train 0.6095350772394972 valid 0.5059226539018935
LOSS train 0.6095350772394972 valid 0.5061447679471339
LOSS train 0.6095350772394972 valid 0.5062460725506147
LOSS train 0.6095350772394972 valid 0.5062935496782112
LOSS train 0.6095350772394972 valid 0.5063085399244143
LOSS train 0.6095350772394972 valid 0.5062773623765805
LOSS train 0.6095350772394972 valid 0.5062012956317129
LOSS train 0.6095350772394972 valid 0.5061488522480486
LOSS train 0.6095350772394972 valid 0.5060755354471695
LOSS train 0.6095350772394972 valid 0.5060331088431338
LOSS train 0.6095350772394972 valid 0.506001810906297
LOSS train 0.6095350772394972 valid 0.5060841496483686
LOSS train 0.6095350772394972 valid 0.5060529897944266
LOSS train 0.6095350772394972 valid 0.5060404118883061
LOSS train 0.6095350772394972 valid 0.5060399014502763
LOSS train 0.6095350772394972 valid 0.5060328820187027
LOSS train 0.6095350772394972 valid 0.5060246253062871
LOSS train 0.6095350772394972 valid 0.5060747514781638
LOSS train 0.6095350772394972 valid 0.5061234491037541
LOSS train 0.6095350772394972 valid 0.5061482603452644
LOSS train 0.6095350772394972 valid 0.5061280384538619
LOSS train 0.6095350772394972 valid 0.5062052693202911
LOSS train 0.6095350772394972 valid 0.5060550814434406
LOSS train 0.6095350772394972 valid 0.5059894460990247
LOSS train 0.6095350772394972 valid 0.5060376569032669
LOSS train 0.6095350772394972 valid 0.5059985906716837
LOSS train 0.6095350772394972 valid 0.5060749050407183
LOSS train 0.6095350772394972 valid 0.5060711848170389
LOSS train 0.6095350772394972 valid 0.5061285316240131
LOSS train 0.6095350772394972 valid 0.506068412696614
LOSS train 0.6095350772394972 valid 0.5061055750120431
LOSS train 0.6095350772394972 valid 0.5061008626384957
LOSS train 0.6095350772394972 valid 0.5060844650102216
LOSS train 0.6095350772394972 valid 0.5061105422992044
LOSS train 0.6095350772394972 valid 0.5061640927424798
LOSS train 0.6095350772394972 valid 0.5062243207661128
LOSS train 0.6095350772394972 valid 0.5060993439823617
LOSS train 0.6095350772394972 valid 0.5060933236840107
LOSS train 0.6095350772394972 valid 0.506093023175543
LOSS train 0.6095350772394972 valid 0.5061940280896313
LOSS train 0.6095350772394972 valid 0.5062099520425151
LOSS train 0.6095350772394972 valid 0.5063450948129432
LOSS train 0.6095350772394972 valid 0.5063411838083125
LOSS train 0.6095350772394972 valid 0.5064708922875415
LOSS train 0.6095350772394972 valid 0.5064620311613436
LOSS train 0.6095350772394972 valid 0.506510001047071
LOSS train 0.6095350772394972 valid 0.5066118058474625
LOSS train 0.6095350772394972 valid 0.5066905604614006
LOSS train 0.6095350772394972 valid 0.5067102513174071
LOSS train 0.6095350772394972 valid 0.506746201948686
LOSS train 0.6095350772394972 valid 0.5068429190179576
LOSS train 0.6095350772394972 valid 0.5067649738668104
LOSS train 0.6095350772394972 valid 0.5067599307504489
LOSS train 0.6095350772394972 valid 0.5068851071660236
LOSS train 0.6095350772394972 valid 0.5068817520780223
LOSS train 0.6095350772394972 valid 0.5067530247876653
LOSS train 0.6095350772394972 valid 0.5066481802269076
LOSS train 0.6095350772394972 valid 0.5066453802922589
LOSS train 0.6095350772394972 valid 0.5067175722248117
LOSS train 0.6095350772394972 valid 0.5066606432722326
LOSS train 0.6095350772394972 valid 0.5065657459980958
LOSS train 0.6095350772394972 valid 0.5065590623986845
LOSS train 0.6095350772394972 valid 0.5066432927010788
LOSS train 0.6095350772394972 valid 0.5066345555765819
LOSS train 0.6095350772394972 valid 0.5067171656879885
LOSS train 0.6095350772394972 valid 0.5065886537029162
LOSS train 0.6095350772394972 valid 0.5066337355808036
LOSS train 0.6095350772394972 valid 0.5065307282547088
LOSS train 0.6095350772394972 valid 0.506651300860911
LOSS train 0.6095350772394972 valid 0.5067408617270195
LOSS train 0.6095350772394972 valid 0.5067267489393015
LOSS train 0.6095350772394972 valid 0.5067197400512118
LOSS train 0.6095350772394972 valid 0.5066696280401025
LOSS train 0.6095350772394972 valid 0.5067532862907269
LOSS train 0.6095350772394972 valid 0.506693754196167
LOSS train 0.6095350772394972 valid 0.5066888027412947
LOSS train 0.6095350772394972 valid 0.5066202057907913
LOSS train 0.6095350772394972 valid 0.5066855067860568
LOSS train 0.6095350772394972 valid 0.5066160424367377
LOSS train 0.6095350772394972 valid 0.5066256231948978
LOSS train 0.6095350772394972 valid 0.5065781923096164
LOSS train 0.6095350772394972 valid 0.5065935831698999
LOSS train 0.6095350772394972 valid 0.5065305982897808
LOSS train 0.6095350772394972 valid 0.5065582191095384
LOSS train 0.6095350772394972 valid 0.5065420482427844
LOSS train 0.6095350772394972 valid 0.5064941167448112
LOSS train 0.6095350772394972 valid 0.5065858881825056
LOSS train 0.6095350772394972 valid 0.5066406305986472
LOSS train 0.6095350772394972 valid 0.5066896752946696
LOSS train 0.6095350772394972 valid 0.5067074397253611
LOSS train 0.6095350772394972 valid 0.5066036478250842
LOSS train 0.6095350772394972 valid 0.5065981476840913
LOSS train 0.6095350772394972 valid 0.5065896747247228
LOSS train 0.6095350772394972 valid 0.5065501461208427
LOSS train 0.6095350772394972 valid 0.5065052459947765
LOSS train 0.6095350772394972 valid 0.5064951447868644
LOSS train 0.6095350772394972 valid 0.5065528949410278
LOSS train 0.6095350772394972 valid 0.5065075899978909
LOSS train 0.6095350772394972 valid 0.5065418295102355
LOSS train 0.6095350772394972 valid 0.5065494817036849
LOSS train 0.6095350772394972 valid 0.5066056321917868
LOSS train 0.6095350772394972 valid 0.5066810650380744
LOSS train 0.6095350772394972 valid 0.5067052260586401
LOSS train 0.6095350772394972 valid 0.5067225188288645
LOSS train 0.6095350772394972 valid 0.5066729937538956
LOSS train 0.6095350772394972 valid 0.5066733446726266
LOSS train 0.6095350772394972 valid 0.5065323107213859
LOSS train 0.6095350772394972 valid 0.5065198442241451
LOSS train 0.6095350772394972 valid 0.506612083512152
LOSS train 0.6095350772394972 valid 0.5065659745415645
LOSS train 0.6095350772394972 valid 0.506602496795711
LOSS train 0.6095350772394972 valid 0.506605574745099
LOSS train 0.6095350772394972 valid 0.5066114623518385
LOSS train 0.6095350772394972 valid 0.5065750063872267
LOSS train 0.6095350772394972 valid 0.5065513810690712
LOSS train 0.6095350772394972 valid 0.5064681667037024
LOSS train 0.6095350772394972 valid 0.5064695777251706
LOSS train 0.6095350772394972 valid 0.5064969080182623
LOSS train 0.6095350772394972 valid 0.5066085825132769
LOSS train 0.6095350772394972 valid 0.506598947359168
LOSS train 0.6095350772394972 valid 0.5066585950768752
LOSS train 0.6095350772394972 valid 0.506645608704097
LOSS train 0.6095350772394972 valid 0.5066770149030905
LOSS train 0.6095350772394972 valid 0.5067189428048011
LOSS train 0.6095350772394972 valid 0.5067019947937557
LOSS train 0.6095350772394972 valid 0.5066808051193542
LOSS train 0.6095350772394972 valid 0.5066919519819997
LOSS train 0.6095350772394972 valid 0.5066848007207552
LOSS train 0.6095350772394972 valid 0.5066944840600935
LOSS train 0.6095350772394972 valid 0.5066761666620282
LOSS train 0.6095350772394972 valid 0.5066883820161391
LOSS train 0.6095350772394972 valid 0.5066230586763858
LOSS train 0.6095350772394972 valid 0.506542290638945
LOSS train 0.6095350772394972 valid 0.5065371220656424
LOSS train 0.6095350772394972 valid 0.5065186187624932
LOSS train 0.6095350772394972 valid 0.5065783821975095
LOSS train 0.6095350772394972 valid 0.5065732738260407
LOSS train 0.6095350772394972 valid 0.5065788081526428
LOSS train 0.6095350772394972 valid 0.5065463612695317
LOSS train 0.6095350772394972 valid 0.5065874690878881
LOSS train 0.6095350772394972 valid 0.5065438708320993
LOSS train 0.6095350772394972 valid 0.5064713277673851
LOSS train 0.6095350772394972 valid 0.5065161027014256
LOSS train 0.6095350772394972 valid 0.5065070781604384
EPOCH 5:
  batch 1 loss: 0.6041973829269409
  batch 2 loss: 0.5932431519031525
  batch 3 loss: 0.5912710030873617
  batch 4 loss: 0.6005229949951172
  batch 5 loss: 0.5966175317764282
  batch 6 loss: 0.5968034267425537
  batch 7 loss: 0.5983150175639561
  batch 8 loss: 0.5984599888324738
  batch 9 loss: 0.605208781030443
  batch 10 loss: 0.6076187789440155
  batch 11 loss: 0.6078823804855347
  batch 12 loss: 0.6094456414381663
  batch 13 loss: 0.6098951284702008
  batch 14 loss: 0.6105924248695374
  batch 15 loss: 0.6131619373957317
  batch 16 loss: 0.6123535260558128
  batch 17 loss: 0.6127860090311836
  batch 18 loss: 0.6127688884735107
  batch 19 loss: 0.6127667364321256
  batch 20 loss: 0.6136538743972778
  batch 21 loss: 0.6136284981455121
  batch 22 loss: 0.613396858627146
  batch 23 loss: 0.6120296457539434
  batch 24 loss: 0.6117857570449511
  batch 25 loss: 0.6127654695510865
  batch 26 loss: 0.6122196087470422
  batch 27 loss: 0.6109797557195028
  batch 28 loss: 0.6096956346716199
  batch 29 loss: 0.6095469470681816
  batch 30 loss: 0.6086406687895457
  batch 31 loss: 0.608296561625696
  batch 32 loss: 0.608500549569726
  batch 33 loss: 0.6086833422834222
  batch 34 loss: 0.6082258294610416
  batch 35 loss: 0.6089659094810486
  batch 36 loss: 0.608854129910469
  batch 37 loss: 0.6084455396677997
  batch 38 loss: 0.6074817478656769
  batch 39 loss: 0.6072687017611968
  batch 40 loss: 0.6071656838059425
  batch 41 loss: 0.6068207359895473
  batch 42 loss: 0.6069440501076835
  batch 43 loss: 0.6074259073235267
  batch 44 loss: 0.6070290397513997
  batch 45 loss: 0.6070978124936421
  batch 46 loss: 0.6067273564960646
  batch 47 loss: 0.6066367638872024
  batch 48 loss: 0.6058648191392422
  batch 49 loss: 0.6051395900395452
  batch 50 loss: 0.6049699795246124
  batch 51 loss: 0.6050366922920826
  batch 52 loss: 0.6053341352022611
  batch 53 loss: 0.6052662122924373
  batch 54 loss: 0.6053651803069644
  batch 55 loss: 0.6049713145602833
  batch 56 loss: 0.6046315633824894
  batch 57 loss: 0.6046899525742782
  batch 58 loss: 0.6049363027358877
  batch 59 loss: 0.6046215235176733
  batch 60 loss: 0.604808880885442
  batch 61 loss: 0.6045793783469279
  batch 62 loss: 0.6048163444765152
  batch 63 loss: 0.6045798271421402
  batch 64 loss: 0.6045361682772636
  batch 65 loss: 0.6043313686664288
  batch 66 loss: 0.6041942004001501
  batch 67 loss: 0.6043809251998787
  batch 68 loss: 0.6044718877357595
  batch 69 loss: 0.6044790770696558
  batch 70 loss: 0.6043246124471937
  batch 71 loss: 0.6044245060061065
  batch 72 loss: 0.6043519833021693
  batch 73 loss: 0.6043114768315668
  batch 74 loss: 0.6044189382243801
  batch 75 loss: 0.6042754761377971
  batch 76 loss: 0.6044747860808122
  batch 77 loss: 0.6040630224463227
  batch 78 loss: 0.6036467743225586
  batch 79 loss: 0.6039177556581135
  batch 80 loss: 0.6038840413093567
  batch 81 loss: 0.603971540927887
  batch 82 loss: 0.6041757079159341
  batch 83 loss: 0.6040589486260012
  batch 84 loss: 0.6038645129828226
  batch 85 loss: 0.6032189839026507
  batch 86 loss: 0.603783214508101
  batch 87 loss: 0.6037720667904821
  batch 88 loss: 0.6034697138450362
  batch 89 loss: 0.603573233224033
  batch 90 loss: 0.6033703254328834
  batch 91 loss: 0.6033035850786901
  batch 92 loss: 0.603046710724416
  batch 93 loss: 0.6031369983509023
  batch 94 loss: 0.6032688383092272
  batch 95 loss: 0.6033536653769643
  batch 96 loss: 0.6032041584451994
  batch 97 loss: 0.6030372399644753
  batch 98 loss: 0.6029518812286611
  batch 99 loss: 0.603028396765391
  batch 100 loss: 0.602792209982872
  batch 101 loss: 0.6027783456415233
  batch 102 loss: 0.6027302771222358
  batch 103 loss: 0.6027490988518428
  batch 104 loss: 0.6027807570420779
  batch 105 loss: 0.6024953819456554
  batch 106 loss: 0.6024642850992814
  batch 107 loss: 0.6020926030996804
  batch 108 loss: 0.602051826538863
  batch 109 loss: 0.6018610580251851
  batch 110 loss: 0.6022882271896709
  batch 111 loss: 0.6021720879786724
  batch 112 loss: 0.6020679399371147
  batch 113 loss: 0.6020452833808629
  batch 114 loss: 0.6023851146823481
  batch 115 loss: 0.602173348095106
  batch 116 loss: 0.6022352165189283
  batch 117 loss: 0.6022032886488825
  batch 118 loss: 0.6021615312261096
  batch 119 loss: 0.6020535025276056
  batch 120 loss: 0.6019425526261329
  batch 121 loss: 0.6016827644395434
  batch 122 loss: 0.6015326366072795
  batch 123 loss: 0.6015240162368712
  batch 124 loss: 0.6020076539247267
  batch 125 loss: 0.6021824851036072
  batch 126 loss: 0.6020502906943125
  batch 127 loss: 0.6020348461594168
  batch 128 loss: 0.6018984881229699
  batch 129 loss: 0.6015612589296444
  batch 130 loss: 0.6016302888210003
  batch 131 loss: 0.6018176861391723
  batch 132 loss: 0.6018040681427176
  batch 133 loss: 0.6020711620051161
  batch 134 loss: 0.6018917204728768
  batch 135 loss: 0.6019439308731644
  batch 136 loss: 0.6019239232820623
  batch 137 loss: 0.6020913680974584
  batch 138 loss: 0.6020479392314303
  batch 139 loss: 0.602158050314128
  batch 140 loss: 0.6020889963422503
  batch 141 loss: 0.601931521233092
  batch 142 loss: 0.601819075329203
  batch 143 loss: 0.60143402573112
  batch 144 loss: 0.6012972009678682
  batch 145 loss: 0.601197558846967
  batch 146 loss: 0.6012532445665908
  batch 147 loss: 0.6013599050288297
  batch 148 loss: 0.6012656434967711
  batch 149 loss: 0.6011533625173888
  batch 150 loss: 0.6009503897031149
  batch 151 loss: 0.6009659123736502
  batch 152 loss: 0.6009091958403587
  batch 153 loss: 0.6010261649399801
  batch 154 loss: 0.6012168275071429
  batch 155 loss: 0.6012244974413226
  batch 156 loss: 0.6011626388017948
  batch 157 loss: 0.6012332932964252
  batch 158 loss: 0.6013014044942735
  batch 159 loss: 0.6012305988455718
  batch 160 loss: 0.6012659903615714
  batch 161 loss: 0.6013749500979548
  batch 162 loss: 0.6013552634804337
  batch 163 loss: 0.601338970880567
  batch 164 loss: 0.6013644908259554
  batch 165 loss: 0.6011863314744198
  batch 166 loss: 0.6013604747243675
  batch 167 loss: 0.6012945781924768
  batch 168 loss: 0.6014909950040636
  batch 169 loss: 0.6014200741722739
  batch 170 loss: 0.6016514325843138
  batch 171 loss: 0.6016776453681857
  batch 172 loss: 0.6016136847956236
  batch 173 loss: 0.6015662668068285
  batch 174 loss: 0.6016270946497204
  batch 175 loss: 0.6015154484340123
  batch 176 loss: 0.6015807606957175
  batch 177 loss: 0.601441089042836
  batch 178 loss: 0.6013940311549755
  batch 179 loss: 0.6012701708511268
  batch 180 loss: 0.6012679305341508
  batch 181 loss: 0.6013797017750819
  batch 182 loss: 0.6012221316059867
  batch 183 loss: 0.6011886218857896
  batch 184 loss: 0.6011397838592529
  batch 185 loss: 0.6011734382526295
  batch 186 loss: 0.6012732114202233
  batch 187 loss: 0.6012998825726025
  batch 188 loss: 0.6012843206841895
  batch 189 loss: 0.6011755882747589
  batch 190 loss: 0.6011399887110057
  batch 191 loss: 0.6010062897392593
  batch 192 loss: 0.6010815833384792
  batch 193 loss: 0.6010974525170005
  batch 194 loss: 0.6011030093296287
  batch 195 loss: 0.6012308499751947
  batch 196 loss: 0.6012575261446894
  batch 197 loss: 0.6014102527937913
  batch 198 loss: 0.6014129296697751
  batch 199 loss: 0.6016697344468467
  batch 200 loss: 0.6017930319905281
  batch 201 loss: 0.6020528300484614
  batch 202 loss: 0.6019961801495882
  batch 203 loss: 0.6020721928239456
  batch 204 loss: 0.6020415585999396
  batch 205 loss: 0.6022415518760681
  batch 206 loss: 0.6022997640290306
  batch 207 loss: 0.6023221842332739
  batch 208 loss: 0.6023285649716854
  batch 209 loss: 0.6022798036844537
  batch 210 loss: 0.6023186308997018
  batch 211 loss: 0.6023485143602741
  batch 212 loss: 0.6022925447180586
  batch 213 loss: 0.6024356557169991
  batch 214 loss: 0.602394645459184
  batch 215 loss: 0.6022857078286105
  batch 216 loss: 0.602222443178848
  batch 217 loss: 0.6022119013944529
  batch 218 loss: 0.6022699549110657
  batch 219 loss: 0.602102210804752
  batch 220 loss: 0.6020708666606382
  batch 221 loss: 0.6020086769065166
  batch 222 loss: 0.6022094265297726
  batch 223 loss: 0.6021855639235321
  batch 224 loss: 0.602150894967573
  batch 225 loss: 0.6020391885439554
  batch 226 loss: 0.6019641179426581
  batch 227 loss: 0.6018328228185881
  batch 228 loss: 0.6018082381863343
  batch 229 loss: 0.6017412928514606
  batch 230 loss: 0.6017332388007123
  batch 231 loss: 0.6018206941616999
  batch 232 loss: 0.6017745884841886
  batch 233 loss: 0.6017734996750631
  batch 234 loss: 0.6016874524772676
  batch 235 loss: 0.6016741313832872
  batch 236 loss: 0.6017016452752938
  batch 237 loss: 0.6017357651694415
  batch 238 loss: 0.6017393938132695
  batch 239 loss: 0.6017777323722839
  batch 240 loss: 0.6018076213697593
  batch 241 loss: 0.6018211567055635
  batch 242 loss: 0.6017215751911983
  batch 243 loss: 0.6017542160096973
  batch 244 loss: 0.6018116566978517
  batch 245 loss: 0.6018446187583768
  batch 246 loss: 0.6019928213057479
  batch 247 loss: 0.601974861341932
  batch 248 loss: 0.6020444804622281
  batch 249 loss: 0.6020459013291631
  batch 250 loss: 0.6020741746425629
  batch 251 loss: 0.6021063845471082
  batch 252 loss: 0.6021015454852392
  batch 253 loss: 0.6020052600283867
  batch 254 loss: 0.6020062469591306
  batch 255 loss: 0.6020018512127446
  batch 256 loss: 0.6019902895204723
  batch 257 loss: 0.6019923074700025
  batch 258 loss: 0.6020307905914247
  batch 259 loss: 0.6019741899718649
  batch 260 loss: 0.601950810276545
  batch 261 loss: 0.6020207265784457
  batch 262 loss: 0.6019782712896362
  batch 263 loss: 0.6019484069864106
  batch 264 loss: 0.6018116638967486
  batch 265 loss: 0.6018359645357672
  batch 266 loss: 0.601818248069376
  batch 267 loss: 0.6018665850385745
  batch 268 loss: 0.6019204223333899
  batch 269 loss: 0.6018742123501009
  batch 270 loss: 0.6018510354889763
  batch 271 loss: 0.6019764848300891
  batch 272 loss: 0.6020392341648831
  batch 273 loss: 0.6020366390109498
  batch 274 loss: 0.6020562983777401
  batch 275 loss: 0.6020602928508412
  batch 276 loss: 0.6021152829778367
  batch 277 loss: 0.6021321822589916
  batch 278 loss: 0.6020859164728535
  batch 279 loss: 0.6020528902716962
  batch 280 loss: 0.6020160432372774
  batch 281 loss: 0.6019634967172698
  batch 282 loss: 0.6018828665111082
  batch 283 loss: 0.6017243855833586
  batch 284 loss: 0.6018296255612038
  batch 285 loss: 0.6017943769170527
  batch 286 loss: 0.6016727508781673
  batch 287 loss: 0.6016420809234061
  batch 288 loss: 0.6014934428450134
  batch 289 loss: 0.6014684882131003
  batch 290 loss: 0.6013596491567019
  batch 291 loss: 0.6012685235423321
  batch 292 loss: 0.6012854541409506
  batch 293 loss: 0.6011892923316045
  batch 294 loss: 0.601180473355209
  batch 295 loss: 0.6012080998743995
  batch 296 loss: 0.6011450618908212
  batch 297 loss: 0.6010981077698345
  batch 298 loss: 0.6009856020444192
  batch 299 loss: 0.6009650431747819
  batch 300 loss: 0.600979119737943
  batch 301 loss: 0.600967947628807
  batch 302 loss: 0.6008558741073735
  batch 303 loss: 0.600917128249757
  batch 304 loss: 0.6009090344764685
  batch 305 loss: 0.600754300883559
  batch 306 loss: 0.6007618465844322
  batch 307 loss: 0.6007461099360587
  batch 308 loss: 0.6007497974417426
  batch 309 loss: 0.6007050405042457
  batch 310 loss: 0.6006945192813873
  batch 311 loss: 0.6007115789165067
  batch 312 loss: 0.6007665619254112
  batch 313 loss: 0.600720136500776
  batch 314 loss: 0.600662011629457
  batch 315 loss: 0.600645064929175
  batch 316 loss: 0.6006113947192325
  batch 317 loss: 0.600604594693951
  batch 318 loss: 0.600519743730437
  batch 319 loss: 0.6005157508820201
  batch 320 loss: 0.6004178237169981
  batch 321 loss: 0.6003308559875251
  batch 322 loss: 0.6003706788424379
  batch 323 loss: 0.6002405582935817
  batch 324 loss: 0.6002030998100469
  batch 325 loss: 0.6001981331751897
  batch 326 loss: 0.6002971502535183
  batch 327 loss: 0.6001811268132761
  batch 328 loss: 0.6001540202556587
  batch 329 loss: 0.6002474492444093
  batch 330 loss: 0.6002725505467618
  batch 331 loss: 0.6002407421518309
  batch 332 loss: 0.6001916859882424
  batch 333 loss: 0.600171008804539
  batch 334 loss: 0.6001509162123332
  batch 335 loss: 0.6000736697396236
  batch 336 loss: 0.6000625544360706
  batch 337 loss: 0.5999646460974606
  batch 338 loss: 0.5999791398203584
  batch 339 loss: 0.5999861876521491
  batch 340 loss: 0.5999168485403061
  batch 341 loss: 0.5998744071403906
  batch 342 loss: 0.5999049099913815
  batch 343 loss: 0.5999979380268398
  batch 344 loss: 0.599996899449548
  batch 345 loss: 0.6000605797422105
  batch 346 loss: 0.5999543970030856
  batch 347 loss: 0.5999594552372649
  batch 348 loss: 0.5999993594556019
  batch 349 loss: 0.5999223999785831
  batch 350 loss: 0.5998780446393149
  batch 351 loss: 0.5999381723906579
  batch 352 loss: 0.599929963323203
  batch 353 loss: 0.5999073100832975
  batch 354 loss: 0.5998994815821028
  batch 355 loss: 0.6000095612566236
  batch 356 loss: 0.5999514276392004
  batch 357 loss: 0.5999702979870537
  batch 358 loss: 0.5999587461269101
  batch 359 loss: 0.5999877824756761
  batch 360 loss: 0.6000125878387027
  batch 361 loss: 0.5999640956149537
  batch 362 loss: 0.5999664555597042
  batch 363 loss: 0.5999328438243918
  batch 364 loss: 0.5998777061045825
  batch 365 loss: 0.5998310681891768
  batch 366 loss: 0.5998164674297708
  batch 367 loss: 0.599848818551617
  batch 368 loss: 0.599843030228563
  batch 369 loss: 0.5998955737284528
  batch 370 loss: 0.599954857697358
  batch 371 loss: 0.6000224663562209
  batch 372 loss: 0.5999657370710886
  batch 373 loss: 0.5999027816603715
  batch 374 loss: 0.5999126966624336
  batch 375 loss: 0.5998664414087931
  batch 376 loss: 0.5999362654191382
  batch 377 loss: 0.59984991262699
  batch 378 loss: 0.5998112666543829
  batch 379 loss: 0.5998102108847183
  batch 380 loss: 0.5998156288736745
  batch 381 loss: 0.5998025522457333
  batch 382 loss: 0.5997308590961377
  batch 383 loss: 0.5997762138476259
  batch 384 loss: 0.5997598570150634
  batch 385 loss: 0.5998417115830755
  batch 386 loss: 0.5998114169879281
  batch 387 loss: 0.5998127440457505
  batch 388 loss: 0.5997850337286585
  batch 389 loss: 0.5998198000814737
  batch 390 loss: 0.5998082073835226
  batch 391 loss: 0.5998194923486246
  batch 392 loss: 0.5997359240237548
  batch 393 loss: 0.5997436169449609
  batch 394 loss: 0.5997949005080964
  batch 395 loss: 0.5996841337107405
  batch 396 loss: 0.5996337177777531
  batch 397 loss: 0.5995710493635471
  batch 398 loss: 0.599582026202475
  batch 399 loss: 0.5995976077882867
  batch 400 loss: 0.599578443467617
  batch 401 loss: 0.5995234219807937
  batch 402 loss: 0.5995396332657752
  batch 403 loss: 0.5994856932914583
  batch 404 loss: 0.5994084756268133
  batch 405 loss: 0.5994559436668584
  batch 406 loss: 0.5995189963009557
  batch 407 loss: 0.5995279991363132
  batch 408 loss: 0.5995935144669869
  batch 409 loss: 0.599567567660931
  batch 410 loss: 0.5995351502081243
  batch 411 loss: 0.5995306495912464
  batch 412 loss: 0.5995575484720249
  batch 413 loss: 0.5995190430784341
  batch 414 loss: 0.5995367035485696
  batch 415 loss: 0.5995505903140608
  batch 416 loss: 0.5995545993344142
  batch 417 loss: 0.5995508576754471
  batch 418 loss: 0.5995180833567842
  batch 419 loss: 0.5995690548050091
  batch 420 loss: 0.5995878274951663
  batch 421 loss: 0.5995572730367937
  batch 422 loss: 0.5996032980098543
  batch 423 loss: 0.5995539425394496
  batch 424 loss: 0.5995101197710577
  batch 425 loss: 0.5995325363383573
  batch 426 loss: 0.5995016850775956
  batch 427 loss: 0.5994693950970224
  batch 428 loss: 0.5994948953668647
  batch 429 loss: 0.5995382972252674
  batch 430 loss: 0.599545557831609
  batch 431 loss: 0.5995556746724033
  batch 432 loss: 0.5995990954063557
  batch 433 loss: 0.59967723647111
  batch 434 loss: 0.599736796820768
  batch 435 loss: 0.5997495832114385
  batch 436 loss: 0.5997457173439341
  batch 437 loss: 0.5997605351070517
  batch 438 loss: 0.5998386593714152
  batch 439 loss: 0.5998380564339884
  batch 440 loss: 0.599825245141983
  batch 441 loss: 0.5998028003169296
  batch 442 loss: 0.5997182086312394
  batch 443 loss: 0.5996651132811811
  batch 444 loss: 0.5996232800655537
  batch 445 loss: 0.5996055079310127
  batch 446 loss: 0.5995887054188904
  batch 447 loss: 0.5995289149967082
  batch 448 loss: 0.5995354039062347
  batch 449 loss: 0.5995928327862032
  batch 450 loss: 0.599582240846422
  batch 451 loss: 0.5995380592980565
  batch 452 loss: 0.599491271561226
  batch 453 loss: 0.5994438482962433
  batch 454 loss: 0.5994284720147759
  batch 455 loss: 0.5994586095705137
  batch 456 loss: 0.5994224284301725
  batch 457 loss: 0.5994553826830841
  batch 458 loss: 0.5994225150893349
  batch 459 loss: 0.5994101299179925
  batch 460 loss: 0.5994158629489982
  batch 461 loss: 0.5993963787716019
  batch 462 loss: 0.5993784555109032
  batch 463 loss: 0.599427900098055
  batch 464 loss: 0.5995121420971279
  batch 465 loss: 0.5994287252426147
  batch 466 loss: 0.5993673361422166
  batch 467 loss: 0.5994221694464347
  batch 468 loss: 0.5993837669619129
  batch 469 loss: 0.5993804274591555
  batch 470 loss: 0.5993678243870431
  batch 471 loss: 0.5994007883557848
  batch 472 loss: 0.5993623801712262
LOSS train 0.5993623801712262 valid 0.4877777099609375
LOSS train 0.5993623801712262 valid 0.4810476005077362
LOSS train 0.5993623801712262 valid 0.4793415466944377
LOSS train 0.5993623801712262 valid 0.47431062161922455
LOSS train 0.5993623801712262 valid 0.46849936842918394
LOSS train 0.5993623801712262 valid 0.4701907883087794
LOSS train 0.5993623801712262 valid 0.4742993244103023
LOSS train 0.5993623801712262 valid 0.47523464262485504
LOSS train 0.5993623801712262 valid 0.4732701778411865
LOSS train 0.5993623801712262 valid 0.4726113736629486
LOSS train 0.5993623801712262 valid 0.4742855808951638
LOSS train 0.5993623801712262 valid 0.4750150839487712
LOSS train 0.5993623801712262 valid 0.47621623140115005
LOSS train 0.5993623801712262 valid 0.4761417784861156
LOSS train 0.5993623801712262 valid 0.4764044344425201
LOSS train 0.5993623801712262 valid 0.47673982940614223
LOSS train 0.5993623801712262 valid 0.47808779162519116
LOSS train 0.5993623801712262 valid 0.4778614540894826
LOSS train 0.5993623801712262 valid 0.476794371479436
LOSS train 0.5993623801712262 valid 0.47877807915210724
LOSS train 0.5993623801712262 valid 0.47787104901813326
LOSS train 0.5993623801712262 valid 0.4766745377670635
LOSS train 0.5993623801712262 valid 0.47664093193800555
LOSS train 0.5993623801712262 valid 0.47595461706320447
LOSS train 0.5993623801712262 valid 0.4751425743103027
LOSS train 0.5993623801712262 valid 0.4750670458261783
LOSS train 0.5993623801712262 valid 0.47527746359507245
LOSS train 0.5993623801712262 valid 0.4754111777458872
LOSS train 0.5993623801712262 valid 0.47483935952186584
LOSS train 0.5993623801712262 valid 0.47584482928117117
LOSS train 0.5993623801712262 valid 0.4765996692642089
LOSS train 0.5993623801712262 valid 0.47617046628147364
LOSS train 0.5993623801712262 valid 0.47677466453927936
LOSS train 0.5993623801712262 valid 0.4769469227860956
LOSS train 0.5993623801712262 valid 0.4773999205657414
LOSS train 0.5993623801712262 valid 0.47706810384988785
LOSS train 0.5993623801712262 valid 0.4776240385867454
LOSS train 0.5993623801712262 valid 0.4778460632813604
LOSS train 0.5993623801712262 valid 0.47747082511583966
LOSS train 0.5993623801712262 valid 0.4777505166828632
LOSS train 0.5993623801712262 valid 0.477679044008255
LOSS train 0.5993623801712262 valid 0.4773672840424946
LOSS train 0.5993623801712262 valid 0.47721008159393485
LOSS train 0.5993623801712262 valid 0.477011574940248
LOSS train 0.5993623801712262 valid 0.47688609096739026
LOSS train 0.5993623801712262 valid 0.4773807026769804
LOSS train 0.5993623801712262 valid 0.47726519627774017
LOSS train 0.5993623801712262 valid 0.4774992012729247
LOSS train 0.5993623801712262 valid 0.4777259917891755
LOSS train 0.5993623801712262 valid 0.4773266416788101
LOSS train 0.5993623801712262 valid 0.4777039669308008
LOSS train 0.5993623801712262 valid 0.47746857427633727
LOSS train 0.5993623801712262 valid 0.4775832970187349
LOSS train 0.5993623801712262 valid 0.4774139799453594
LOSS train 0.5993623801712262 valid 0.47731743075630884
LOSS train 0.5993623801712262 valid 0.4773936410035406
LOSS train 0.5993623801712262 valid 0.47718410220062524
LOSS train 0.5993623801712262 valid 0.47693541543237095
LOSS train 0.5993623801712262 valid 0.47702603673530836
LOSS train 0.5993623801712262 valid 0.4770600701371829
LOSS train 0.5993623801712262 valid 0.4764385492098136
LOSS train 0.5993623801712262 valid 0.4766497597579033
LOSS train 0.5993623801712262 valid 0.47669259849048795
LOSS train 0.5993623801712262 valid 0.4774201004765928
LOSS train 0.5993623801712262 valid 0.47756204834351174
LOSS train 0.5993623801712262 valid 0.4775100210399339
LOSS train 0.5993623801712262 valid 0.4774075688710853
LOSS train 0.5993623801712262 valid 0.47744353334693346
LOSS train 0.5993623801712262 valid 0.4772763027661089
LOSS train 0.5993623801712262 valid 0.4770493813923427
LOSS train 0.5993623801712262 valid 0.47677605966447106
LOSS train 0.5993623801712262 valid 0.4765106137428019
LOSS train 0.5993623801712262 valid 0.47624488644403956
LOSS train 0.5993623801712262 valid 0.47576284166928884
LOSS train 0.5993623801712262 valid 0.47575620412826536
LOSS train 0.5993623801712262 valid 0.47555713433968394
LOSS train 0.5993623801712262 valid 0.4755254325928626
LOSS train 0.5993623801712262 valid 0.47546339952028716
LOSS train 0.5993623801712262 valid 0.47540981369682506
LOSS train 0.5993623801712262 valid 0.4752041857689619
LOSS train 0.5993623801712262 valid 0.47511311151363234
LOSS train 0.5993623801712262 valid 0.4749680524919091
LOSS train 0.5993623801712262 valid 0.4749215410416385
LOSS train 0.5993623801712262 valid 0.4748847654887608
LOSS train 0.5993623801712262 valid 0.47484736547750583
LOSS train 0.5993623801712262 valid 0.47473915302476216
LOSS train 0.5993623801712262 valid 0.4748229219995696
LOSS train 0.5993623801712262 valid 0.4747392433610829
LOSS train 0.5993623801712262 valid 0.47494118669059837
LOSS train 0.5993623801712262 valid 0.47492701841725243
LOSS train 0.5993623801712262 valid 0.474694638134359
LOSS train 0.5993623801712262 valid 0.47482214123010635
LOSS train 0.5993623801712262 valid 0.47471641628972944
LOSS train 0.5993623801712262 valid 0.4745600331336894
LOSS train 0.5993623801712262 valid 0.47442713128893
LOSS train 0.5993623801712262 valid 0.474378558807075
LOSS train 0.5993623801712262 valid 0.47463315756050584
LOSS train 0.5993623801712262 valid 0.474576617686116
LOSS train 0.5993623801712262 valid 0.4746683808890256
LOSS train 0.5993623801712262 valid 0.47461370468139646
LOSS train 0.5993623801712262 valid 0.47467964208952274
LOSS train 0.5993623801712262 valid 0.4747614585885815
LOSS train 0.5993623801712262 valid 0.47502102030133736
LOSS train 0.5993623801712262 valid 0.4751251368568494
LOSS train 0.5993623801712262 valid 0.4751791585059393
LOSS train 0.5993623801712262 valid 0.4750741495276397
LOSS train 0.5993623801712262 valid 0.4749967244183906
LOSS train 0.5993623801712262 valid 0.47507042713739256
LOSS train 0.5993623801712262 valid 0.47508075013073214
LOSS train 0.5993623801712262 valid 0.4752264908768914
LOSS train 0.5993623801712262 valid 0.4752031835886809
LOSS train 0.5993623801712262 valid 0.47511565153087887
LOSS train 0.5993623801712262 valid 0.47519918511399123
LOSS train 0.5993623801712262 valid 0.47517844720890645
LOSS train 0.5993623801712262 valid 0.47525752497755963
LOSS train 0.5993623801712262 valid 0.475355494125136
LOSS train 0.5993623801712262 valid 0.47523782294020694
LOSS train 0.5993623801712262 valid 0.47527609790785835
LOSS train 0.5993623801712262 valid 0.4752622457111583
LOSS train 0.5993623801712262 valid 0.47532655025521914
LOSS train 0.5993623801712262 valid 0.4751904205349851
LOSS train 0.5993623801712262 valid 0.4750127628689907
LOSS train 0.5993623801712262 valid 0.4749604727679152
LOSS train 0.5993623801712262 valid 0.4751441757525167
LOSS train 0.5993623801712262 valid 0.47515190982818606
LOSS train 0.5993623801712262 valid 0.4750921622155205
LOSS train 0.5993623801712262 valid 0.4753614635918084
LOSS train 0.5993623801712262 valid 0.475463358219713
LOSS train 0.5993623801712262 valid 0.4755395817202191
LOSS train 0.5993623801712262 valid 0.4755701065063477
LOSS train 0.5993623801712262 valid 0.4756214216010261
LOSS train 0.5993623801712262 valid 0.47545856553496735
LOSS train 0.5993623801712262 valid 0.4753811933044204
LOSS train 0.5993623801712262 valid 0.47535802713081016
LOSS train 0.5993623801712262 valid 0.47538289582287824
LOSS train 0.5993623801712262 valid 0.4753899486625896
LOSS train 0.5993623801712262 valid 0.47533373458542094
LOSS train 0.5993623801712262 valid 0.47539533761100494
LOSS train 0.5993623801712262 valid 0.47517351945527164
LOSS train 0.5993623801712262 valid 0.4752505762236459
LOSS train 0.5993623801712262 valid 0.4753586561121839
LOSS train 0.5993623801712262 valid 0.47554198704974754
LOSS train 0.5993623801712262 valid 0.47553356460758023
LOSS train 0.5993623801712262 valid 0.4755079340603616
LOSS train 0.5993623801712262 valid 0.47538916982453444
LOSS train 0.5993623801712262 valid 0.4754854497844226
LOSS train 0.5993623801712262 valid 0.4751915112644637
LOSS train 0.5993623801712262 valid 0.47550330854750966
LOSS train 0.5993623801712262 valid 0.475567265444954
LOSS train 0.5993623801712262 valid 0.47566306312878925
LOSS train 0.5993623801712262 valid 0.4758263380322235
LOSS train 0.5993623801712262 valid 0.475838699819226
LOSS train 0.5993623801712262 valid 0.4758593270591661
LOSS train 0.5993623801712262 valid 0.4757888226153015
LOSS train 0.5993623801712262 valid 0.47578042361044115
LOSS train 0.5993623801712262 valid 0.4759691705306371
LOSS train 0.5993623801712262 valid 0.47600430383044445
LOSS train 0.5993623801712262 valid 0.47596500097196315
LOSS train 0.5993623801712262 valid 0.4756889206433446
LOSS train 0.5993623801712262 valid 0.475728658773005
LOSS train 0.5993623801712262 valid 0.47575265261697475
LOSS train 0.5993623801712262 valid 0.47571430327715697
LOSS train 0.5993623801712262 valid 0.4756207085825914
LOSS train 0.5993623801712262 valid 0.47556526958942413
LOSS train 0.5993623801712262 valid 0.47545028166337444
LOSS train 0.5993623801712262 valid 0.47533910245780486
LOSS train 0.5993623801712262 valid 0.47546867874568094
LOSS train 0.5993623801712262 valid 0.47543308990342276
LOSS train 0.5993623801712262 valid 0.4754282842726397
LOSS train 0.5993623801712262 valid 0.47541682369568766
LOSS train 0.5993623801712262 valid 0.4755146097370058
LOSS train 0.5993623801712262 valid 0.4755468009862789
LOSS train 0.5993623801712262 valid 0.4757079359768443
LOSS train 0.5993623801712262 valid 0.4757015799311386
LOSS train 0.5993623801712262 valid 0.4757198112351554
LOSS train 0.5993623801712262 valid 0.47575981661000033
LOSS train 0.5993623801712262 valid 0.4757615033179353
LOSS train 0.5993623801712262 valid 0.4758004383759552
LOSS train 0.5993623801712262 valid 0.4757781936136704
LOSS train 0.5993623801712262 valid 0.4758988789386219
LOSS train 0.5993623801712262 valid 0.47592289227148443
LOSS train 0.5993623801712262 valid 0.47584018389602284
LOSS train 0.5993623801712262 valid 0.4758365103781549
LOSS train 0.5993623801712262 valid 0.47587327092238096
LOSS train 0.5993623801712262 valid 0.47581698894500735
LOSS train 0.5993623801712262 valid 0.4759116127926816
LOSS train 0.5993623801712262 valid 0.4760613734709388
LOSS train 0.5993623801712262 valid 0.47624688326044284
LOSS train 0.5993623801712262 valid 0.47619206706682843
LOSS train 0.5993623801712262 valid 0.4761745183091415
LOSS train 0.5993623801712262 valid 0.47622995351621616
LOSS train 0.5993623801712262 valid 0.47627409889052313
LOSS train 0.5993623801712262 valid 0.4762644970046424
LOSS train 0.5993623801712262 valid 0.4762356934166446
LOSS train 0.5993623801712262 valid 0.4761887564108922
LOSS train 0.5993623801712262 valid 0.47628444235543815
LOSS train 0.5993623801712262 valid 0.4763799343012311
LOSS train 0.5993623801712262 valid 0.47627882057368154
LOSS train 0.5993623801712262 valid 0.4762992872365156
LOSS train 0.5993623801712262 valid 0.4764243583381176
LOSS train 0.5993623801712262 valid 0.47634318811976495
LOSS train 0.5993623801712262 valid 0.47642427505833085
LOSS train 0.5993623801712262 valid 0.47640527116841286
LOSS train 0.5993623801712262 valid 0.47640648250486334
LOSS train 0.5993623801712262 valid 0.47639754516322436
LOSS train 0.5993623801712262 valid 0.47642359759622405
LOSS train 0.5993623801712262 valid 0.4765813061292621
LOSS train 0.5993623801712262 valid 0.4765577747558172
LOSS train 0.5993623801712262 valid 0.4764290553245818
LOSS train 0.5993623801712262 valid 0.47642126977443694
LOSS train 0.5993623801712262 valid 0.4764905464592703
LOSS train 0.5993623801712262 valid 0.47647437144000576
LOSS train 0.5993623801712262 valid 0.47640377283096313
LOSS train 0.5993623801712262 valid 0.4763941801039972
LOSS train 0.5993623801712262 valid 0.47637540684189905
LOSS train 0.5993623801712262 valid 0.47638601119871493
LOSS train 0.5993623801712262 valid 0.47648071171501266
LOSS train 0.5993623801712262 valid 0.4764152479554535
LOSS train 0.5993623801712262 valid 0.4764520180279806
LOSS train 0.5993623801712262 valid 0.47647915807637303
LOSS train 0.5993623801712262 valid 0.4765596085004677
LOSS train 0.5993623801712262 valid 0.4766532790821952
LOSS train 0.5993623801712262 valid 0.4768058752532497
LOSS train 0.5993623801712262 valid 0.4767852332442999
LOSS train 0.5993623801712262 valid 0.4767089666260613
LOSS train 0.5993623801712262 valid 0.47668092678078505
LOSS train 0.5993623801712262 valid 0.4768863483147474
LOSS train 0.5993623801712262 valid 0.47693871955076855
LOSS train 0.5993623801712262 valid 0.4769291063063009
LOSS train 0.5993623801712262 valid 0.4769171270339385
LOSS train 0.5993623801712262 valid 0.4768717888887827
LOSS train 0.5993623801712262 valid 0.4768296414665107
LOSS train 0.5993623801712262 valid 0.47674422113168907
LOSS train 0.5993623801712262 valid 0.4766611020025025
LOSS train 0.5993623801712262 valid 0.47669806480407717
LOSS train 0.5993623801712262 valid 0.4766571607630132
LOSS train 0.5993623801712262 valid 0.47671341443363624
LOSS train 0.5993623801712262 valid 0.4766428544491279
LOSS train 0.5993623801712262 valid 0.47666920316269207
LOSS train 0.5993623801712262 valid 0.47661632088323436
LOSS train 0.5993623801712262 valid 0.4765973908525285
LOSS train 0.5993623801712262 valid 0.4765369733256742
LOSS train 0.5993623801712262 valid 0.47657100948286646
LOSS train 0.5993623801712262 valid 0.4765760153532028
LOSS train 0.5993623801712262 valid 0.4765653622393705
LOSS train 0.5993623801712262 valid 0.47652937556669966
LOSS train 0.5993623801712262 valid 0.4766735784437975
LOSS train 0.5993623801712262 valid 0.4765408853850057
LOSS train 0.5993623801712262 valid 0.47646779372510184
LOSS train 0.5993623801712262 valid 0.47650287008285525
LOSS train 0.5993623801712262 valid 0.47648498451567267
LOSS train 0.5993623801712262 valid 0.47654975879760014
LOSS train 0.5993623801712262 valid 0.4765742604911563
LOSS train 0.5993623801712262 valid 0.4766143055882041
LOSS train 0.5993623801712262 valid 0.4765866062220405
LOSS train 0.5993623801712262 valid 0.4766340581700206
LOSS train 0.5993623801712262 valid 0.4766299744292456
LOSS train 0.5993623801712262 valid 0.47659864675166996
LOSS train 0.5993623801712262 valid 0.4766448579699837
LOSS train 0.5993623801712262 valid 0.47670233937410206
LOSS train 0.5993623801712262 valid 0.47677934512324716
LOSS train 0.5993623801712262 valid 0.4766882375906442
LOSS train 0.5993623801712262 valid 0.47669112954302884
LOSS train 0.5993623801712262 valid 0.4766915308480913
LOSS train 0.5993623801712262 valid 0.4767100069882735
LOSS train 0.5993623801712262 valid 0.47672075246061596
LOSS train 0.5993623801712262 valid 0.47682765795943444
LOSS train 0.5993623801712262 valid 0.4768178225008409
LOSS train 0.5993623801712262 valid 0.47694618750682105
LOSS train 0.5993623801712262 valid 0.47695787880155777
LOSS train 0.5993623801712262 valid 0.47698344691653094
LOSS train 0.5993623801712262 valid 0.4770551556173493
LOSS train 0.5993623801712262 valid 0.47711144873510786
LOSS train 0.5993623801712262 valid 0.4771181355862722
LOSS train 0.5993623801712262 valid 0.47714778119867496
LOSS train 0.5993623801712262 valid 0.47721852059813513
LOSS train 0.5993623801712262 valid 0.47718607733826346
LOSS train 0.5993623801712262 valid 0.47711025328516105
LOSS train 0.5993623801712262 valid 0.4772479255353251
LOSS train 0.5993623801712262 valid 0.4772516155881541
LOSS train 0.5993623801712262 valid 0.47714090654858493
LOSS train 0.5993623801712262 valid 0.4770588002940442
LOSS train 0.5993623801712262 valid 0.4770170430201945
LOSS train 0.5993623801712262 valid 0.47709247312495406
LOSS train 0.5993623801712262 valid 0.47706783298860517
LOSS train 0.5993623801712262 valid 0.47700836983594025
LOSS train 0.5993623801712262 valid 0.47694989696196977
LOSS train 0.5993623801712262 valid 0.4769640200667911
LOSS train 0.5993623801712262 valid 0.47695651536994327
LOSS train 0.5993623801712262 valid 0.4770459027125918
LOSS train 0.5993623801712262 valid 0.47696351021835487
LOSS train 0.5993623801712262 valid 0.477040244496032
LOSS train 0.5993623801712262 valid 0.47699527671312714
LOSS train 0.5993623801712262 valid 0.47709817586301945
LOSS train 0.5993623801712262 valid 0.4771636156712548
LOSS train 0.5993623801712262 valid 0.4771876572757154
LOSS train 0.5993623801712262 valid 0.4771596917801032
LOSS train 0.5993623801712262 valid 0.4771204041754639
LOSS train 0.5993623801712262 valid 0.47720161917616294
LOSS train 0.5993623801712262 valid 0.4771524082620939
LOSS train 0.5993623801712262 valid 0.47718025402373254
LOSS train 0.5993623801712262 valid 0.47707409436339576
LOSS train 0.5993623801712262 valid 0.4770986860734795
LOSS train 0.5993623801712262 valid 0.4770815515596616
LOSS train 0.5993623801712262 valid 0.4770650099535457
LOSS train 0.5993623801712262 valid 0.4769929409806245
LOSS train 0.5993623801712262 valid 0.4770160637771656
LOSS train 0.5993623801712262 valid 0.4769451379195436
LOSS train 0.5993623801712262 valid 0.47697769669653145
LOSS train 0.5993623801712262 valid 0.4769572692532693
LOSS train 0.5993623801712262 valid 0.4769229566935941
LOSS train 0.5993623801712262 valid 0.4769659174176363
LOSS train 0.5993623801712262 valid 0.47703291918523016
LOSS train 0.5993623801712262 valid 0.47707333942507485
LOSS train 0.5993623801712262 valid 0.47709729359263464
LOSS train 0.5993623801712262 valid 0.476975216801408
LOSS train 0.5993623801712262 valid 0.4769800840304101
LOSS train 0.5993623801712262 valid 0.47696652736678813
LOSS train 0.5993623801712262 valid 0.4769719509308615
LOSS train 0.5993623801712262 valid 0.47688899049535394
LOSS train 0.5993623801712262 valid 0.47686626959441236
LOSS train 0.5993623801712262 valid 0.4769241870930476
LOSS train 0.5993623801712262 valid 0.4768896860419412
LOSS train 0.5993623801712262 valid 0.4769251336470062
LOSS train 0.5993623801712262 valid 0.4769370264273423
LOSS train 0.5993623801712262 valid 0.47695031295890455
LOSS train 0.5993623801712262 valid 0.47701995680820686
LOSS train 0.5993623801712262 valid 0.4770822492314548
LOSS train 0.5993623801712262 valid 0.4771268034416129
LOSS train 0.5993623801712262 valid 0.4771132399638494
LOSS train 0.5993623801712262 valid 0.47710759519090107
LOSS train 0.5993623801712262 valid 0.4770131337355418
LOSS train 0.5993623801712262 valid 0.4770308543253947
LOSS train 0.5993623801712262 valid 0.47711549226395383
LOSS train 0.5993623801712262 valid 0.4770615637302399
LOSS train 0.5993623801712262 valid 0.4770898833161309
LOSS train 0.5993623801712262 valid 0.4770794477236377
LOSS train 0.5993623801712262 valid 0.47713483914115723
LOSS train 0.5993623801712262 valid 0.4771369579619011
LOSS train 0.5993623801712262 valid 0.47710951286203723
LOSS train 0.5993623801712262 valid 0.47703848311628416
LOSS train 0.5993623801712262 valid 0.4770023690329658
LOSS train 0.5993623801712262 valid 0.4769816409047074
LOSS train 0.5993623801712262 valid 0.4770892941674521
LOSS train 0.5993623801712262 valid 0.4770755928495656
LOSS train 0.5993623801712262 valid 0.477135378329051
LOSS train 0.5993623801712262 valid 0.47705547953888733
LOSS train 0.5993623801712262 valid 0.47709830687648946
LOSS train 0.5993623801712262 valid 0.477133876273147
LOSS train 0.5993623801712262 valid 0.4771367808750698
LOSS train 0.5993623801712262 valid 0.47709930571395787
LOSS train 0.5993623801712262 valid 0.4771074941381812
LOSS train 0.5993623801712262 valid 0.477094216573002
LOSS train 0.5993623801712262 valid 0.4770939512609762
LOSS train 0.5993623801712262 valid 0.4770996743524578
LOSS train 0.5993623801712262 valid 0.4771226808596193
LOSS train 0.5993623801712262 valid 0.47706532202848867
LOSS train 0.5993623801712262 valid 0.47699424299780885
LOSS train 0.5993623801712262 valid 0.4769429375202211
LOSS train 0.5993623801712262 valid 0.47692042721642386
LOSS train 0.5993623801712262 valid 0.4769748290820135
LOSS train 0.5993623801712262 valid 0.47699988052989895
LOSS train 0.5993623801712262 valid 0.4770225634588026
LOSS train 0.5993623801712262 valid 0.47698926270663083
LOSS train 0.5993623801712262 valid 0.47703061430421595
LOSS train 0.5993623801712262 valid 0.47700231518250347
LOSS train 0.5993623801712262 valid 0.47694197167167873
LOSS train 0.5993623801712262 valid 0.47699710111255234
LOSS train 0.5993623801712262 valid 0.47698669268832944
EPOCH 6:
  batch 1 loss: 0.5877947807312012
  batch 2 loss: 0.5805933475494385
  batch 3 loss: 0.586151917775472
  batch 4 loss: 0.5929261147975922
  batch 5 loss: 0.5904687285423279
  batch 6 loss: 0.5877417723337809
  batch 7 loss: 0.5909770727157593
  batch 8 loss: 0.5881973281502724
  batch 9 loss: 0.5944206118583679
  batch 10 loss: 0.5975253641605377
  batch 11 loss: 0.5983218117193743
  batch 12 loss: 0.5988842298587164
  batch 13 loss: 0.6003829470047584
  batch 14 loss: 0.60158571600914
  batch 15 loss: 0.6051923235257467
  batch 16 loss: 0.604993436485529
  batch 17 loss: 0.6051474634338828
  batch 18 loss: 0.6048881279097663
  batch 19 loss: 0.6041358772077059
  batch 20 loss: 0.6056054532527924
  batch 21 loss: 0.6057209741501581
  batch 22 loss: 0.6052502583373677
  batch 23 loss: 0.6043707210084667
  batch 24 loss: 0.6034697319070498
  batch 25 loss: 0.6049124383926392
  batch 26 loss: 0.6040768898450412
  batch 27 loss: 0.6032239242836281
  batch 28 loss: 0.602911325437682
  batch 29 loss: 0.6025927416209517
  batch 30 loss: 0.6023504594961803
  batch 31 loss: 0.6025034766043386
  batch 32 loss: 0.6021066680550575
  batch 33 loss: 0.6020014358289314
  batch 34 loss: 0.6014073946896721
  batch 35 loss: 0.6023733479636056
  batch 36 loss: 0.6021369679106606
  batch 37 loss: 0.6015443753551792
  batch 38 loss: 0.6008234196587613
  batch 39 loss: 0.6004816675797487
  batch 40 loss: 0.600092525780201
  batch 41 loss: 0.599858382853066
  batch 42 loss: 0.5995651497727349
  batch 43 loss: 0.5996408226878144
  batch 44 loss: 0.5990194800225171
  batch 45 loss: 0.5991803977224562
  batch 46 loss: 0.5987020005350527
  batch 47 loss: 0.5985307503253856
  batch 48 loss: 0.5974505692720413
  batch 49 loss: 0.5964177372504254
  batch 50 loss: 0.5965922605991364
  batch 51 loss: 0.5961321089781967
  batch 52 loss: 0.5964936625498992
  batch 53 loss: 0.5966719827562008
  batch 54 loss: 0.5968303978443146
  batch 55 loss: 0.5963606173341924
  batch 56 loss: 0.5962141294564519
  batch 57 loss: 0.5961434496076483
  batch 58 loss: 0.5962054719185007
  batch 59 loss: 0.595982924356299
  batch 60 loss: 0.5961580504973729
  batch 61 loss: 0.5959256056879387
  batch 62 loss: 0.5961616933345795
  batch 63 loss: 0.596046819573357
  batch 64 loss: 0.5960417734459043
  batch 65 loss: 0.5959203582543593
  batch 66 loss: 0.5957171004829984
  batch 67 loss: 0.5959700319304395
  batch 68 loss: 0.5960742138764438
  batch 69 loss: 0.5961313861003821
  batch 70 loss: 0.5961796820163727
  batch 71 loss: 0.5963980975285382
  batch 72 loss: 0.5962269836001926
  batch 73 loss: 0.5960610843684575
  batch 74 loss: 0.5960873325128813
  batch 75 loss: 0.5960179344813029
  batch 76 loss: 0.5961138511958876
  batch 77 loss: 0.5959375647755413
  batch 78 loss: 0.595615362509703
  batch 79 loss: 0.5959006661101233
  batch 80 loss: 0.5959289573132992
  batch 81 loss: 0.5959661735428704
  batch 82 loss: 0.5963013412022009
  batch 83 loss: 0.5962851650743599
  batch 84 loss: 0.5962298448596682
  batch 85 loss: 0.5958009775947122
  batch 86 loss: 0.5964529493520426
  batch 87 loss: 0.5966125836317566
  batch 88 loss: 0.5965417596426877
  batch 89 loss: 0.5967435341202811
  batch 90 loss: 0.596608931488461
  batch 91 loss: 0.5967385375892723
  batch 92 loss: 0.596525820053142
  batch 93 loss: 0.596549480833033
  batch 94 loss: 0.5968520102348733
  batch 95 loss: 0.596979118020911
  batch 96 loss: 0.5968613879134258
  batch 97 loss: 0.5966453128254291
  batch 98 loss: 0.5966205943603905
  batch 99 loss: 0.5967233740922177
  batch 100 loss: 0.5964609742164612
  batch 101 loss: 0.5963884232067825
  batch 102 loss: 0.5965080179420172
  batch 103 loss: 0.5963718295097351
  batch 104 loss: 0.5965780885173724
  batch 105 loss: 0.5963319216455732
  batch 106 loss: 0.5962887378233783
  batch 107 loss: 0.5961044954362317
  batch 108 loss: 0.5959299388859007
  batch 109 loss: 0.5956272504745274
  batch 110 loss: 0.5961211881854317
  batch 111 loss: 0.5960863962903753
  batch 112 loss: 0.59598526305386
  batch 113 loss: 0.5962180917241932
  batch 114 loss: 0.5965139489424857
  batch 115 loss: 0.5964224862015766
  batch 116 loss: 0.5963598109524826
  batch 117 loss: 0.5963729115632864
  batch 118 loss: 0.5963086768732233
  batch 119 loss: 0.5961580637122402
  batch 120 loss: 0.5961106350024541
  batch 121 loss: 0.5960203098856713
  batch 122 loss: 0.5958042696851199
  batch 123 loss: 0.5957693108698217
  batch 124 loss: 0.5959329129226746
  batch 125 loss: 0.5959614605903626
  batch 126 loss: 0.5957054850601015
  batch 127 loss: 0.5957523260529586
  batch 128 loss: 0.595652109477669
  batch 129 loss: 0.5954013009404027
  batch 130 loss: 0.5953321273510273
  batch 131 loss: 0.5953681182315331
  batch 132 loss: 0.5952508092829676
  batch 133 loss: 0.595506807467095
  batch 134 loss: 0.5954039288100912
  batch 135 loss: 0.5954952270896346
  batch 136 loss: 0.5955537509392289
  batch 137 loss: 0.5956637702719139
  batch 138 loss: 0.5956465610559436
  batch 139 loss: 0.5956705697148824
  batch 140 loss: 0.5955974353211266
  batch 141 loss: 0.5953790266463097
  batch 142 loss: 0.5952185665217924
  batch 143 loss: 0.5948837332792215
  batch 144 loss: 0.5947957527306345
  batch 145 loss: 0.594726823938304
  batch 146 loss: 0.594740870880754
  batch 147 loss: 0.5948129446328092
  batch 148 loss: 0.5947306252814628
  batch 149 loss: 0.5946858641285224
  batch 150 loss: 0.594579801162084
  batch 151 loss: 0.5945775094411231
  batch 152 loss: 0.594549418672135
  batch 153 loss: 0.5946365528636508
  batch 154 loss: 0.5948066738518801
  batch 155 loss: 0.5948599334686033
  batch 156 loss: 0.5948086388600178
  batch 157 loss: 0.5948247495730212
  batch 158 loss: 0.59477261538747
  batch 159 loss: 0.5948807117324205
  batch 160 loss: 0.5949334423989058
  batch 161 loss: 0.5951072455192945
  batch 162 loss: 0.5950482428809742
  batch 163 loss: 0.5950784460167212
  batch 164 loss: 0.5950778014049297
  batch 165 loss: 0.5950470606486002
  batch 166 loss: 0.5951850960053593
  batch 167 loss: 0.5950574553655293
  batch 168 loss: 0.5952812681595484
  batch 169 loss: 0.5952181921908136
  batch 170 loss: 0.5954732723095838
  batch 171 loss: 0.595473741578777
  batch 172 loss: 0.5953556912582975
  batch 173 loss: 0.5953410247157764
  batch 174 loss: 0.5953126457230798
  batch 175 loss: 0.5952604562895638
  batch 176 loss: 0.595266519961032
  batch 177 loss: 0.5950053529550801
  batch 178 loss: 0.5949452408913816
  batch 179 loss: 0.5949097921728422
  batch 180 loss: 0.5949975500504175
  batch 181 loss: 0.5951990942928672
  batch 182 loss: 0.5950255773879669
  batch 183 loss: 0.5951154955097886
  batch 184 loss: 0.5950996127465497
  batch 185 loss: 0.5951329025062355
  batch 186 loss: 0.5951582388852232
  batch 187 loss: 0.5951724211799907
  batch 188 loss: 0.5951657656659471
  batch 189 loss: 0.5950551165474786
  batch 190 loss: 0.5949974022413554
  batch 191 loss: 0.5949146123456706
  batch 192 loss: 0.594895863905549
  batch 193 loss: 0.5948305608695035
  batch 194 loss: 0.5947993646577462
  batch 195 loss: 0.5948033439807403
  batch 196 loss: 0.5947441048159892
  batch 197 loss: 0.5947535025891919
  batch 198 loss: 0.594678708399185
  batch 199 loss: 0.5948185782935751
  batch 200 loss: 0.594890365600586
  batch 201 loss: 0.5950116458816908
  batch 202 loss: 0.5949370226647595
  batch 203 loss: 0.5949518457422116
  batch 204 loss: 0.5948470912727655
  batch 205 loss: 0.5949793175953191
  batch 206 loss: 0.5950340894819464
  batch 207 loss: 0.5949907538971463
  batch 208 loss: 0.5949834106633296
  batch 209 loss: 0.5949748449348377
  batch 210 loss: 0.5949698269367218
  batch 211 loss: 0.5949759562433613
  batch 212 loss: 0.5949828933994725
  batch 213 loss: 0.5950122097848167
  batch 214 loss: 0.5948616617193846
  batch 215 loss: 0.5946850898653961
  batch 216 loss: 0.5945859443810251
  batch 217 loss: 0.5945447834406031
  batch 218 loss: 0.5945743366118965
  batch 219 loss: 0.5943476391709559
  batch 220 loss: 0.59435922015797
  batch 221 loss: 0.594271061377288
  batch 222 loss: 0.5943921267449319
  batch 223 loss: 0.5943541719239923
  batch 224 loss: 0.5943208296916315
  batch 225 loss: 0.5941679702864753
  batch 226 loss: 0.5941851663905963
  batch 227 loss: 0.5939865695222359
  batch 228 loss: 0.5939601774801287
  batch 229 loss: 0.593901386427567
  batch 230 loss: 0.593904484614082
  batch 231 loss: 0.5939600232875708
  batch 232 loss: 0.5938758156422911
  batch 233 loss: 0.5938886204502614
  batch 234 loss: 0.5937758154339261
  batch 235 loss: 0.5937953464528347
  batch 236 loss: 0.5937126816834434
  batch 237 loss: 0.5937243923859254
  batch 238 loss: 0.5937291699297288
  batch 239 loss: 0.5937142022982801
  batch 240 loss: 0.593690704802672
  batch 241 loss: 0.5935995835980934
  batch 242 loss: 0.59352544122491
  batch 243 loss: 0.5935811486263824
  batch 244 loss: 0.5935449429222794
  batch 245 loss: 0.5935955300623057
  batch 246 loss: 0.5937500714771147
  batch 247 loss: 0.5937394364642711
  batch 248 loss: 0.5937863554685346
  batch 249 loss: 0.5937938115682947
  batch 250 loss: 0.593776415348053
  batch 251 loss: 0.5937357580519292
  batch 252 loss: 0.5937692418931022
  batch 253 loss: 0.5936877063140568
  batch 254 loss: 0.5936351155671548
  batch 255 loss: 0.5936575179006539
  batch 256 loss: 0.593644505366683
  batch 257 loss: 0.5937061138190184
  batch 258 loss: 0.5937241422113522
  batch 259 loss: 0.5935978074791809
  batch 260 loss: 0.5934854537248612
  batch 261 loss: 0.5935629307081873
  batch 262 loss: 0.5935813937023395
  batch 263 loss: 0.5935888498908213
  batch 264 loss: 0.5934159552509134
  batch 265 loss: 0.5933808441432017
  batch 266 loss: 0.5933542312087869
  batch 267 loss: 0.5934677947773023
  batch 268 loss: 0.5934235816126439
  batch 269 loss: 0.5933745481267738
  batch 270 loss: 0.5933152783800054
  batch 271 loss: 0.5933080999613688
  batch 272 loss: 0.5932921320199966
  batch 273 loss: 0.5932373249487126
  batch 274 loss: 0.5931776631487548
  batch 275 loss: 0.5932088507305492
  batch 276 loss: 0.5932272735281267
  batch 277 loss: 0.5931624890664855
  batch 278 loss: 0.5931500009924388
  batch 279 loss: 0.5931891017062689
  batch 280 loss: 0.593104461474078
  batch 281 loss: 0.5930862119189361
  batch 282 loss: 0.5930064193745876
  batch 283 loss: 0.5928639590529586
  batch 284 loss: 0.5930014120441087
  batch 285 loss: 0.592948619733777
  batch 286 loss: 0.5928676297197809
  batch 287 loss: 0.5928393990735974
  batch 288 loss: 0.592716492091616
  batch 289 loss: 0.5927374121639555
  batch 290 loss: 0.5925956148525764
  batch 291 loss: 0.5925339859785493
  batch 292 loss: 0.5925708913231549
  batch 293 loss: 0.5925814672134843
  batch 294 loss: 0.5925580776062142
  batch 295 loss: 0.5925600688336259
  batch 296 loss: 0.5925246567742245
  batch 297 loss: 0.592486874222354
  batch 298 loss: 0.5924621654436892
  batch 299 loss: 0.5925347511983635
  batch 300 loss: 0.592544377843539
  batch 301 loss: 0.59255697481656
  batch 302 loss: 0.5924543300211824
  batch 303 loss: 0.5924972262319559
  batch 304 loss: 0.5924115451542955
  batch 305 loss: 0.5922485906569684
  batch 306 loss: 0.5922376480367448
  batch 307 loss: 0.5922394144418573
  batch 308 loss: 0.5922363696547298
  batch 309 loss: 0.5921517897963909
  batch 310 loss: 0.5921287811571552
  batch 311 loss: 0.5921413917633498
  batch 312 loss: 0.5921337153667059
  batch 313 loss: 0.5921359494471321
  batch 314 loss: 0.5920476163648496
  batch 315 loss: 0.592000951464214
  batch 316 loss: 0.5919233611490153
  batch 317 loss: 0.5919417674985218
  batch 318 loss: 0.5917880312076904
  batch 319 loss: 0.5918041237843074
  batch 320 loss: 0.5917409049347043
  batch 321 loss: 0.5916366053518848
  batch 322 loss: 0.5916356533210471
  batch 323 loss: 0.5915968377523747
  batch 324 loss: 0.5915307641765217
  batch 325 loss: 0.5914958473352285
  batch 326 loss: 0.5915577342173804
  batch 327 loss: 0.5914858738216785
  batch 328 loss: 0.5914430158530793
  batch 329 loss: 0.5914373881548733
  batch 330 loss: 0.5914254298715881
  batch 331 loss: 0.5913898849415274
  batch 332 loss: 0.5913662526262812
  batch 333 loss: 0.5913567158194991
  batch 334 loss: 0.591267519368383
  batch 335 loss: 0.5911298803429106
  batch 336 loss: 0.5910664525415216
  batch 337 loss: 0.5909546627842708
  batch 338 loss: 0.5909057404162615
  batch 339 loss: 0.5909311115565905
  batch 340 loss: 0.5909132440300549
  batch 341 loss: 0.5909016536128137
  batch 342 loss: 0.5909869947977233
  batch 343 loss: 0.591096559523146
  batch 344 loss: 0.5911299002378486
  batch 345 loss: 0.5911826857622119
  batch 346 loss: 0.5910425165485096
  batch 347 loss: 0.5910317463215216
  batch 348 loss: 0.5911248028278351
  batch 349 loss: 0.5911406302520402
  batch 350 loss: 0.5911339364733015
  batch 351 loss: 0.5911949450134212
  batch 352 loss: 0.5911680637774143
  batch 353 loss: 0.5911844423404834
  batch 354 loss: 0.5912398370982563
  batch 355 loss: 0.591295012453912
  batch 356 loss: 0.59125710822893
  batch 357 loss: 0.5912494422340927
  batch 358 loss: 0.5912709009713967
  batch 359 loss: 0.5912520148295878
  batch 360 loss: 0.5912999765740501
  batch 361 loss: 0.591225738010248
  batch 362 loss: 0.5912388214090253
  batch 363 loss: 0.5911740838003553
  batch 364 loss: 0.5910866167191621
  batch 365 loss: 0.5910541870822645
  batch 366 loss: 0.5910561713364606
  batch 367 loss: 0.5909759930109133
  batch 368 loss: 0.5909589546854082
  batch 369 loss: 0.5911066113771785
  batch 370 loss: 0.5911979528697762
  batch 371 loss: 0.5912650463716039
  batch 372 loss: 0.5912623250035829
  batch 373 loss: 0.5912224346766842
  batch 374 loss: 0.5911631724413704
  batch 375 loss: 0.5911445585886638
  batch 376 loss: 0.591253012101701
  batch 377 loss: 0.591190952837309
  batch 378 loss: 0.5911145951382066
  batch 379 loss: 0.5911034987281054
  batch 380 loss: 0.5910682044531169
  batch 381 loss: 0.5909656707070318
  batch 382 loss: 0.5909056393575918
  batch 383 loss: 0.5909449968574564
  batch 384 loss: 0.5909681476963063
  batch 385 loss: 0.5910768416020777
  batch 386 loss: 0.5910721736250764
  batch 387 loss: 0.5911065644996111
  batch 388 loss: 0.5911298816658787
  batch 389 loss: 0.5911491314059358
  batch 390 loss: 0.5911620052961203
  batch 391 loss: 0.5911333315512713
  batch 392 loss: 0.5910673424297449
  batch 393 loss: 0.591111226542912
  batch 394 loss: 0.5911456098411288
  batch 395 loss: 0.5911252175705343
  batch 396 loss: 0.5910832770545074
  batch 397 loss: 0.5910722894092051
  batch 398 loss: 0.5910383131935368
  batch 399 loss: 0.5910731911061701
  batch 400 loss: 0.5910321454703807
  batch 401 loss: 0.5909436290103598
  batch 402 loss: 0.591028787158615
  batch 403 loss: 0.5910294480418449
  batch 404 loss: 0.5909735938109973
  batch 405 loss: 0.5909664310055015
  batch 406 loss: 0.5909608558480963
  batch 407 loss: 0.5909686088562012
  batch 408 loss: 0.591030522012243
  batch 409 loss: 0.5910093151852671
  batch 410 loss: 0.590977648845533
  batch 411 loss: 0.5909810987122157
  batch 412 loss: 0.5909264576666563
  batch 413 loss: 0.590835635656306
  batch 414 loss: 0.590849967394474
  batch 415 loss: 0.5908713082233107
  batch 416 loss: 0.5908800721741639
  batch 417 loss: 0.5908540836055216
  batch 418 loss: 0.5908141280190226
  batch 419 loss: 0.5908715821678143
  batch 420 loss: 0.5909073758692969
  batch 421 loss: 0.5908746545218515
  batch 422 loss: 0.5909517575496746
  batch 423 loss: 0.5909041738397405
  batch 424 loss: 0.59086210646157
  batch 425 loss: 0.5909156242538901
  batch 426 loss: 0.5908945828256472
  batch 427 loss: 0.5908693463238397
  batch 428 loss: 0.5908718955851047
  batch 429 loss: 0.5908689874035495
  batch 430 loss: 0.5908850267876026
  batch 431 loss: 0.5909041774798436
  batch 432 loss: 0.5908859377657926
  batch 433 loss: 0.5908803032672433
  batch 434 loss: 0.5909159973195072
  batch 435 loss: 0.590890616521068
  batch 436 loss: 0.5909185017194223
  batch 437 loss: 0.5909873892295279
  batch 438 loss: 0.5910536690389729
  batch 439 loss: 0.5910024222045933
  batch 440 loss: 0.5909926495768807
  batch 441 loss: 0.5909413096585782
  batch 442 loss: 0.5908071293550379
  batch 443 loss: 0.5907725494010184
  batch 444 loss: 0.5907485374996254
  batch 445 loss: 0.5906689657254165
  batch 446 loss: 0.5906561603727897
  batch 447 loss: 0.5905786775369238
  batch 448 loss: 0.5906103941212807
  batch 449 loss: 0.5906745381238466
  batch 450 loss: 0.5906845902072059
  batch 451 loss: 0.590634856546533
  batch 452 loss: 0.5905900068778908
  batch 453 loss: 0.590504154464267
  batch 454 loss: 0.590504016776442
  batch 455 loss: 0.5905481565129626
  batch 456 loss: 0.5905613714927122
  batch 457 loss: 0.5906106896160468
  batch 458 loss: 0.5905743087743568
  batch 459 loss: 0.5905419476411441
  batch 460 loss: 0.5905694072661193
  batch 461 loss: 0.590568699185088
  batch 462 loss: 0.5905736515790353
  batch 463 loss: 0.5906093132161168
  batch 464 loss: 0.5906629525125027
  batch 465 loss: 0.5906090380043112
  batch 466 loss: 0.5905559898190232
  batch 467 loss: 0.5905818588218036
  batch 468 loss: 0.5905504689002649
  batch 469 loss: 0.5905434077482488
  batch 470 loss: 0.5905183939223594
  batch 471 loss: 0.5905495883299793
  batch 472 loss: 0.5905182404538333
LOSS train 0.5905182404538333 valid 0.47779783606529236
LOSS train 0.5905182404538333 valid 0.469423770904541
LOSS train 0.5905182404538333 valid 0.4663999676704407
LOSS train 0.5905182404538333 valid 0.4643072187900543
LOSS train 0.5905182404538333 valid 0.4592006325721741
LOSS train 0.5905182404538333 valid 0.464925358692805
LOSS train 0.5905182404538333 valid 0.472202513899122
LOSS train 0.5905182404538333 valid 0.4728209711611271
LOSS train 0.5905182404538333 valid 0.47136377957132125
LOSS train 0.5905182404538333 valid 0.47262352108955386
LOSS train 0.5905182404538333 valid 0.47421651536768133
LOSS train 0.5905182404538333 valid 0.4734448293844859
LOSS train 0.5905182404538333 valid 0.4751998529984401
LOSS train 0.5905182404538333 valid 0.4762249354805265
LOSS train 0.5905182404538333 valid 0.4769875804583232
LOSS train 0.5905182404538333 valid 0.4766862690448761
LOSS train 0.5905182404538333 valid 0.47850727333742027
LOSS train 0.5905182404538333 valid 0.4783914155430264
LOSS train 0.5905182404538333 valid 0.47685480588360835
LOSS train 0.5905182404538333 valid 0.47894031554460526
LOSS train 0.5905182404538333 valid 0.47883984446525574
LOSS train 0.5905182404538333 valid 0.4776621718298305
LOSS train 0.5905182404538333 valid 0.4773983139058818
LOSS train 0.5905182404538333 valid 0.47653406610091525
LOSS train 0.5905182404538333 valid 0.4754620146751404
LOSS train 0.5905182404538333 valid 0.4748984861832399
LOSS train 0.5905182404538333 valid 0.4749419280776271
LOSS train 0.5905182404538333 valid 0.47480738908052444
LOSS train 0.5905182404538333 valid 0.47451346804355754
LOSS train 0.5905182404538333 valid 0.475421197215716
LOSS train 0.5905182404538333 valid 0.47635969327342126
LOSS train 0.5905182404538333 valid 0.4759681383147836
LOSS train 0.5905182404538333 valid 0.47681998032512085
LOSS train 0.5905182404538333 valid 0.4771093857638976
LOSS train 0.5905182404538333 valid 0.4779957592487335
LOSS train 0.5905182404538333 valid 0.47740347186724347
LOSS train 0.5905182404538333 valid 0.47764478905780894
LOSS train 0.5905182404538333 valid 0.4775866897482621
LOSS train 0.5905182404538333 valid 0.4773339965404608
LOSS train 0.5905182404538333 valid 0.47784418389201166
LOSS train 0.5905182404538333 valid 0.4776352484051774
LOSS train 0.5905182404538333 valid 0.47746114290895914
LOSS train 0.5905182404538333 valid 0.47724672389584916
LOSS train 0.5905182404538333 valid 0.4771682037548585
LOSS train 0.5905182404538333 valid 0.47716306845347084
LOSS train 0.5905182404538333 valid 0.4778030799782794
LOSS train 0.5905182404538333 valid 0.4778795102809338
LOSS train 0.5905182404538333 valid 0.47820014630754787
LOSS train 0.5905182404538333 valid 0.47833077579128497
LOSS train 0.5905182404538333 valid 0.4777954512834549
LOSS train 0.5905182404538333 valid 0.47834303390746025
LOSS train 0.5905182404538333 valid 0.47805282129691196
LOSS train 0.5905182404538333 valid 0.4781169486495684
LOSS train 0.5905182404538333 valid 0.47793446977933246
LOSS train 0.5905182404538333 valid 0.47785973115400837
LOSS train 0.5905182404538333 valid 0.477888427142586
LOSS train 0.5905182404538333 valid 0.4775986791702739
LOSS train 0.5905182404538333 valid 0.47746753846776896
LOSS train 0.5905182404538333 valid 0.47756764999890733
LOSS train 0.5905182404538333 valid 0.47757065842549007
LOSS train 0.5905182404538333 valid 0.4767557485181777
LOSS train 0.5905182404538333 valid 0.47686003917647946
LOSS train 0.5905182404538333 valid 0.4769014295131441
LOSS train 0.5905182404538333 valid 0.4776302515529096
LOSS train 0.5905182404538333 valid 0.47764484928204465
LOSS train 0.5905182404538333 valid 0.47772853347388183
LOSS train 0.5905182404538333 valid 0.47766320963404074
LOSS train 0.5905182404538333 valid 0.4776774057570626
LOSS train 0.5905182404538333 valid 0.47738363172696985
LOSS train 0.5905182404538333 valid 0.4771356169666563
LOSS train 0.5905182404538333 valid 0.4768434456536468
LOSS train 0.5905182404538333 valid 0.4766438682046201
LOSS train 0.5905182404538333 valid 0.4765696386768393
LOSS train 0.5905182404538333 valid 0.4760523680094126
LOSS train 0.5905182404538333 valid 0.4761603053410848
LOSS train 0.5905182404538333 valid 0.4760994601406549
LOSS train 0.5905182404538333 valid 0.47616335323878695
LOSS train 0.5905182404538333 valid 0.47602122716414624
LOSS train 0.5905182404538333 valid 0.4758814603467531
LOSS train 0.5905182404538333 valid 0.47553294599056245
LOSS train 0.5905182404538333 valid 0.47544754802444833
LOSS train 0.5905182404538333 valid 0.4753357190184477
LOSS train 0.5905182404538333 valid 0.47530242657086935
LOSS train 0.5905182404538333 valid 0.4751802615466572
LOSS train 0.5905182404538333 valid 0.47513603848569536
LOSS train 0.5905182404538333 valid 0.4748840578073679
LOSS train 0.5905182404538333 valid 0.4748890766467171
LOSS train 0.5905182404538333 valid 0.4747537100179629
LOSS train 0.5905182404538333 valid 0.4748835962140158
LOSS train 0.5905182404538333 valid 0.4748734033770031
LOSS train 0.5905182404538333 valid 0.4746632756112696
LOSS train 0.5905182404538333 valid 0.47471812335045444
LOSS train 0.5905182404538333 valid 0.47459879389373205
LOSS train 0.5905182404538333 valid 0.47438780456147295
LOSS train 0.5905182404538333 valid 0.47409718758181524
LOSS train 0.5905182404538333 valid 0.4740853126471241
LOSS train 0.5905182404538333 valid 0.47443243369613725
LOSS train 0.5905182404538333 valid 0.4742729800696276
LOSS train 0.5905182404538333 valid 0.4743409903362544
LOSS train 0.5905182404538333 valid 0.47434414088726046
LOSS train 0.5905182404538333 valid 0.474398130237466
LOSS train 0.5905182404538333 valid 0.47438333198135973
LOSS train 0.5905182404538333 valid 0.47467279318466926
LOSS train 0.5905182404538333 valid 0.47492684309299177
LOSS train 0.5905182404538333 valid 0.4749250775291806
LOSS train 0.5905182404538333 valid 0.47491956094525895
LOSS train 0.5905182404538333 valid 0.47484034132734637
LOSS train 0.5905182404538333 valid 0.4749885645729524
LOSS train 0.5905182404538333 valid 0.47515249170294593
LOSS train 0.5905182404538333 valid 0.4751619143919511
LOSS train 0.5905182404538333 valid 0.4751526831506609
LOSS train 0.5905182404538333 valid 0.4751615029360567
LOSS train 0.5905182404538333 valid 0.47522152446012583
LOSS train 0.5905182404538333 valid 0.47514029448492484
LOSS train 0.5905182404538333 valid 0.4752627678539442
LOSS train 0.5905182404538333 valid 0.4753762534980116
LOSS train 0.5905182404538333 valid 0.47524876930774784
LOSS train 0.5905182404538333 valid 0.47515204700372987
LOSS train 0.5905182404538333 valid 0.4751859963441095
LOSS train 0.5905182404538333 valid 0.4751875249048074
LOSS train 0.5905182404538333 valid 0.47511178772311563
LOSS train 0.5905182404538333 valid 0.47491090927944807
LOSS train 0.5905182404538333 valid 0.4749673839991655
LOSS train 0.5905182404538333 valid 0.4751906142600121
LOSS train 0.5905182404538333 valid 0.47525284123420714
LOSS train 0.5905182404538333 valid 0.4752326338064103
LOSS train 0.5905182404538333 valid 0.47551240554944735
LOSS train 0.5905182404538333 valid 0.4756419165059924
LOSS train 0.5905182404538333 valid 0.4757162815378618
LOSS train 0.5905182404538333 valid 0.4757457648332302
LOSS train 0.5905182404538333 valid 0.47580948654021926
LOSS train 0.5905182404538333 valid 0.4756495403972539
LOSS train 0.5905182404538333 valid 0.4754520885478285
LOSS train 0.5905182404538333 valid 0.4754253347863012
LOSS train 0.5905182404538333 valid 0.4754701455434163
LOSS train 0.5905182404538333 valid 0.47555019859881964
LOSS train 0.5905182404538333 valid 0.47550449993488564
LOSS train 0.5905182404538333 valid 0.47553012077359186
LOSS train 0.5905182404538333 valid 0.4752945173129761
LOSS train 0.5905182404538333 valid 0.4753446070211274
LOSS train 0.5905182404538333 valid 0.475472241005999
LOSS train 0.5905182404538333 valid 0.4756553832074286
LOSS train 0.5905182404538333 valid 0.47560888820594843
LOSS train 0.5905182404538333 valid 0.4755923650744889
LOSS train 0.5905182404538333 valid 0.4754785778193638
LOSS train 0.5905182404538333 valid 0.4756623398359508
LOSS train 0.5905182404538333 valid 0.4753110546644042
LOSS train 0.5905182404538333 valid 0.475755205025544
LOSS train 0.5905182404538333 valid 0.475766294554576
LOSS train 0.5905182404538333 valid 0.47577447096506753
LOSS train 0.5905182404538333 valid 0.47593946212174876
LOSS train 0.5905182404538333 valid 0.4759314083739331
LOSS train 0.5905182404538333 valid 0.47597349586050497
LOSS train 0.5905182404538333 valid 0.4759741154584018
LOSS train 0.5905182404538333 valid 0.47590023298417367
LOSS train 0.5905182404538333 valid 0.4760946430839025
LOSS train 0.5905182404538333 valid 0.47616687549906933
LOSS train 0.5905182404538333 valid 0.4761897442461569
LOSS train 0.5905182404538333 valid 0.4759074067169765
LOSS train 0.5905182404538333 valid 0.47600467689335346
LOSS train 0.5905182404538333 valid 0.47601316008508576
LOSS train 0.5905182404538333 valid 0.4759416589398443
LOSS train 0.5905182404538333 valid 0.47584057329622514
LOSS train 0.5905182404538333 valid 0.47575949550401875
LOSS train 0.5905182404538333 valid 0.47569675463618655
LOSS train 0.5905182404538333 valid 0.4755279294338571
LOSS train 0.5905182404538333 valid 0.47565569028169097
LOSS train 0.5905182404538333 valid 0.47564063203476725
LOSS train 0.5905182404538333 valid 0.47564699628649376
LOSS train 0.5905182404538333 valid 0.4756105231888154
LOSS train 0.5905182404538333 valid 0.4757782344581091
LOSS train 0.5905182404538333 valid 0.47587870390609255
LOSS train 0.5905182404538333 valid 0.47601582859292885
LOSS train 0.5905182404538333 valid 0.4760057035533861
LOSS train 0.5905182404538333 valid 0.4760506432397025
LOSS train 0.5905182404538333 valid 0.4760942973873832
LOSS train 0.5905182404538333 valid 0.47609511421898665
LOSS train 0.5905182404538333 valid 0.4761762506841274
LOSS train 0.5905182404538333 valid 0.47610901137970013
LOSS train 0.5905182404538333 valid 0.47625808566808703
LOSS train 0.5905182404538333 valid 0.4762371111640614
LOSS train 0.5905182404538333 valid 0.4762131128009859
LOSS train 0.5905182404538333 valid 0.47623748873752325
LOSS train 0.5905182404538333 valid 0.4763038218345331
LOSS train 0.5905182404538333 valid 0.47622613310813905
LOSS train 0.5905182404538333 valid 0.4763410775571741
LOSS train 0.5905182404538333 valid 0.47655139616466463
LOSS train 0.5905182404538333 valid 0.47668464148932316
LOSS train 0.5905182404538333 valid 0.47664499046310543
LOSS train 0.5905182404538333 valid 0.4766544732608293
LOSS train 0.5905182404538333 valid 0.476775099313696
LOSS train 0.5905182404538333 valid 0.4768521284374098
LOSS train 0.5905182404538333 valid 0.47679533504451493
LOSS train 0.5905182404538333 valid 0.47675255739811767
LOSS train 0.5905182404538333 valid 0.4766564836868873
LOSS train 0.5905182404538333 valid 0.4767075951914398
LOSS train 0.5905182404538333 valid 0.47679517005905886
LOSS train 0.5905182404538333 valid 0.47662231085276363
LOSS train 0.5905182404538333 valid 0.4766664298335512
LOSS train 0.5905182404538333 valid 0.47677005141973494
LOSS train 0.5905182404538333 valid 0.4766908216832289
LOSS train 0.5905182404538333 valid 0.4767668313614213
LOSS train 0.5905182404538333 valid 0.4767100000616365
LOSS train 0.5905182404538333 valid 0.47669437819836186
LOSS train 0.5905182404538333 valid 0.4766584091070222
LOSS train 0.5905182404538333 valid 0.47675633980232535
LOSS train 0.5905182404538333 valid 0.47692479142820204
LOSS train 0.5905182404538333 valid 0.47692977579740375
LOSS train 0.5905182404538333 valid 0.4767947968398555
LOSS train 0.5905182404538333 valid 0.47669619634037924
LOSS train 0.5905182404538333 valid 0.4767930270371279
LOSS train 0.5905182404538333 valid 0.476777842022338
LOSS train 0.5905182404538333 valid 0.47667430208322586
LOSS train 0.5905182404538333 valid 0.4767160776341073
LOSS train 0.5905182404538333 valid 0.4767767114694728
LOSS train 0.5905182404538333 valid 0.47682187471676757
LOSS train 0.5905182404538333 valid 0.4769433993623004
LOSS train 0.5905182404538333 valid 0.47694828381779
LOSS train 0.5905182404538333 valid 0.47697961942790307
LOSS train 0.5905182404538333 valid 0.477037458663637
LOSS train 0.5905182404538333 valid 0.4770774456980002
LOSS train 0.5905182404538333 valid 0.477239152735418
LOSS train 0.5905182404538333 valid 0.47734755745383123
LOSS train 0.5905182404538333 valid 0.47736391092517544
LOSS train 0.5905182404538333 valid 0.4772461654080285
LOSS train 0.5905182404538333 valid 0.47725262222564324
LOSS train 0.5905182404538333 valid 0.477509283152971
LOSS train 0.5905182404538333 valid 0.4776270916326004
LOSS train 0.5905182404538333 valid 0.4777095602849685
LOSS train 0.5905182404538333 valid 0.47766044697035914
LOSS train 0.5905182404538333 valid 0.4775864488376684
LOSS train 0.5905182404538333 valid 0.47753027967851736
LOSS train 0.5905182404538333 valid 0.4774377507201592
LOSS train 0.5905182404538333 valid 0.47738242098408884
LOSS train 0.5905182404538333 valid 0.477476311871346
LOSS train 0.5905182404538333 valid 0.47745320516622675
LOSS train 0.5905182404538333 valid 0.47747632685089914
LOSS train 0.5905182404538333 valid 0.47743259107365327
LOSS train 0.5905182404538333 valid 0.47739687499640876
LOSS train 0.5905182404538333 valid 0.4773560091853142
LOSS train 0.5905182404538333 valid 0.47732955489415846
LOSS train 0.5905182404538333 valid 0.47726660868353094
LOSS train 0.5905182404538333 valid 0.47734409914095216
LOSS train 0.5905182404538333 valid 0.47741576833803145
LOSS train 0.5905182404538333 valid 0.4774258266906349
LOSS train 0.5905182404538333 valid 0.4773967230949945
LOSS train 0.5905182404538333 valid 0.4775731740934163
LOSS train 0.5905182404538333 valid 0.47739868478909614
LOSS train 0.5905182404538333 valid 0.4773301518107035
LOSS train 0.5905182404538333 valid 0.47737635600566863
LOSS train 0.5905182404538333 valid 0.4773743510008808
LOSS train 0.5905182404538333 valid 0.4774219425661223
LOSS train 0.5905182404538333 valid 0.47746738226046204
LOSS train 0.5905182404538333 valid 0.4775144707734191
LOSS train 0.5905182404538333 valid 0.4774988412857056
LOSS train 0.5905182404538333 valid 0.4775278598535806
LOSS train 0.5905182404538333 valid 0.47752782679253514
LOSS train 0.5905182404538333 valid 0.4775299502666606
LOSS train 0.5905182404538333 valid 0.47758413960574675
LOSS train 0.5905182404538333 valid 0.4776209552700703
LOSS train 0.5905182404538333 valid 0.47767395431967985
LOSS train 0.5905182404538333 valid 0.47758353040873547
LOSS train 0.5905182404538333 valid 0.47760501798568117
LOSS train 0.5905182404538333 valid 0.47762044214389543
LOSS train 0.5905182404538333 valid 0.47767155687764007
LOSS train 0.5905182404538333 valid 0.47771281362476203
LOSS train 0.5905182404538333 valid 0.4777821985523352
LOSS train 0.5905182404538333 valid 0.477761304645396
LOSS train 0.5905182404538333 valid 0.4779347970140025
LOSS train 0.5905182404538333 valid 0.4779365751478407
LOSS train 0.5905182404538333 valid 0.47796879835234357
LOSS train 0.5905182404538333 valid 0.47802785740179177
LOSS train 0.5905182404538333 valid 0.47808469979317636
LOSS train 0.5905182404538333 valid 0.4780958485211769
LOSS train 0.5905182404538333 valid 0.47814287456599147
LOSS train 0.5905182404538333 valid 0.4781881373213685
LOSS train 0.5905182404538333 valid 0.47817433644287854
LOSS train 0.5905182404538333 valid 0.47812813531151777
LOSS train 0.5905182404538333 valid 0.4782678097166041
LOSS train 0.5905182404538333 valid 0.478288207841771
LOSS train 0.5905182404538333 valid 0.4781288430359864
LOSS train 0.5905182404538333 valid 0.4780375317056128
LOSS train 0.5905182404538333 valid 0.4779706897457581
LOSS train 0.5905182404538333 valid 0.47804820988799485
LOSS train 0.5905182404538333 valid 0.4780549029509226
LOSS train 0.5905182404538333 valid 0.47799289997641026
LOSS train 0.5905182404538333 valid 0.47792569124740175
LOSS train 0.5905182404538333 valid 0.4779511873299877
LOSS train 0.5905182404538333 valid 0.477889204417133
LOSS train 0.5905182404538333 valid 0.4780002578579146
LOSS train 0.5905182404538333 valid 0.47792623389217864
LOSS train 0.5905182404538333 valid 0.47803160925842314
LOSS train 0.5905182404538333 valid 0.4779689536770049
LOSS train 0.5905182404538333 valid 0.47804835996254774
LOSS train 0.5905182404538333 valid 0.47812154181933
LOSS train 0.5905182404538333 valid 0.47810645784075195
LOSS train 0.5905182404538333 valid 0.478015197948976
LOSS train 0.5905182404538333 valid 0.477982436350528
LOSS train 0.5905182404538333 valid 0.4780928126745001
LOSS train 0.5905182404538333 valid 0.47805648217598595
LOSS train 0.5905182404538333 valid 0.4780867136396047
LOSS train 0.5905182404538333 valid 0.47796719072275606
LOSS train 0.5905182404538333 valid 0.4779942530413272
LOSS train 0.5905182404538333 valid 0.47796927931669514
LOSS train 0.5905182404538333 valid 0.4779132857674458
LOSS train 0.5905182404538333 valid 0.477815660094124
LOSS train 0.5905182404538333 valid 0.4778945749862186
LOSS train 0.5905182404538333 valid 0.47782867053499467
LOSS train 0.5905182404538333 valid 0.4778896004058011
LOSS train 0.5905182404538333 valid 0.47787400301425687
LOSS train 0.5905182404538333 valid 0.4778257565291365
LOSS train 0.5905182404538333 valid 0.47786985748471356
LOSS train 0.5905182404538333 valid 0.47794904067112615
LOSS train 0.5905182404538333 valid 0.47803964423146217
LOSS train 0.5905182404538333 valid 0.4780513102100009
LOSS train 0.5905182404538333 valid 0.4778901109401184
LOSS train 0.5905182404538333 valid 0.4779343639826549
LOSS train 0.5905182404538333 valid 0.4779054381937351
LOSS train 0.5905182404538333 valid 0.47796177518405136
LOSS train 0.5905182404538333 valid 0.4778557942248881
LOSS train 0.5905182404538333 valid 0.47781193228525537
LOSS train 0.5905182404538333 valid 0.4778140429754435
LOSS train 0.5905182404538333 valid 0.4777465549415848
LOSS train 0.5905182404538333 valid 0.4777754940736441
LOSS train 0.5905182404538333 valid 0.4777826052445632
LOSS train 0.5905182404538333 valid 0.47780976906144546
LOSS train 0.5905182404538333 valid 0.4779068521403391
LOSS train 0.5905182404538333 valid 0.47799675311984086
LOSS train 0.5905182404538333 valid 0.47799925220773576
LOSS train 0.5905182404538333 valid 0.4779638442126187
LOSS train 0.5905182404538333 valid 0.4779284881861188
LOSS train 0.5905182404538333 valid 0.47782505734498243
LOSS train 0.5905182404538333 valid 0.47781846025684577
LOSS train 0.5905182404538333 valid 0.4778873067416117
LOSS train 0.5905182404538333 valid 0.47782628527328147
LOSS train 0.5905182404538333 valid 0.4778451416641474
LOSS train 0.5905182404538333 valid 0.4777985174507345
LOSS train 0.5905182404538333 valid 0.4778482148633201
LOSS train 0.5905182404538333 valid 0.4778559317806829
LOSS train 0.5905182404538333 valid 0.4778500917203286
LOSS train 0.5905182404538333 valid 0.477764017158939
LOSS train 0.5905182404538333 valid 0.4777192162317142
LOSS train 0.5905182404538333 valid 0.47771691085645823
LOSS train 0.5905182404538333 valid 0.47784740382502244
LOSS train 0.5905182404538333 valid 0.4778448298357535
LOSS train 0.5905182404538333 valid 0.4778953071446777
LOSS train 0.5905182404538333 valid 0.47777858582628563
LOSS train 0.5905182404538333 valid 0.47782961159259424
LOSS train 0.5905182404538333 valid 0.47787548042300093
LOSS train 0.5905182404538333 valid 0.47785369762352536
LOSS train 0.5905182404538333 valid 0.47780516115348903
LOSS train 0.5905182404538333 valid 0.4778052309358662
LOSS train 0.5905182404538333 valid 0.47779832244257076
LOSS train 0.5905182404538333 valid 0.477807689689647
LOSS train 0.5905182404538333 valid 0.4778124660673276
LOSS train 0.5905182404538333 valid 0.47782768836517014
LOSS train 0.5905182404538333 valid 0.4777427204683715
LOSS train 0.5905182404538333 valid 0.47765803162279075
LOSS train 0.5905182404538333 valid 0.4776247936537007
LOSS train 0.5905182404538333 valid 0.4775857667956087
LOSS train 0.5905182404538333 valid 0.47764707800424
LOSS train 0.5905182404538333 valid 0.47767516888307604
LOSS train 0.5905182404538333 valid 0.4777188263320397
LOSS train 0.5905182404538333 valid 0.4776551651430654
LOSS train 0.5905182404538333 valid 0.4776816699602833
LOSS train 0.5905182404538333 valid 0.47768901475791725
LOSS train 0.5905182404538333 valid 0.4776175378616239
LOSS train 0.5905182404538333 valid 0.47767010849455127
LOSS train 0.5905182404538333 valid 0.47763727407468365
EPOCH 7:
  batch 1 loss: 0.5718163251876831
  batch 2 loss: 0.565967470407486
  batch 3 loss: 0.5725322564442953
  batch 4 loss: 0.5834069848060608
  batch 5 loss: 0.5807644367218018
  batch 6 loss: 0.5810038050015768
  batch 7 loss: 0.5858862229755947
  batch 8 loss: 0.5852276384830475
  batch 9 loss: 0.5859174066119723
  batch 10 loss: 0.5871886193752289
  batch 11 loss: 0.5890783667564392
  batch 12 loss: 0.5913277020057043
  batch 13 loss: 0.5931677222251892
  batch 14 loss: 0.5931849351951054
  batch 15 loss: 0.5959182858467102
  batch 16 loss: 0.5958461761474609
  batch 17 loss: 0.595449917456683
  batch 18 loss: 0.5945966607994504
  batch 19 loss: 0.5940987216798883
  batch 20 loss: 0.595244300365448
  batch 21 loss: 0.5951603196916126
  batch 22 loss: 0.5946156328374689
  batch 23 loss: 0.593892760898756
  batch 24 loss: 0.5928104743361473
  batch 25 loss: 0.5946794939041138
  batch 26 loss: 0.5937958313868597
  batch 27 loss: 0.593510111172994
  batch 28 loss: 0.5930071494409016
  batch 29 loss: 0.5931098152851236
  batch 30 loss: 0.5922356247901917
  batch 31 loss: 0.5923166428842852
  batch 32 loss: 0.5923704709857702
  batch 33 loss: 0.592399593555566
  batch 34 loss: 0.5918015679892372
  batch 35 loss: 0.5929568375859942
  batch 36 loss: 0.592843610379431
  batch 37 loss: 0.5926484143411791
  batch 38 loss: 0.5923174054999101
  batch 39 loss: 0.5923202190643702
  batch 40 loss: 0.5921329140663147
  batch 41 loss: 0.5921744515256184
  batch 42 loss: 0.5918617532366798
  batch 43 loss: 0.59225611215414
  batch 44 loss: 0.5920260169289329
  batch 45 loss: 0.5927726798587375
  batch 46 loss: 0.5923785398835721
  batch 47 loss: 0.592628371208272
  batch 48 loss: 0.5918664795656999
  batch 49 loss: 0.5911169210258795
  batch 50 loss: 0.5910252201557159
  batch 51 loss: 0.5906610103214488
  batch 52 loss: 0.5913044856144831
  batch 53 loss: 0.5912394591097562
  batch 54 loss: 0.5915652127177627
  batch 55 loss: 0.5909758730368181
  batch 56 loss: 0.5908616983464786
  batch 57 loss: 0.5908182116976956
  batch 58 loss: 0.5911108985029417
  batch 59 loss: 0.590990550437216
  batch 60 loss: 0.5907177060842514
  batch 61 loss: 0.590339756402813
  batch 62 loss: 0.590834221532268
  batch 63 loss: 0.5909009925902836
  batch 64 loss: 0.5909212389960885
  batch 65 loss: 0.5906235557336074
  batch 66 loss: 0.5904593061317097
  batch 67 loss: 0.5907488162837812
  batch 68 loss: 0.5911157175022013
  batch 69 loss: 0.5911428937013599
  batch 70 loss: 0.5911257445812226
  batch 71 loss: 0.5913106077153918
  batch 72 loss: 0.5911604902810521
  batch 73 loss: 0.5913346483282846
  batch 74 loss: 0.5915357478567072
  batch 75 loss: 0.5915437316894532
  batch 76 loss: 0.5918227606698087
  batch 77 loss: 0.5915795007309357
  batch 78 loss: 0.5912705079103128
  batch 79 loss: 0.5917225442355192
  batch 80 loss: 0.5915901809930801
  batch 81 loss: 0.5915546402519132
  batch 82 loss: 0.5918633167336627
  batch 83 loss: 0.5918173086212342
  batch 84 loss: 0.5916510082426525
  batch 85 loss: 0.59098220502629
  batch 86 loss: 0.5915589339511339
  batch 87 loss: 0.5916768497434156
  batch 88 loss: 0.591440465639938
  batch 89 loss: 0.5913404440611936
  batch 90 loss: 0.5911040882269541
  batch 91 loss: 0.5912574575497553
  batch 92 loss: 0.5909127806839736
  batch 93 loss: 0.59077747086043
  batch 94 loss: 0.590917096493092
  batch 95 loss: 0.5910366497541729
  batch 96 loss: 0.5909628657003244
  batch 97 loss: 0.5906618606183947
  batch 98 loss: 0.5907473728364828
  batch 99 loss: 0.5907699814950577
  batch 100 loss: 0.5905569964647293
  batch 101 loss: 0.5907049527262697
  batch 102 loss: 0.5907233000970354
  batch 103 loss: 0.590641222532513
  batch 104 loss: 0.590789370238781
  batch 105 loss: 0.5907338619232178
  batch 106 loss: 0.590612918700812
  batch 107 loss: 0.5905318182205486
  batch 108 loss: 0.5903001714635778
  batch 109 loss: 0.5900720932068081
  batch 110 loss: 0.5905111166563901
  batch 111 loss: 0.5906790591575004
  batch 112 loss: 0.5906271093658039
  batch 113 loss: 0.5905906447267111
  batch 114 loss: 0.5909395348607448
  batch 115 loss: 0.5908301622971245
  batch 116 loss: 0.5910003616892058
  batch 117 loss: 0.590990632517725
  batch 118 loss: 0.5910318882788642
  batch 119 loss: 0.590935811776073
  batch 120 loss: 0.5907804891467094
  batch 121 loss: 0.5906995086630514
  batch 122 loss: 0.5906660024259911
  batch 123 loss: 0.5905703340119463
  batch 124 loss: 0.5907439363579596
  batch 125 loss: 0.5907777500152588
  batch 126 loss: 0.5905955897437202
  batch 127 loss: 0.5905775526377159
  batch 128 loss: 0.5904104332439601
  batch 129 loss: 0.5900899795598762
  batch 130 loss: 0.5901850980061751
  batch 131 loss: 0.5901401274986849
  batch 132 loss: 0.5900640212225191
  batch 133 loss: 0.5902441592144787
  batch 134 loss: 0.5900918418791756
  batch 135 loss: 0.5901473138067458
  batch 136 loss: 0.590209511711317
  batch 137 loss: 0.590435027206031
  batch 138 loss: 0.5903584974399512
  batch 139 loss: 0.5904213833294326
  batch 140 loss: 0.5902581981250218
  batch 141 loss: 0.59018101379381
  batch 142 loss: 0.5901165869034511
  batch 143 loss: 0.5898528236609238
  batch 144 loss: 0.5897987373173237
  batch 145 loss: 0.5897641736885597
  batch 146 loss: 0.5898539595407982
  batch 147 loss: 0.5898956790262339
  batch 148 loss: 0.5897540502451561
  batch 149 loss: 0.5897182414195682
  batch 150 loss: 0.5896417435010274
  batch 151 loss: 0.5896542585448713
  batch 152 loss: 0.5896195922242967
  batch 153 loss: 0.5897131133702845
  batch 154 loss: 0.5897484119836386
  batch 155 loss: 0.5899087006045926
  batch 156 loss: 0.5898971041807761
  batch 157 loss: 0.5899772621264123
  batch 158 loss: 0.5899299062505553
  batch 159 loss: 0.5898988633035863
  batch 160 loss: 0.5899111736565829
  batch 161 loss: 0.5900191598057006
  batch 162 loss: 0.5899222452699402
  batch 163 loss: 0.5898875820856153
  batch 164 loss: 0.5897999104203248
  batch 165 loss: 0.5896883382941738
  batch 166 loss: 0.589728926678738
  batch 167 loss: 0.5895641645985449
  batch 168 loss: 0.5896948615000361
  batch 169 loss: 0.5896187572789615
  batch 170 loss: 0.5899852672043968
  batch 171 loss: 0.5900540766660233
  batch 172 loss: 0.5899810648934786
  batch 173 loss: 0.5900286046755796
  batch 174 loss: 0.5900769298789145
  batch 175 loss: 0.5899980814116341
  batch 176 loss: 0.5899233469231562
  batch 177 loss: 0.5897025469332765
  batch 178 loss: 0.5896256532561913
  batch 179 loss: 0.5896100381899146
  batch 180 loss: 0.5896804203589757
  batch 181 loss: 0.5897779171638067
  batch 182 loss: 0.5896603661579091
  batch 183 loss: 0.5897314144613964
  batch 184 loss: 0.5897129890711411
  batch 185 loss: 0.5898559344781412
  batch 186 loss: 0.5899231539618585
  batch 187 loss: 0.5897928183091515
  batch 188 loss: 0.5896928158212216
  batch 189 loss: 0.5895585799343371
  batch 190 loss: 0.5894771042623018
  batch 191 loss: 0.5894491772377054
  batch 192 loss: 0.5894154304017624
  batch 193 loss: 0.589372849526183
  batch 194 loss: 0.5895401423739404
  batch 195 loss: 0.5895794464991643
  batch 196 loss: 0.5894092698486484
  batch 197 loss: 0.5893570705113678
  batch 198 loss: 0.5892843724501253
  batch 199 loss: 0.5893249224178755
  batch 200 loss: 0.5892797470092773
  batch 201 loss: 0.5893823169357147
  batch 202 loss: 0.5893639178559331
  batch 203 loss: 0.5893578394293197
  batch 204 loss: 0.5892768750588099
  batch 205 loss: 0.5893588298704566
  batch 206 loss: 0.5893394047195472
  batch 207 loss: 0.5893276711017037
  batch 208 loss: 0.5892052842447391
  batch 209 loss: 0.5890756300761939
  batch 210 loss: 0.5890248823733557
  batch 211 loss: 0.5890412067915026
  batch 212 loss: 0.5889394564448662
  batch 213 loss: 0.5888858356386283
  batch 214 loss: 0.5887580296703588
  batch 215 loss: 0.5886038070501283
  batch 216 loss: 0.5885851408044497
  batch 217 loss: 0.5885055957851322
  batch 218 loss: 0.5885889984052116
  batch 219 loss: 0.5884185653843291
  batch 220 loss: 0.5883962734179063
  batch 221 loss: 0.5883900258875541
  batch 222 loss: 0.5884679802903184
  batch 223 loss: 0.5884496561614921
  batch 224 loss: 0.5883876149143491
  batch 225 loss: 0.5882723686430189
  batch 226 loss: 0.5883023672926743
  batch 227 loss: 0.5882028462078077
  batch 228 loss: 0.5881551125070505
  batch 229 loss: 0.5880558428285424
  batch 230 loss: 0.5880167090374491
  batch 231 loss: 0.5880943412904616
  batch 232 loss: 0.5880372416356514
  batch 233 loss: 0.5881116006507382
  batch 234 loss: 0.5880364342632457
  batch 235 loss: 0.5880303012563827
  batch 236 loss: 0.5879294642452466
  batch 237 loss: 0.5878737780112254
  batch 238 loss: 0.5878400574712193
  batch 239 loss: 0.5878873203090045
  batch 240 loss: 0.5879228728512923
  batch 241 loss: 0.5878617676956525
  batch 242 loss: 0.5877627407716326
  batch 243 loss: 0.587774604681588
  batch 244 loss: 0.5877992625607819
  batch 245 loss: 0.5877588595662798
  batch 246 loss: 0.5878859692957343
  batch 247 loss: 0.5878896944918613
  batch 248 loss: 0.5878662733781722
  batch 249 loss: 0.5879406184556494
  batch 250 loss: 0.5879036166667938
  batch 251 loss: 0.5879355984854984
  batch 252 loss: 0.5879736658599641
  batch 253 loss: 0.5879096761051374
  batch 254 loss: 0.5879082086048727
  batch 255 loss: 0.5878887578552845
  batch 256 loss: 0.5878957854583859
  batch 257 loss: 0.5879284630489721
  batch 258 loss: 0.5878385541050933
  batch 259 loss: 0.5876748396162821
  batch 260 loss: 0.5875805880014713
  batch 261 loss: 0.5876083668621107
  batch 262 loss: 0.5876679725319375
  batch 263 loss: 0.5876826974828887
  batch 264 loss: 0.5875496868834351
  batch 265 loss: 0.5875722880633372
  batch 266 loss: 0.5875098595493718
  batch 267 loss: 0.5876358745249917
  batch 268 loss: 0.5875662060371086
  batch 269 loss: 0.5876001682423304
  batch 270 loss: 0.5875901350268611
  batch 271 loss: 0.5875967103176891
  batch 272 loss: 0.5876326578504899
  batch 273 loss: 0.5876128053490496
  batch 274 loss: 0.5876202761691852
  batch 275 loss: 0.5876893940838901
  batch 276 loss: 0.5877582275349161
  batch 277 loss: 0.5877488735350461
  batch 278 loss: 0.5877012466784004
  batch 279 loss: 0.5877160075317575
  batch 280 loss: 0.5877310818859509
  batch 281 loss: 0.5876558244864711
  batch 282 loss: 0.5875543262941617
  batch 283 loss: 0.5873868259018807
  batch 284 loss: 0.5874791470631747
  batch 285 loss: 0.587514326865213
  batch 286 loss: 0.5874820322423548
  batch 287 loss: 0.587401298280377
  batch 288 loss: 0.5872989230685763
  batch 289 loss: 0.5872961695218993
  batch 290 loss: 0.5871583254172884
  batch 291 loss: 0.5871219290900476
  batch 292 loss: 0.5872237041388473
  batch 293 loss: 0.5872001562509114
  batch 294 loss: 0.5871504674963399
  batch 295 loss: 0.5871340521311356
  batch 296 loss: 0.5871406845949791
  batch 297 loss: 0.5870864399354466
  batch 298 loss: 0.5870193109016291
  batch 299 loss: 0.5870514821049362
  batch 300 loss: 0.5871065413951874
  batch 301 loss: 0.5870583108889305
  batch 302 loss: 0.5870468419119222
  batch 303 loss: 0.5870494669420098
  batch 304 loss: 0.5869155981038746
  batch 305 loss: 0.5867745577311907
  batch 306 loss: 0.5867626649491927
  batch 307 loss: 0.5867281214422045
  batch 308 loss: 0.5867318220726856
  batch 309 loss: 0.5866134594945074
  batch 310 loss: 0.5866208899405695
  batch 311 loss: 0.5866587202265332
  batch 312 loss: 0.5866026459978178
  batch 313 loss: 0.5866430464644021
  batch 314 loss: 0.5865434747972306
  batch 315 loss: 0.5864700841525244
  batch 316 loss: 0.5864047034631802
  batch 317 loss: 0.5864298990472258
  batch 318 loss: 0.5862461045478125
  batch 319 loss: 0.5862425986128541
  batch 320 loss: 0.5862276174128056
  batch 321 loss: 0.5861374132358397
  batch 322 loss: 0.58617666604356
  batch 323 loss: 0.5861356468761668
  batch 324 loss: 0.586102310890033
  batch 325 loss: 0.5861029579089239
  batch 326 loss: 0.586148920783236
  batch 327 loss: 0.586086335349885
  batch 328 loss: 0.5860642412813698
  batch 329 loss: 0.5860695538187461
  batch 330 loss: 0.5860933032902804
  batch 331 loss: 0.5860582069687973
  batch 332 loss: 0.5860458239015326
  batch 333 loss: 0.5860216370573988
  batch 334 loss: 0.5859413743019104
  batch 335 loss: 0.5858093302641342
  batch 336 loss: 0.5857525891846135
  batch 337 loss: 0.585686390583876
  batch 338 loss: 0.5856927698533211
  batch 339 loss: 0.5857234498744166
  batch 340 loss: 0.5857326574185315
  batch 341 loss: 0.5856558890286778
  batch 342 loss: 0.5856147019835244
  batch 343 loss: 0.585638376783699
  batch 344 loss: 0.5856245588078055
  batch 345 loss: 0.5856474242348602
  batch 346 loss: 0.5855639023932419
  batch 347 loss: 0.5855538960149034
  batch 348 loss: 0.5855924824531051
  batch 349 loss: 0.5855281838031758
  batch 350 loss: 0.5855539005143302
  batch 351 loss: 0.585596383806647
  batch 352 loss: 0.5855598168616946
  batch 353 loss: 0.585557497256876
  batch 354 loss: 0.5856443237786912
  batch 355 loss: 0.5857164137799975
  batch 356 loss: 0.5856763445929195
  batch 357 loss: 0.5856237909039196
  batch 358 loss: 0.5856193763583732
  batch 359 loss: 0.5856139649919813
  batch 360 loss: 0.5856652667125066
  batch 361 loss: 0.5855730438496598
  batch 362 loss: 0.5855759494212451
  batch 363 loss: 0.5855075785936403
  batch 364 loss: 0.5854453996315108
  batch 365 loss: 0.5853813556775654
  batch 366 loss: 0.5854298773684788
  batch 367 loss: 0.5853238225957679
  batch 368 loss: 0.5852680974032568
  batch 369 loss: 0.5853280943583666
  batch 370 loss: 0.5854877011196034
  batch 371 loss: 0.5855790169412556
  batch 372 loss: 0.5855636652759326
  batch 373 loss: 0.5855340745110295
  batch 374 loss: 0.5854662132454428
  batch 375 loss: 0.5854730167388916
  batch 376 loss: 0.5855805095522961
  batch 377 loss: 0.5855689083549641
  batch 378 loss: 0.5855127609280683
  batch 379 loss: 0.58548526556322
  batch 380 loss: 0.585519958797254
  batch 381 loss: 0.585464156049443
  batch 382 loss: 0.5854204738639412
  batch 383 loss: 0.5854230719197824
  batch 384 loss: 0.5854672178005179
  batch 385 loss: 0.5856079733216918
  batch 386 loss: 0.5856056214923068
  batch 387 loss: 0.5855999279391858
  batch 388 loss: 0.5856313250728489
  batch 389 loss: 0.5856922187658079
  batch 390 loss: 0.5857337089685294
  batch 391 loss: 0.5857053406708076
  batch 392 loss: 0.5856392090113796
  batch 393 loss: 0.585726624985081
  batch 394 loss: 0.5858356917872647
  batch 395 loss: 0.5858441508269008
  batch 396 loss: 0.5858300398997586
  batch 397 loss: 0.5857941457246353
  batch 398 loss: 0.5858134103180775
  batch 399 loss: 0.5858206663812909
  batch 400 loss: 0.5857911561429501
  batch 401 loss: 0.5857446233827872
  batch 402 loss: 0.5857903072193488
  batch 403 loss: 0.5858302821888226
  batch 404 loss: 0.5857755972607301
  batch 405 loss: 0.585746905244427
  batch 406 loss: 0.5857988701665343
  batch 407 loss: 0.5858726316939408
  batch 408 loss: 0.5859849263055652
  batch 409 loss: 0.5859788600856343
  batch 410 loss: 0.5859342220352917
  batch 411 loss: 0.5858966837254174
  batch 412 loss: 0.5858806363008555
  batch 413 loss: 0.5858717664679373
  batch 414 loss: 0.585933627569733
  batch 415 loss: 0.585962274419256
  batch 416 loss: 0.5860139803531078
  batch 417 loss: 0.5859957300215888
  batch 418 loss: 0.5859867541128368
  batch 419 loss: 0.5860493907211504
  batch 420 loss: 0.5861027613991783
  batch 421 loss: 0.5860906677970977
  batch 422 loss: 0.5860949579573356
  batch 423 loss: 0.5860845786178084
  batch 424 loss: 0.5860018259230649
  batch 425 loss: 0.5860228269240435
  batch 426 loss: 0.5859853868753138
  batch 427 loss: 0.5859466475681063
  batch 428 loss: 0.5859335531419683
  batch 429 loss: 0.5859750330031335
  batch 430 loss: 0.585988413040028
  batch 431 loss: 0.5859924058349946
  batch 432 loss: 0.585993989750191
  batch 433 loss: 0.5859935850799772
  batch 434 loss: 0.5860353993930025
  batch 435 loss: 0.5860283065116269
  batch 436 loss: 0.5859854433241241
  batch 437 loss: 0.5860570231346026
  batch 438 loss: 0.5861424448555463
  batch 439 loss: 0.5861315216724856
  batch 440 loss: 0.5861589173024351
  batch 441 loss: 0.586121276527846
  batch 442 loss: 0.5860505183627702
  batch 443 loss: 0.5860112048433274
  batch 444 loss: 0.5859896870883735
  batch 445 loss: 0.5859422356894847
  batch 446 loss: 0.5859004535749889
  batch 447 loss: 0.5858456132395956
  batch 448 loss: 0.585911591936435
  batch 449 loss: 0.5859435095818908
  batch 450 loss: 0.5859356641769409
  batch 451 loss: 0.5859128659686069
  batch 452 loss: 0.5859106027447016
  batch 453 loss: 0.5858441509684716
  batch 454 loss: 0.585840490158434
  batch 455 loss: 0.5858664440584707
  batch 456 loss: 0.5858666464163546
  batch 457 loss: 0.5859321078012496
  batch 458 loss: 0.5859098543766804
  batch 459 loss: 0.5858782762276061
  batch 460 loss: 0.5859347414711248
  batch 461 loss: 0.585950058478854
  batch 462 loss: 0.585936951043802
  batch 463 loss: 0.5859815792440081
  batch 464 loss: 0.5860274733397467
  batch 465 loss: 0.5859864682279607
  batch 466 loss: 0.5859591258697755
  batch 467 loss: 0.5859915811959375
  batch 468 loss: 0.5859663101852449
  batch 469 loss: 0.5859522529756591
  batch 470 loss: 0.5859276353044712
  batch 471 loss: 0.5859370774524227
  batch 472 loss: 0.5858767648874703
LOSS train 0.5858767648874703 valid 0.45404359698295593
LOSS train 0.5858767648874703 valid 0.4533602148294449
LOSS train 0.5858767648874703 valid 0.4506576160589854
LOSS train 0.5858767648874703 valid 0.4484846219420433
LOSS train 0.5858767648874703 valid 0.44412996172904967
LOSS train 0.5858767648874703 valid 0.4487302551666896
LOSS train 0.5858767648874703 valid 0.4548604999269758
LOSS train 0.5858767648874703 valid 0.45572782307863235
LOSS train 0.5858767648874703 valid 0.454152438375685
LOSS train 0.5858767648874703 valid 0.45546614527702334
LOSS train 0.5858767648874703 valid 0.4562224501913244
LOSS train 0.5858767648874703 valid 0.4551446462670962
LOSS train 0.5858767648874703 valid 0.4582956456221067
LOSS train 0.5858767648874703 valid 0.4594753874199731
LOSS train 0.5858767648874703 valid 0.45996455748875936
LOSS train 0.5858767648874703 valid 0.45938750728964806
LOSS train 0.5858767648874703 valid 0.46113290681558494
LOSS train 0.5858767648874703 valid 0.4613238424062729
LOSS train 0.5858767648874703 valid 0.46016839460322734
LOSS train 0.5858767648874703 valid 0.4612377300858498
LOSS train 0.5858767648874703 valid 0.46164827261652264
LOSS train 0.5858767648874703 valid 0.46008202839981427
LOSS train 0.5858767648874703 valid 0.45997869968414307
LOSS train 0.5858767648874703 valid 0.459299457569917
LOSS train 0.5858767648874703 valid 0.4585632061958313
LOSS train 0.5858767648874703 valid 0.45789083723838514
LOSS train 0.5858767648874703 valid 0.4579166659602412
LOSS train 0.5858767648874703 valid 0.45803286135196686
LOSS train 0.5858767648874703 valid 0.4574463655208719
LOSS train 0.5858767648874703 valid 0.4584607779979706
LOSS train 0.5858767648874703 valid 0.4597791625607398
LOSS train 0.5858767648874703 valid 0.4594758190214634
LOSS train 0.5858767648874703 valid 0.45972332087430084
LOSS train 0.5858767648874703 valid 0.4599304541068919
LOSS train 0.5858767648874703 valid 0.4607340795653207
LOSS train 0.5858767648874703 valid 0.46025755339198643
LOSS train 0.5858767648874703 valid 0.46024303017435847
LOSS train 0.5858767648874703 valid 0.4601347618981412
LOSS train 0.5858767648874703 valid 0.459830750257541
LOSS train 0.5858767648874703 valid 0.4602885223925114
LOSS train 0.5858767648874703 valid 0.4601291621603617
LOSS train 0.5858767648874703 valid 0.46003861796288265
LOSS train 0.5858767648874703 valid 0.459403301394263
LOSS train 0.5858767648874703 valid 0.4592160514809869
LOSS train 0.5858767648874703 valid 0.45907684299680923
LOSS train 0.5858767648874703 valid 0.45956873375436536
LOSS train 0.5858767648874703 valid 0.4599535275012889
LOSS train 0.5858767648874703 valid 0.46031834309299785
LOSS train 0.5858767648874703 valid 0.4607172675278722
LOSS train 0.5858767648874703 valid 0.46019282639026643
LOSS train 0.5858767648874703 valid 0.4606521953554714
LOSS train 0.5858767648874703 valid 0.4604733672279578
LOSS train 0.5858767648874703 valid 0.46054826086422185
LOSS train 0.5858767648874703 valid 0.46027714510758716
LOSS train 0.5858767648874703 valid 0.46030349948189475
LOSS train 0.5858767648874703 valid 0.46017624863556456
LOSS train 0.5858767648874703 valid 0.4598225559058942
LOSS train 0.5858767648874703 valid 0.459694671733626
LOSS train 0.5858767648874703 valid 0.4598377513683448
LOSS train 0.5858767648874703 valid 0.45975302209456764
LOSS train 0.5858767648874703 valid 0.45894707470643714
LOSS train 0.5858767648874703 valid 0.45895422033725247
LOSS train 0.5858767648874703 valid 0.45912600367788287
LOSS train 0.5858767648874703 valid 0.4598531969822943
LOSS train 0.5858767648874703 valid 0.4598591011304122
LOSS train 0.5858767648874703 valid 0.45983530490687397
LOSS train 0.5858767648874703 valid 0.4596436953366692
LOSS train 0.5858767648874703 valid 0.45963652607272654
LOSS train 0.5858767648874703 valid 0.45940924209097156
LOSS train 0.5858767648874703 valid 0.45916101719651903
LOSS train 0.5858767648874703 valid 0.4589289355445916
LOSS train 0.5858767648874703 valid 0.45873323041531777
LOSS train 0.5858767648874703 valid 0.4587186991351925
LOSS train 0.5858767648874703 valid 0.45831902445973577
LOSS train 0.5858767648874703 valid 0.4583581399917602
LOSS train 0.5858767648874703 valid 0.45820408118398565
LOSS train 0.5858767648874703 valid 0.45812781213165876
LOSS train 0.5858767648874703 valid 0.45813470696791625
LOSS train 0.5858767648874703 valid 0.4579216966146155
LOSS train 0.5858767648874703 valid 0.45757503174245356
LOSS train 0.5858767648874703 valid 0.45749329895149043
LOSS train 0.5858767648874703 valid 0.4574805523564176
LOSS train 0.5858767648874703 valid 0.4573750959103366
LOSS train 0.5858767648874703 valid 0.45729416147584007
LOSS train 0.5858767648874703 valid 0.45714074127814347
LOSS train 0.5858767648874703 valid 0.45690487948961034
LOSS train 0.5858767648874703 valid 0.45697829606889306
LOSS train 0.5858767648874703 valid 0.45690594105557963
LOSS train 0.5858767648874703 valid 0.45688911535766685
LOSS train 0.5858767648874703 valid 0.45691512326399486
LOSS train 0.5858767648874703 valid 0.4568784875529153
LOSS train 0.5858767648874703 valid 0.45693190298650577
LOSS train 0.5858767648874703 valid 0.4567634511378504
LOSS train 0.5858767648874703 valid 0.4565066381337795
LOSS train 0.5858767648874703 valid 0.4562530633650328
LOSS train 0.5858767648874703 valid 0.4562641012792786
LOSS train 0.5858767648874703 valid 0.45646808073692713
LOSS train 0.5858767648874703 valid 0.4562810069444228
LOSS train 0.5858767648874703 valid 0.45641000975262036
LOSS train 0.5858767648874703 valid 0.45643799632787707
LOSS train 0.5858767648874703 valid 0.4564750772891658
LOSS train 0.5858767648874703 valid 0.45647546882722895
LOSS train 0.5858767648874703 valid 0.4567720519686208
LOSS train 0.5858767648874703 valid 0.4569379475254279
LOSS train 0.5858767648874703 valid 0.4569938438279288
LOSS train 0.5858767648874703 valid 0.4569869654358558
LOSS train 0.5858767648874703 valid 0.45689335103346923
LOSS train 0.5858767648874703 valid 0.4569636619201413
LOSS train 0.5858767648874703 valid 0.4571118737579486
LOSS train 0.5858767648874703 valid 0.4572228575294668
LOSS train 0.5858767648874703 valid 0.45705888104868364
LOSS train 0.5858767648874703 valid 0.4570655112287828
LOSS train 0.5858767648874703 valid 0.4571075463189488
LOSS train 0.5858767648874703 valid 0.4569742765865828
LOSS train 0.5858767648874703 valid 0.4571427736593329
LOSS train 0.5858767648874703 valid 0.4572926716044031
LOSS train 0.5858767648874703 valid 0.4571759682944697
LOSS train 0.5858767648874703 valid 0.4570670155650478
LOSS train 0.5858767648874703 valid 0.45699820874118
LOSS train 0.5858767648874703 valid 0.4570173047482967
LOSS train 0.5858767648874703 valid 0.4569434693529586
LOSS train 0.5858767648874703 valid 0.4568218227292671
LOSS train 0.5858767648874703 valid 0.4569193105387494
LOSS train 0.5858767648874703 valid 0.4571109265089035
LOSS train 0.5858767648874703 valid 0.4571006984710693
LOSS train 0.5858767648874703 valid 0.4570942466694211
LOSS train 0.5858767648874703 valid 0.45730764119643863
LOSS train 0.5858767648874703 valid 0.4575345159973949
LOSS train 0.5858767648874703 valid 0.4576420060885969
LOSS train 0.5858767648874703 valid 0.4575713833937278
LOSS train 0.5858767648874703 valid 0.4575968464367262
LOSS train 0.5858767648874703 valid 0.4575143126827298
LOSS train 0.5858767648874703 valid 0.457427148756228
LOSS train 0.5858767648874703 valid 0.45739426897532903
LOSS train 0.5858767648874703 valid 0.45741395199740376
LOSS train 0.5858767648874703 valid 0.4574659861185971
LOSS train 0.5858767648874703 valid 0.45737997110742723
LOSS train 0.5858767648874703 valid 0.4574004619017891
LOSS train 0.5858767648874703 valid 0.4572145355691155
LOSS train 0.5858767648874703 valid 0.45724526068993976
LOSS train 0.5858767648874703 valid 0.4573766887187958
LOSS train 0.5858767648874703 valid 0.4575419717691314
LOSS train 0.5858767648874703 valid 0.45750125450687806
LOSS train 0.5858767648874703 valid 0.45748300788303214
LOSS train 0.5858767648874703 valid 0.45740634922323553
LOSS train 0.5858767648874703 valid 0.4576339642070744
LOSS train 0.5858767648874703 valid 0.4573918380299393
LOSS train 0.5858767648874703 valid 0.457775965937086
LOSS train 0.5858767648874703 valid 0.4577231349161007
LOSS train 0.5858767648874703 valid 0.45770794510841367
LOSS train 0.5858767648874703 valid 0.45788136420660464
LOSS train 0.5858767648874703 valid 0.45785826111310407
LOSS train 0.5858767648874703 valid 0.45788318639487224
LOSS train 0.5858767648874703 valid 0.45793812209135526
LOSS train 0.5858767648874703 valid 0.45788548665661966
LOSS train 0.5858767648874703 valid 0.4580445123406557
LOSS train 0.5858767648874703 valid 0.45807305528859427
LOSS train 0.5858767648874703 valid 0.4580720889417431
LOSS train 0.5858767648874703 valid 0.4578598068570191
LOSS train 0.5858767648874703 valid 0.457956806384027
LOSS train 0.5858767648874703 valid 0.45798558570583414
LOSS train 0.5858767648874703 valid 0.4579283983251195
LOSS train 0.5858767648874703 valid 0.45782262397690054
LOSS train 0.5858767648874703 valid 0.45773119515762095
LOSS train 0.5858767648874703 valid 0.4576922266772299
LOSS train 0.5858767648874703 valid 0.45752788828798086
LOSS train 0.5858767648874703 valid 0.4576740755649384
LOSS train 0.5858767648874703 valid 0.4577056361096246
LOSS train 0.5858767648874703 valid 0.45766122242402746
LOSS train 0.5858767648874703 valid 0.45771366848665124
LOSS train 0.5858767648874703 valid 0.4578381163334986
LOSS train 0.5858767648874703 valid 0.4579614863492722
LOSS train 0.5858767648874703 valid 0.4580644679207333
LOSS train 0.5858767648874703 valid 0.45812319099217996
LOSS train 0.5858767648874703 valid 0.4581316420010158
LOSS train 0.5858767648874703 valid 0.4581699760800058
LOSS train 0.5858767648874703 valid 0.45818382063827945
LOSS train 0.5858767648874703 valid 0.45828007412760446
LOSS train 0.5858767648874703 valid 0.4582216641423423
LOSS train 0.5858767648874703 valid 0.45830903152624763
LOSS train 0.5858767648874703 valid 0.45827498883832224
LOSS train 0.5858767648874703 valid 0.4582720403815364
LOSS train 0.5858767648874703 valid 0.45830182511298384
LOSS train 0.5858767648874703 valid 0.4584386058799598
LOSS train 0.5858767648874703 valid 0.45833661540134535
LOSS train 0.5858767648874703 valid 0.4584289816438511
LOSS train 0.5858767648874703 valid 0.4586279916572061
LOSS train 0.5858767648874703 valid 0.4587306740119102
LOSS train 0.5858767648874703 valid 0.4586808900669138
LOSS train 0.5858767648874703 valid 0.45864787211543634
LOSS train 0.5858767648874703 valid 0.4587216180656593
LOSS train 0.5858767648874703 valid 0.45875820455451805
LOSS train 0.5858767648874703 valid 0.4587146673795473
LOSS train 0.5858767648874703 valid 0.45866531840304736
LOSS train 0.5858767648874703 valid 0.45861210823059084
LOSS train 0.5858767648874703 valid 0.4586716799103484
LOSS train 0.5858767648874703 valid 0.45869307000624954
LOSS train 0.5858767648874703 valid 0.4585755785005261
LOSS train 0.5858767648874703 valid 0.458644165765101
LOSS train 0.5858767648874703 valid 0.4586988818645477
LOSS train 0.5858767648874703 valid 0.45862272366955503
LOSS train 0.5858767648874703 valid 0.45866804695365454
LOSS train 0.5858767648874703 valid 0.4585965390275852
LOSS train 0.5858767648874703 valid 0.4585575505214579
LOSS train 0.5858767648874703 valid 0.4584870466371862
LOSS train 0.5858767648874703 valid 0.45853495105956366
LOSS train 0.5858767648874703 valid 0.4586869712901
LOSS train 0.5858767648874703 valid 0.458672412026387
LOSS train 0.5858767648874703 valid 0.45855361836378655
LOSS train 0.5858767648874703 valid 0.45847460272766294
LOSS train 0.5858767648874703 valid 0.4585563760798124
LOSS train 0.5858767648874703 valid 0.4585527773454504
LOSS train 0.5858767648874703 valid 0.4585036382149083
LOSS train 0.5858767648874703 valid 0.4585265430891625
LOSS train 0.5858767648874703 valid 0.45852499618086706
LOSS train 0.5858767648874703 valid 0.4586050731164438
LOSS train 0.5858767648874703 valid 0.45871470422239347
LOSS train 0.5858767648874703 valid 0.4587131577347397
LOSS train 0.5858767648874703 valid 0.4587078625208711
LOSS train 0.5858767648874703 valid 0.458686395666816
LOSS train 0.5858767648874703 valid 0.4587228397977838
LOSS train 0.5858767648874703 valid 0.4588420823350683
LOSS train 0.5858767648874703 valid 0.4589230597286481
LOSS train 0.5858767648874703 valid 0.4589106916849102
LOSS train 0.5858767648874703 valid 0.4587892056836022
LOSS train 0.5858767648874703 valid 0.458727876037623
LOSS train 0.5858767648874703 valid 0.45894383373239495
LOSS train 0.5858767648874703 valid 0.45910984107799696
LOSS train 0.5858767648874703 valid 0.45921411264411227
LOSS train 0.5858767648874703 valid 0.45921925695046134
LOSS train 0.5858767648874703 valid 0.4591038402540859
LOSS train 0.5858767648874703 valid 0.4591025255363563
LOSS train 0.5858767648874703 valid 0.45896290632788206
LOSS train 0.5858767648874703 valid 0.45891436781638706
LOSS train 0.5858767648874703 valid 0.4590351497873347
LOSS train 0.5858767648874703 valid 0.45908786066002766
LOSS train 0.5858767648874703 valid 0.45907657672081315
LOSS train 0.5858767648874703 valid 0.45903414575492635
LOSS train 0.5858767648874703 valid 0.45902309569853617
LOSS train 0.5858767648874703 valid 0.45896961477895576
LOSS train 0.5858767648874703 valid 0.4589612137727223
LOSS train 0.5858767648874703 valid 0.4589100033044815
LOSS train 0.5858767648874703 valid 0.45897411233113133
LOSS train 0.5858767648874703 valid 0.4590822715984016
LOSS train 0.5858767648874703 valid 0.45908804730493197
LOSS train 0.5858767648874703 valid 0.4590462173630552
LOSS train 0.5858767648874703 valid 0.45922655144683744
LOSS train 0.5858767648874703 valid 0.4590998874796975
LOSS train 0.5858767648874703 valid 0.45905660050939845
LOSS train 0.5858767648874703 valid 0.45915701961517336
LOSS train 0.5858767648874703 valid 0.4591590099600682
LOSS train 0.5858767648874703 valid 0.45920746501476045
LOSS train 0.5858767648874703 valid 0.45926274388675165
LOSS train 0.5858767648874703 valid 0.45933833870831436
LOSS train 0.5858767648874703 valid 0.45930464805341237
LOSS train 0.5858767648874703 valid 0.4593405550112948
LOSS train 0.5858767648874703 valid 0.45931786600253927
LOSS train 0.5858767648874703 valid 0.45932751108509623
LOSS train 0.5858767648874703 valid 0.4593828203135015
LOSS train 0.5858767648874703 valid 0.45939474220459275
LOSS train 0.5858767648874703 valid 0.4594372486931154
LOSS train 0.5858767648874703 valid 0.459375370322293
LOSS train 0.5858767648874703 valid 0.4594047310914377
LOSS train 0.5858767648874703 valid 0.45944348101814586
LOSS train 0.5858767648874703 valid 0.45944812489005754
LOSS train 0.5858767648874703 valid 0.4594948725368744
LOSS train 0.5858767648874703 valid 0.45958949418996603
LOSS train 0.5858767648874703 valid 0.4595392523194427
LOSS train 0.5858767648874703 valid 0.45973567792030956
LOSS train 0.5858767648874703 valid 0.45971429966114186
LOSS train 0.5858767648874703 valid 0.45977259287095157
LOSS train 0.5858767648874703 valid 0.45981078671620174
LOSS train 0.5858767648874703 valid 0.45986589276310286
LOSS train 0.5858767648874703 valid 0.45984563079193563
LOSS train 0.5858767648874703 valid 0.459876027432355
LOSS train 0.5858767648874703 valid 0.45991867597120395
LOSS train 0.5858767648874703 valid 0.45993424397943683
LOSS train 0.5858767648874703 valid 0.4599032644316447
LOSS train 0.5858767648874703 valid 0.46001472887599765
LOSS train 0.5858767648874703 valid 0.46003821726356237
LOSS train 0.5858767648874703 valid 0.4598936147961328
LOSS train 0.5858767648874703 valid 0.45981006429973226
LOSS train 0.5858767648874703 valid 0.459753098315148
LOSS train 0.5858767648874703 valid 0.4598138160269025
LOSS train 0.5858767648874703 valid 0.45980425142405323
LOSS train 0.5858767648874703 valid 0.4597468874254427
LOSS train 0.5858767648874703 valid 0.4597077698865419
LOSS train 0.5858767648874703 valid 0.45974482575224507
LOSS train 0.5858767648874703 valid 0.45967572968723863
LOSS train 0.5858767648874703 valid 0.45974063287521233
LOSS train 0.5858767648874703 valid 0.4596232807718192
LOSS train 0.5858767648874703 valid 0.4596901318594201
LOSS train 0.5858767648874703 valid 0.4596357670050025
LOSS train 0.5858767648874703 valid 0.45967418776482954
LOSS train 0.5858767648874703 valid 0.45978176098758894
LOSS train 0.5858767648874703 valid 0.45978770334575625
LOSS train 0.5858767648874703 valid 0.4597084838332552
LOSS train 0.5858767648874703 valid 0.45970491504909206
LOSS train 0.5858767648874703 valid 0.4597683003714252
LOSS train 0.5858767648874703 valid 0.45973229855298997
LOSS train 0.5858767648874703 valid 0.45974801802555987
LOSS train 0.5858767648874703 valid 0.4596623850381927
LOSS train 0.5858767648874703 valid 0.45968438345606966
LOSS train 0.5858767648874703 valid 0.4596590722273839
LOSS train 0.5858767648874703 valid 0.45963506376157043
LOSS train 0.5858767648874703 valid 0.4595435304579392
LOSS train 0.5858767648874703 valid 0.45961398138673765
LOSS train 0.5858767648874703 valid 0.45954528808980794
LOSS train 0.5858767648874703 valid 0.45956892971082025
LOSS train 0.5858767648874703 valid 0.4595526039600372
LOSS train 0.5858767648874703 valid 0.45952120289158593
LOSS train 0.5858767648874703 valid 0.45957233384251595
LOSS train 0.5858767648874703 valid 0.4596506822794771
LOSS train 0.5858767648874703 valid 0.45973173220446156
LOSS train 0.5858767648874703 valid 0.45974582102563644
LOSS train 0.5858767648874703 valid 0.4596047474047806
LOSS train 0.5858767648874703 valid 0.4596533142617824
LOSS train 0.5858767648874703 valid 0.4596165661354485
LOSS train 0.5858767648874703 valid 0.45967477111607136
LOSS train 0.5858767648874703 valid 0.4596045779064298
LOSS train 0.5858767648874703 valid 0.4596208264337522
LOSS train 0.5858767648874703 valid 0.4595953140014447
LOSS train 0.5858767648874703 valid 0.4595765688286477
LOSS train 0.5858767648874703 valid 0.4595991360184587
LOSS train 0.5858767648874703 valid 0.459576743382674
LOSS train 0.5858767648874703 valid 0.45962870651227566
LOSS train 0.5858767648874703 valid 0.4597078705781826
LOSS train 0.5858767648874703 valid 0.4598001942220258
LOSS train 0.5858767648874703 valid 0.45981774341009307
LOSS train 0.5858767648874703 valid 0.4597910490902987
LOSS train 0.5858767648874703 valid 0.4597644825716393
LOSS train 0.5858767648874703 valid 0.459667960563338
LOSS train 0.5858767648874703 valid 0.4596615326297176
LOSS train 0.5858767648874703 valid 0.4597542957809871
LOSS train 0.5858767648874703 valid 0.45969685867651183
LOSS train 0.5858767648874703 valid 0.4597291803608338
LOSS train 0.5858767648874703 valid 0.45971578306543365
LOSS train 0.5858767648874703 valid 0.4597394776767528
LOSS train 0.5858767648874703 valid 0.4597376362588202
LOSS train 0.5858767648874703 valid 0.45972551168764336
LOSS train 0.5858767648874703 valid 0.4596676865805629
LOSS train 0.5858767648874703 valid 0.459641822074589
LOSS train 0.5858767648874703 valid 0.45962983004900876
LOSS train 0.5858767648874703 valid 0.4597304866237696
LOSS train 0.5858767648874703 valid 0.4597169844136722
LOSS train 0.5858767648874703 valid 0.4597658686382922
LOSS train 0.5858767648874703 valid 0.4596899597548614
LOSS train 0.5858767648874703 valid 0.4597525157291314
LOSS train 0.5858767648874703 valid 0.45978358217160137
LOSS train 0.5858767648874703 valid 0.4597583953823362
LOSS train 0.5858767648874703 valid 0.4597067622377662
LOSS train 0.5858767648874703 valid 0.45973505393009295
LOSS train 0.5858767648874703 valid 0.4597057415642076
LOSS train 0.5858767648874703 valid 0.4597261532046701
LOSS train 0.5858767648874703 valid 0.45974674577444374
LOSS train 0.5858767648874703 valid 0.45978040089098254
LOSS train 0.5858767648874703 valid 0.45971075601938394
LOSS train 0.5858767648874703 valid 0.4596276060995443
LOSS train 0.5858767648874703 valid 0.4596195297320905
LOSS train 0.5858767648874703 valid 0.45960344473520914
LOSS train 0.5858767648874703 valid 0.4596724978279209
LOSS train 0.5858767648874703 valid 0.4597090600439198
LOSS train 0.5858767648874703 valid 0.4597206842308202
LOSS train 0.5858767648874703 valid 0.4596917670997944
LOSS train 0.5858767648874703 valid 0.45969978219842256
LOSS train 0.5858767648874703 valid 0.4596998492876689
LOSS train 0.5858767648874703 valid 0.4596172291836232
LOSS train 0.5858767648874703 valid 0.4596611434674781
LOSS train 0.5858767648874703 valid 0.4596431138231179
EPOCH 8:
  batch 1 loss: 0.5732053518295288
  batch 2 loss: 0.5639491081237793
  batch 3 loss: 0.5724430481592814
  batch 4 loss: 0.5811124444007874
  batch 5 loss: 0.5806204795837402
  batch 6 loss: 0.5813830693562826
  batch 7 loss: 0.5882379497800555
  batch 8 loss: 0.5863770544528961
  batch 9 loss: 0.5862748887803819
  batch 10 loss: 0.5869372725486756
  batch 11 loss: 0.5872295823964205
  batch 12 loss: 0.5885589867830276
  batch 13 loss: 0.5909056938611544
  batch 14 loss: 0.5923641920089722
  batch 15 loss: 0.596007212003072
  batch 16 loss: 0.5958693623542786
  batch 17 loss: 0.5951773699592141
  batch 18 loss: 0.5949384272098541
  batch 19 loss: 0.5952600460303458
  batch 20 loss: 0.5969306141138077
  batch 21 loss: 0.5964859042848859
  batch 22 loss: 0.5961183417927135
  batch 23 loss: 0.595756331215734
  batch 24 loss: 0.5948736146092415
  batch 25 loss: 0.5966011166572571
  batch 26 loss: 0.595141413120123
  batch 27 loss: 0.5949453137539051
  batch 28 loss: 0.5936469967876162
  batch 29 loss: 0.5940977519956129
  batch 30 loss: 0.5938036541144053
  batch 31 loss: 0.5940580887179221
  batch 32 loss: 0.593540832400322
  batch 33 loss: 0.5939040418827173
  batch 34 loss: 0.5931130735313191
  batch 35 loss: 0.5944836803844997
  batch 36 loss: 0.5946662028630575
  batch 37 loss: 0.5939541829598917
  batch 38 loss: 0.593654918043237
  batch 39 loss: 0.5935451434208796
  batch 40 loss: 0.5929017752408982
  batch 41 loss: 0.5928369033627394
  batch 42 loss: 0.5926336646080017
  batch 43 loss: 0.5928460525911908
  batch 44 loss: 0.5923257294026288
  batch 45 loss: 0.5924703545040555
  batch 46 loss: 0.5922691575858904
  batch 47 loss: 0.5925681083760364
  batch 48 loss: 0.5919216225544611
  batch 49 loss: 0.5911270939573949
  batch 50 loss: 0.5909679806232453
  batch 51 loss: 0.590471672076805
  batch 52 loss: 0.590656000834245
  batch 53 loss: 0.5907218433775991
  batch 54 loss: 0.5907256051346108
  batch 55 loss: 0.5905047449198636
  batch 56 loss: 0.5902746522000858
  batch 57 loss: 0.5898244914255644
  batch 58 loss: 0.5895491314345392
  batch 59 loss: 0.5890142806505753
  batch 60 loss: 0.588806493083636
  batch 61 loss: 0.5884403547302621
  batch 62 loss: 0.5887066145097056
  batch 63 loss: 0.588454112174019
  batch 64 loss: 0.5884179603308439
  batch 65 loss: 0.5880592089432937
  batch 66 loss: 0.588036880348668
  batch 67 loss: 0.5886136951731212
  batch 68 loss: 0.5889010403086158
  batch 69 loss: 0.588638709075209
  batch 70 loss: 0.5887296719210489
  batch 71 loss: 0.5888927377445597
  batch 72 loss: 0.5887258326013883
  batch 73 loss: 0.5887282409080087
  batch 74 loss: 0.5886581193756413
  batch 75 loss: 0.5887473837534587
  batch 76 loss: 0.5892023914738705
  batch 77 loss: 0.5889705195055379
  batch 78 loss: 0.5888032546410193
  batch 79 loss: 0.5893120599698417
  batch 80 loss: 0.5894006311893463
  batch 81 loss: 0.5893973244561089
  batch 82 loss: 0.5897662901296848
  batch 83 loss: 0.589882541851825
  batch 84 loss: 0.5899716225408372
  batch 85 loss: 0.5893059933886808
  batch 86 loss: 0.5897807056127593
  batch 87 loss: 0.5898742641525707
  batch 88 loss: 0.5896258835088123
  batch 89 loss: 0.5895566397838379
  batch 90 loss: 0.5892384509245555
  batch 91 loss: 0.5892602159426763
  batch 92 loss: 0.58901180067788
  batch 93 loss: 0.5893211409609805
  batch 94 loss: 0.5893956486214983
  batch 95 loss: 0.5894407554676658
  batch 96 loss: 0.5893009776870409
  batch 97 loss: 0.5889872048319
  batch 98 loss: 0.589217087443994
  batch 99 loss: 0.5892100418456877
  batch 100 loss: 0.5891179168224334
  batch 101 loss: 0.5890135434594485
  batch 102 loss: 0.5891060601262486
  batch 103 loss: 0.58910163803008
  batch 104 loss: 0.5890118410954108
  batch 105 loss: 0.5890944645518348
  batch 106 loss: 0.5889507712058302
  batch 107 loss: 0.5891649962585663
  batch 108 loss: 0.5890521445760021
  batch 109 loss: 0.5889299216620419
  batch 110 loss: 0.5892401846972379
  batch 111 loss: 0.5891929805815757
  batch 112 loss: 0.5890208445489407
  batch 113 loss: 0.5890846927609064
  batch 114 loss: 0.5893928607304891
  batch 115 loss: 0.5891281542570694
  batch 116 loss: 0.5892465577043337
  batch 117 loss: 0.5892459714514577
  batch 118 loss: 0.5893197322295884
  batch 119 loss: 0.5892579184860742
  batch 120 loss: 0.5891794184843699
  batch 121 loss: 0.5890988692764408
  batch 122 loss: 0.5889657007866218
  batch 123 loss: 0.5889591138537337
  batch 124 loss: 0.5891434593546775
  batch 125 loss: 0.5892399535179138
  batch 126 loss: 0.5889638988744645
  batch 127 loss: 0.5890265876852622
  batch 128 loss: 0.5888437489047647
  batch 129 loss: 0.588500786197278
  batch 130 loss: 0.588324341407189
  batch 131 loss: 0.5883652840861837
  batch 132 loss: 0.5882180129939859
  batch 133 loss: 0.5882621273062283
  batch 134 loss: 0.5882259976508012
  batch 135 loss: 0.5883709920777215
  batch 136 loss: 0.5884092086378265
  batch 137 loss: 0.5886194605896943
  batch 138 loss: 0.5885576722414597
  batch 139 loss: 0.5885676870243155
  batch 140 loss: 0.5884515992232732
  batch 141 loss: 0.5882841885512602
  batch 142 loss: 0.5881284605449354
  batch 143 loss: 0.5878868565692769
  batch 144 loss: 0.5878090411424637
  batch 145 loss: 0.5878528586749373
  batch 146 loss: 0.5878900069079988
  batch 147 loss: 0.5879813659758795
  batch 148 loss: 0.5878450620818783
  batch 149 loss: 0.5877047613163122
  batch 150 loss: 0.5877004857858023
  batch 151 loss: 0.5877529062972163
  batch 152 loss: 0.5878016756553399
  batch 153 loss: 0.5877083738644918
  batch 154 loss: 0.5876849235652329
  batch 155 loss: 0.5878181369073929
  batch 156 loss: 0.5878343761731417
  batch 157 loss: 0.5878289759538735
  batch 158 loss: 0.5877559083172038
  batch 159 loss: 0.587703620112917
  batch 160 loss: 0.5877310194075107
  batch 161 loss: 0.587815331005902
  batch 162 loss: 0.5877660969157278
  batch 163 loss: 0.5876823780726801
  batch 164 loss: 0.5875823276072014
  batch 165 loss: 0.5874746821143411
  batch 166 loss: 0.5874503053814532
  batch 167 loss: 0.5873214820187963
  batch 168 loss: 0.5874739530540648
  batch 169 loss: 0.5874321816940985
  batch 170 loss: 0.5877570478355183
  batch 171 loss: 0.5876931823485079
  batch 172 loss: 0.5876883767371954
  batch 173 loss: 0.587670886447664
  batch 174 loss: 0.5876997257101124
  batch 175 loss: 0.5876041974340166
  batch 176 loss: 0.5875721184367483
  batch 177 loss: 0.5872905170176662
  batch 178 loss: 0.5871007251605559
  batch 179 loss: 0.5870373838440666
  batch 180 loss: 0.5870686736371782
  batch 181 loss: 0.5871849903085614
  batch 182 loss: 0.5869979445750897
  batch 183 loss: 0.5871117727352622
  batch 184 loss: 0.5870258905317473
  batch 185 loss: 0.5871393661241273
  batch 186 loss: 0.5871441857789153
  batch 187 loss: 0.587071312940057
  batch 188 loss: 0.5869540965303461
  batch 189 loss: 0.5867524910225439
  batch 190 loss: 0.5866714546554967
  batch 191 loss: 0.5866071416445428
  batch 192 loss: 0.5866014696657658
  batch 193 loss: 0.5865275866009411
  batch 194 loss: 0.586520356615794
  batch 195 loss: 0.5864941010108361
  batch 196 loss: 0.5863837624082759
  batch 197 loss: 0.5863427513747046
  batch 198 loss: 0.5862517823474576
  batch 199 loss: 0.5863261432503936
  batch 200 loss: 0.5862158408761025
  batch 201 loss: 0.58626027694389
  batch 202 loss: 0.5861576990325852
  batch 203 loss: 0.586165599635082
  batch 204 loss: 0.5859973807545269
  batch 205 loss: 0.5860737489490975
  batch 206 loss: 0.5859895183623416
  batch 207 loss: 0.5859565720466025
  batch 208 loss: 0.5859082616292514
  batch 209 loss: 0.5857634550076353
  batch 210 loss: 0.5857315665199643
  batch 211 loss: 0.5857818567357357
  batch 212 loss: 0.5856816228830589
  batch 213 loss: 0.5857690544755246
  batch 214 loss: 0.5855820872516275
  batch 215 loss: 0.585463235267373
  batch 216 loss: 0.5854422645988288
  batch 217 loss: 0.5852996860781023
  batch 218 loss: 0.5852967946354403
  batch 219 loss: 0.5851081046339583
  batch 220 loss: 0.5850716089660472
  batch 221 loss: 0.5850504984683041
  batch 222 loss: 0.5851158754782634
  batch 223 loss: 0.5851722263434542
  batch 224 loss: 0.5851273871958256
  batch 225 loss: 0.5849856644206577
  batch 226 loss: 0.5850703001549814
  batch 227 loss: 0.5849004826356661
  batch 228 loss: 0.5848423033429865
  batch 229 loss: 0.5847916613499671
  batch 230 loss: 0.5847201546897058
  batch 231 loss: 0.5847618974648513
  batch 232 loss: 0.5847227416675667
  batch 233 loss: 0.5847051018297417
  batch 234 loss: 0.5846148734418755
  batch 235 loss: 0.5846290984052293
  batch 236 loss: 0.5845206783989728
  batch 237 loss: 0.5845114241672468
  batch 238 loss: 0.5844825658978534
  batch 239 loss: 0.5844552584273047
  batch 240 loss: 0.5844456094006697
  batch 241 loss: 0.5843609766841429
  batch 242 loss: 0.5842552970756184
  batch 243 loss: 0.5842942158871718
  batch 244 loss: 0.5842852226046266
  batch 245 loss: 0.5842211956880531
  batch 246 loss: 0.5843872461861711
  batch 247 loss: 0.5844844719658979
  batch 248 loss: 0.5844773940982357
  batch 249 loss: 0.5845189254925433
  batch 250 loss: 0.584481770992279
  batch 251 loss: 0.5844842397359263
  batch 252 loss: 0.5844720658801851
  batch 253 loss: 0.58438245298363
  batch 254 loss: 0.5843001238004429
  batch 255 loss: 0.5842311499165553
  batch 256 loss: 0.5842346318531781
  batch 257 loss: 0.5843053900778061
  batch 258 loss: 0.5842903827049936
  batch 259 loss: 0.5841818502510837
  batch 260 loss: 0.5840687194695839
  batch 261 loss: 0.5840777277489732
  batch 262 loss: 0.5841852981625623
  batch 263 loss: 0.5842164650616084
  batch 264 loss: 0.5840587062817632
  batch 265 loss: 0.5839723112448206
  batch 266 loss: 0.5840028728309431
  batch 267 loss: 0.5841251261225354
  batch 268 loss: 0.5840269538448818
  batch 269 loss: 0.5840596999820723
  batch 270 loss: 0.5839979920122359
  batch 271 loss: 0.5840018873285103
  batch 272 loss: 0.583992942729417
  batch 273 loss: 0.5839881399175623
  batch 274 loss: 0.5839933191772795
  batch 275 loss: 0.5840794845060868
  batch 276 loss: 0.5840557018915812
  batch 277 loss: 0.5839782757449237
  batch 278 loss: 0.5838978196219574
  batch 279 loss: 0.5839426551668447
  batch 280 loss: 0.5839654911841665
  batch 281 loss: 0.5838597945047019
  batch 282 loss: 0.5837791099193248
  batch 283 loss: 0.5836536734769706
  batch 284 loss: 0.5837653835474605
  batch 285 loss: 0.5837970206612035
  batch 286 loss: 0.5837397114797072
  batch 287 loss: 0.5836499499527004
  batch 288 loss: 0.5835461432321204
  batch 289 loss: 0.5835588341353262
  batch 290 loss: 0.583395738437258
  batch 291 loss: 0.5833507702522671
  batch 292 loss: 0.5834596359158215
  batch 293 loss: 0.5834601377057541
  batch 294 loss: 0.583410075327166
  batch 295 loss: 0.5834254268872536
  batch 296 loss: 0.583444711525698
  batch 297 loss: 0.5834635624580512
  batch 298 loss: 0.5834392809227809
  batch 299 loss: 0.5834831920355857
  batch 300 loss: 0.5835919859011968
  batch 301 loss: 0.5835301519628379
  batch 302 loss: 0.583508385135638
  batch 303 loss: 0.5835136287283189
  batch 304 loss: 0.5835002082351007
  batch 305 loss: 0.5833751023792829
  batch 306 loss: 0.5833530634446861
  batch 307 loss: 0.58333470359299
  batch 308 loss: 0.5833731167889261
  batch 309 loss: 0.5832814587744308
  batch 310 loss: 0.5833045594153866
  batch 311 loss: 0.5833668825710702
  batch 312 loss: 0.5833200562076691
  batch 313 loss: 0.5833429816051032
  batch 314 loss: 0.5832977680264005
  batch 315 loss: 0.5832351909743415
  batch 316 loss: 0.5831607412311095
  batch 317 loss: 0.5832580739767393
  batch 318 loss: 0.5831626254432606
  batch 319 loss: 0.5831494531287669
  batch 320 loss: 0.5831423407420516
  batch 321 loss: 0.5830078906730699
  batch 322 loss: 0.5830482435152398
  batch 323 loss: 0.5830138072878953
  batch 324 loss: 0.5829696912824371
  batch 325 loss: 0.5829577820117657
  batch 326 loss: 0.5829280720897979
  batch 327 loss: 0.5828625536110787
  batch 328 loss: 0.5827892922410151
  batch 329 loss: 0.5828055096252349
  batch 330 loss: 0.5827850379727103
  batch 331 loss: 0.5827580036713638
  batch 332 loss: 0.5827899440584412
  batch 333 loss: 0.5828079180316524
  batch 334 loss: 0.58274309524519
  batch 335 loss: 0.5826268767243001
  batch 336 loss: 0.5825569578224704
  batch 337 loss: 0.5824799827722839
  batch 338 loss: 0.5825396762091732
  batch 339 loss: 0.5826139437765498
  batch 340 loss: 0.5826733043965171
  batch 341 loss: 0.5826459055072751
  batch 342 loss: 0.5825932501700887
  batch 343 loss: 0.5826505130651046
  batch 344 loss: 0.5826210975646973
  batch 345 loss: 0.5827012986376665
  batch 346 loss: 0.5825870304093884
  batch 347 loss: 0.5825670002516821
  batch 348 loss: 0.5826335328406301
  batch 349 loss: 0.5825819004230991
  batch 350 loss: 0.5825649041788918
  batch 351 loss: 0.5826203651577658
  batch 352 loss: 0.582610593770038
  batch 353 loss: 0.5826445823012938
  batch 354 loss: 0.5826738661965408
  batch 355 loss: 0.5827702154575939
  batch 356 loss: 0.5827123497644168
  batch 357 loss: 0.5826424926268954
  batch 358 loss: 0.5826708526251703
  batch 359 loss: 0.5826994720275688
  batch 360 loss: 0.5827942945890956
  batch 361 loss: 0.5827530997281589
  batch 362 loss: 0.5827258219376453
  batch 363 loss: 0.5827076057428827
  batch 364 loss: 0.5827039195286049
  batch 365 loss: 0.5826857547237448
  batch 366 loss: 0.5827539599006945
  batch 367 loss: 0.5826094759582499
  batch 368 loss: 0.5825766146830891
  batch 369 loss: 0.5826356212298075
  batch 370 loss: 0.5826645437124613
  batch 371 loss: 0.5827103082060493
  batch 372 loss: 0.582673317001712
  batch 373 loss: 0.582674755487621
  batch 374 loss: 0.5826172347374778
  batch 375 loss: 0.582611473719279
  batch 376 loss: 0.5827133227536019
  batch 377 loss: 0.582630100870006
  batch 378 loss: 0.5825472527710849
  batch 379 loss: 0.5825185609052552
  batch 380 loss: 0.5825479752139041
  batch 381 loss: 0.5824320356989783
  batch 382 loss: 0.5823649349012924
  batch 383 loss: 0.582359116942702
  batch 384 loss: 0.5823470936156809
  batch 385 loss: 0.5824708927761425
  batch 386 loss: 0.5824206460634044
  batch 387 loss: 0.5824466138231046
  batch 388 loss: 0.5824563858128086
  batch 389 loss: 0.582524764353941
  batch 390 loss: 0.5825554123291603
  batch 391 loss: 0.5825688637735899
  batch 392 loss: 0.5825713815129533
  batch 393 loss: 0.5826859443848976
  batch 394 loss: 0.5827678885254158
  batch 395 loss: 0.5827888523476034
  batch 396 loss: 0.5828542786114144
  batch 397 loss: 0.582867173013519
  batch 398 loss: 0.5828368617362113
  batch 399 loss: 0.5828739026734105
  batch 400 loss: 0.5828190870583058
  batch 401 loss: 0.582755447474501
  batch 402 loss: 0.5827647671474153
  batch 403 loss: 0.582792842950182
  batch 404 loss: 0.5827588418332657
  batch 405 loss: 0.5827048613701338
  batch 406 loss: 0.582704908742106
  batch 407 loss: 0.5827647946976326
  batch 408 loss: 0.5828835226449312
  batch 409 loss: 0.5828650995979682
  batch 410 loss: 0.582813603267437
  batch 411 loss: 0.5827955475978898
  batch 412 loss: 0.5827926009604074
  batch 413 loss: 0.582760011312748
  batch 414 loss: 0.5827780363064458
  batch 415 loss: 0.5827850277165333
  batch 416 loss: 0.5827795887509217
  batch 417 loss: 0.5827429857757166
  batch 418 loss: 0.5827496714854354
  batch 419 loss: 0.5828171140538764
  batch 420 loss: 0.5829008819091888
  batch 421 loss: 0.5828744712464883
  batch 422 loss: 0.5829124274129551
  batch 423 loss: 0.5829099008095744
  batch 424 loss: 0.5828308295809997
  batch 425 loss: 0.5828849740589366
  batch 426 loss: 0.582879727575141
  batch 427 loss: 0.5828711708758977
  batch 428 loss: 0.5828527269240852
  batch 429 loss: 0.582866015412035
  batch 430 loss: 0.5828649897908056
  batch 431 loss: 0.5828613201869336
  batch 432 loss: 0.582855961802933
  batch 433 loss: 0.5828289284992438
  batch 434 loss: 0.5828570782588923
  batch 435 loss: 0.5828362395023478
  batch 436 loss: 0.5828365524974438
  batch 437 loss: 0.5829210843319751
  batch 438 loss: 0.5830271674073451
  batch 439 loss: 0.5830124083032369
  batch 440 loss: 0.5829842934554273
  batch 441 loss: 0.5829511984946236
  batch 442 loss: 0.5828878043463867
  batch 443 loss: 0.5828800233707471
  batch 444 loss: 0.5828580708654078
  batch 445 loss: 0.5828032117211417
  batch 446 loss: 0.5827783382259677
  batch 447 loss: 0.5826907131229204
  batch 448 loss: 0.5827230036790881
  batch 449 loss: 0.582742134818521
  batch 450 loss: 0.5827684111065334
  batch 451 loss: 0.5827602502247711
  batch 452 loss: 0.582695753832834
  batch 453 loss: 0.5826386483036656
  batch 454 loss: 0.5826457489429592
  batch 455 loss: 0.582692497248178
  batch 456 loss: 0.5827002389389172
  batch 457 loss: 0.5827524335953026
  batch 458 loss: 0.5827459862138507
  batch 459 loss: 0.5827381239477586
  batch 460 loss: 0.5827982771655787
  batch 461 loss: 0.582802798510115
  batch 462 loss: 0.5828134989067589
  batch 463 loss: 0.582843280894195
  batch 464 loss: 0.5828701924404194
  batch 465 loss: 0.5828045947577364
  batch 466 loss: 0.5827740962924876
  batch 467 loss: 0.5827718571115612
  batch 468 loss: 0.582728419930507
  batch 469 loss: 0.5827155655889369
  batch 470 loss: 0.5826984855722874
  batch 471 loss: 0.582708025813862
  batch 472 loss: 0.5826967390159429
LOSS train 0.5826967390159429 valid 0.4780104160308838
LOSS train 0.5826967390159429 valid 0.47747525572776794
LOSS train 0.5826967390159429 valid 0.47571160395940143
LOSS train 0.5826967390159429 valid 0.4721992611885071
LOSS train 0.5826967390159429 valid 0.4676302492618561
LOSS train 0.5826967390159429 valid 0.4724411616722743
LOSS train 0.5826967390159429 valid 0.4758055678435734
LOSS train 0.5826967390159429 valid 0.47679073736071587
LOSS train 0.5826967390159429 valid 0.4755026400089264
LOSS train 0.5826967390159429 valid 0.47758247554302213
LOSS train 0.5826967390159429 valid 0.47954161871563306
LOSS train 0.5826967390159429 valid 0.47997917234897614
LOSS train 0.5826967390159429 valid 0.4825675441668584
LOSS train 0.5826967390159429 valid 0.4839022031852177
LOSS train 0.5826967390159429 valid 0.48366026480992635
LOSS train 0.5826967390159429 valid 0.48295219242572784
LOSS train 0.5826967390159429 valid 0.4840771100100349
LOSS train 0.5826967390159429 valid 0.4838264402416017
LOSS train 0.5826967390159429 valid 0.4822425450149335
LOSS train 0.5826967390159429 valid 0.4834274634718895
LOSS train 0.5826967390159429 valid 0.4833722866716839
LOSS train 0.5826967390159429 valid 0.4814717783169313
LOSS train 0.5826967390159429 valid 0.4817605990430583
LOSS train 0.5826967390159429 valid 0.4812638498842716
LOSS train 0.5826967390159429 valid 0.4812579035758972
LOSS train 0.5826967390159429 valid 0.4808124005794525
LOSS train 0.5826967390159429 valid 0.4812801491331171
LOSS train 0.5826967390159429 valid 0.48157443425485064
LOSS train 0.5826967390159429 valid 0.48077016041196624
LOSS train 0.5826967390159429 valid 0.48152273893356323
LOSS train 0.5826967390159429 valid 0.4829027402785517
LOSS train 0.5826967390159429 valid 0.4826568774878979
LOSS train 0.5826967390159429 valid 0.4833448258313266
LOSS train 0.5826967390159429 valid 0.48392611742019653
LOSS train 0.5826967390159429 valid 0.48490675006593975
LOSS train 0.5826967390159429 valid 0.48457277400626075
LOSS train 0.5826967390159429 valid 0.4844887651301719
LOSS train 0.5826967390159429 valid 0.48414216778780284
LOSS train 0.5826967390159429 valid 0.4838846157758664
LOSS train 0.5826967390159429 valid 0.48437143862247467
LOSS train 0.5826967390159429 valid 0.48471374628020497
LOSS train 0.5826967390159429 valid 0.4843484035560063
LOSS train 0.5826967390159429 valid 0.4836113882619281
LOSS train 0.5826967390159429 valid 0.4832648208195513
LOSS train 0.5826967390159429 valid 0.48313400944074
LOSS train 0.5826967390159429 valid 0.48358883352383325
LOSS train 0.5826967390159429 valid 0.4838348715863329
LOSS train 0.5826967390159429 valid 0.484094404305021
LOSS train 0.5826967390159429 valid 0.4843543019829964
LOSS train 0.5826967390159429 valid 0.48393754243850706
LOSS train 0.5826967390159429 valid 0.48461150655559465
LOSS train 0.5826967390159429 valid 0.4843625735778075
LOSS train 0.5826967390159429 valid 0.4842322030157413
LOSS train 0.5826967390159429 valid 0.48407441488018743
LOSS train 0.5826967390159429 valid 0.48383766412734985
LOSS train 0.5826967390159429 valid 0.48364383088690893
LOSS train 0.5826967390159429 valid 0.4830580615160758
LOSS train 0.5826967390159429 valid 0.48298297360025605
LOSS train 0.5826967390159429 valid 0.4834024037344981
LOSS train 0.5826967390159429 valid 0.483011919260025
LOSS train 0.5826967390159429 valid 0.4822137424203216
LOSS train 0.5826967390159429 valid 0.48204126761805627
LOSS train 0.5826967390159429 valid 0.48227354647621273
LOSS train 0.5826967390159429 valid 0.4828545544296503
LOSS train 0.5826967390159429 valid 0.48302043676376344
LOSS train 0.5826967390159429 valid 0.4828666304097031
LOSS train 0.5826967390159429 valid 0.4828577228446505
LOSS train 0.5826967390159429 valid 0.48284168629085317
LOSS train 0.5826967390159429 valid 0.4826050271158633
LOSS train 0.5826967390159429 valid 0.4822302426610674
LOSS train 0.5826967390159429 valid 0.481813907623291
LOSS train 0.5826967390159429 valid 0.4816948158873452
LOSS train 0.5826967390159429 valid 0.48167658056298346
LOSS train 0.5826967390159429 valid 0.48121476213674286
LOSS train 0.5826967390159429 valid 0.48112395564715066
LOSS train 0.5826967390159429 valid 0.48103772495922287
LOSS train 0.5826967390159429 valid 0.48099468280742697
LOSS train 0.5826967390159429 valid 0.4811018155171321
LOSS train 0.5826967390159429 valid 0.480833788461323
LOSS train 0.5826967390159429 valid 0.48049322217702867
LOSS train 0.5826967390159429 valid 0.4802955653932359
LOSS train 0.5826967390159429 valid 0.48033440767264945
LOSS train 0.5826967390159429 valid 0.4802317166902933
LOSS train 0.5826967390159429 valid 0.4803233160859063
LOSS train 0.5826967390159429 valid 0.4802394235835356
LOSS train 0.5826967390159429 valid 0.47999881797058636
LOSS train 0.5826967390159429 valid 0.4800302043728445
LOSS train 0.5826967390159429 valid 0.4799123806032268
LOSS train 0.5826967390159429 valid 0.48009482796272535
LOSS train 0.5826967390159429 valid 0.4800927413834466
LOSS train 0.5826967390159429 valid 0.48016598427688684
LOSS train 0.5826967390159429 valid 0.4801239283836406
LOSS train 0.5826967390159429 valid 0.4799447174995176
LOSS train 0.5826967390159429 valid 0.47972589097124463
LOSS train 0.5826967390159429 valid 0.4795875762638293
LOSS train 0.5826967390159429 valid 0.479533967251579
LOSS train 0.5826967390159429 valid 0.47967796749675395
LOSS train 0.5826967390159429 valid 0.4794469378432449
LOSS train 0.5826967390159429 valid 0.47964438434803125
LOSS train 0.5826967390159429 valid 0.47968724817037584
LOSS train 0.5826967390159429 valid 0.47971901946728773
LOSS train 0.5826967390159429 valid 0.47984201913955166
LOSS train 0.5826967390159429 valid 0.4801088742260794
LOSS train 0.5826967390159429 valid 0.48014937742398334
LOSS train 0.5826967390159429 valid 0.4801006419318063
LOSS train 0.5826967390159429 valid 0.48010342582216803
LOSS train 0.5826967390159429 valid 0.47999430872569576
LOSS train 0.5826967390159429 valid 0.4800562196307712
LOSS train 0.5826967390159429 valid 0.4801434989369244
LOSS train 0.5826967390159429 valid 0.48025678287852896
LOSS train 0.5826967390159429 valid 0.4802547712046821
LOSS train 0.5826967390159429 valid 0.4804766255297831
LOSS train 0.5826967390159429 valid 0.4806007397385825
LOSS train 0.5826967390159429 valid 0.4805231779290919
LOSS train 0.5826967390159429 valid 0.4806224382441977
LOSS train 0.5826967390159429 valid 0.4806913314708348
LOSS train 0.5826967390159429 valid 0.48053215991737497
LOSS train 0.5826967390159429 valid 0.4805117231809487
LOSS train 0.5826967390159429 valid 0.48043809743488536
LOSS train 0.5826967390159429 valid 0.48042793373266857
LOSS train 0.5826967390159429 valid 0.4803153212405433
LOSS train 0.5826967390159429 valid 0.48008103155698933
LOSS train 0.5826967390159429 valid 0.4802173911555996
LOSS train 0.5826967390159429 valid 0.48049155190106363
LOSS train 0.5826967390159429 valid 0.48053161454200743
LOSS train 0.5826967390159429 valid 0.48047174229508355
LOSS train 0.5826967390159429 valid 0.4805776821816061
LOSS train 0.5826967390159429 valid 0.4807614202145487
LOSS train 0.5826967390159429 valid 0.48088621377020846
LOSS train 0.5826967390159429 valid 0.48074450011436753
LOSS train 0.5826967390159429 valid 0.4807442151408159
LOSS train 0.5826967390159429 valid 0.48066291822628543
LOSS train 0.5826967390159429 valid 0.4805567589469422
LOSS train 0.5826967390159429 valid 0.48053891645438634
LOSS train 0.5826967390159429 valid 0.4806124499550572
LOSS train 0.5826967390159429 valid 0.4806452912881094
LOSS train 0.5826967390159429 valid 0.4805744642758892
LOSS train 0.5826967390159429 valid 0.48061966982440674
LOSS train 0.5826967390159429 valid 0.48054638526422516
LOSS train 0.5826967390159429 valid 0.480487459897995
LOSS train 0.5826967390159429 valid 0.4806371483396977
LOSS train 0.5826967390159429 valid 0.4808204232806891
LOSS train 0.5826967390159429 valid 0.48067073888712
LOSS train 0.5826967390159429 valid 0.48071106688843834
LOSS train 0.5826967390159429 valid 0.4805208025307491
LOSS train 0.5826967390159429 valid 0.4808127925004045
LOSS train 0.5826967390159429 valid 0.4805914344025307
LOSS train 0.5826967390159429 valid 0.4809606117573944
LOSS train 0.5826967390159429 valid 0.48092852762881544
LOSS train 0.5826967390159429 valid 0.48093692282835643
LOSS train 0.5826967390159429 valid 0.4810334625623084
LOSS train 0.5826967390159429 valid 0.48096082026236936
LOSS train 0.5826967390159429 valid 0.4809322984390009
LOSS train 0.5826967390159429 valid 0.48097812703677584
LOSS train 0.5826967390159429 valid 0.4810156403049346
LOSS train 0.5826967390159429 valid 0.4812786078605896
LOSS train 0.5826967390159429 valid 0.48130778218530545
LOSS train 0.5826967390159429 valid 0.4812752672388584
LOSS train 0.5826967390159429 valid 0.4810174216264449
LOSS train 0.5826967390159429 valid 0.4811050256714225
LOSS train 0.5826967390159429 valid 0.48119327203827617
LOSS train 0.5826967390159429 valid 0.48110630243648717
LOSS train 0.5826967390159429 valid 0.4809811438885203
LOSS train 0.5826967390159429 valid 0.48084358852810977
LOSS train 0.5826967390159429 valid 0.4806965865872123
LOSS train 0.5826967390159429 valid 0.48052407262555086
LOSS train 0.5826967390159429 valid 0.4806876280707513
LOSS train 0.5826967390159429 valid 0.4808242723700546
LOSS train 0.5826967390159429 valid 0.48079000386966053
LOSS train 0.5826967390159429 valid 0.4809254369314979
LOSS train 0.5826967390159429 valid 0.4811273035947342
LOSS train 0.5826967390159429 valid 0.48124991010787876
LOSS train 0.5826967390159429 valid 0.48134115527820037
LOSS train 0.5826967390159429 valid 0.4813734546475027
LOSS train 0.5826967390159429 valid 0.48149286951337544
LOSS train 0.5826967390159429 valid 0.48160450702363794
LOSS train 0.5826967390159429 valid 0.48160884760867406
LOSS train 0.5826967390159429 valid 0.4817548114597128
LOSS train 0.5826967390159429 valid 0.48176377662067305
LOSS train 0.5826967390159429 valid 0.4818034286300341
LOSS train 0.5826967390159429 valid 0.4817621535029859
LOSS train 0.5826967390159429 valid 0.4817764272729119
LOSS train 0.5826967390159429 valid 0.4818391869954073
LOSS train 0.5826967390159429 valid 0.48193862532144005
LOSS train 0.5826967390159429 valid 0.4818145645631326
LOSS train 0.5826967390159429 valid 0.48195885233981633
LOSS train 0.5826967390159429 valid 0.48209721901837516
LOSS train 0.5826967390159429 valid 0.48216579474033194
LOSS train 0.5826967390159429 valid 0.482091521775281
LOSS train 0.5826967390159429 valid 0.48204640448093417
LOSS train 0.5826967390159429 valid 0.4822734261994587
LOSS train 0.5826967390159429 valid 0.4823930615869661
LOSS train 0.5826967390159429 valid 0.48233643066080123
LOSS train 0.5826967390159429 valid 0.4822780035205723
LOSS train 0.5826967390159429 valid 0.4821806556139237
LOSS train 0.5826967390159429 valid 0.48223736243588583
LOSS train 0.5826967390159429 valid 0.48234618527029977
LOSS train 0.5826967390159429 valid 0.48219335455485063
LOSS train 0.5826967390159429 valid 0.48224969036016035
LOSS train 0.5826967390159429 valid 0.48235843271017076
LOSS train 0.5826967390159429 valid 0.4822164649394021
LOSS train 0.5826967390159429 valid 0.48223139847269153
LOSS train 0.5826967390159429 valid 0.48214708598963735
LOSS train 0.5826967390159429 valid 0.48212449486349146
LOSS train 0.5826967390159429 valid 0.4820649808499871
LOSS train 0.5826967390159429 valid 0.4821857663902264
LOSS train 0.5826967390159429 valid 0.4822819749802207
LOSS train 0.5826967390159429 valid 0.4821757644128341
LOSS train 0.5826967390159429 valid 0.4820271885851354
LOSS train 0.5826967390159429 valid 0.48190913455826895
LOSS train 0.5826967390159429 valid 0.48199737354477434
LOSS train 0.5826967390159429 valid 0.48194420618830985
LOSS train 0.5826967390159429 valid 0.4819123353196981
LOSS train 0.5826967390159429 valid 0.48192039633465705
LOSS train 0.5826967390159429 valid 0.4818851245004077
LOSS train 0.5826967390159429 valid 0.4818808960693854
LOSS train 0.5826967390159429 valid 0.4820493503649663
LOSS train 0.5826967390159429 valid 0.48210567946827737
LOSS train 0.5826967390159429 valid 0.4820732145004621
LOSS train 0.5826967390159429 valid 0.4820227400823073
LOSS train 0.5826967390159429 valid 0.48207864070909595
LOSS train 0.5826967390159429 valid 0.48220063276119063
LOSS train 0.5826967390159429 valid 0.48226327305417427
LOSS train 0.5826967390159429 valid 0.48227592850370066
LOSS train 0.5826967390159429 valid 0.48219168371624416
LOSS train 0.5826967390159429 valid 0.48205720138760794
LOSS train 0.5826967390159429 valid 0.4822244355331959
LOSS train 0.5826967390159429 valid 0.4823309337360817
LOSS train 0.5826967390159429 valid 0.48239232450072944
LOSS train 0.5826967390159429 valid 0.48241287327331045
LOSS train 0.5826967390159429 valid 0.48227345337083327
LOSS train 0.5826967390159429 valid 0.4823075295265379
LOSS train 0.5826967390159429 valid 0.48212205762515253
LOSS train 0.5826967390159429 valid 0.4820565169947779
LOSS train 0.5826967390159429 valid 0.4821496982523735
LOSS train 0.5826967390159429 valid 0.4821347747061212
LOSS train 0.5826967390159429 valid 0.4821234833339096
LOSS train 0.5826967390159429 valid 0.48206902364221943
LOSS train 0.5826967390159429 valid 0.4820985900058906
LOSS train 0.5826967390159429 valid 0.4820495559523503
LOSS train 0.5826967390159429 valid 0.48207909820980055
LOSS train 0.5826967390159429 valid 0.4820211258801547
LOSS train 0.5826967390159429 valid 0.48205816549528774
LOSS train 0.5826967390159429 valid 0.482158544366477
LOSS train 0.5826967390159429 valid 0.4821618564274846
LOSS train 0.5826967390159429 valid 0.482048065197177
LOSS train 0.5826967390159429 valid 0.4822215662311446
LOSS train 0.5826967390159429 valid 0.4821257711418213
LOSS train 0.5826967390159429 valid 0.4820590185592452
LOSS train 0.5826967390159429 valid 0.48216916382312774
LOSS train 0.5826967390159429 valid 0.482203942489814
LOSS train 0.5826967390159429 valid 0.48226493656162234
LOSS train 0.5826967390159429 valid 0.4823034100617345
LOSS train 0.5826967390159429 valid 0.4823609598743634
LOSS train 0.5826967390159429 valid 0.4823032146575404
LOSS train 0.5826967390159429 valid 0.4823167995782569
LOSS train 0.5826967390159429 valid 0.48233366430037683
LOSS train 0.5826967390159429 valid 0.4823256925094959
LOSS train 0.5826967390159429 valid 0.4824001731559577
LOSS train 0.5826967390159429 valid 0.48242289813665246
LOSS train 0.5826967390159429 valid 0.48250404057374857
LOSS train 0.5826967390159429 valid 0.48247837485702894
LOSS train 0.5826967390159429 valid 0.48250361699115185
LOSS train 0.5826967390159429 valid 0.4825212142684243
LOSS train 0.5826967390159429 valid 0.4825611617205278
LOSS train 0.5826967390159429 valid 0.4826258834367408
LOSS train 0.5826967390159429 valid 0.48270114028498473
LOSS train 0.5826967390159429 valid 0.4826411936265319
LOSS train 0.5826967390159429 valid 0.48276447607238937
LOSS train 0.5826967390159429 valid 0.4827418147413819
LOSS train 0.5826967390159429 valid 0.482773701973067
LOSS train 0.5826967390159429 valid 0.4828067436156904
LOSS train 0.5826967390159429 valid 0.48285514487451686
LOSS train 0.5826967390159429 valid 0.48279605240282353
LOSS train 0.5826967390159429 valid 0.4828128442981026
LOSS train 0.5826967390159429 valid 0.4828663827932399
LOSS train 0.5826967390159429 valid 0.48286840728474006
LOSS train 0.5826967390159429 valid 0.48280760270657297
LOSS train 0.5826967390159429 valid 0.4829122243602643
LOSS train 0.5826967390159429 valid 0.48293362408876417
LOSS train 0.5826967390159429 valid 0.482781204676713
LOSS train 0.5826967390159429 valid 0.4826990120799829
LOSS train 0.5826967390159429 valid 0.48262161922117847
LOSS train 0.5826967390159429 valid 0.4826706931204863
LOSS train 0.5826967390159429 valid 0.4827097364684992
LOSS train 0.5826967390159429 valid 0.4826081808838811
LOSS train 0.5826967390159429 valid 0.48258551352946183
LOSS train 0.5826967390159429 valid 0.4826187796683775
LOSS train 0.5826967390159429 valid 0.4825686960896819
LOSS train 0.5826967390159429 valid 0.48256869932700847
LOSS train 0.5826967390159429 valid 0.4824492103865057
LOSS train 0.5826967390159429 valid 0.48248814464840173
LOSS train 0.5826967390159429 valid 0.4824156735740831
LOSS train 0.5826967390159429 valid 0.4824419537571823
LOSS train 0.5826967390159429 valid 0.48257698255070186
LOSS train 0.5826967390159429 valid 0.4826196676774605
LOSS train 0.5826967390159429 valid 0.4825540548221832
LOSS train 0.5826967390159429 valid 0.4825587518663214
LOSS train 0.5826967390159429 valid 0.48264232666596124
LOSS train 0.5826967390159429 valid 0.48262474914391834
LOSS train 0.5826967390159429 valid 0.4827127114086848
LOSS train 0.5826967390159429 valid 0.4826100391662673
LOSS train 0.5826967390159429 valid 0.4826953877316843
LOSS train 0.5826967390159429 valid 0.48266268688205044
LOSS train 0.5826967390159429 valid 0.4826193468492539
LOSS train 0.5826967390159429 valid 0.4825744877258937
LOSS train 0.5826967390159429 valid 0.48260159843907685
LOSS train 0.5826967390159429 valid 0.4825438147821984
LOSS train 0.5826967390159429 valid 0.48256494128974126
LOSS train 0.5826967390159429 valid 0.48252543009096577
LOSS train 0.5826967390159429 valid 0.48250793960316773
LOSS train 0.5826967390159429 valid 0.4825449006106609
LOSS train 0.5826967390159429 valid 0.4826344374460153
LOSS train 0.5826967390159429 valid 0.4827433107954681
LOSS train 0.5826967390159429 valid 0.48277811502653456
LOSS train 0.5826967390159429 valid 0.48266082577690295
LOSS train 0.5826967390159429 valid 0.4827213993395917
LOSS train 0.5826967390159429 valid 0.48269889330339133
LOSS train 0.5826967390159429 valid 0.4827865761088727
LOSS train 0.5826967390159429 valid 0.48272384209558367
LOSS train 0.5826967390159429 valid 0.48278514349200646
LOSS train 0.5826967390159429 valid 0.48274637666178044
LOSS train 0.5826967390159429 valid 0.48270563306085096
LOSS train 0.5826967390159429 valid 0.48274176549396397
LOSS train 0.5826967390159429 valid 0.4827073552975288
LOSS train 0.5826967390159429 valid 0.48276029947710913
LOSS train 0.5826967390159429 valid 0.4828247437965615
LOSS train 0.5826967390159429 valid 0.4829361356067948
LOSS train 0.5826967390159429 valid 0.4829629492071262
LOSS train 0.5826967390159429 valid 0.4829513829765898
LOSS train 0.5826967390159429 valid 0.48290596780820194
LOSS train 0.5826967390159429 valid 0.4828171471515334
LOSS train 0.5826967390159429 valid 0.48281022020288417
LOSS train 0.5826967390159429 valid 0.4828280758358047
LOSS train 0.5826967390159429 valid 0.48277480762396285
LOSS train 0.5826967390159429 valid 0.48283136636018753
LOSS train 0.5826967390159429 valid 0.4827973117460483
LOSS train 0.5826967390159429 valid 0.48284084706969516
LOSS train 0.5826967390159429 valid 0.48285138703728847
LOSS train 0.5826967390159429 valid 0.4828312492545913
LOSS train 0.5826967390159429 valid 0.4827816532678968
LOSS train 0.5826967390159429 valid 0.48274203934516124
LOSS train 0.5826967390159429 valid 0.4827470232898223
LOSS train 0.5826967390159429 valid 0.48285567873092583
LOSS train 0.5826967390159429 valid 0.4828291253767152
LOSS train 0.5826967390159429 valid 0.48288438740493245
LOSS train 0.5826967390159429 valid 0.48279494614010243
LOSS train 0.5826967390159429 valid 0.4828919377820245
LOSS train 0.5826967390159429 valid 0.48289989724883375
LOSS train 0.5826967390159429 valid 0.48289384961128234
LOSS train 0.5826967390159429 valid 0.48284858482176085
LOSS train 0.5826967390159429 valid 0.4828491346402602
LOSS train 0.5826967390159429 valid 0.4828793333880287
LOSS train 0.5826967390159429 valid 0.4828975198969329
LOSS train 0.5826967390159429 valid 0.4829647937291105
LOSS train 0.5826967390159429 valid 0.48300961865467973
LOSS train 0.5826967390159429 valid 0.4829541997415345
LOSS train 0.5826967390159429 valid 0.48285769966727526
LOSS train 0.5826967390159429 valid 0.48287389363086985
LOSS train 0.5826967390159429 valid 0.4828799596263303
LOSS train 0.5826967390159429 valid 0.4829556497015121
LOSS train 0.5826967390159429 valid 0.4830108750097001
LOSS train 0.5826967390159429 valid 0.48303987311594415
LOSS train 0.5826967390159429 valid 0.48303343732278425
LOSS train 0.5826967390159429 valid 0.4830772130456689
LOSS train 0.5826967390159429 valid 0.48306877096819745
LOSS train 0.5826967390159429 valid 0.4830186978510355
LOSS train 0.5826967390159429 valid 0.48303395145289274
LOSS train 0.5826967390159429 valid 0.48302139143956707
EPOCH 9:
  batch 1 loss: 0.5588910579681396
  batch 2 loss: 0.5569113492965698
  batch 3 loss: 0.5666010975837708
  batch 4 loss: 0.5779178738594055
  batch 5 loss: 0.5757952928543091
  batch 6 loss: 0.574944535891215
  batch 7 loss: 0.5825371146202087
  batch 8 loss: 0.5845327004790306
  batch 9 loss: 0.584580679734548
  batch 10 loss: 0.5822854995727539
  batch 11 loss: 0.5829309766942804
  batch 12 loss: 0.5843647221724192
  batch 13 loss: 0.5855916921909039
  batch 14 loss: 0.5877620577812195
  batch 15 loss: 0.5906991124153137
  batch 16 loss: 0.5906760357320309
  batch 17 loss: 0.5907365259002236
  batch 18 loss: 0.5904897683196597
  batch 19 loss: 0.5907340206597981
  batch 20 loss: 0.5918891817331314
  batch 21 loss: 0.5920173497427077
  batch 22 loss: 0.5916754413734783
  batch 23 loss: 0.5909497556479081
  batch 24 loss: 0.5907361383239428
  batch 25 loss: 0.592730700969696
  batch 26 loss: 0.5912756874011114
  batch 27 loss: 0.5917282457704898
  batch 28 loss: 0.5899770983627864
  batch 29 loss: 0.5901402214477802
  batch 30 loss: 0.5890295128027598
  batch 31 loss: 0.5888945960229443
  batch 32 loss: 0.5883277412503958
  batch 33 loss: 0.5883137981096903
  batch 34 loss: 0.5879346640671
  batch 35 loss: 0.5890032223292759
  batch 36 loss: 0.5886939929591285
  batch 37 loss: 0.5881825975469641
  batch 38 loss: 0.5878686026522988
  batch 39 loss: 0.5876651238172482
  batch 40 loss: 0.5866486519575119
  batch 41 loss: 0.5864862610654134
  batch 42 loss: 0.5864955115885961
  batch 43 loss: 0.5866534252499425
  batch 44 loss: 0.5861005904999647
  batch 45 loss: 0.5861427929666307
  batch 46 loss: 0.585905812356783
  batch 47 loss: 0.5864216254112569
  batch 48 loss: 0.5857615508139133
  batch 49 loss: 0.5846877548159385
  batch 50 loss: 0.5847901713848114
  batch 51 loss: 0.5841189903371474
  batch 52 loss: 0.5845576776907995
  batch 53 loss: 0.5847260007318461
  batch 54 loss: 0.5845510650564123
  batch 55 loss: 0.5843450546264648
  batch 56 loss: 0.584241339138576
  batch 57 loss: 0.5839733544148897
  batch 58 loss: 0.5838503436795597
  batch 59 loss: 0.5834798166307352
  batch 60 loss: 0.5833796362082163
  batch 61 loss: 0.5832105982499044
  batch 62 loss: 0.5832868497217855
  batch 63 loss: 0.5831604959472777
  batch 64 loss: 0.5831323582679033
  batch 65 loss: 0.5826453850819514
  batch 66 loss: 0.5826595642349937
  batch 67 loss: 0.5831009754494055
  batch 68 loss: 0.5834418184616986
  batch 69 loss: 0.5831969034844551
  batch 70 loss: 0.5835677853652409
  batch 71 loss: 0.5836061533068267
  batch 72 loss: 0.5833424205581347
  batch 73 loss: 0.5833556317303279
  batch 74 loss: 0.583412238874951
  batch 75 loss: 0.5835104894638061
  batch 76 loss: 0.583842250077348
  batch 77 loss: 0.5834505705090313
  batch 78 loss: 0.5828742132737086
  batch 79 loss: 0.5833402577834793
  batch 80 loss: 0.5834809809923172
  batch 81 loss: 0.5836773566257807
  batch 82 loss: 0.5841951806370805
  batch 83 loss: 0.5842386182532253
  batch 84 loss: 0.5842860823585874
  batch 85 loss: 0.5836431461222031
  batch 86 loss: 0.5840632277865743
  batch 87 loss: 0.5842095599777397
  batch 88 loss: 0.5841201042587106
  batch 89 loss: 0.5841081303157164
  batch 90 loss: 0.5839914017253451
  batch 91 loss: 0.5843887997197581
  batch 92 loss: 0.584455580815025
  batch 93 loss: 0.5846485213566852
  batch 94 loss: 0.5847274223540692
  batch 95 loss: 0.584905553491492
  batch 96 loss: 0.5849026013165712
  batch 97 loss: 0.5846988140922231
  batch 98 loss: 0.5849156477013413
  batch 99 loss: 0.5849180089102851
  batch 100 loss: 0.5850026178359985
  batch 101 loss: 0.5848329220667924
  batch 102 loss: 0.5847849401773191
  batch 103 loss: 0.5847643631175884
  batch 104 loss: 0.5847788252509557
  batch 105 loss: 0.5849905871209644
  batch 106 loss: 0.5848685131882722
  batch 107 loss: 0.5847858430069184
  batch 108 loss: 0.5845367384177668
  batch 109 loss: 0.5844271593137619
  batch 110 loss: 0.5847593876448545
  batch 111 loss: 0.5848028794065252
  batch 112 loss: 0.5846220909484795
  batch 113 loss: 0.5845858670968925
  batch 114 loss: 0.5848795755913383
  batch 115 loss: 0.5846526762713556
  batch 116 loss: 0.5848981517142263
  batch 117 loss: 0.5848549395544916
  batch 118 loss: 0.5848104696152574
  batch 119 loss: 0.5847502481035826
  batch 120 loss: 0.5846135521928469
  batch 121 loss: 0.5844086467727156
  batch 122 loss: 0.5842219488542588
  batch 123 loss: 0.5841409244188448
  batch 124 loss: 0.5844282214680026
  batch 125 loss: 0.5844223275184631
  batch 126 loss: 0.584236188540383
  batch 127 loss: 0.5843595482233003
  batch 128 loss: 0.5840458893217146
  batch 129 loss: 0.5836173083431037
  batch 130 loss: 0.5834518056649428
  batch 131 loss: 0.5833172129310724
  batch 132 loss: 0.583230249357946
  batch 133 loss: 0.5833504652618465
  batch 134 loss: 0.5832931519444309
  batch 135 loss: 0.5834096047613356
  batch 136 loss: 0.5833481458180091
  batch 137 loss: 0.5835087564739868
  batch 138 loss: 0.5835882878821829
  batch 139 loss: 0.5836057006883965
  batch 140 loss: 0.5834849659885679
  batch 141 loss: 0.5833915738349266
  batch 142 loss: 0.583212415517216
  batch 143 loss: 0.5830270472940031
  batch 144 loss: 0.5829691444006231
  batch 145 loss: 0.5830382269004296
  batch 146 loss: 0.5830363369967839
  batch 147 loss: 0.5830204831499631
  batch 148 loss: 0.5830033860496573
  batch 149 loss: 0.5829544287399958
  batch 150 loss: 0.5828852383295695
  batch 151 loss: 0.5830084788088767
  batch 152 loss: 0.5830480672026935
  batch 153 loss: 0.5829482736930348
  batch 154 loss: 0.5829389633296372
  batch 155 loss: 0.5830234185341866
  batch 156 loss: 0.5830470640689899
  batch 157 loss: 0.5831341162608688
  batch 158 loss: 0.5830489242378669
  batch 159 loss: 0.5830562028495021
  batch 160 loss: 0.5830494131892919
  batch 161 loss: 0.5832260680494842
  batch 162 loss: 0.5831251530735581
  batch 163 loss: 0.5831109413340048
  batch 164 loss: 0.5830738340936056
  batch 165 loss: 0.5830095435633804
  batch 166 loss: 0.583063881440335
  batch 167 loss: 0.5829829580769568
  batch 168 loss: 0.58318442070768
  batch 169 loss: 0.5830720567844323
  batch 170 loss: 0.5833130854017594
  batch 171 loss: 0.5832361087464449
  batch 172 loss: 0.5830708121837571
  batch 173 loss: 0.5830490440991573
  batch 174 loss: 0.5831264212898825
  batch 175 loss: 0.5830693353925432
  batch 176 loss: 0.5829644006761637
  batch 177 loss: 0.582716986621167
  batch 178 loss: 0.5825587584731284
  batch 179 loss: 0.5824384153222238
  batch 180 loss: 0.5823953916629155
  batch 181 loss: 0.5824707789315703
  batch 182 loss: 0.5823238311888097
  batch 183 loss: 0.5824468233546273
  batch 184 loss: 0.5822429870781691
  batch 185 loss: 0.5823155425690316
  batch 186 loss: 0.5822237515321342
  batch 187 loss: 0.5821654331237874
  batch 188 loss: 0.5820077797199817
  batch 189 loss: 0.581855162741646
  batch 190 loss: 0.581803971529007
  batch 191 loss: 0.5818143499459272
  batch 192 loss: 0.5818551601842046
  batch 193 loss: 0.5817399380120589
  batch 194 loss: 0.581768351731841
  batch 195 loss: 0.5816919271762554
  batch 196 loss: 0.5816155720730217
  batch 197 loss: 0.5815306696189841
  batch 198 loss: 0.5815115558980691
  batch 199 loss: 0.5817261925294771
  batch 200 loss: 0.5817747828364372
  batch 201 loss: 0.5819443043191634
  batch 202 loss: 0.5819083210265282
  batch 203 loss: 0.5819671500492566
  batch 204 loss: 0.5818376319081175
  batch 205 loss: 0.581933587353404
  batch 206 loss: 0.581797827216028
  batch 207 loss: 0.5817715568818908
  batch 208 loss: 0.5816834460084255
  batch 209 loss: 0.5815861048310568
  batch 210 loss: 0.5816456916786376
  batch 211 loss: 0.5816737831486345
  batch 212 loss: 0.5815905284769131
  batch 213 loss: 0.581722659124455
  batch 214 loss: 0.5815392949870813
  batch 215 loss: 0.581445943200311
  batch 216 loss: 0.5813637759398531
  batch 217 loss: 0.5811970319066729
  batch 218 loss: 0.5812188952887823
  batch 219 loss: 0.5810786499280364
  batch 220 loss: 0.5810788054357875
  batch 221 loss: 0.5810241704612835
  batch 222 loss: 0.5811767376757957
  batch 223 loss: 0.5811871995840372
  batch 224 loss: 0.5811675888087068
  batch 225 loss: 0.5810347578260634
  batch 226 loss: 0.581042743625894
  batch 227 loss: 0.5809082247087084
  batch 228 loss: 0.5808579338747158
  batch 229 loss: 0.5808756507640322
  batch 230 loss: 0.5808883915776791
  batch 231 loss: 0.5809854449647845
  batch 232 loss: 0.5808969566534306
  batch 233 loss: 0.5808477800803123
  batch 234 loss: 0.5807668704252976
  batch 235 loss: 0.5807969899887734
  batch 236 loss: 0.5806515085495124
  batch 237 loss: 0.5806662905568312
  batch 238 loss: 0.5805512769382541
  batch 239 loss: 0.580604050199357
  batch 240 loss: 0.5805628463625908
  batch 241 loss: 0.5805068179284884
  batch 242 loss: 0.5804680871569421
  batch 243 loss: 0.5804365108042587
  batch 244 loss: 0.580566547200328
  batch 245 loss: 0.5805364119763277
  batch 246 loss: 0.580730498079362
  batch 247 loss: 0.580771835468076
  batch 248 loss: 0.5807608990899978
  batch 249 loss: 0.5808405227450482
  batch 250 loss: 0.5808498954772949
  batch 251 loss: 0.5808704979866149
  batch 252 loss: 0.580901538095777
  batch 253 loss: 0.5807971252283088
  batch 254 loss: 0.5807440180008806
  batch 255 loss: 0.5806914091110229
  batch 256 loss: 0.5806750603951514
  batch 257 loss: 0.5807723790291218
  batch 258 loss: 0.5807287833949392
  batch 259 loss: 0.5806268702142487
  batch 260 loss: 0.5805397533453428
  batch 261 loss: 0.5804993905326873
  batch 262 loss: 0.5805630811298167
  batch 263 loss: 0.5805606443165826
  batch 264 loss: 0.5804088456612645
  batch 265 loss: 0.5803434446172894
  batch 266 loss: 0.5803377119670237
  batch 267 loss: 0.5804559253574757
  batch 268 loss: 0.5803215892902062
  batch 269 loss: 0.580315740356658
  batch 270 loss: 0.5802582990240168
  batch 271 loss: 0.5803126063733963
  batch 272 loss: 0.5803712290876052
  batch 273 loss: 0.5803912843103374
  batch 274 loss: 0.58042399269821
  batch 275 loss: 0.5805270296877081
  batch 276 loss: 0.5805814199257588
  batch 277 loss: 0.5804990289013309
  batch 278 loss: 0.5805101973547352
  batch 279 loss: 0.5805263504332538
  batch 280 loss: 0.5805616125464439
  batch 281 loss: 0.5804867290517189
  batch 282 loss: 0.5804071354527846
  batch 283 loss: 0.5802660927755673
  batch 284 loss: 0.5803163891107264
  batch 285 loss: 0.5804027666125381
  batch 286 loss: 0.5804038164498923
  batch 287 loss: 0.5803715412209673
  batch 288 loss: 0.5802551845295562
  batch 289 loss: 0.5802940400413988
  batch 290 loss: 0.5801221343977698
  batch 291 loss: 0.5800846743419817
  batch 292 loss: 0.5801737392193651
  batch 293 loss: 0.5801651146224741
  batch 294 loss: 0.5801474109393399
  batch 295 loss: 0.5800955236968347
  batch 296 loss: 0.5800447647233267
  batch 297 loss: 0.580041690105541
  batch 298 loss: 0.5800410741127577
  batch 299 loss: 0.5800867961800616
  batch 300 loss: 0.5801825634638469
  batch 301 loss: 0.5801518913915387
  batch 302 loss: 0.5800526633562632
  batch 303 loss: 0.5800411268429394
  batch 304 loss: 0.5799511092665949
  batch 305 loss: 0.5797555595147805
  batch 306 loss: 0.5797286150502223
  batch 307 loss: 0.5797106487743241
  batch 308 loss: 0.5797202126546339
  batch 309 loss: 0.579646015630185
  batch 310 loss: 0.5796651001899473
  batch 311 loss: 0.5798010118904604
  batch 312 loss: 0.5798019810746877
  batch 313 loss: 0.5797867032285696
  batch 314 loss: 0.5796775692587446
  batch 315 loss: 0.579632526352292
  batch 316 loss: 0.5795789389293405
  batch 317 loss: 0.5796161117237825
  batch 318 loss: 0.5794885662741631
  batch 319 loss: 0.5794944936952621
  batch 320 loss: 0.579458512738347
  batch 321 loss: 0.5793463654607256
  batch 322 loss: 0.5794073189637676
  batch 323 loss: 0.579398463754093
  batch 324 loss: 0.5793578582413402
  batch 325 loss: 0.5793924452708318
  batch 326 loss: 0.5793661621450646
  batch 327 loss: 0.5793097416559855
  batch 328 loss: 0.5792254543885952
  batch 329 loss: 0.5792289994045594
  batch 330 loss: 0.5792942240382686
  batch 331 loss: 0.5792905702691784
  batch 332 loss: 0.5792982005570309
  batch 333 loss: 0.5792884692415461
  batch 334 loss: 0.5792478783401901
  batch 335 loss: 0.5791491168648449
  batch 336 loss: 0.5791089777790365
  batch 337 loss: 0.5790411759201073
  batch 338 loss: 0.5790631227944729
  batch 339 loss: 0.5791002956815173
  batch 340 loss: 0.5791533149340573
  batch 341 loss: 0.579117601393255
  batch 342 loss: 0.5791028413856238
  batch 343 loss: 0.5791154536839477
  batch 344 loss: 0.5791050999663597
  batch 345 loss: 0.5792335192362468
  batch 346 loss: 0.579128676067198
  batch 347 loss: 0.5791165096959051
  batch 348 loss: 0.5791737339619932
  batch 349 loss: 0.5791140806709114
  batch 350 loss: 0.57914640886443
  batch 351 loss: 0.5791929418544823
  batch 352 loss: 0.5791762462732467
  batch 353 loss: 0.5791722840020069
  batch 354 loss: 0.57925676457626
  batch 355 loss: 0.5792889596710742
  batch 356 loss: 0.5792500755090392
  batch 357 loss: 0.5791581286435702
  batch 358 loss: 0.5791927268052234
  batch 359 loss: 0.57922101967182
  batch 360 loss: 0.5792553125156297
  batch 361 loss: 0.5791644465560067
  batch 362 loss: 0.5791894625563648
  batch 363 loss: 0.5791864303189532
  batch 364 loss: 0.5791777560671607
  batch 365 loss: 0.5790953378154807
  batch 366 loss: 0.579131812182932
  batch 367 loss: 0.5790209854656084
  batch 368 loss: 0.5789863842984905
  batch 369 loss: 0.5790576760361834
  batch 370 loss: 0.5791166173445211
  batch 371 loss: 0.5791347704807703
  batch 372 loss: 0.5791174231037017
  batch 373 loss: 0.5790970085773007
  batch 374 loss: 0.579070154358359
  batch 375 loss: 0.5790719725290934
  batch 376 loss: 0.5791403446742829
  batch 377 loss: 0.5791110162393484
  batch 378 loss: 0.5790109326915135
  batch 379 loss: 0.5790134515800074
  batch 380 loss: 0.5790299846937782
  batch 381 loss: 0.5789137102487519
  batch 382 loss: 0.5788820153443601
  batch 383 loss: 0.5789188882700769
  batch 384 loss: 0.5788741442374885
  batch 385 loss: 0.5790068860177869
  batch 386 loss: 0.5789370441066168
  batch 387 loss: 0.5790082151575606
  batch 388 loss: 0.5790385889638331
  batch 389 loss: 0.5790519766452074
  batch 390 loss: 0.5790940752396216
  batch 391 loss: 0.5791121474312394
  batch 392 loss: 0.5790664818213911
  batch 393 loss: 0.5791324516592439
  batch 394 loss: 0.5791717967406143
  batch 395 loss: 0.5791613909262645
  batch 396 loss: 0.5791628920670712
  batch 397 loss: 0.5791779134976173
  batch 398 loss: 0.5791226433749175
  batch 399 loss: 0.5792023033127749
  batch 400 loss: 0.5791019481420517
  batch 401 loss: 0.5790651721550045
  batch 402 loss: 0.5790864656220621
  batch 403 loss: 0.579075951138442
  batch 404 loss: 0.5790470761827903
  batch 405 loss: 0.5789967816552998
  batch 406 loss: 0.5790551629266129
  batch 407 loss: 0.5790197505119099
  batch 408 loss: 0.5790836743864358
  batch 409 loss: 0.5790392926969272
  batch 410 loss: 0.5789916428124032
  batch 411 loss: 0.5789704305412126
  batch 412 loss: 0.5789645450207793
  batch 413 loss: 0.578919328153855
  batch 414 loss: 0.5789409746294436
  batch 415 loss: 0.5789633368871299
  batch 416 loss: 0.5789237972348928
  batch 417 loss: 0.5788882986532984
  batch 418 loss: 0.5789068048935758
  batch 419 loss: 0.5789790570309168
  batch 420 loss: 0.5790436714887619
  batch 421 loss: 0.5790095792247111
  batch 422 loss: 0.5790166946666501
  batch 423 loss: 0.5790327318171238
  batch 424 loss: 0.578959013071825
  batch 425 loss: 0.5790405364597545
  batch 426 loss: 0.5790147393801962
  batch 427 loss: 0.5790109492018295
  batch 428 loss: 0.5789601541011133
  batch 429 loss: 0.578987021824141
  batch 430 loss: 0.5790110061335009
  batch 431 loss: 0.5790317411212523
  batch 432 loss: 0.5790104465904059
  batch 433 loss: 0.578998335239243
  batch 434 loss: 0.5790549213161117
  batch 435 loss: 0.5790600827370567
  batch 436 loss: 0.5790450760257353
  batch 437 loss: 0.5791919827461243
  batch 438 loss: 0.5793121708854693
  batch 439 loss: 0.5792919415004704
  batch 440 loss: 0.5792799428105354
  batch 441 loss: 0.5792638697321453
  batch 442 loss: 0.5791913390968719
  batch 443 loss: 0.5792390779501697
  batch 444 loss: 0.5792549762639914
  batch 445 loss: 0.5792293813791168
  batch 446 loss: 0.5792466490258016
  batch 447 loss: 0.5791770965194275
  batch 448 loss: 0.5792031459776419
  batch 449 loss: 0.5792126305119232
  batch 450 loss: 0.5792225980758667
  batch 451 loss: 0.5792454816814008
  batch 452 loss: 0.5791959174438915
  batch 453 loss: 0.5791899628986587
  batch 454 loss: 0.579241753543526
  batch 455 loss: 0.5793173024942587
  batch 456 loss: 0.5793824325266638
  batch 457 loss: 0.5793988039509211
  batch 458 loss: 0.5794125298225203
  batch 459 loss: 0.5794416811471411
  batch 460 loss: 0.5795021650583848
  batch 461 loss: 0.5795084442337268
  batch 462 loss: 0.5795278738845479
  batch 463 loss: 0.5795838401590516
  batch 464 loss: 0.5796405599805815
  batch 465 loss: 0.5795877363092156
  batch 466 loss: 0.5795825919368236
  batch 467 loss: 0.579590554921479
  batch 468 loss: 0.5795453279955775
  batch 469 loss: 0.5795759577740992
  batch 470 loss: 0.579547866861871
  batch 471 loss: 0.5795375316259461
  batch 472 loss: 0.5795185727588201
LOSS train 0.5795185727588201 valid 0.4469072222709656
LOSS train 0.5795185727588201 valid 0.4431343972682953
LOSS train 0.5795185727588201 valid 0.4384787877400716
LOSS train 0.5795185727588201 valid 0.43582437187433243
LOSS train 0.5795185727588201 valid 0.4310602366924286
LOSS train 0.5795185727588201 valid 0.434733306368192
LOSS train 0.5795185727588201 valid 0.43818097029413494
LOSS train 0.5795185727588201 valid 0.437127023935318
LOSS train 0.5795185727588201 valid 0.4370090630319383
LOSS train 0.5795185727588201 valid 0.438593253493309
LOSS train 0.5795185727588201 valid 0.44172896580262616
LOSS train 0.5795185727588201 valid 0.44145789990822476
LOSS train 0.5795185727588201 valid 0.44284753386790937
LOSS train 0.5795185727588201 valid 0.44387216014521463
LOSS train 0.5795185727588201 valid 0.44413878321647643
LOSS train 0.5795185727588201 valid 0.44318034313619137
LOSS train 0.5795185727588201 valid 0.444091120186974
LOSS train 0.5795185727588201 valid 0.4441881328821182
LOSS train 0.5795185727588201 valid 0.44274186303741053
LOSS train 0.5795185727588201 valid 0.44341080337762834
LOSS train 0.5795185727588201 valid 0.44414077628226506
LOSS train 0.5795185727588201 valid 0.4423121525482698
LOSS train 0.5795185727588201 valid 0.4421702610409778
LOSS train 0.5795185727588201 valid 0.44187474623322487
LOSS train 0.5795185727588201 valid 0.4414937651157379
LOSS train 0.5795185727588201 valid 0.4406704283677615
LOSS train 0.5795185727588201 valid 0.4411635818304839
LOSS train 0.5795185727588201 valid 0.44115933988775524
LOSS train 0.5795185727588201 valid 0.4405685252156751
LOSS train 0.5795185727588201 valid 0.44136503835519153
LOSS train 0.5795185727588201 valid 0.4423370649737696
LOSS train 0.5795185727588201 valid 0.4423304349184036
LOSS train 0.5795185727588201 valid 0.44293804240949225
LOSS train 0.5795185727588201 valid 0.4437990188598633
LOSS train 0.5795185727588201 valid 0.44459734984806604
LOSS train 0.5795185727588201 valid 0.4446806526846356
LOSS train 0.5795185727588201 valid 0.444994965115109
LOSS train 0.5795185727588201 valid 0.444866900381289
LOSS train 0.5795185727588201 valid 0.4445367806997055
LOSS train 0.5795185727588201 valid 0.44476978927850724
LOSS train 0.5795185727588201 valid 0.44512567723669655
LOSS train 0.5795185727588201 valid 0.44497557623045786
LOSS train 0.5795185727588201 valid 0.44439979763918147
LOSS train 0.5795185727588201 valid 0.4442279054359956
LOSS train 0.5795185727588201 valid 0.4441467457347446
LOSS train 0.5795185727588201 valid 0.44454002056432806
LOSS train 0.5795185727588201 valid 0.4445971066647388
LOSS train 0.5795185727588201 valid 0.4447623162219922
LOSS train 0.5795185727588201 valid 0.4450440449374063
LOSS train 0.5795185727588201 valid 0.4442362481355667
LOSS train 0.5795185727588201 valid 0.44486334919929504
LOSS train 0.5795185727588201 valid 0.44466297271159977
LOSS train 0.5795185727588201 valid 0.4444036208233743
LOSS train 0.5795185727588201 valid 0.4441529374431681
LOSS train 0.5795185727588201 valid 0.44406803141940726
LOSS train 0.5795185727588201 valid 0.44379176092999323
LOSS train 0.5795185727588201 valid 0.44330418005324246
LOSS train 0.5795185727588201 valid 0.4431613601487258
LOSS train 0.5795185727588201 valid 0.44356076798196564
LOSS train 0.5795185727588201 valid 0.44341361820697783
LOSS train 0.5795185727588201 valid 0.44266474833253955
LOSS train 0.5795185727588201 valid 0.4424876243837418
LOSS train 0.5795185727588201 valid 0.4425028548354194
LOSS train 0.5795185727588201 valid 0.442960939835757
LOSS train 0.5795185727588201 valid 0.4430295380262228
LOSS train 0.5795185727588201 valid 0.4429326183868177
LOSS train 0.5795185727588201 valid 0.44293439032426524
LOSS train 0.5795185727588201 valid 0.4430431053042412
LOSS train 0.5795185727588201 valid 0.4429680584133535
LOSS train 0.5795185727588201 valid 0.4428107917308807
LOSS train 0.5795185727588201 valid 0.44254902550871944
LOSS train 0.5795185727588201 valid 0.44232623361878926
LOSS train 0.5795185727588201 valid 0.4424658621827217
LOSS train 0.5795185727588201 valid 0.44198949433661794
LOSS train 0.5795185727588201 valid 0.441855434179306
LOSS train 0.5795185727588201 valid 0.442051852612119
LOSS train 0.5795185727588201 valid 0.44210790504108777
LOSS train 0.5795185727588201 valid 0.44215083771791214
LOSS train 0.5795185727588201 valid 0.4418655856500698
LOSS train 0.5795185727588201 valid 0.44168395549058914
LOSS train 0.5795185727588201 valid 0.4415599722185253
LOSS train 0.5795185727588201 valid 0.44152778059971043
LOSS train 0.5795185727588201 valid 0.4414058090692543
LOSS train 0.5795185727588201 valid 0.4415040754136585
LOSS train 0.5795185727588201 valid 0.4412885378388798
LOSS train 0.5795185727588201 valid 0.44114930338637776
LOSS train 0.5795185727588201 valid 0.44125929200786285
LOSS train 0.5795185727588201 valid 0.44107048315080727
LOSS train 0.5795185727588201 valid 0.4412831687525417
LOSS train 0.5795185727588201 valid 0.44137517544958327
LOSS train 0.5795185727588201 valid 0.44144092483834907
LOSS train 0.5795185727588201 valid 0.44130366068819293
LOSS train 0.5795185727588201 valid 0.4411430012795233
LOSS train 0.5795185727588201 valid 0.44094295260754035
LOSS train 0.5795185727588201 valid 0.4408024091469614
LOSS train 0.5795185727588201 valid 0.4405983239412308
LOSS train 0.5795185727588201 valid 0.4408633211224349
LOSS train 0.5795185727588201 valid 0.44069755503109526
LOSS train 0.5795185727588201 valid 0.4409467764575072
LOSS train 0.5795185727588201 valid 0.44103011906147005
LOSS train 0.5795185727588201 valid 0.44105633916241105
LOSS train 0.5795185727588201 valid 0.4410814622453615
LOSS train 0.5795185727588201 valid 0.441362774487838
LOSS train 0.5795185727588201 valid 0.4413519063248084
LOSS train 0.5795185727588201 valid 0.4413725634415944
LOSS train 0.5795185727588201 valid 0.44151887072707124
LOSS train 0.5795185727588201 valid 0.4415102163764918
LOSS train 0.5795185727588201 valid 0.4416426933474011
LOSS train 0.5795185727588201 valid 0.44190879863336546
LOSS train 0.5795185727588201 valid 0.44212291105227036
LOSS train 0.5795185727588201 valid 0.4421368139284151
LOSS train 0.5795185727588201 valid 0.44228887584592613
LOSS train 0.5795185727588201 valid 0.4423783730089137
LOSS train 0.5795185727588201 valid 0.44217633338351
LOSS train 0.5795185727588201 valid 0.4422888299693232
LOSS train 0.5795185727588201 valid 0.44245732729804926
LOSS train 0.5795185727588201 valid 0.4423539495875693
LOSS train 0.5795185727588201 valid 0.44236668287697484
LOSS train 0.5795185727588201 valid 0.442384766430414
LOSS train 0.5795185727588201 valid 0.4423724701007207
LOSS train 0.5795185727588201 valid 0.44228460916802903
LOSS train 0.5795185727588201 valid 0.44210712074256336
LOSS train 0.5795185727588201 valid 0.44218597276424004
LOSS train 0.5795185727588201 valid 0.44248193959074633
LOSS train 0.5795185727588201 valid 0.4425114998817444
LOSS train 0.5795185727588201 valid 0.44237455299922396
LOSS train 0.5795185727588201 valid 0.44245626771543906
LOSS train 0.5795185727588201 valid 0.44272615830413997
LOSS train 0.5795185727588201 valid 0.44280766586000603
LOSS train 0.5795185727588201 valid 0.4425925892132979
LOSS train 0.5795185727588201 valid 0.44261043649593385
LOSS train 0.5795185727588201 valid 0.4424634158159747
LOSS train 0.5795185727588201 valid 0.44229506213862196
LOSS train 0.5795185727588201 valid 0.44227067636909767
LOSS train 0.5795185727588201 valid 0.44240970986860767
LOSS train 0.5795185727588201 valid 0.442358816809514
LOSS train 0.5795185727588201 valid 0.4422908586307164
LOSS train 0.5795185727588201 valid 0.4423204688490301
LOSS train 0.5795185727588201 valid 0.4421605302704324
LOSS train 0.5795185727588201 valid 0.44215689556939264
LOSS train 0.5795185727588201 valid 0.4423655704826328
LOSS train 0.5795185727588201 valid 0.4424875193918255
LOSS train 0.5795185727588201 valid 0.44241695262335395
LOSS train 0.5795185727588201 valid 0.44252814414600533
LOSS train 0.5795185727588201 valid 0.4424238227564713
LOSS train 0.5795185727588201 valid 0.44273918071021773
LOSS train 0.5795185727588201 valid 0.4425160446945502
LOSS train 0.5795185727588201 valid 0.4428723913592261
LOSS train 0.5795185727588201 valid 0.4428186560637199
LOSS train 0.5795185727588201 valid 0.44284659445285796
LOSS train 0.5795185727588201 valid 0.4429437370095032
LOSS train 0.5795185727588201 valid 0.4428973731241728
LOSS train 0.5795185727588201 valid 0.4428091208919201
LOSS train 0.5795185727588201 valid 0.44290929916617156
LOSS train 0.5795185727588201 valid 0.4428051383264603
LOSS train 0.5795185727588201 valid 0.4429763200191351
LOSS train 0.5795185727588201 valid 0.4430103298205479
LOSS train 0.5795185727588201 valid 0.44307160283191294
LOSS train 0.5795185727588201 valid 0.4429370549114995
LOSS train 0.5795185727588201 valid 0.4430377038195729
LOSS train 0.5795185727588201 valid 0.4431484928412467
LOSS train 0.5795185727588201 valid 0.4430787813516311
LOSS train 0.5795185727588201 valid 0.44300974274705524
LOSS train 0.5795185727588201 valid 0.44286805300450904
LOSS train 0.5795185727588201 valid 0.4426881562579762
LOSS train 0.5795185727588201 valid 0.44244569970900754
LOSS train 0.5795185727588201 valid 0.44260322191044243
LOSS train 0.5795185727588201 valid 0.442654195108584
LOSS train 0.5795185727588201 valid 0.4426250607657009
LOSS train 0.5795185727588201 valid 0.4426407980568269
LOSS train 0.5795185727588201 valid 0.44284421397231477
LOSS train 0.5795185727588201 valid 0.4429229381819104
LOSS train 0.5795185727588201 valid 0.44312316799439444
LOSS train 0.5795185727588201 valid 0.4430724132335049
LOSS train 0.5795185727588201 valid 0.44314783590180534
LOSS train 0.5795185727588201 valid 0.44321812503039837
LOSS train 0.5795185727588201 valid 0.44318689279637097
LOSS train 0.5795185727588201 valid 0.4434085399582145
LOSS train 0.5795185727588201 valid 0.4434306524985329
LOSS train 0.5795185727588201 valid 0.4434919849038124
LOSS train 0.5795185727588201 valid 0.4434472816425134
LOSS train 0.5795185727588201 valid 0.4434571691921779
LOSS train 0.5795185727588201 valid 0.44348763263290697
LOSS train 0.5795185727588201 valid 0.4435166868826617
LOSS train 0.5795185727588201 valid 0.44342748442211666
LOSS train 0.5795185727588201 valid 0.4435251473739583
LOSS train 0.5795185727588201 valid 0.44372358169147674
LOSS train 0.5795185727588201 valid 0.44378954933044756
LOSS train 0.5795185727588201 valid 0.4437010001253199
LOSS train 0.5795185727588201 valid 0.44368735504777806
LOSS train 0.5795185727588201 valid 0.44387614212111026
LOSS train 0.5795185727588201 valid 0.4439368814540406
LOSS train 0.5795185727588201 valid 0.44395277954136153
LOSS train 0.5795185727588201 valid 0.44382109178095747
LOSS train 0.5795185727588201 valid 0.44365525474915135
LOSS train 0.5795185727588201 valid 0.4437073247165096
LOSS train 0.5795185727588201 valid 0.44378157557569786
LOSS train 0.5795185727588201 valid 0.4436166289478842
LOSS train 0.5795185727588201 valid 0.4436805751455489
LOSS train 0.5795185727588201 valid 0.44376006722450256
LOSS train 0.5795185727588201 valid 0.44368880838897096
LOSS train 0.5795185727588201 valid 0.4437259977111722
LOSS train 0.5795185727588201 valid 0.44365573590024937
LOSS train 0.5795185727588201 valid 0.4436575055998914
LOSS train 0.5795185727588201 valid 0.4435931138876008
LOSS train 0.5795185727588201 valid 0.4436909527454561
LOSS train 0.5795185727588201 valid 0.44375400151607497
LOSS train 0.5795185727588201 valid 0.44371085040844405
LOSS train 0.5795185727588201 valid 0.4435408677210648
LOSS train 0.5795185727588201 valid 0.44343038087799436
LOSS train 0.5795185727588201 valid 0.44356642882405867
LOSS train 0.5795185727588201 valid 0.443571685760651
LOSS train 0.5795185727588201 valid 0.4435754340019584
LOSS train 0.5795185727588201 valid 0.4435531782491185
LOSS train 0.5795185727588201 valid 0.44353964578273686
LOSS train 0.5795185727588201 valid 0.4435868948973991
LOSS train 0.5795185727588201 valid 0.44372259801433933
LOSS train 0.5795185727588201 valid 0.4437285970657244
LOSS train 0.5795185727588201 valid 0.44371666987192687
LOSS train 0.5795185727588201 valid 0.44366221143440765
LOSS train 0.5795185727588201 valid 0.4437466537520896
LOSS train 0.5795185727588201 valid 0.44382914336952
LOSS train 0.5795185727588201 valid 0.44384843084309666
LOSS train 0.5795185727588201 valid 0.4438632048134293
LOSS train 0.5795185727588201 valid 0.44378855890697905
LOSS train 0.5795185727588201 valid 0.44362614969764136
LOSS train 0.5795185727588201 valid 0.4437968564191054
LOSS train 0.5795185727588201 valid 0.4439061499739948
LOSS train 0.5795185727588201 valid 0.4439868966044297
LOSS train 0.5795185727588201 valid 0.4440009223378223
LOSS train 0.5795185727588201 valid 0.44390027760427236
LOSS train 0.5795185727588201 valid 0.44388672555315084
LOSS train 0.5795185727588201 valid 0.4437447525400972
LOSS train 0.5795185727588201 valid 0.44367458524867
LOSS train 0.5795185727588201 valid 0.44382671320692024
LOSS train 0.5795185727588201 valid 0.44382426231089284
LOSS train 0.5795185727588201 valid 0.443805261503292
LOSS train 0.5795185727588201 valid 0.4437469754900251
LOSS train 0.5795185727588201 valid 0.44374496492880655
LOSS train 0.5795185727588201 valid 0.4436697008709113
LOSS train 0.5795185727588201 valid 0.4436883273461053
LOSS train 0.5795185727588201 valid 0.44363919627075354
LOSS train 0.5795185727588201 valid 0.4436453523213971
LOSS train 0.5795185727588201 valid 0.44375241706605817
LOSS train 0.5795185727588201 valid 0.44370420940068306
LOSS train 0.5795185727588201 valid 0.44362155160283656
LOSS train 0.5795185727588201 valid 0.44389089833386997
LOSS train 0.5795185727588201 valid 0.4438364636753836
LOSS train 0.5795185727588201 valid 0.44376040438571607
LOSS train 0.5795185727588201 valid 0.44384624481201174
LOSS train 0.5795185727588201 valid 0.44383678825727974
LOSS train 0.5795185727588201 valid 0.44386608094450025
LOSS train 0.5795185727588201 valid 0.4439676910521013
LOSS train 0.5795185727588201 valid 0.4440075452402821
LOSS train 0.5795185727588201 valid 0.4439395600674199
LOSS train 0.5795185727588201 valid 0.44397053483407944
LOSS train 0.5795185727588201 valid 0.4439280815857394
LOSS train 0.5795185727588201 valid 0.44395333747993143
LOSS train 0.5795185727588201 valid 0.4440044607665088
LOSS train 0.5795185727588201 valid 0.4439767476457816
LOSS train 0.5795185727588201 valid 0.44402707468047453
LOSS train 0.5795185727588201 valid 0.44404780705466523
LOSS train 0.5795185727588201 valid 0.4440995670090157
LOSS train 0.5795185727588201 valid 0.44412151814410183
LOSS train 0.5795185727588201 valid 0.44413816568986425
LOSS train 0.5795185727588201 valid 0.44419208807604654
LOSS train 0.5795185727588201 valid 0.44423229752408433
LOSS train 0.5795185727588201 valid 0.4441683272372431
LOSS train 0.5795185727588201 valid 0.444328285504451
LOSS train 0.5795185727588201 valid 0.4443536889773828
LOSS train 0.5795185727588201 valid 0.44439929866702793
LOSS train 0.5795185727588201 valid 0.4444683287292719
LOSS train 0.5795185727588201 valid 0.4445153244467445
LOSS train 0.5795185727588201 valid 0.44446910243399823
LOSS train 0.5795185727588201 valid 0.44448893601244144
LOSS train 0.5795185727588201 valid 0.44457132844389347
LOSS train 0.5795185727588201 valid 0.44460002147333716
LOSS train 0.5795185727588201 valid 0.4445914496406377
LOSS train 0.5795185727588201 valid 0.44466615823434674
LOSS train 0.5795185727588201 valid 0.4446905488414424
LOSS train 0.5795185727588201 valid 0.44452608257426063
LOSS train 0.5795185727588201 valid 0.4444806682513961
LOSS train 0.5795185727588201 valid 0.44445245689301105
LOSS train 0.5795185727588201 valid 0.44448996188355167
LOSS train 0.5795185727588201 valid 0.44451566882300797
LOSS train 0.5795185727588201 valid 0.44443170726299286
LOSS train 0.5795185727588201 valid 0.44441552621146946
LOSS train 0.5795185727588201 valid 0.444447366003361
LOSS train 0.5795185727588201 valid 0.4443691342965954
LOSS train 0.5795185727588201 valid 0.44437286442723767
LOSS train 0.5795185727588201 valid 0.4442662922377439
LOSS train 0.5795185727588201 valid 0.44427034616062083
LOSS train 0.5795185727588201 valid 0.44422526520266875
LOSS train 0.5795185727588201 valid 0.44425693620629864
LOSS train 0.5795185727588201 valid 0.44439439894789357
LOSS train 0.5795185727588201 valid 0.4444543883405827
LOSS train 0.5795185727588201 valid 0.4443819792784424
LOSS train 0.5795185727588201 valid 0.44436055261816754
LOSS train 0.5795185727588201 valid 0.44445517699056647
LOSS train 0.5795185727588201 valid 0.4444283855954806
LOSS train 0.5795185727588201 valid 0.44445592006575624
LOSS train 0.5795185727588201 valid 0.4443693978107528
LOSS train 0.5795185727588201 valid 0.4444302493589546
LOSS train 0.5795185727588201 valid 0.4444302146960246
LOSS train 0.5795185727588201 valid 0.4443834839297123
LOSS train 0.5795185727588201 valid 0.44430461827836004
LOSS train 0.5795185727588201 valid 0.44431548194310566
LOSS train 0.5795185727588201 valid 0.4443001335898003
LOSS train 0.5795185727588201 valid 0.4443321571380961
LOSS train 0.5795185727588201 valid 0.44427470084159604
LOSS train 0.5795185727588201 valid 0.4442273888173977
LOSS train 0.5795185727588201 valid 0.44424316191520447
LOSS train 0.5795185727588201 valid 0.4443015479051267
LOSS train 0.5795185727588201 valid 0.4444083075994139
LOSS train 0.5795185727588201 valid 0.44445401307136295
LOSS train 0.5795185727588201 valid 0.44437429242873494
LOSS train 0.5795185727588201 valid 0.44443125472835937
LOSS train 0.5795185727588201 valid 0.4443998908471761
LOSS train 0.5795185727588201 valid 0.444461709559898
LOSS train 0.5795185727588201 valid 0.4443955425173044
LOSS train 0.5795185727588201 valid 0.4444402785873116
LOSS train 0.5795185727588201 valid 0.4444164423653798
LOSS train 0.5795185727588201 valid 0.4443852350623246
LOSS train 0.5795185727588201 valid 0.44440899154654256
LOSS train 0.5795185727588201 valid 0.44440573151295004
LOSS train 0.5795185727588201 valid 0.444477477962254
LOSS train 0.5795185727588201 valid 0.4445316963786379
LOSS train 0.5795185727588201 valid 0.444654901489252
LOSS train 0.5795185727588201 valid 0.44467183331588117
LOSS train 0.5795185727588201 valid 0.44465742580818407
LOSS train 0.5795185727588201 valid 0.44456066501824876
LOSS train 0.5795185727588201 valid 0.4444592836571027
LOSS train 0.5795185727588201 valid 0.4444402365892141
LOSS train 0.5795185727588201 valid 0.44451669991730214
LOSS train 0.5795185727588201 valid 0.4444592382480849
LOSS train 0.5795185727588201 valid 0.4444780872159061
LOSS train 0.5795185727588201 valid 0.44442236609204233
LOSS train 0.5795185727588201 valid 0.44444470821753057
LOSS train 0.5795185727588201 valid 0.4444415753921576
LOSS train 0.5795185727588201 valid 0.44443623002837684
LOSS train 0.5795185727588201 valid 0.4443691269743128
LOSS train 0.5795185727588201 valid 0.44436402000181857
LOSS train 0.5795185727588201 valid 0.44437834125218517
LOSS train 0.5795185727588201 valid 0.4444937407104082
LOSS train 0.5795185727588201 valid 0.4444741368293762
LOSS train 0.5795185727588201 valid 0.44448193761310134
LOSS train 0.5795185727588201 valid 0.44441502135493915
LOSS train 0.5795185727588201 valid 0.44447904516910686
LOSS train 0.5795185727588201 valid 0.4445283284843139
LOSS train 0.5795185727588201 valid 0.44453809916973114
LOSS train 0.5795185727588201 valid 0.4444793565490647
LOSS train 0.5795185727588201 valid 0.44448073877191
LOSS train 0.5795185727588201 valid 0.4445152921818471
LOSS train 0.5795185727588201 valid 0.44451318933802136
LOSS train 0.5795185727588201 valid 0.44456304043111666
LOSS train 0.5795185727588201 valid 0.4445924928851342
LOSS train 0.5795185727588201 valid 0.4445419678000175
LOSS train 0.5795185727588201 valid 0.4444955203619749
LOSS train 0.5795185727588201 valid 0.44447562588290584
LOSS train 0.5795185727588201 valid 0.4444664885600408
LOSS train 0.5795185727588201 valid 0.44454148750225925
LOSS train 0.5795185727588201 valid 0.4445738188963569
LOSS train 0.5795185727588201 valid 0.44458499320939227
LOSS train 0.5795185727588201 valid 0.44458786250798255
LOSS train 0.5795185727588201 valid 0.44460031390190125
LOSS train 0.5795185727588201 valid 0.44459436882714753
LOSS train 0.5795185727588201 valid 0.444514476148569
LOSS train 0.5795185727588201 valid 0.44454951114628627
LOSS train 0.5795185727588201 valid 0.4445571008574995
EPOCH 10:
  batch 1 loss: 0.5571198463439941
  batch 2 loss: 0.5665072798728943
  batch 3 loss: 0.5781600077946981
  batch 4 loss: 0.5867968201637268
  batch 5 loss: 0.586180305480957
  batch 6 loss: 0.5848000347614288
  batch 7 loss: 0.5920179997171674
  batch 8 loss: 0.590064637362957
  batch 9 loss: 0.5899569061067369
  batch 10 loss: 0.5882103323936463
  batch 11 loss: 0.5891611901196566
  batch 12 loss: 0.5917536069949468
  batch 13 loss: 0.5927613927767827
  batch 14 loss: 0.5928374316011157
  batch 15 loss: 0.595767096678416
  batch 16 loss: 0.5954199060797691
  batch 17 loss: 0.595389162792879
  batch 18 loss: 0.5940402944882711
  batch 19 loss: 0.5935133946569342
  batch 20 loss: 0.5936944723129273
  batch 21 loss: 0.5933802184604463
  batch 22 loss: 0.5932062755931508
  batch 23 loss: 0.5924572711405547
  batch 24 loss: 0.5921977137525877
  batch 25 loss: 0.5935740637779235
  batch 26 loss: 0.5921118236505069
  batch 27 loss: 0.5916592235918399
  batch 28 loss: 0.5897738018206188
  batch 29 loss: 0.5896270521755876
  batch 30 loss: 0.5886182308197021
  batch 31 loss: 0.5885408924471948
  batch 32 loss: 0.5881529934704304
  batch 33 loss: 0.5881323218345642
  batch 34 loss: 0.5868784697616801
  batch 35 loss: 0.5886466962950571
  batch 36 loss: 0.5883943554427888
  batch 37 loss: 0.5873739703281505
  batch 38 loss: 0.5871862031911549
  batch 39 loss: 0.5870789518723121
  batch 40 loss: 0.5862907707691193
  batch 41 loss: 0.5862643602417736
  batch 42 loss: 0.5863715977895827
  batch 43 loss: 0.5862941741943359
  batch 44 loss: 0.5857428881255063
  batch 45 loss: 0.5857123692830404
  batch 46 loss: 0.5854796819064928
  batch 47 loss: 0.5857240595716111
  batch 48 loss: 0.5851775705814362
  batch 49 loss: 0.5844743628891147
  batch 50 loss: 0.5846209251880645
  batch 51 loss: 0.5840396074687734
  batch 52 loss: 0.5844964029697272
  batch 53 loss: 0.5845740167599804
  batch 54 loss: 0.5846414764722189
  batch 55 loss: 0.58419884334911
  batch 56 loss: 0.5841229887945312
  batch 57 loss: 0.5840910160750673
  batch 58 loss: 0.5840608457039143
  batch 59 loss: 0.5836348695270086
  batch 60 loss: 0.5836114068826039
  batch 61 loss: 0.5833535800214673
  batch 62 loss: 0.5833781880717124
  batch 63 loss: 0.5834409537769499
  batch 64 loss: 0.5833795582875609
  batch 65 loss: 0.5832928144014798
  batch 66 loss: 0.5831511363838658
  batch 67 loss: 0.5835925892217836
  batch 68 loss: 0.5840172469615936
  batch 69 loss: 0.5839733662812606
  batch 70 loss: 0.5841729828289577
  batch 71 loss: 0.584192264247948
  batch 72 loss: 0.5841424937049547
  batch 73 loss: 0.5840379644746649
  batch 74 loss: 0.5840025954955333
  batch 75 loss: 0.584153790473938
  batch 76 loss: 0.5843984202334755
  batch 77 loss: 0.584168917172915
  batch 78 loss: 0.5836568811000922
  batch 79 loss: 0.5841523921942409
  batch 80 loss: 0.5841261111199856
  batch 81 loss: 0.5842361332457743
  batch 82 loss: 0.5845556520834202
  batch 83 loss: 0.5845301869403885
  batch 84 loss: 0.5847084366139912
  batch 85 loss: 0.5841592403019176
  batch 86 loss: 0.5846292189387388
  batch 87 loss: 0.5849040952222101
  batch 88 loss: 0.584983230991797
  batch 89 loss: 0.5849059739809358
  batch 90 loss: 0.5848000526428223
  batch 91 loss: 0.5848940139288431
  batch 92 loss: 0.5847507307062978
  batch 93 loss: 0.5848274865458089
  batch 94 loss: 0.5849201894821004
  batch 95 loss: 0.5850341445521304
  batch 96 loss: 0.5847982497264942
  batch 97 loss: 0.584555744510336
  batch 98 loss: 0.58467378786632
  batch 99 loss: 0.584577146804694
  batch 100 loss: 0.5846168941259384
  batch 101 loss: 0.5845428970780703
  batch 102 loss: 0.5847291256867203
  batch 103 loss: 0.5847051351973154
  batch 104 loss: 0.5848327107154406
  batch 105 loss: 0.585082813671657
  batch 106 loss: 0.5849270269555865
  batch 107 loss: 0.5847834928013455
  batch 108 loss: 0.5845581431079794
  batch 109 loss: 0.5845195476068269
  batch 110 loss: 0.5848263355818661
  batch 111 loss: 0.5847747728631303
  batch 112 loss: 0.5846449152699539
  batch 113 loss: 0.584619878140171
  batch 114 loss: 0.5848377686843538
  batch 115 loss: 0.5846565531647724
  batch 116 loss: 0.5847806750700392
  batch 117 loss: 0.5847738364822844
  batch 118 loss: 0.5847287587190079
  batch 119 loss: 0.584699070253292
  batch 120 loss: 0.5847110723455747
  batch 121 loss: 0.5844658307792726
  batch 122 loss: 0.5843393998067887
  batch 123 loss: 0.5844197486474262
  batch 124 loss: 0.5847245719163648
  batch 125 loss: 0.5846457533836364
  batch 126 loss: 0.5844393178584084
  batch 127 loss: 0.5845255781346419
  batch 128 loss: 0.5842634807340801
  batch 129 loss: 0.5839116360790045
  batch 130 loss: 0.5838034749031067
  batch 131 loss: 0.5835643797430373
  batch 132 loss: 0.5834545529249943
  batch 133 loss: 0.5835231497771758
  batch 134 loss: 0.5835030946268964
  batch 135 loss: 0.5836721769085637
  batch 136 loss: 0.5835171258624863
  batch 137 loss: 0.5836525933585898
  batch 138 loss: 0.5838213701179062
  batch 139 loss: 0.5837737622020913
  batch 140 loss: 0.5836950357471193
  batch 141 loss: 0.5836573953324176
  batch 142 loss: 0.5837136431479119
  batch 143 loss: 0.5836167235474486
  batch 144 loss: 0.5836132168769836
  batch 145 loss: 0.5835648955969975
  batch 146 loss: 0.5835030323838535
  batch 147 loss: 0.5835016175192229
  batch 148 loss: 0.5835480738330532
  batch 149 loss: 0.5834030536997238
  batch 150 loss: 0.5833750263849894
  batch 151 loss: 0.5834362696338173
  batch 152 loss: 0.583571939876205
  batch 153 loss: 0.583538202678456
  batch 154 loss: 0.5835790928308066
  batch 155 loss: 0.5836037428148331
  batch 156 loss: 0.5836393313530164
  batch 157 loss: 0.5837146081742207
  batch 158 loss: 0.5838076230845873
  batch 159 loss: 0.5838394045080029
  batch 160 loss: 0.5838577721267939
  batch 161 loss: 0.5839223835779273
  batch 162 loss: 0.5838351577152441
  batch 163 loss: 0.5838681148605113
  batch 164 loss: 0.5836824142351383
  batch 165 loss: 0.5835632927490003
  batch 166 loss: 0.5835194286093655
  batch 167 loss: 0.5834057659446122
  batch 168 loss: 0.5835070936452775
  batch 169 loss: 0.5834601567341731
  batch 170 loss: 0.583709406151491
  batch 171 loss: 0.5837956757573356
  batch 172 loss: 0.5836919844150543
  batch 173 loss: 0.5836937596343156
  batch 174 loss: 0.5836474594028517
  batch 175 loss: 0.5835977642876762
  batch 176 loss: 0.5835376083850861
  batch 177 loss: 0.5833418887887297
  batch 178 loss: 0.5831394048219316
  batch 179 loss: 0.5831479273694854
  batch 180 loss: 0.5831483609146542
  batch 181 loss: 0.5831428226186426
  batch 182 loss: 0.5830652428852333
  batch 183 loss: 0.5831792305727475
  batch 184 loss: 0.5830853999308918
  batch 185 loss: 0.5832925078031179
  batch 186 loss: 0.5832475020039466
  batch 187 loss: 0.583205905827609
  batch 188 loss: 0.5831208514406326
  batch 189 loss: 0.5828872401878317
  batch 190 loss: 0.5828339946897406
  batch 191 loss: 0.5828164073185147
  batch 192 loss: 0.5828815956289569
  batch 193 loss: 0.5828978243269451
  batch 194 loss: 0.5829708640722885
  batch 195 loss: 0.5830059112646641
  batch 196 loss: 0.5829288180993528
  batch 197 loss: 0.5829036453653713
  batch 198 loss: 0.5829264648032911
  batch 199 loss: 0.5829360916386896
  batch 200 loss: 0.5828636646270752
  batch 201 loss: 0.5829283538742445
  batch 202 loss: 0.5829043211323199
  batch 203 loss: 0.5828716790147603
  batch 204 loss: 0.5826774087606692
  batch 205 loss: 0.5826377819224102
  batch 206 loss: 0.5824635025945682
  batch 207 loss: 0.5824690800934023
  batch 208 loss: 0.5823897418494408
  batch 209 loss: 0.5822907945756136
  batch 210 loss: 0.5823583560330527
  batch 211 loss: 0.5823936561272608
  batch 212 loss: 0.5822927400750934
  batch 213 loss: 0.5823376450180447
  batch 214 loss: 0.5821765385498511
  batch 215 loss: 0.5820789705875308
  batch 216 loss: 0.5819979359706243
  batch 217 loss: 0.5818110210005589
  batch 218 loss: 0.5817571862028279
  batch 219 loss: 0.581631374957899
  batch 220 loss: 0.5816055452281779
  batch 221 loss: 0.5815983937876257
  batch 222 loss: 0.5816662950558705
  batch 223 loss: 0.5815890717399494
  batch 224 loss: 0.581593733014805
  batch 225 loss: 0.5814679331249661
  batch 226 loss: 0.5815298910689565
  batch 227 loss: 0.5814139391357153
  batch 228 loss: 0.5813375162450891
  batch 229 loss: 0.5813215450428458
  batch 230 loss: 0.5812817993371383
  batch 231 loss: 0.5813499077573999
  batch 232 loss: 0.5811620459988199
  batch 233 loss: 0.5811605330700527
  batch 234 loss: 0.5810820113899361
  batch 235 loss: 0.581099829521585
  batch 236 loss: 0.5809872877799859
  batch 237 loss: 0.580962764059944
  batch 238 loss: 0.5808309637197927
  batch 239 loss: 0.5808606491926823
  batch 240 loss: 0.5807945591708025
  batch 241 loss: 0.5807050149965088
  batch 242 loss: 0.5806133003274271
  batch 243 loss: 0.5805556001486601
  batch 244 loss: 0.5806110718699752
  batch 245 loss: 0.5804686054891469
  batch 246 loss: 0.5805934541593722
  batch 247 loss: 0.5806089108772123
  batch 248 loss: 0.5806094249410014
  batch 249 loss: 0.5806966613095448
  batch 250 loss: 0.5806458895206451
  batch 251 loss: 0.5806515238199575
  batch 252 loss: 0.5806423517919722
  batch 253 loss: 0.5805296994480691
  batch 254 loss: 0.580506109581219
  batch 255 loss: 0.5804042883947784
  batch 256 loss: 0.5803754932712764
  batch 257 loss: 0.5805364921399128
  batch 258 loss: 0.5804718224577201
  batch 259 loss: 0.58030677463097
  batch 260 loss: 0.5802477190127739
  batch 261 loss: 0.5802121669396587
  batch 262 loss: 0.5803128262512557
  batch 263 loss: 0.5802450325099234
  batch 264 loss: 0.5802091682950655
  batch 265 loss: 0.580118159977895
  batch 266 loss: 0.5801472890197783
  batch 267 loss: 0.5802621091349741
  batch 268 loss: 0.5801424428598204
  batch 269 loss: 0.580118158049743
  batch 270 loss: 0.5800893315562495
  batch 271 loss: 0.5800672833330077
  batch 272 loss: 0.5801068550961859
  batch 273 loss: 0.5801561933297378
  batch 274 loss: 0.5801966188162783
  batch 275 loss: 0.5802648338404569
  batch 276 loss: 0.5803161986928055
  batch 277 loss: 0.580320588733315
  batch 278 loss: 0.5803124814582385
  batch 279 loss: 0.5803224615298719
  batch 280 loss: 0.5804006287029811
  batch 281 loss: 0.5803265032819157
  batch 282 loss: 0.5801527508607147
  batch 283 loss: 0.5800217796551466
  batch 284 loss: 0.5801017529947657
  batch 285 loss: 0.5801308393478394
  batch 286 loss: 0.5801129451581648
  batch 287 loss: 0.5800736957726162
  batch 288 loss: 0.579927795049217
  batch 289 loss: 0.579973964955155
  batch 290 loss: 0.5797935738645751
  batch 291 loss: 0.5798103926108056
  batch 292 loss: 0.5799341412031487
  batch 293 loss: 0.5799653857641253
  batch 294 loss: 0.5799511667011547
  batch 295 loss: 0.5799429721751456
  batch 296 loss: 0.5799245312809944
  batch 297 loss: 0.5799499752144219
  batch 298 loss: 0.5799347340260577
  batch 299 loss: 0.5799576787645602
  batch 300 loss: 0.5800599112113317
  batch 301 loss: 0.5799833039112662
  batch 302 loss: 0.5798776783295815
  batch 303 loss: 0.579876179939056
  batch 304 loss: 0.579797590445531
  batch 305 loss: 0.5796044785468305
  batch 306 loss: 0.5795508621175305
  batch 307 loss: 0.5795438287700815
  batch 308 loss: 0.579556506369021
  batch 309 loss: 0.5794172180894895
  batch 310 loss: 0.5794653459902732
  batch 311 loss: 0.5795943938267576
  batch 312 loss: 0.5795847817491262
  batch 313 loss: 0.5795722790419484
  batch 314 loss: 0.5795538013528108
  batch 315 loss: 0.579500588916597
  batch 316 loss: 0.5794361231825019
  batch 317 loss: 0.5794389497970557
  batch 318 loss: 0.5792935580577491
  batch 319 loss: 0.5792875544030838
  batch 320 loss: 0.5792766341939568
  batch 321 loss: 0.5792282858741618
  batch 322 loss: 0.5793145189744345
  batch 323 loss: 0.579265108234004
  batch 324 loss: 0.5792396239660405
  batch 325 loss: 0.5792498751787039
  batch 326 loss: 0.5791867819666131
  batch 327 loss: 0.5791506021759196
  batch 328 loss: 0.5790577539946975
  batch 329 loss: 0.5790623431872451
  batch 330 loss: 0.5790881588603511
  batch 331 loss: 0.5791223731646005
  batch 332 loss: 0.5791202957730696
  batch 333 loss: 0.5790784552290633
  batch 334 loss: 0.5790489266018668
  batch 335 loss: 0.578982147174095
  batch 336 loss: 0.5789175563979716
  batch 337 loss: 0.5788074192378216
  batch 338 loss: 0.5788336810628338
  batch 339 loss: 0.5789068814224199
  batch 340 loss: 0.5789239315425648
  batch 341 loss: 0.5789112511618046
  batch 342 loss: 0.5789080500951287
  batch 343 loss: 0.5788977641405935
  batch 344 loss: 0.5788912812984267
  batch 345 loss: 0.5789740180623704
  batch 346 loss: 0.5788811031793584
  batch 347 loss: 0.5788864690907063
  batch 348 loss: 0.5789562182864924
  batch 349 loss: 0.578911484141746
  batch 350 loss: 0.5789002854483468
  batch 351 loss: 0.5789886566988084
  batch 352 loss: 0.5789906196296215
  batch 353 loss: 0.5789688788459929
  batch 354 loss: 0.5790363543451169
  batch 355 loss: 0.5791087530028652
  batch 356 loss: 0.5791237555193097
  batch 357 loss: 0.5790619583023029
  batch 358 loss: 0.5791085402392808
  batch 359 loss: 0.5791471290057084
  batch 360 loss: 0.5791856658127573
  batch 361 loss: 0.5790951582203281
  batch 362 loss: 0.579136102403725
  batch 363 loss: 0.57913964789761
  batch 364 loss: 0.5791062383533834
  batch 365 loss: 0.5791078301325236
  batch 366 loss: 0.5791544472910667
  batch 367 loss: 0.5790180346296658
  batch 368 loss: 0.5790021404947924
  batch 369 loss: 0.5790222694234151
  batch 370 loss: 0.5791405047919299
  batch 371 loss: 0.5791730625288827
  batch 372 loss: 0.57910364001028
  batch 373 loss: 0.5791389670512631
  batch 374 loss: 0.5790861502369458
  batch 375 loss: 0.5790621898969015
  batch 376 loss: 0.5791428842126055
  batch 377 loss: 0.5791121240636082
  batch 378 loss: 0.5790291297688055
  batch 379 loss: 0.5790495526507536
  batch 380 loss: 0.5791065372918781
  batch 381 loss: 0.5790029989452813
  batch 382 loss: 0.5789544548039661
  batch 383 loss: 0.5789689591285765
  batch 384 loss: 0.5789750109737118
  batch 385 loss: 0.5790835318627295
  batch 386 loss: 0.5790368119360869
  batch 387 loss: 0.5790219548752757
  batch 388 loss: 0.5789977049397439
  batch 389 loss: 0.5790538864454451
  batch 390 loss: 0.579120934009552
  batch 391 loss: 0.5791202550349028
  batch 392 loss: 0.5790273542610966
  batch 393 loss: 0.5790602246313604
  batch 394 loss: 0.579144776018743
  batch 395 loss: 0.5791272489330437
  batch 396 loss: 0.5791353432819096
  batch 397 loss: 0.579104753675629
  batch 398 loss: 0.579041328561965
  batch 399 loss: 0.5790567672939826
  batch 400 loss: 0.5789961858093738
  batch 401 loss: 0.5789324935534945
  batch 402 loss: 0.5789214987956469
  batch 403 loss: 0.5789186913085634
  batch 404 loss: 0.5789062953231359
  batch 405 loss: 0.578908473768352
  batch 406 loss: 0.5789306880218055
  batch 407 loss: 0.5789115881451224
  batch 408 loss: 0.5789895953208792
  batch 409 loss: 0.5789399970423038
  batch 410 loss: 0.578914827835269
  batch 411 loss: 0.5788544855848716
  batch 412 loss: 0.578811215254867
  batch 413 loss: 0.5787587924961893
  batch 414 loss: 0.5787885531711118
  batch 415 loss: 0.578810358191111
  batch 416 loss: 0.578729335218668
  batch 417 loss: 0.5786821865063492
  batch 418 loss: 0.5787316761803969
  batch 419 loss: 0.5788479640830957
  batch 420 loss: 0.5789144301698321
  batch 421 loss: 0.5789153556076195
  batch 422 loss: 0.5790025812189726
  batch 423 loss: 0.5790260518696291
  batch 424 loss: 0.5789635469609836
  batch 425 loss: 0.5790341448783874
  batch 426 loss: 0.5789998761365112
  batch 427 loss: 0.578975150959274
  batch 428 loss: 0.5789825718536555
  batch 429 loss: 0.5790133687443945
  batch 430 loss: 0.5789885490439659
  batch 431 loss: 0.5789952304413036
  batch 432 loss: 0.5789691075958587
  batch 433 loss: 0.5789281048620546
  batch 434 loss: 0.5789505743211315
  batch 435 loss: 0.5789606505426867
  batch 436 loss: 0.5789296763752578
  batch 437 loss: 0.5790350516273446
  batch 438 loss: 0.5791385511285094
  batch 439 loss: 0.5791191696306024
  batch 440 loss: 0.5790961233052341
  batch 441 loss: 0.5790808771202623
  batch 442 loss: 0.5790123490456542
  batch 443 loss: 0.5790019599094348
  batch 444 loss: 0.5790133450750832
  batch 445 loss: 0.5789667004949591
  batch 446 loss: 0.5789712588616016
  batch 447 loss: 0.5788880369273874
  batch 448 loss: 0.5789155169789281
  batch 449 loss: 0.578923776579859
  batch 450 loss: 0.5789176860120562
  batch 451 loss: 0.5789221659996557
  batch 452 loss: 0.578897855318753
  batch 453 loss: 0.5788403682361375
  batch 454 loss: 0.5788926391612066
  batch 455 loss: 0.578974373131008
  batch 456 loss: 0.5790048174952206
  batch 457 loss: 0.5790475856031839
  batch 458 loss: 0.5790057732809059
  batch 459 loss: 0.5790098691298291
  batch 460 loss: 0.5790920888600142
  batch 461 loss: 0.5791065470515518
  batch 462 loss: 0.5791119355143923
  batch 463 loss: 0.5791539074792718
  batch 464 loss: 0.5792236975554762
  batch 465 loss: 0.5791993946157475
  batch 466 loss: 0.5791836595842255
  batch 467 loss: 0.579202678397585
  batch 468 loss: 0.5791740141108505
  batch 469 loss: 0.5791637880969912
  batch 470 loss: 0.5791483456784107
  batch 471 loss: 0.5791730079681251
  batch 472 loss: 0.5791481888647807
LOSS train 0.5791481888647807 valid 0.4270867109298706
LOSS train 0.5791481888647807 valid 0.42904232442379
LOSS train 0.5791481888647807 valid 0.4291710952917735
LOSS train 0.5791481888647807 valid 0.4269351586699486
LOSS train 0.5791481888647807 valid 0.4219163656234741
LOSS train 0.5791481888647807 valid 0.4257974624633789
LOSS train 0.5791481888647807 valid 0.42954507044383455
LOSS train 0.5791481888647807 valid 0.4290713742375374
LOSS train 0.5791481888647807 valid 0.4290274779001872
LOSS train 0.5791481888647807 valid 0.43129290342330934
LOSS train 0.5791481888647807 valid 0.43406840617006476
LOSS train 0.5791481888647807 valid 0.43435153365135193
LOSS train 0.5791481888647807 valid 0.43623964373882
LOSS train 0.5791481888647807 valid 0.4379198466028486
LOSS train 0.5791481888647807 valid 0.4385167976220449
LOSS train 0.5791481888647807 valid 0.4371295217424631
LOSS train 0.5791481888647807 valid 0.4378535765058854
LOSS train 0.5791481888647807 valid 0.43763907584879136
LOSS train 0.5791481888647807 valid 0.43675404316500616
LOSS train 0.5791481888647807 valid 0.4374568939208984
LOSS train 0.5791481888647807 valid 0.43766558454150245
LOSS train 0.5791481888647807 valid 0.4357913854447278
LOSS train 0.5791481888647807 valid 0.4360473557658818
LOSS train 0.5791481888647807 valid 0.4355461373925209
LOSS train 0.5791481888647807 valid 0.43490618109703066
LOSS train 0.5791481888647807 valid 0.4339904681994365
LOSS train 0.5791481888647807 valid 0.4341207577122582
LOSS train 0.5791481888647807 valid 0.4343101052301271
LOSS train 0.5791481888647807 valid 0.43366683454349125
LOSS train 0.5791481888647807 valid 0.43432157138983407
LOSS train 0.5791481888647807 valid 0.43511444810898076
LOSS train 0.5791481888647807 valid 0.4353040000423789
LOSS train 0.5791481888647807 valid 0.436146543784575
LOSS train 0.5791481888647807 valid 0.43716029647518606
LOSS train 0.5791481888647807 valid 0.4377452628953116
LOSS train 0.5791481888647807 valid 0.43784214473432964
LOSS train 0.5791481888647807 valid 0.4380395694358929
LOSS train 0.5791481888647807 valid 0.43782640993595123
LOSS train 0.5791481888647807 valid 0.43751756044534534
LOSS train 0.5791481888647807 valid 0.43791849762201307
LOSS train 0.5791481888647807 valid 0.43832096384792796
LOSS train 0.5791481888647807 valid 0.4382125863007137
LOSS train 0.5791481888647807 valid 0.43780754194703214
LOSS train 0.5791481888647807 valid 0.4377818744290959
LOSS train 0.5791481888647807 valid 0.43765964971648325
LOSS train 0.5791481888647807 valid 0.4381087143783984
LOSS train 0.5791481888647807 valid 0.4382251672288205
LOSS train 0.5791481888647807 valid 0.43873131399353343
LOSS train 0.5791481888647807 valid 0.439084278685706
LOSS train 0.5791481888647807 valid 0.4384246891736984
LOSS train 0.5791481888647807 valid 0.4390982956278558
LOSS train 0.5791481888647807 valid 0.4389827257165542
LOSS train 0.5791481888647807 valid 0.43862624382073023
LOSS train 0.5791481888647807 valid 0.4382605834139718
LOSS train 0.5791481888647807 valid 0.43819382028146225
LOSS train 0.5791481888647807 valid 0.4379924674119268
LOSS train 0.5791481888647807 valid 0.4374547208610334
LOSS train 0.5791481888647807 valid 0.43717858246688185
LOSS train 0.5791481888647807 valid 0.43758854269981384
LOSS train 0.5791481888647807 valid 0.43732426514228184
LOSS train 0.5791481888647807 valid 0.43667520997954196
LOSS train 0.5791481888647807 valid 0.4366455827989886
LOSS train 0.5791481888647807 valid 0.4367281108621567
LOSS train 0.5791481888647807 valid 0.43711088178679347
LOSS train 0.5791481888647807 valid 0.43712911101487967
LOSS train 0.5791481888647807 valid 0.4370313670599099
LOSS train 0.5791481888647807 valid 0.4368467015116962
LOSS train 0.5791481888647807 valid 0.43710460864445744
LOSS train 0.5791481888647807 valid 0.4369559085023576
LOSS train 0.5791481888647807 valid 0.436674183181354
LOSS train 0.5791481888647807 valid 0.4363800963045846
LOSS train 0.5791481888647807 valid 0.43614602502849364
LOSS train 0.5791481888647807 valid 0.4363400111459706
LOSS train 0.5791481888647807 valid 0.43587102036218384
LOSS train 0.5791481888647807 valid 0.43573567350705467
LOSS train 0.5791481888647807 valid 0.4359058482866538
LOSS train 0.5791481888647807 valid 0.4358791588962852
LOSS train 0.5791481888647807 valid 0.436025531628193
LOSS train 0.5791481888647807 valid 0.4357140826273568
LOSS train 0.5791481888647807 valid 0.43548648357391356
LOSS train 0.5791481888647807 valid 0.4352396641984398
LOSS train 0.5791481888647807 valid 0.4352244091470067
LOSS train 0.5791481888647807 valid 0.4351321656301797
LOSS train 0.5791481888647807 valid 0.43519127368927
LOSS train 0.5791481888647807 valid 0.43505854536505306
LOSS train 0.5791481888647807 valid 0.4349199911189634
LOSS train 0.5791481888647807 valid 0.43495572743744687
LOSS train 0.5791481888647807 valid 0.4347463328052651
LOSS train 0.5791481888647807 valid 0.43493949797716036
LOSS train 0.5791481888647807 valid 0.43513222965929244
LOSS train 0.5791481888647807 valid 0.4351877409678239
LOSS train 0.5791481888647807 valid 0.4350875499455825
LOSS train 0.5791481888647807 valid 0.43498631638865315
LOSS train 0.5791481888647807 valid 0.43487978298613367
LOSS train 0.5791481888647807 valid 0.4347456706197638
LOSS train 0.5791481888647807 valid 0.43454252059261006
LOSS train 0.5791481888647807 valid 0.434744958410558
LOSS train 0.5791481888647807 valid 0.43455893227032255
LOSS train 0.5791481888647807 valid 0.4348457542934803
LOSS train 0.5791481888647807 valid 0.4348955950140953
LOSS train 0.5791481888647807 valid 0.4349148394447742
LOSS train 0.5791481888647807 valid 0.4349224842062183
LOSS train 0.5791481888647807 valid 0.4352531797677568
LOSS train 0.5791481888647807 valid 0.4352435495417852
LOSS train 0.5791481888647807 valid 0.43530281129337495
LOSS train 0.5791481888647807 valid 0.4353646605082278
LOSS train 0.5791481888647807 valid 0.4352851406993153
LOSS train 0.5791481888647807 valid 0.43542570731154195
LOSS train 0.5791481888647807 valid 0.4357146760192486
LOSS train 0.5791481888647807 valid 0.4358606747605584
LOSS train 0.5791481888647807 valid 0.4358072930628115
LOSS train 0.5791481888647807 valid 0.43596809250967844
LOSS train 0.5791481888647807 valid 0.43608752446891985
LOSS train 0.5791481888647807 valid 0.4358675979208528
LOSS train 0.5791481888647807 valid 0.4359830211038175
LOSS train 0.5791481888647807 valid 0.43613776076456595
LOSS train 0.5791481888647807 valid 0.43609290882053536
LOSS train 0.5791481888647807 valid 0.43604213075112486
LOSS train 0.5791481888647807 valid 0.43601410103445293
LOSS train 0.5791481888647807 valid 0.4360075481235981
LOSS train 0.5791481888647807 valid 0.4359947312469325
LOSS train 0.5791481888647807 valid 0.43586179907204675
LOSS train 0.5791481888647807 valid 0.43588978003680223
LOSS train 0.5791481888647807 valid 0.4361147032149376
LOSS train 0.5791481888647807 valid 0.4360510718822479
LOSS train 0.5791481888647807 valid 0.4359524805867483
LOSS train 0.5791481888647807 valid 0.4360638901473969
LOSS train 0.5791481888647807 valid 0.4362837513908744
LOSS train 0.5791481888647807 valid 0.43642758976581486
LOSS train 0.5791481888647807 valid 0.4362639431770031
LOSS train 0.5791481888647807 valid 0.43621263795226584
LOSS train 0.5791481888647807 valid 0.4360436043052962
LOSS train 0.5791481888647807 valid 0.4359117549164851
LOSS train 0.5791481888647807 valid 0.43593876352950706
LOSS train 0.5791481888647807 valid 0.43601185657359937
LOSS train 0.5791481888647807 valid 0.43597689884550433
LOSS train 0.5791481888647807 valid 0.43591975774208125
LOSS train 0.5791481888647807 valid 0.435842658298603
LOSS train 0.5791481888647807 valid 0.43568378815548026
LOSS train 0.5791481888647807 valid 0.4356906250119209
LOSS train 0.5791481888647807 valid 0.43584900375799085
LOSS train 0.5791481888647807 valid 0.435976634143104
LOSS train 0.5791481888647807 valid 0.4359058512674345
LOSS train 0.5791481888647807 valid 0.4359723524087005
LOSS train 0.5791481888647807 valid 0.4358928277574736
LOSS train 0.5791481888647807 valid 0.4362144343657036
LOSS train 0.5791481888647807 valid 0.43604843206957083
LOSS train 0.5791481888647807 valid 0.4363581951002817
LOSS train 0.5791481888647807 valid 0.43627644105245605
LOSS train 0.5791481888647807 valid 0.43631865561008454
LOSS train 0.5791481888647807 valid 0.4364237055083774
LOSS train 0.5791481888647807 valid 0.4363819188193271
LOSS train 0.5791481888647807 valid 0.4363747315079558
LOSS train 0.5791481888647807 valid 0.43650353825711585
LOSS train 0.5791481888647807 valid 0.4364367356223445
LOSS train 0.5791481888647807 valid 0.4366529478858679
LOSS train 0.5791481888647807 valid 0.43669219799102493
LOSS train 0.5791481888647807 valid 0.43674841108201423
LOSS train 0.5791481888647807 valid 0.4365859342820989
LOSS train 0.5791481888647807 valid 0.43665440045297144
LOSS train 0.5791481888647807 valid 0.43673268552892697
LOSS train 0.5791481888647807 valid 0.4366483428963908
LOSS train 0.5791481888647807 valid 0.4365794883549579
LOSS train 0.5791481888647807 valid 0.43648788932620025
LOSS train 0.5791481888647807 valid 0.4363256152832147
LOSS train 0.5791481888647807 valid 0.43615926227655755
LOSS train 0.5791481888647807 valid 0.4363007515133498
LOSS train 0.5791481888647807 valid 0.4363485945477372
LOSS train 0.5791481888647807 valid 0.4363437215604726
LOSS train 0.5791481888647807 valid 0.436419694388614
LOSS train 0.5791481888647807 valid 0.4366187812292088
LOSS train 0.5791481888647807 valid 0.4367140711740006
LOSS train 0.5791481888647807 valid 0.43682772868630515
LOSS train 0.5791481888647807 valid 0.43682965122420214
LOSS train 0.5791481888647807 valid 0.43693781444004604
LOSS train 0.5791481888647807 valid 0.4370400275696408
LOSS train 0.5791481888647807 valid 0.4371031450349732
LOSS train 0.5791481888647807 valid 0.43731389705384716
LOSS train 0.5791481888647807 valid 0.4373302621215415
LOSS train 0.5791481888647807 valid 0.4374802599350611
LOSS train 0.5791481888647807 valid 0.4375638874525523
LOSS train 0.5791481888647807 valid 0.4375729135104588
LOSS train 0.5791481888647807 valid 0.4376445998910998
LOSS train 0.5791481888647807 valid 0.43774718289142067
LOSS train 0.5791481888647807 valid 0.4377280728237049
LOSS train 0.5791481888647807 valid 0.4377876193292679
LOSS train 0.5791481888647807 valid 0.4379185004667802
LOSS train 0.5791481888647807 valid 0.4379621366871164
LOSS train 0.5791481888647807 valid 0.43788807196591895
LOSS train 0.5791481888647807 valid 0.43786365515307374
LOSS train 0.5791481888647807 valid 0.43799911962129684
LOSS train 0.5791481888647807 valid 0.4380883388221264
LOSS train 0.5791481888647807 valid 0.43811558905043135
LOSS train 0.5791481888647807 valid 0.4379852349610673
LOSS train 0.5791481888647807 valid 0.4378376705524249
LOSS train 0.5791481888647807 valid 0.4379141935888602
LOSS train 0.5791481888647807 valid 0.437961393806535
LOSS train 0.5791481888647807 valid 0.43783006433284644
LOSS train 0.5791481888647807 valid 0.43786082435492896
LOSS train 0.5791481888647807 valid 0.4379485712945461
LOSS train 0.5791481888647807 valid 0.4378738306944643
LOSS train 0.5791481888647807 valid 0.43793305533357185
LOSS train 0.5791481888647807 valid 0.43788017706918014
LOSS train 0.5791481888647807 valid 0.4379034993403098
LOSS train 0.5791481888647807 valid 0.4378220547990101
LOSS train 0.5791481888647807 valid 0.43791508978431665
LOSS train 0.5791481888647807 valid 0.43795425002125726
LOSS train 0.5791481888647807 valid 0.43794421665370464
LOSS train 0.5791481888647807 valid 0.4378082297350231
LOSS train 0.5791481888647807 valid 0.4377007207700184
LOSS train 0.5791481888647807 valid 0.4378324422226133
LOSS train 0.5791481888647807 valid 0.43780520980088217
LOSS train 0.5791481888647807 valid 0.4378766852645247
LOSS train 0.5791481888647807 valid 0.43780816757233343
LOSS train 0.5791481888647807 valid 0.43776215106941935
LOSS train 0.5791481888647807 valid 0.4377699342590791
LOSS train 0.5791481888647807 valid 0.4378910196541641
LOSS train 0.5791481888647807 valid 0.4378946150114777
LOSS train 0.5791481888647807 valid 0.43790102494906075
LOSS train 0.5791481888647807 valid 0.43782564984126526
LOSS train 0.5791481888647807 valid 0.43790239567670347
LOSS train 0.5791481888647807 valid 0.4380284628352603
LOSS train 0.5791481888647807 valid 0.4380964305368774
LOSS train 0.5791481888647807 valid 0.43810986035636496
LOSS train 0.5791481888647807 valid 0.4380642745229933
LOSS train 0.5791481888647807 valid 0.4378985414462807
LOSS train 0.5791481888647807 valid 0.4380508297603036
LOSS train 0.5791481888647807 valid 0.4381231381966357
LOSS train 0.5791481888647807 valid 0.4382054421839235
LOSS train 0.5791481888647807 valid 0.4382402118133462
LOSS train 0.5791481888647807 valid 0.4381063236044599
LOSS train 0.5791481888647807 valid 0.43809179794685593
LOSS train 0.5791481888647807 valid 0.43792849894245295
LOSS train 0.5791481888647807 valid 0.4379206099826047
LOSS train 0.5791481888647807 valid 0.43805751901991824
LOSS train 0.5791481888647807 valid 0.43802194979231235
LOSS train 0.5791481888647807 valid 0.43796946378699836
LOSS train 0.5791481888647807 valid 0.4379043401289387
LOSS train 0.5791481888647807 valid 0.4379148842400587
LOSS train 0.5791481888647807 valid 0.43782653510570524
LOSS train 0.5791481888647807 valid 0.4378679726133703
LOSS train 0.5791481888647807 valid 0.43785599181967333
LOSS train 0.5791481888647807 valid 0.4378711925857842
LOSS train 0.5791481888647807 valid 0.4379688759074836
LOSS train 0.5791481888647807 valid 0.4379297266201097
LOSS train 0.5791481888647807 valid 0.4378779007167351
LOSS train 0.5791481888647807 valid 0.4381385443181644
LOSS train 0.5791481888647807 valid 0.43805974469550196
LOSS train 0.5791481888647807 valid 0.43797964563810204
LOSS train 0.5791481888647807 valid 0.4380534858703613
LOSS train 0.5791481888647807 valid 0.4380262116511979
LOSS train 0.5791481888647807 valid 0.43805175534789526
LOSS train 0.5791481888647807 valid 0.4381490553556224
LOSS train 0.5791481888647807 valid 0.43820233689987753
LOSS train 0.5791481888647807 valid 0.43817686882673523
LOSS train 0.5791481888647807 valid 0.4381896940758452
LOSS train 0.5791481888647807 valid 0.4381635417502214
LOSS train 0.5791481888647807 valid 0.43816336977851483
LOSS train 0.5791481888647807 valid 0.4382150317020858
LOSS train 0.5791481888647807 valid 0.43821731221217375
LOSS train 0.5791481888647807 valid 0.4382388225232048
LOSS train 0.5791481888647807 valid 0.4382639506845984
LOSS train 0.5791481888647807 valid 0.43833893605511454
LOSS train 0.5791481888647807 valid 0.4383688464083455
LOSS train 0.5791481888647807 valid 0.43838310444130085
LOSS train 0.5791481888647807 valid 0.43839633509628756
LOSS train 0.5791481888647807 valid 0.4384248143947973
LOSS train 0.5791481888647807 valid 0.43837725549046674
LOSS train 0.5791481888647807 valid 0.4385215805144115
LOSS train 0.5791481888647807 valid 0.43851311769750384
LOSS train 0.5791481888647807 valid 0.43855665134767763
LOSS train 0.5791481888647807 valid 0.43861176226945486
LOSS train 0.5791481888647807 valid 0.4386751040434226
LOSS train 0.5791481888647807 valid 0.43862366882989007
LOSS train 0.5791481888647807 valid 0.43860965782945804
LOSS train 0.5791481888647807 valid 0.4386653926061547
LOSS train 0.5791481888647807 valid 0.438720430062566
LOSS train 0.5791481888647807 valid 0.4386732070137271
LOSS train 0.5791481888647807 valid 0.43874122827283796
LOSS train 0.5791481888647807 valid 0.43874705455132895
LOSS train 0.5791481888647807 valid 0.43859838124271816
LOSS train 0.5791481888647807 valid 0.4385737249403135
LOSS train 0.5791481888647807 valid 0.4385182426801419
LOSS train 0.5791481888647807 valid 0.4385652094030044
LOSS train 0.5791481888647807 valid 0.43859048067477713
LOSS train 0.5791481888647807 valid 0.4385095141775958
LOSS train 0.5791481888647807 valid 0.43850677997808424
LOSS train 0.5791481888647807 valid 0.4385379625277387
LOSS train 0.5791481888647807 valid 0.43844616990600904
LOSS train 0.5791481888647807 valid 0.4383924439035613
LOSS train 0.5791481888647807 valid 0.43826947455963317
LOSS train 0.5791481888647807 valid 0.4382602167251992
LOSS train 0.5791481888647807 valid 0.4382098698575342
LOSS train 0.5791481888647807 valid 0.43821210206365907
LOSS train 0.5791481888647807 valid 0.43834531842652014
LOSS train 0.5791481888647807 valid 0.438392490853329
LOSS train 0.5791481888647807 valid 0.43834005973555823
LOSS train 0.5791481888647807 valid 0.43829889335488315
LOSS train 0.5791481888647807 valid 0.4383755179751278
LOSS train 0.5791481888647807 valid 0.43836177239815394
LOSS train 0.5791481888647807 valid 0.43842963968400545
LOSS train 0.5791481888647807 valid 0.43833369411380085
LOSS train 0.5791481888647807 valid 0.4384032749500212
LOSS train 0.5791481888647807 valid 0.43841966888622236
LOSS train 0.5791481888647807 valid 0.43838097707169954
LOSS train 0.5791481888647807 valid 0.4383523452515696
LOSS train 0.5791481888647807 valid 0.43838615157316874
LOSS train 0.5791481888647807 valid 0.4383897537534887
LOSS train 0.5791481888647807 valid 0.43841475055441503
LOSS train 0.5791481888647807 valid 0.438381052209485
LOSS train 0.5791481888647807 valid 0.43836005717228466
LOSS train 0.5791481888647807 valid 0.43840832435167754
LOSS train 0.5791481888647807 valid 0.43849228993772316
LOSS train 0.5791481888647807 valid 0.4385690095887822
LOSS train 0.5791481888647807 valid 0.43861416653981283
LOSS train 0.5791481888647807 valid 0.43851618949748294
LOSS train 0.5791481888647807 valid 0.43859144133348194
LOSS train 0.5791481888647807 valid 0.4385362574889225
LOSS train 0.5791481888647807 valid 0.43858865641501255
LOSS train 0.5791481888647807 valid 0.43854135535657407
LOSS train 0.5791481888647807 valid 0.4385798977357205
LOSS train 0.5791481888647807 valid 0.4385442627327783
LOSS train 0.5791481888647807 valid 0.4384963087068623
LOSS train 0.5791481888647807 valid 0.43850384358270666
LOSS train 0.5791481888647807 valid 0.43846266196324274
LOSS train 0.5791481888647807 valid 0.4385404898527941
LOSS train 0.5791481888647807 valid 0.43861300947104753
LOSS train 0.5791481888647807 valid 0.4387113779056363
LOSS train 0.5791481888647807 valid 0.43876781960026473
LOSS train 0.5791481888647807 valid 0.43876814444859824
LOSS train 0.5791481888647807 valid 0.43867005430319517
LOSS train 0.5791481888647807 valid 0.43858675317591933
LOSS train 0.5791481888647807 valid 0.4385977054501439
LOSS train 0.5791481888647807 valid 0.43866527401758526
LOSS train 0.5791481888647807 valid 0.43860262676851075
LOSS train 0.5791481888647807 valid 0.43862084822640535
LOSS train 0.5791481888647807 valid 0.4385995501403639
LOSS train 0.5791481888647807 valid 0.4386176486339795
LOSS train 0.5791481888647807 valid 0.4385993036724473
LOSS train 0.5791481888647807 valid 0.43858121624764274
LOSS train 0.5791481888647807 valid 0.43854883828820374
LOSS train 0.5791481888647807 valid 0.43853809166024305
LOSS train 0.5791481888647807 valid 0.43857867976666887
LOSS train 0.5791481888647807 valid 0.4386870357706103
LOSS train 0.5791481888647807 valid 0.4386777644572051
LOSS train 0.5791481888647807 valid 0.43871423240341895
LOSS train 0.5791481888647807 valid 0.438662067356302
LOSS train 0.5791481888647807 valid 0.4387563529542123
LOSS train 0.5791481888647807 valid 0.43877628189444884
LOSS train 0.5791481888647807 valid 0.43877108684607913
LOSS train 0.5791481888647807 valid 0.4387326145443821
LOSS train 0.5791481888647807 valid 0.4387481627477841
LOSS train 0.5791481888647807 valid 0.4387575869182014
LOSS train 0.5791481888647807 valid 0.4387635652628322
LOSS train 0.5791481888647807 valid 0.43879946369520373
LOSS train 0.5791481888647807 valid 0.4388591419444995
LOSS train 0.5791481888647807 valid 0.43882411334361016
LOSS train 0.5791481888647807 valid 0.4387639921637221
LOSS train 0.5791481888647807 valid 0.43875511268719325
LOSS train 0.5791481888647807 valid 0.4387604861623711
LOSS train 0.5791481888647807 valid 0.43882309201681713
LOSS train 0.5791481888647807 valid 0.43884973993617526
LOSS train 0.5791481888647807 valid 0.4388703945254491
LOSS train 0.5791481888647807 valid 0.43890162377239583
LOSS train 0.5791481888647807 valid 0.4389347743498136
LOSS train 0.5791481888647807 valid 0.43891629829107087
LOSS train 0.5791481888647807 valid 0.43885599332544395
LOSS train 0.5791481888647807 valid 0.4388918802142143
LOSS train 0.5791481888647807 valid 0.43890783966072205
EPOCH 11:
  batch 1 loss: 0.55742347240448
  batch 2 loss: 0.5531656742095947
  batch 3 loss: 0.5620892445246378
  batch 4 loss: 0.5757971405982971
  batch 5 loss: 0.5792215824127197
  batch 6 loss: 0.5755384167035421
  batch 7 loss: 0.5806076952389309
  batch 8 loss: 0.5795572623610497
  batch 9 loss: 0.5797993673218621
  batch 10 loss: 0.580248898267746
  batch 11 loss: 0.5825875672427091
  batch 12 loss: 0.5855586528778076
  batch 13 loss: 0.5859546661376953
  batch 14 loss: 0.5858036960874285
  batch 15 loss: 0.5875365734100342
  batch 16 loss: 0.5867841690778732
  batch 17 loss: 0.5875584167592666
  batch 18 loss: 0.5862248606152005
  batch 19 loss: 0.5858275796237745
  batch 20 loss: 0.5864132732152939
  batch 21 loss: 0.5859862424078441
  batch 22 loss: 0.5859861888668754
  batch 23 loss: 0.5852175043976825
  batch 24 loss: 0.585070384045442
  batch 25 loss: 0.5863704061508179
  batch 26 loss: 0.5845494637122521
  batch 27 loss: 0.584606632038399
  batch 28 loss: 0.5835305941956384
  batch 29 loss: 0.5837023032122645
  batch 30 loss: 0.5827472388744355
  batch 31 loss: 0.5823005303259818
  batch 32 loss: 0.5817316211760044
  batch 33 loss: 0.5815027410333807
  batch 34 loss: 0.5809064349707436
  batch 35 loss: 0.5825765183993749
  batch 36 loss: 0.5824641469452116
  batch 37 loss: 0.5816744243776476
  batch 38 loss: 0.581367407974444
  batch 39 loss: 0.5811549241726215
  batch 40 loss: 0.5805836856365204
  batch 41 loss: 0.5803899212581355
  batch 42 loss: 0.580789837099257
  batch 43 loss: 0.5803503726803979
  batch 44 loss: 0.5801640166477724
  batch 45 loss: 0.5801317161983914
  batch 46 loss: 0.5796847965406335
  batch 47 loss: 0.5798964918927944
  batch 48 loss: 0.5792463111380736
  batch 49 loss: 0.5783849796470331
  batch 50 loss: 0.5786727440357208
  batch 51 loss: 0.578053726869471
  batch 52 loss: 0.5786278947041585
  batch 53 loss: 0.5787084440015396
  batch 54 loss: 0.5785602242858322
  batch 55 loss: 0.5783472516319969
  batch 56 loss: 0.578249814254897
  batch 57 loss: 0.578478035173918
  batch 58 loss: 0.5781273636324652
  batch 59 loss: 0.5777666740498301
  batch 60 loss: 0.5778768946727116
  batch 61 loss: 0.5776779397589261
  batch 62 loss: 0.5779562188733008
  batch 63 loss: 0.5778328643904792
  batch 64 loss: 0.577794405631721
  batch 65 loss: 0.5776487579712501
  batch 66 loss: 0.5774339139461517
  batch 67 loss: 0.5779430581562555
  batch 68 loss: 0.5781969542012495
  batch 69 loss: 0.5782484239426212
  batch 70 loss: 0.57865246960095
  batch 71 loss: 0.5788129593285036
  batch 72 loss: 0.578527360326714
  batch 73 loss: 0.5782507004803175
  batch 74 loss: 0.5785058406559197
  batch 75 loss: 0.5786945311228434
  batch 76 loss: 0.5789014885300084
  batch 77 loss: 0.578599889557083
  batch 78 loss: 0.5780061903672341
  batch 79 loss: 0.5782906880861596
  batch 80 loss: 0.578121967613697
  batch 81 loss: 0.5781540561605383
  batch 82 loss: 0.5787313987569112
  batch 83 loss: 0.5788729578615671
  batch 84 loss: 0.5790770749251047
  batch 85 loss: 0.5783179668819203
  batch 86 loss: 0.5787411165791888
  batch 87 loss: 0.5790233831296022
  batch 88 loss: 0.5789237137545239
  batch 89 loss: 0.5787930669409506
  batch 90 loss: 0.5785688519477844
  batch 91 loss: 0.5787670887433566
  batch 92 loss: 0.5786632655755334
  batch 93 loss: 0.5788204625088681
  batch 94 loss: 0.5789902533622499
  batch 95 loss: 0.579310166835785
  batch 96 loss: 0.5791934213290612
  batch 97 loss: 0.5791806375857481
  batch 98 loss: 0.5794361002591192
  batch 99 loss: 0.5793754771502331
  batch 100 loss: 0.5794449210166931
  batch 101 loss: 0.5793537220152298
  batch 102 loss: 0.579612231722065
  batch 103 loss: 0.579668488317323
  batch 104 loss: 0.579744781439121
  batch 105 loss: 0.5799723295938402
  batch 106 loss: 0.5798919437066564
  batch 107 loss: 0.5798925846536583
  batch 108 loss: 0.5797088256588688
  batch 109 loss: 0.5797575444256494
  batch 110 loss: 0.5798672881993381
  batch 111 loss: 0.5798509008175617
  batch 112 loss: 0.5796813672142369
  batch 113 loss: 0.57976465678848
  batch 114 loss: 0.58000676046338
  batch 115 loss: 0.5798811586006828
  batch 116 loss: 0.5799088884016563
  batch 117 loss: 0.5799900889396667
  batch 118 loss: 0.5799506114701093
  batch 119 loss: 0.5799191824528349
  batch 120 loss: 0.5798489545782407
  batch 121 loss: 0.5796400934211479
  batch 122 loss: 0.5796454416923835
  batch 123 loss: 0.5796032421957187
  batch 124 loss: 0.5798244884898586
  batch 125 loss: 0.5797449212074279
  batch 126 loss: 0.5795077151722379
  batch 127 loss: 0.5797886022432582
  batch 128 loss: 0.5794972805306315
  batch 129 loss: 0.5792020051054252
  batch 130 loss: 0.5792456296774057
  batch 131 loss: 0.5790517375669406
  batch 132 loss: 0.5790838436646895
  batch 133 loss: 0.5793101913050601
  batch 134 loss: 0.5793357878478606
  batch 135 loss: 0.5794201528584516
  batch 136 loss: 0.5792472064495087
  batch 137 loss: 0.579393635701089
  batch 138 loss: 0.5794386328130529
  batch 139 loss: 0.579371958327808
  batch 140 loss: 0.5793303178889411
  batch 141 loss: 0.5791636861807911
  batch 142 loss: 0.5791265515374465
  batch 143 loss: 0.578988353272418
  batch 144 loss: 0.5788732125527329
  batch 145 loss: 0.5789870948627077
  batch 146 loss: 0.5789490648328441
  batch 147 loss: 0.5788923680376844
  batch 148 loss: 0.5789342788425652
  batch 149 loss: 0.5788343280753834
  batch 150 loss: 0.57883926431338
  batch 151 loss: 0.5790310091530251
  batch 152 loss: 0.5791557529254964
  batch 153 loss: 0.5790145806237763
  batch 154 loss: 0.579068891026757
  batch 155 loss: 0.5793019560075575
  batch 156 loss: 0.5794542496785139
  batch 157 loss: 0.579657036407738
  batch 158 loss: 0.5795927730542195
  batch 159 loss: 0.5796575602495445
  batch 160 loss: 0.5797500785440206
  batch 161 loss: 0.5799654859193364
  batch 162 loss: 0.5799298242286399
  batch 163 loss: 0.5798528172487131
  batch 164 loss: 0.5797064958549127
  batch 165 loss: 0.579627648266879
  batch 166 loss: 0.5796225063772087
  batch 167 loss: 0.5795409229701151
  batch 168 loss: 0.5796848414909272
  batch 169 loss: 0.5796498726810929
  batch 170 loss: 0.5798146230332991
  batch 171 loss: 0.5798410752363372
  batch 172 loss: 0.5797641959994339
  batch 173 loss: 0.5798183331599814
  batch 174 loss: 0.5797503676222658
  batch 175 loss: 0.5796789622306824
  batch 176 loss: 0.5796258798377081
  batch 177 loss: 0.5794740750291253
  batch 178 loss: 0.5792667527547043
  batch 179 loss: 0.5792923243352155
  batch 180 loss: 0.579268949230512
  batch 181 loss: 0.5793499343961642
  batch 182 loss: 0.5793099092258202
  batch 183 loss: 0.5795280594643348
  batch 184 loss: 0.5795090434991795
  batch 185 loss: 0.5796090970168243
  batch 186 loss: 0.5795700050169422
  batch 187 loss: 0.5795501572563049
  batch 188 loss: 0.5794644076773461
  batch 189 loss: 0.5792557108339178
  batch 190 loss: 0.5791492424513164
  batch 191 loss: 0.5791891454402065
  batch 192 loss: 0.5792646743357182
  batch 193 loss: 0.5792398357020758
  batch 194 loss: 0.5791631552976432
  batch 195 loss: 0.5791952148461953
  batch 196 loss: 0.5791989756481988
  batch 197 loss: 0.579182226645765
  batch 198 loss: 0.5791964115518512
  batch 199 loss: 0.5791573710178011
  batch 200 loss: 0.5791013127565384
  batch 201 loss: 0.5791502173860275
  batch 202 loss: 0.5792121468204083
  batch 203 loss: 0.5792535446547522
  batch 204 loss: 0.579116721071449
  batch 205 loss: 0.5790943061433187
  batch 206 loss: 0.5789033779241506
  batch 207 loss: 0.5788371393070129
  batch 208 loss: 0.5788223835138174
  batch 209 loss: 0.5787703637301066
  batch 210 loss: 0.5787768713065556
  batch 211 loss: 0.5787818604170993
  batch 212 loss: 0.5786541787520895
  batch 213 loss: 0.5787511616245682
  batch 214 loss: 0.5785808031247041
  batch 215 loss: 0.578445002921792
  batch 216 loss: 0.5783150593439738
  batch 217 loss: 0.5781209185925497
  batch 218 loss: 0.5779901494126801
  batch 219 loss: 0.5778834270015699
  batch 220 loss: 0.5777973421595314
  batch 221 loss: 0.5777132912998286
  batch 222 loss: 0.5778367283107998
  batch 223 loss: 0.5777828909891068
  batch 224 loss: 0.5778211464307138
  batch 225 loss: 0.5777458786964417
  batch 226 loss: 0.5778771947442958
  batch 227 loss: 0.5777815871826878
  batch 228 loss: 0.5776976529966321
  batch 229 loss: 0.5776986945664518
  batch 230 loss: 0.5777194435181825
  batch 231 loss: 0.5778514846062763
  batch 232 loss: 0.57779311388731
  batch 233 loss: 0.5777665660616665
  batch 234 loss: 0.5776928823727828
  batch 235 loss: 0.5777142253327877
  batch 236 loss: 0.577638636706239
  batch 237 loss: 0.5777534558300228
  batch 238 loss: 0.5776530734631193
  batch 239 loss: 0.5776791293251964
  batch 240 loss: 0.5776737228035926
  batch 241 loss: 0.5776760667191502
  batch 242 loss: 0.5775867853282897
  batch 243 loss: 0.5775164086141704
  batch 244 loss: 0.5776149532834037
  batch 245 loss: 0.5775568300363969
  batch 246 loss: 0.5776920468826604
  batch 247 loss: 0.5776253926609209
  batch 248 loss: 0.5775411547191681
  batch 249 loss: 0.5775981514329412
  batch 250 loss: 0.5775989241600037
  batch 251 loss: 0.5777118745078129
  batch 252 loss: 0.5777734477841665
  batch 253 loss: 0.5777338632481842
  batch 254 loss: 0.577674569811408
  batch 255 loss: 0.5776047222754535
  batch 256 loss: 0.577578418655321
  batch 257 loss: 0.5777842260984132
  batch 258 loss: 0.5777133021705835
  batch 259 loss: 0.5775902308092155
  batch 260 loss: 0.5775524480984762
  batch 261 loss: 0.5775387600007185
  batch 262 loss: 0.577547573861275
  batch 263 loss: 0.5774677284770139
  batch 264 loss: 0.577376665039496
  batch 265 loss: 0.5772704387610813
  batch 266 loss: 0.5772202503412289
  batch 267 loss: 0.5773716852459568
  batch 268 loss: 0.5772731648897057
  batch 269 loss: 0.5773712868584133
  batch 270 loss: 0.5774086261237109
  batch 271 loss: 0.5774513056357409
  batch 272 loss: 0.5774655383737648
  batch 273 loss: 0.5774717106050624
  batch 274 loss: 0.5775002878512779
  batch 275 loss: 0.577587070681832
  batch 276 loss: 0.5776074677705765
  batch 277 loss: 0.577582013090595
  batch 278 loss: 0.5776263447545416
  batch 279 loss: 0.5776410382708341
  batch 280 loss: 0.5776826588170869
  batch 281 loss: 0.5776545863558813
  batch 282 loss: 0.5775054122539277
  batch 283 loss: 0.5773749416792772
  batch 284 loss: 0.5774050938411498
  batch 285 loss: 0.5774154073313663
  batch 286 loss: 0.5773744818630752
  batch 287 loss: 0.5773837221624128
  batch 288 loss: 0.5772274446984133
  batch 289 loss: 0.5772819337547856
  batch 290 loss: 0.577069499985925
  batch 291 loss: 0.5770368852566198
  batch 292 loss: 0.5771307588031848
  batch 293 loss: 0.5771443939453099
  batch 294 loss: 0.5771006862727963
  batch 295 loss: 0.5771122890003657
  batch 296 loss: 0.5770787167790774
  batch 297 loss: 0.5770540692990878
  batch 298 loss: 0.577013490384057
  batch 299 loss: 0.5770280759868813
  batch 300 loss: 0.5771584955851237
  batch 301 loss: 0.577097111762164
  batch 302 loss: 0.577021651710106
  batch 303 loss: 0.5771283383416658
  batch 304 loss: 0.5770986099776468
  batch 305 loss: 0.5769398261289127
  batch 306 loss: 0.5769001475346633
  batch 307 loss: 0.576904296875
  batch 308 loss: 0.5769208733524595
  batch 309 loss: 0.5768251675618119
  batch 310 loss: 0.5768024892576279
  batch 311 loss: 0.5769433693487162
  batch 312 loss: 0.5769118893987093
  batch 313 loss: 0.5769108794748593
  batch 314 loss: 0.576841356458178
  batch 315 loss: 0.5767830309413728
  batch 316 loss: 0.5766727564078343
  batch 317 loss: 0.5767146484332882
  batch 318 loss: 0.5765757058401527
  batch 319 loss: 0.5765139533434542
  batch 320 loss: 0.5765267809852958
  batch 321 loss: 0.5764451095619677
  batch 322 loss: 0.5765250815738062
  batch 323 loss: 0.5765276482968876
  batch 324 loss: 0.5765176150533888
  batch 325 loss: 0.5765644662196819
  batch 326 loss: 0.576527297679632
  batch 327 loss: 0.5765081288617685
  batch 328 loss: 0.5764762286732836
  batch 329 loss: 0.5764636381056534
  batch 330 loss: 0.5764491500276507
  batch 331 loss: 0.5764641023474517
  batch 332 loss: 0.5765127931014601
  batch 333 loss: 0.5765379355834411
  batch 334 loss: 0.576523464596914
  batch 335 loss: 0.5764457538946351
  batch 336 loss: 0.5763823207290399
  batch 337 loss: 0.5762403911582087
  batch 338 loss: 0.5762949816926697
  batch 339 loss: 0.5763459555519014
  batch 340 loss: 0.576368300704395
  batch 341 loss: 0.5763170159806954
  batch 342 loss: 0.5762603007561979
  batch 343 loss: 0.5763059600796714
  batch 344 loss: 0.5763234988201497
  batch 345 loss: 0.5764636162398518
  batch 346 loss: 0.576286229095018
  batch 347 loss: 0.5762961024166184
  batch 348 loss: 0.5763956167917142
  batch 349 loss: 0.576377122142595
  batch 350 loss: 0.5763714865275792
  batch 351 loss: 0.5764647114310849
  batch 352 loss: 0.5764827575873245
  batch 353 loss: 0.5764720809696079
  batch 354 loss: 0.5765446240955827
  batch 355 loss: 0.5766338544832149
  batch 356 loss: 0.5766359073727318
  batch 357 loss: 0.5765716663929594
  batch 358 loss: 0.576590045703856
  batch 359 loss: 0.5766328149851319
  batch 360 loss: 0.576701778670152
  batch 361 loss: 0.5766232474358789
  batch 362 loss: 0.5766481874068139
  batch 363 loss: 0.5766244331995646
  batch 364 loss: 0.5765601593059498
  batch 365 loss: 0.5765513178420394
  batch 366 loss: 0.5766629153262071
  batch 367 loss: 0.5765442265151957
  batch 368 loss: 0.5764772963264714
  batch 369 loss: 0.5764716679487771
  batch 370 loss: 0.5765516337510702
  batch 371 loss: 0.5765535820205256
  batch 372 loss: 0.5765426993690511
  batch 373 loss: 0.5765413888018508
  batch 374 loss: 0.5765136810228786
  batch 375 loss: 0.5765150930086772
  batch 376 loss: 0.5766173726383675
  batch 377 loss: 0.5765800446034742
  batch 378 loss: 0.5764899706398999
  batch 379 loss: 0.5765031096488631
  batch 380 loss: 0.5765736076392626
  batch 381 loss: 0.5764469995586265
  batch 382 loss: 0.5763872552916641
  batch 383 loss: 0.5764166676967013
  batch 384 loss: 0.5764350869382421
  batch 385 loss: 0.5765155717924044
  batch 386 loss: 0.5764551138013138
  batch 387 loss: 0.5764710524285487
  batch 388 loss: 0.5765179454051342
  batch 389 loss: 0.5765689599176912
  batch 390 loss: 0.5766297285373394
  batch 391 loss: 0.5766314301649322
  batch 392 loss: 0.5765530327144934
  batch 393 loss: 0.5765922991677398
  batch 394 loss: 0.5766317320959217
  batch 395 loss: 0.5766181496125233
  batch 396 loss: 0.5766099354233405
  batch 397 loss: 0.5765965999824274
  batch 398 loss: 0.5765022138255326
  batch 399 loss: 0.5765566911016192
  batch 400 loss: 0.5764750017225743
  batch 401 loss: 0.5764330424870041
  batch 402 loss: 0.5764388087673566
  batch 403 loss: 0.5764320751573548
  batch 404 loss: 0.5764422335542074
  batch 405 loss: 0.5764052698641647
  batch 406 loss: 0.5764176452101157
  batch 407 loss: 0.5764481622991163
  batch 408 loss: 0.5765214242479381
  batch 409 loss: 0.5764982362248204
  batch 410 loss: 0.5765095376386875
  batch 411 loss: 0.5765247526250037
  batch 412 loss: 0.5764968108783648
  batch 413 loss: 0.5764843075385105
  batch 414 loss: 0.5765095787923693
  batch 415 loss: 0.5765574357595789
  batch 416 loss: 0.5764921734539362
  batch 417 loss: 0.5764764660268092
  batch 418 loss: 0.5765141605190113
  batch 419 loss: 0.5766076239310471
  batch 420 loss: 0.5766993156501226
  batch 421 loss: 0.57668258826693
  batch 422 loss: 0.5767247450860191
  batch 423 loss: 0.5767058466624988
  batch 424 loss: 0.5766381323337555
  batch 425 loss: 0.5767490466903238
  batch 426 loss: 0.5767464879812769
  batch 427 loss: 0.5767301891950031
  batch 428 loss: 0.576655461687908
  batch 429 loss: 0.576642513414085
  batch 430 loss: 0.5766375421091567
  batch 431 loss: 0.576628469397463
  batch 432 loss: 0.5766164272747658
  batch 433 loss: 0.5765416037127823
  batch 434 loss: 0.5765685436363044
  batch 435 loss: 0.5766112006943801
  batch 436 loss: 0.576554669152706
  batch 437 loss: 0.5767158103480219
  batch 438 loss: 0.5768650947096141
  batch 439 loss: 0.5768440976772873
  batch 440 loss: 0.5768047852949663
  batch 441 loss: 0.5768034282455098
  batch 442 loss: 0.5767357404685128
  batch 443 loss: 0.5767480262784334
  batch 444 loss: 0.5767635280216062
  batch 445 loss: 0.5767247793379794
  batch 446 loss: 0.5767598249719816
  batch 447 loss: 0.5766975304957738
  batch 448 loss: 0.5767435850575566
  batch 449 loss: 0.5767450538403738
  batch 450 loss: 0.5767359668678708
  batch 451 loss: 0.5767698713522529
  batch 452 loss: 0.5767372974516016
  batch 453 loss: 0.5766837758733737
  batch 454 loss: 0.5766943364941601
  batch 455 loss: 0.576754363159557
  batch 456 loss: 0.5767800221056268
  batch 457 loss: 0.5768362187191486
  batch 458 loss: 0.5767885680802525
  batch 459 loss: 0.5768113471324148
  batch 460 loss: 0.5768898155378259
  batch 461 loss: 0.5769458086009657
  batch 462 loss: 0.5769624010825054
  batch 463 loss: 0.5770084702170436
  batch 464 loss: 0.5771005509485458
  batch 465 loss: 0.5770695106957549
  batch 466 loss: 0.5770524336033113
  batch 467 loss: 0.577048290465067
  batch 468 loss: 0.5769766766546119
  batch 469 loss: 0.5769773459892029
  batch 470 loss: 0.5769165934400355
  batch 471 loss: 0.5769472468937026
  batch 472 loss: 0.5769333620950327
LOSS train 0.5769333620950327 valid 0.42864280939102173
LOSS train 0.5769333620950327 valid 0.43924371898174286
LOSS train 0.5769333620950327 valid 0.4375291168689728
LOSS train 0.5769333620950327 valid 0.43407975882291794
LOSS train 0.5769333620950327 valid 0.43004112839698794
LOSS train 0.5769333620950327 valid 0.43436940014362335
LOSS train 0.5769333620950327 valid 0.4396320624010904
LOSS train 0.5769333620950327 valid 0.4401671253144741
LOSS train 0.5769333620950327 valid 0.4407319128513336
LOSS train 0.5769333620950327 valid 0.44217349886894225
LOSS train 0.5769333620950327 valid 0.4453330554745414
LOSS train 0.5769333620950327 valid 0.4449765334526698
LOSS train 0.5769333620950327 valid 0.4472112816113692
LOSS train 0.5769333620950327 valid 0.4484216549566814
LOSS train 0.5769333620950327 valid 0.4491594056288401
LOSS train 0.5769333620950327 valid 0.44767835922539234
LOSS train 0.5769333620950327 valid 0.44882465285413403
LOSS train 0.5769333620950327 valid 0.448560420009825
LOSS train 0.5769333620950327 valid 0.4478616432139748
LOSS train 0.5769333620950327 valid 0.44860933274030684
LOSS train 0.5769333620950327 valid 0.44876836736996967
LOSS train 0.5769333620950327 valid 0.44686579975214874
LOSS train 0.5769333620950327 valid 0.4466969889143239
LOSS train 0.5769333620950327 valid 0.4459175119797389
LOSS train 0.5769333620950327 valid 0.4452352571487427
LOSS train 0.5769333620950327 valid 0.44440369193370527
LOSS train 0.5769333620950327 valid 0.44465764253227796
LOSS train 0.5769333620950327 valid 0.4450446388551167
LOSS train 0.5769333620950327 valid 0.44390041047129136
LOSS train 0.5769333620950327 valid 0.444574228922526
LOSS train 0.5769333620950327 valid 0.4453872240358783
LOSS train 0.5769333620950327 valid 0.4454936319962144
LOSS train 0.5769333620950327 valid 0.4465718386751233
LOSS train 0.5769333620950327 valid 0.4477590199779062
LOSS train 0.5769333620950327 valid 0.44846986106463843
LOSS train 0.5769333620950327 valid 0.4487856717573272
LOSS train 0.5769333620950327 valid 0.448952046600548
LOSS train 0.5769333620950327 valid 0.4487112893870002
LOSS train 0.5769333620950327 valid 0.44837876237355745
LOSS train 0.5769333620950327 valid 0.4486718975007534
LOSS train 0.5769333620950327 valid 0.4490939742181359
LOSS train 0.5769333620950327 valid 0.4490353734720321
LOSS train 0.5769333620950327 valid 0.44872676910356035
LOSS train 0.5769333620950327 valid 0.44880341806195
LOSS train 0.5769333620950327 valid 0.4486587166786194
LOSS train 0.5769333620950327 valid 0.4491052711787431
LOSS train 0.5769333620950327 valid 0.4489997606328193
LOSS train 0.5769333620950327 valid 0.44955157053967315
LOSS train 0.5769333620950327 valid 0.45005779302850063
LOSS train 0.5769333620950327 valid 0.4492583739757538
LOSS train 0.5769333620950327 valid 0.4498480441523533
LOSS train 0.5769333620950327 valid 0.44975909762657607
LOSS train 0.5769333620950327 valid 0.4493527665453137
LOSS train 0.5769333620950327 valid 0.44893306107432757
LOSS train 0.5769333620950327 valid 0.4490259278904308
LOSS train 0.5769333620950327 valid 0.44874266747917446
LOSS train 0.5769333620950327 valid 0.4483226187396468
LOSS train 0.5769333620950327 valid 0.448098994020758
LOSS train 0.5769333620950327 valid 0.4484619781122369
LOSS train 0.5769333620950327 valid 0.4482309858004252
LOSS train 0.5769333620950327 valid 0.447509018124127
LOSS train 0.5769333620950327 valid 0.4475960760347305
LOSS train 0.5769333620950327 valid 0.447472578003293
LOSS train 0.5769333620950327 valid 0.44794191885739565
LOSS train 0.5769333620950327 valid 0.4481329844548152
LOSS train 0.5769333620950327 valid 0.44807908074422315
LOSS train 0.5769333620950327 valid 0.4478505489541523
LOSS train 0.5769333620950327 valid 0.4481685205417521
LOSS train 0.5769333620950327 valid 0.4481537367986596
LOSS train 0.5769333620950327 valid 0.4477778647627149
LOSS train 0.5769333620950327 valid 0.44760488834179624
LOSS train 0.5769333620950327 valid 0.44733354614840615
LOSS train 0.5769333620950327 valid 0.447524270782732
LOSS train 0.5769333620950327 valid 0.44716290122753866
LOSS train 0.5769333620950327 valid 0.44706015984217323
LOSS train 0.5769333620950327 valid 0.4472895127378012
LOSS train 0.5769333620950327 valid 0.44718685320445467
LOSS train 0.5769333620950327 valid 0.4472671731924399
LOSS train 0.5769333620950327 valid 0.44697062048730973
LOSS train 0.5769333620950327 valid 0.44686205945909024
LOSS train 0.5769333620950327 valid 0.4466166853168864
LOSS train 0.5769333620950327 valid 0.44660801167895153
LOSS train 0.5769333620950327 valid 0.44655096495007895
LOSS train 0.5769333620950327 valid 0.4466694174777894
LOSS train 0.5769333620950327 valid 0.4465486831524793
LOSS train 0.5769333620950327 valid 0.446424154001613
LOSS train 0.5769333620950327 valid 0.44637214829181804
LOSS train 0.5769333620950327 valid 0.4462470280175859
LOSS train 0.5769333620950327 valid 0.4464167667908615
LOSS train 0.5769333620950327 valid 0.4465643541680442
LOSS train 0.5769333620950327 valid 0.44666554999875496
LOSS train 0.5769333620950327 valid 0.44653925137675327
LOSS train 0.5769333620950327 valid 0.44642903695824326
LOSS train 0.5769333620950327 valid 0.4463530959601098
LOSS train 0.5769333620950327 valid 0.44617629584513213
LOSS train 0.5769333620950327 valid 0.4459780513619383
LOSS train 0.5769333620950327 valid 0.44614965245895777
LOSS train 0.5769333620950327 valid 0.4459097187738029
LOSS train 0.5769333620950327 valid 0.44616337135584666
LOSS train 0.5769333620950327 valid 0.4462341958284378
LOSS train 0.5769333620950327 valid 0.4462755552612909
LOSS train 0.5769333620950327 valid 0.4463626496932086
LOSS train 0.5769333620950327 valid 0.44667254229193754
LOSS train 0.5769333620950327 valid 0.44665404953635657
LOSS train 0.5769333620950327 valid 0.4467534403006236
LOSS train 0.5769333620950327 valid 0.4467944747434472
LOSS train 0.5769333620950327 valid 0.4466147918567479
LOSS train 0.5769333620950327 valid 0.44676597554374625
LOSS train 0.5769333620950327 valid 0.4469951541598784
LOSS train 0.5769333620950327 valid 0.44720551100644196
LOSS train 0.5769333620950327 valid 0.44726161162058514
LOSS train 0.5769333620950327 valid 0.4474390963358538
LOSS train 0.5769333620950327 valid 0.447480206468464
LOSS train 0.5769333620950327 valid 0.44724557169696744
LOSS train 0.5769333620950327 valid 0.44736051041146985
LOSS train 0.5769333620950327 valid 0.4475228812160163
LOSS train 0.5769333620950327 valid 0.44744536535352725
LOSS train 0.5769333620950327 valid 0.4473925581422903
LOSS train 0.5769333620950327 valid 0.4474254298109968
LOSS train 0.5769333620950327 valid 0.44745299890637397
LOSS train 0.5769333620950327 valid 0.44741867716647377
LOSS train 0.5769333620950327 valid 0.4472696014115068
LOSS train 0.5769333620950327 valid 0.44727808043239564
LOSS train 0.5769333620950327 valid 0.44738271063373936
LOSS train 0.5769333620950327 valid 0.44737581539154053
LOSS train 0.5769333620950327 valid 0.4472418006450411
LOSS train 0.5769333620950327 valid 0.44741219141351896
LOSS train 0.5769333620950327 valid 0.44761826493777335
LOSS train 0.5769333620950327 valid 0.44774502585100573
LOSS train 0.5769333620950327 valid 0.44761066001195177
LOSS train 0.5769333620950327 valid 0.44753536399994187
LOSS train 0.5769333620950327 valid 0.4473935446955941
LOSS train 0.5769333620950327 valid 0.44728699640223857
LOSS train 0.5769333620950327 valid 0.44722481828127336
LOSS train 0.5769333620950327 valid 0.447307680050532
LOSS train 0.5769333620950327 valid 0.44730009029016776
LOSS train 0.5769333620950327 valid 0.447283060663808
LOSS train 0.5769333620950327 valid 0.4470898908549461
LOSS train 0.5769333620950327 valid 0.44698692976142007
LOSS train 0.5769333620950327 valid 0.44698580907923835
LOSS train 0.5769333620950327 valid 0.44710722142922965
LOSS train 0.5769333620950327 valid 0.44727041981589627
LOSS train 0.5769333620950327 valid 0.44721195185101115
LOSS train 0.5769333620950327 valid 0.4472715426236391
LOSS train 0.5769333620950327 valid 0.44705395924633945
LOSS train 0.5769333620950327 valid 0.44737037995906725
LOSS train 0.5769333620950327 valid 0.4472016463068878
LOSS train 0.5769333620950327 valid 0.4475342534683846
LOSS train 0.5769333620950327 valid 0.4474653309623667
LOSS train 0.5769333620950327 valid 0.4475800424814224
LOSS train 0.5769333620950327 valid 0.4477254592424986
LOSS train 0.5769333620950327 valid 0.4475884906163341
LOSS train 0.5769333620950327 valid 0.4475887859958449
LOSS train 0.5769333620950327 valid 0.44773287006786894
LOSS train 0.5769333620950327 valid 0.4476420646713626
LOSS train 0.5769333620950327 valid 0.44786437237874055
LOSS train 0.5769333620950327 valid 0.44788851441851085
LOSS train 0.5769333620950327 valid 0.4479311715952958
LOSS train 0.5769333620950327 valid 0.4478032581461301
LOSS train 0.5769333620950327 valid 0.4478143393993378
LOSS train 0.5769333620950327 valid 0.44790026545524597
LOSS train 0.5769333620950327 valid 0.44780924419562024
LOSS train 0.5769333620950327 valid 0.4477911037535755
LOSS train 0.5769333620950327 valid 0.44770332934652884
LOSS train 0.5769333620950327 valid 0.4475595317103646
LOSS train 0.5769333620950327 valid 0.44734590150505665
LOSS train 0.5769333620950327 valid 0.44751403627995245
LOSS train 0.5769333620950327 valid 0.4476257901461351
LOSS train 0.5769333620950327 valid 0.44762686388732414
LOSS train 0.5769333620950327 valid 0.4476266845184214
LOSS train 0.5769333620950327 valid 0.44785187955488237
LOSS train 0.5769333620950327 valid 0.4479452406251153
LOSS train 0.5769333620950327 valid 0.44806263522605677
LOSS train 0.5769333620950327 valid 0.4480634999686274
LOSS train 0.5769333620950327 valid 0.44813313620431083
LOSS train 0.5769333620950327 valid 0.44823366014117544
LOSS train 0.5769333620950327 valid 0.44826120592780033
LOSS train 0.5769333620950327 valid 0.4484588579180535
LOSS train 0.5769333620950327 valid 0.4484955636815652
LOSS train 0.5769333620950327 valid 0.44863923258251615
LOSS train 0.5769333620950327 valid 0.4487157111668455
LOSS train 0.5769333620950327 valid 0.4487341576880151
LOSS train 0.5769333620950327 valid 0.4487999951253172
LOSS train 0.5769333620950327 valid 0.448854324610337
LOSS train 0.5769333620950327 valid 0.4488119420167562
LOSS train 0.5769333620950327 valid 0.4488400701553591
LOSS train 0.5769333620950327 valid 0.448969160490495
LOSS train 0.5769333620950327 valid 0.4490493206267661
LOSS train 0.5769333620950327 valid 0.4489908379221719
LOSS train 0.5769333620950327 valid 0.4489557972079829
LOSS train 0.5769333620950327 valid 0.44912251752084464
LOSS train 0.5769333620950327 valid 0.4492656186533471
LOSS train 0.5769333620950327 valid 0.44929538319765594
LOSS train 0.5769333620950327 valid 0.44916252008418445
LOSS train 0.5769333620950327 valid 0.4490328010840294
LOSS train 0.5769333620950327 valid 0.44911531389367826
LOSS train 0.5769333620950327 valid 0.4491806664140091
LOSS train 0.5769333620950327 valid 0.44905319313208264
LOSS train 0.5769333620950327 valid 0.44907827832590996
LOSS train 0.5769333620950327 valid 0.44911458253860476
LOSS train 0.5769333620950327 valid 0.449055731148269
LOSS train 0.5769333620950327 valid 0.4490854999806621
LOSS train 0.5769333620950327 valid 0.44903532595470036
LOSS train 0.5769333620950327 valid 0.4490766358726165
LOSS train 0.5769333620950327 valid 0.44898442320707366
LOSS train 0.5769333620950327 valid 0.4490680353155414
LOSS train 0.5769333620950327 valid 0.44912027175299785
LOSS train 0.5769333620950327 valid 0.44910867211337274
LOSS train 0.5769333620950327 valid 0.4489455936057716
LOSS train 0.5769333620950327 valid 0.4488653066612425
LOSS train 0.5769333620950327 valid 0.4489533375789769
LOSS train 0.5769333620950327 valid 0.44895580973265303
LOSS train 0.5769333620950327 valid 0.44899752372307394
LOSS train 0.5769333620950327 valid 0.44894092885133263
LOSS train 0.5769333620950327 valid 0.448855766307476
LOSS train 0.5769333620950327 valid 0.4488546958676091
LOSS train 0.5769333620950327 valid 0.4489778975187908
LOSS train 0.5769333620950327 valid 0.4489517176370008
LOSS train 0.5769333620950327 valid 0.448946217695872
LOSS train 0.5769333620950327 valid 0.4489142594012347
LOSS train 0.5769333620950327 valid 0.44893941229285156
LOSS train 0.5769333620950327 valid 0.44906680822909417
LOSS train 0.5769333620950327 valid 0.4491871861331666
LOSS train 0.5769333620950327 valid 0.4491994826655303
LOSS train 0.5769333620950327 valid 0.4491534539063772
LOSS train 0.5769333620950327 valid 0.44901106289002746
LOSS train 0.5769333620950327 valid 0.44912774000924066
LOSS train 0.5769333620950327 valid 0.4492015260876271
LOSS train 0.5769333620950327 valid 0.4492701803492667
LOSS train 0.5769333620950327 valid 0.44936415877031244
LOSS train 0.5769333620950327 valid 0.4492168801945525
LOSS train 0.5769333620950327 valid 0.44924292970320273
LOSS train 0.5769333620950327 valid 0.4490989605244649
LOSS train 0.5769333620950327 valid 0.4491125107066244
LOSS train 0.5769333620950327 valid 0.44921305040095716
LOSS train 0.5769333620950327 valid 0.4491907755954791
LOSS train 0.5769333620950327 valid 0.44914267284457693
LOSS train 0.5769333620950327 valid 0.4490716184387688
LOSS train 0.5769333620950327 valid 0.44907179936205494
LOSS train 0.5769333620950327 valid 0.4489995310703913
LOSS train 0.5769333620950327 valid 0.44903937996175775
LOSS train 0.5769333620950327 valid 0.44903173168336064
LOSS train 0.5769333620950327 valid 0.4490022167502117
LOSS train 0.5769333620950327 valid 0.44905731057534454
LOSS train 0.5769333620950327 valid 0.4490427803020088
LOSS train 0.5769333620950327 valid 0.44896463662143643
LOSS train 0.5769333620950327 valid 0.44921569387439775
LOSS train 0.5769333620950327 valid 0.44916410768224346
LOSS train 0.5769333620950327 valid 0.4491105772644641
LOSS train 0.5769333620950327 valid 0.4492119026184082
LOSS train 0.5769333620950327 valid 0.44918444182768286
LOSS train 0.5769333620950327 valid 0.44925515814906075
LOSS train 0.5769333620950327 valid 0.4493582231018383
LOSS train 0.5769333620950327 valid 0.44938150282919875
LOSS train 0.5769333620950327 valid 0.4493564290158889
LOSS train 0.5769333620950327 valid 0.44936718221288174
LOSS train 0.5769333620950327 valid 0.4493426695639985
LOSS train 0.5769333620950327 valid 0.44936249641947046
LOSS train 0.5769333620950327 valid 0.4494056107915046
LOSS train 0.5769333620950327 valid 0.44946167973371653
LOSS train 0.5769333620950327 valid 0.44949941251469755
LOSS train 0.5769333620950327 valid 0.4495527546369392
LOSS train 0.5769333620950327 valid 0.4496386473849699
LOSS train 0.5769333620950327 valid 0.4496627487242222
LOSS train 0.5769333620950327 valid 0.4497204337479933
LOSS train 0.5769333620950327 valid 0.449752613341898
LOSS train 0.5769333620950327 valid 0.44975148582279906
LOSS train 0.5769333620950327 valid 0.44970253376818414
LOSS train 0.5769333620950327 valid 0.44988250355738246
LOSS train 0.5769333620950327 valid 0.4498735335138109
LOSS train 0.5769333620950327 valid 0.44992389010327327
LOSS train 0.5769333620950327 valid 0.4499805685790146
LOSS train 0.5769333620950327 valid 0.4500964932389312
LOSS train 0.5769333620950327 valid 0.4500803203478347
LOSS train 0.5769333620950327 valid 0.45002801895141603
LOSS train 0.5769333620950327 valid 0.4500578645130862
LOSS train 0.5769333620950327 valid 0.45011723880733395
LOSS train 0.5769333620950327 valid 0.450073403741816
LOSS train 0.5769333620950327 valid 0.45014383491649423
LOSS train 0.5769333620950327 valid 0.45015062785574367
LOSS train 0.5769333620950327 valid 0.45003394331796315
LOSS train 0.5769333620950327 valid 0.4499935081875916
LOSS train 0.5769333620950327 valid 0.4499560933652278
LOSS train 0.5769333620950327 valid 0.45003651743623574
LOSS train 0.5769333620950327 valid 0.45006420214970905
LOSS train 0.5769333620950327 valid 0.45000484293991033
LOSS train 0.5769333620950327 valid 0.44998221530316185
LOSS train 0.5769333620950327 valid 0.45002782593170804
LOSS train 0.5769333620950327 valid 0.4499585878065301
LOSS train 0.5769333620950327 valid 0.44995511955228346
LOSS train 0.5769333620950327 valid 0.4498132829813613
LOSS train 0.5769333620950327 valid 0.4498131496653165
LOSS train 0.5769333620950327 valid 0.44975460216453866
LOSS train 0.5769333620950327 valid 0.44974554203399997
LOSS train 0.5769333620950327 valid 0.4498711805222398
LOSS train 0.5769333620950327 valid 0.44994879644867536
LOSS train 0.5769333620950327 valid 0.44990544176663616
LOSS train 0.5769333620950327 valid 0.4498863497236431
LOSS train 0.5769333620950327 valid 0.44994790408523583
LOSS train 0.5769333620950327 valid 0.4499145966768265
LOSS train 0.5769333620950327 valid 0.4499540912154505
LOSS train 0.5769333620950327 valid 0.4498635158436188
LOSS train 0.5769333620950327 valid 0.44990758366710676
LOSS train 0.5769333620950327 valid 0.44989768268638536
LOSS train 0.5769333620950327 valid 0.4498664219848445
LOSS train 0.5769333620950327 valid 0.4498307828614914
LOSS train 0.5769333620950327 valid 0.44985417094603425
LOSS train 0.5769333620950327 valid 0.4498311375062187
LOSS train 0.5769333620950327 valid 0.449840588573499
LOSS train 0.5769333620950327 valid 0.44979714472447674
LOSS train 0.5769333620950327 valid 0.4497353980778881
LOSS train 0.5769333620950327 valid 0.4497749512203229
LOSS train 0.5769333620950327 valid 0.4498438371446567
LOSS train 0.5769333620950327 valid 0.44991884565657114
LOSS train 0.5769333620950327 valid 0.44996993872854446
LOSS train 0.5769333620950327 valid 0.4498647576834582
LOSS train 0.5769333620950327 valid 0.44992670482641517
LOSS train 0.5769333620950327 valid 0.44987642558865576
LOSS train 0.5769333620950327 valid 0.44993163827444693
LOSS train 0.5769333620950327 valid 0.449866858497262
LOSS train 0.5769333620950327 valid 0.44989685198971047
LOSS train 0.5769333620950327 valid 0.44988799483879754
LOSS train 0.5769333620950327 valid 0.44982563342103277
LOSS train 0.5769333620950327 valid 0.4498306499955095
LOSS train 0.5769333620950327 valid 0.44980736017227174
LOSS train 0.5769333620950327 valid 0.4498890536877275
LOSS train 0.5769333620950327 valid 0.4499543481463686
LOSS train 0.5769333620950327 valid 0.45007019490003586
LOSS train 0.5769333620950327 valid 0.45012137502160116
LOSS train 0.5769333620950327 valid 0.4501265424670595
LOSS train 0.5769333620950327 valid 0.4500575723784928
LOSS train 0.5769333620950327 valid 0.44997327702950285
LOSS train 0.5769333620950327 valid 0.44997625388540663
LOSS train 0.5769333620950327 valid 0.4500671154903081
LOSS train 0.5769333620950327 valid 0.44999163346504095
LOSS train 0.5769333620950327 valid 0.4500282612584886
LOSS train 0.5769333620950327 valid 0.45001892431553464
LOSS train 0.5769333620950327 valid 0.4500267607925912
LOSS train 0.5769333620950327 valid 0.44999525750984487
LOSS train 0.5769333620950327 valid 0.44996814044082867
LOSS train 0.5769333620950327 valid 0.4499084736245119
LOSS train 0.5769333620950327 valid 0.4498867070117192
LOSS train 0.5769333620950327 valid 0.44991395685485086
LOSS train 0.5769333620950327 valid 0.4500274686792562
LOSS train 0.5769333620950327 valid 0.4500238821990248
LOSS train 0.5769333620950327 valid 0.45006771945539925
LOSS train 0.5769333620950327 valid 0.4500170140513769
LOSS train 0.5769333620950327 valid 0.45010688044558994
LOSS train 0.5769333620950327 valid 0.4501359483232471
LOSS train 0.5769333620950327 valid 0.4501369866303035
LOSS train 0.5769333620950327 valid 0.45009754092944654
LOSS train 0.5769333620950327 valid 0.45010699585757474
LOSS train 0.5769333620950327 valid 0.45011526447517675
LOSS train 0.5769333620950327 valid 0.45011591852384775
LOSS train 0.5769333620950327 valid 0.45015754422671356
LOSS train 0.5769333620950327 valid 0.4502204813146859
LOSS train 0.5769333620950327 valid 0.4501703871565373
LOSS train 0.5769333620950327 valid 0.45009416882885234
LOSS train 0.5769333620950327 valid 0.45009005484806797
LOSS train 0.5769333620950327 valid 0.45010277065965865
LOSS train 0.5769333620950327 valid 0.4501507850234859
LOSS train 0.5769333620950327 valid 0.45019155098588426
LOSS train 0.5769333620950327 valid 0.4502219703079255
LOSS train 0.5769333620950327 valid 0.4502718428989033
LOSS train 0.5769333620950327 valid 0.45030859210719804
LOSS train 0.5769333620950327 valid 0.4502699801016375
LOSS train 0.5769333620950327 valid 0.45022244804236805
LOSS train 0.5769333620950327 valid 0.45025432449967967
LOSS train 0.5769333620950327 valid 0.45025936455584475
EPOCH 12:
  batch 1 loss: 0.5528749227523804
  batch 2 loss: 0.5560409426689148
  batch 3 loss: 0.5644691785176595
  batch 4 loss: 0.5788451433181763
  batch 5 loss: 0.5819414138793946
  batch 6 loss: 0.5782468815644582
  batch 7 loss: 0.5808927587100438
  batch 8 loss: 0.5788295194506645
  batch 9 loss: 0.5772319502300687
  batch 10 loss: 0.5755145251750946
  batch 11 loss: 0.5768728093667463
  batch 12 loss: 0.5784215678771337
  batch 13 loss: 0.5805835127830505
  batch 14 loss: 0.5809211773531777
  batch 15 loss: 0.5820149858792623
  batch 16 loss: 0.5812499336898327
  batch 17 loss: 0.5811855792999268
  batch 18 loss: 0.5807682474454244
  batch 19 loss: 0.5811302850120946
  batch 20 loss: 0.581558108329773
  batch 21 loss: 0.5819988818395705
  batch 22 loss: 0.5818727477030321
  batch 23 loss: 0.5813633903213169
  batch 24 loss: 0.5814538771907488
  batch 25 loss: 0.5832445192337036
  batch 26 loss: 0.5820816938693707
  batch 27 loss: 0.5819013935548288
  batch 28 loss: 0.5806428641080856
  batch 29 loss: 0.5811273990006283
  batch 30 loss: 0.5802382926146189
  batch 31 loss: 0.580299848510373
  batch 32 loss: 0.5795678775757551
  batch 33 loss: 0.5797698768702421
  batch 34 loss: 0.5798005531815922
  batch 35 loss: 0.5811065554618835
  batch 36 loss: 0.5805908954805798
  batch 37 loss: 0.5803278346319456
  batch 38 loss: 0.5798653285754355
  batch 39 loss: 0.5796794218894763
  batch 40 loss: 0.5789630621671676
  batch 41 loss: 0.5789683737405916
  batch 42 loss: 0.5793278146357763
  batch 43 loss: 0.5791007876396179
  batch 44 loss: 0.5787903097542849
  batch 45 loss: 0.5790863262282477
  batch 46 loss: 0.5786873037400453
  batch 47 loss: 0.5787707617942323
  batch 48 loss: 0.5787556916475296
  batch 49 loss: 0.5783264709978687
  batch 50 loss: 0.5785700964927674
  batch 51 loss: 0.5780718022701787
  batch 52 loss: 0.5789096389825528
  batch 53 loss: 0.5791087026865978
  batch 54 loss: 0.5789573225710127
  batch 55 loss: 0.578739793734117
  batch 56 loss: 0.578482278755733
  batch 57 loss: 0.5783741913343731
  batch 58 loss: 0.5784649848937988
  batch 59 loss: 0.5781322667154215
  batch 60 loss: 0.5780642747879028
  batch 61 loss: 0.5777779768724911
  batch 62 loss: 0.5779592548647234
  batch 63 loss: 0.5780829115519448
  batch 64 loss: 0.578080028295517
  batch 65 loss: 0.578140257872068
  batch 66 loss: 0.5778530122655811
  batch 67 loss: 0.5781015068737428
  batch 68 loss: 0.5782959680346882
  batch 69 loss: 0.5782554581545402
  batch 70 loss: 0.57851203254291
  batch 71 loss: 0.5786969502207259
  batch 72 loss: 0.5781558660997285
  batch 73 loss: 0.5780451730506061
  batch 74 loss: 0.5781710743904114
  batch 75 loss: 0.5785713434219361
  batch 76 loss: 0.5790339049540068
  batch 77 loss: 0.5788030570203607
  batch 78 loss: 0.5782860800241812
  batch 79 loss: 0.578530191620694
  batch 80 loss: 0.5785095028579235
  batch 81 loss: 0.5784705134085667
  batch 82 loss: 0.5788601164410754
  batch 83 loss: 0.579238270420626
  batch 84 loss: 0.5794588362886792
  batch 85 loss: 0.5787958243313958
  batch 86 loss: 0.5792627445487089
  batch 87 loss: 0.5794602701033669
  batch 88 loss: 0.579450477253307
  batch 89 loss: 0.5795501711663236
  batch 90 loss: 0.5795284900400374
  batch 91 loss: 0.5796023653103755
  batch 92 loss: 0.5794795822838078
  batch 93 loss: 0.5796989696000212
  batch 94 loss: 0.5797082889587322
  batch 95 loss: 0.579960276578602
  batch 96 loss: 0.5799810836712519
  batch 97 loss: 0.5798549774995784
  batch 98 loss: 0.5800482253639065
  batch 99 loss: 0.5799507324141685
  batch 100 loss: 0.5800140100717545
  batch 101 loss: 0.5799265680926862
  batch 102 loss: 0.5799790287719053
  batch 103 loss: 0.5798439869602907
  batch 104 loss: 0.5799747894589717
  batch 105 loss: 0.5800415748641604
  batch 106 loss: 0.5800740865041625
  batch 107 loss: 0.5799242948817316
  batch 108 loss: 0.5797641906473372
  batch 109 loss: 0.5797733538741365
  batch 110 loss: 0.5798636306415904
  batch 111 loss: 0.579722543557485
  batch 112 loss: 0.5797490642539093
  batch 113 loss: 0.5798983806002457
  batch 114 loss: 0.5802249720222071
  batch 115 loss: 0.5802793326585189
  batch 116 loss: 0.5803346361579567
  batch 117 loss: 0.5803525188030341
  batch 118 loss: 0.5803305486501273
  batch 119 loss: 0.5802809305551673
  batch 120 loss: 0.5801498234272003
  batch 121 loss: 0.5801577242937955
  batch 122 loss: 0.5800368673488742
  batch 123 loss: 0.5800341915308944
  batch 124 loss: 0.5802188030173702
  batch 125 loss: 0.5801924595832825
  batch 126 loss: 0.579947233673126
  batch 127 loss: 0.5800264266532237
  batch 128 loss: 0.5798311145044863
  batch 129 loss: 0.5795625018519025
  batch 130 loss: 0.5795150935649872
  batch 131 loss: 0.5793705641768361
  batch 132 loss: 0.5794038908048109
  batch 133 loss: 0.5794835238528431
  batch 134 loss: 0.5795117879091803
  batch 135 loss: 0.5795226083861457
  batch 136 loss: 0.5794677090118913
  batch 137 loss: 0.5795914078280874
  batch 138 loss: 0.5797736251699752
  batch 139 loss: 0.5797027671079842
  batch 140 loss: 0.579510617681912
  batch 141 loss: 0.5792484076310557
  batch 142 loss: 0.5792291114028071
  batch 143 loss: 0.5790605503362376
  batch 144 loss: 0.5789775869084729
  batch 145 loss: 0.5790574546517997
  batch 146 loss: 0.5789550469346243
  batch 147 loss: 0.5789779254368373
  batch 148 loss: 0.5789722590833097
  batch 149 loss: 0.5788833462951968
  batch 150 loss: 0.578938737710317
  batch 151 loss: 0.5791129383030317
  batch 152 loss: 0.5790950852005106
  batch 153 loss: 0.5789530538266001
  batch 154 loss: 0.5789701214858464
  batch 155 loss: 0.579068975679336
  batch 156 loss: 0.5790236030633633
  batch 157 loss: 0.5791449110219433
  batch 158 loss: 0.5790515206282651
  batch 159 loss: 0.5790812448135711
  batch 160 loss: 0.579087457805872
  batch 161 loss: 0.5792243621364144
  batch 162 loss: 0.5790437577683248
  batch 163 loss: 0.5789753502131971
  batch 164 loss: 0.5787103884830708
  batch 165 loss: 0.5785139296994065
  batch 166 loss: 0.5784488201859486
  batch 167 loss: 0.5783143389724685
  batch 168 loss: 0.5784271788739023
  batch 169 loss: 0.5783552915386899
  batch 170 loss: 0.5785081852884854
  batch 171 loss: 0.5785646706993817
  batch 172 loss: 0.5784621845151103
  batch 173 loss: 0.5785452892325517
  batch 174 loss: 0.578492224901572
  batch 175 loss: 0.5784628534317017
  batch 176 loss: 0.5785227214748209
  batch 177 loss: 0.5783897052376957
  batch 178 loss: 0.5783028763331725
  batch 179 loss: 0.5783156432918997
  batch 180 loss: 0.578272400630845
  batch 181 loss: 0.5783457024979987
  batch 182 loss: 0.5782588576222514
  batch 183 loss: 0.578407127349103
  batch 184 loss: 0.5783356943208239
  batch 185 loss: 0.5783815586889113
  batch 186 loss: 0.5783256805071266
  batch 187 loss: 0.5783429502803374
  batch 188 loss: 0.5781939622569592
  batch 189 loss: 0.5779750277756384
  batch 190 loss: 0.5778653577754372
  batch 191 loss: 0.5778239472374243
  batch 192 loss: 0.5778500049685439
  batch 193 loss: 0.5777607047496064
  batch 194 loss: 0.5777825114038802
  batch 195 loss: 0.5778904972932277
  batch 196 loss: 0.5779078645365578
  batch 197 loss: 0.5778080808934827
  batch 198 loss: 0.5777804691984196
  batch 199 loss: 0.5778354427323269
  batch 200 loss: 0.5778853014111519
  batch 201 loss: 0.5778755711678841
  batch 202 loss: 0.5779309266864663
  batch 203 loss: 0.577983777217677
  batch 204 loss: 0.5779826214500502
  batch 205 loss: 0.5780530141621101
  batch 206 loss: 0.5778715228571475
  batch 207 loss: 0.5778710732713414
  batch 208 loss: 0.5778543648238366
  batch 209 loss: 0.5777183286310953
  batch 210 loss: 0.5776717895553225
  batch 211 loss: 0.577763872406494
  batch 212 loss: 0.5776723125633204
  batch 213 loss: 0.5777669143229024
  batch 214 loss: 0.5776148282478903
  batch 215 loss: 0.5774243047071058
  batch 216 loss: 0.5772886692925736
  batch 217 loss: 0.5771792921053099
  batch 218 loss: 0.577114992458886
  batch 219 loss: 0.5770601744521154
  batch 220 loss: 0.576981749588793
  batch 221 loss: 0.5768778078696307
  batch 222 loss: 0.5769954901020806
  batch 223 loss: 0.5770410021324329
  batch 224 loss: 0.5770874582231045
  batch 225 loss: 0.5770154248343574
  batch 226 loss: 0.5770983938622264
  batch 227 loss: 0.5770143288872841
  batch 228 loss: 0.576913789960376
  batch 229 loss: 0.5769082620154302
  batch 230 loss: 0.5768877021644426
  batch 231 loss: 0.5769386428259152
  batch 232 loss: 0.576820438535049
  batch 233 loss: 0.576756107193206
  batch 234 loss: 0.5766890853898138
  batch 235 loss: 0.5768467629209478
  batch 236 loss: 0.5767582336724815
  batch 237 loss: 0.5767980290867608
  batch 238 loss: 0.576718837273221
  batch 239 loss: 0.5767192483945871
  batch 240 loss: 0.5767578221857548
  batch 241 loss: 0.5767737983173354
  batch 242 loss: 0.5766408453302935
  batch 243 loss: 0.5766404435467818
  batch 244 loss: 0.5767479883354218
  batch 245 loss: 0.576715734783484
  batch 246 loss: 0.5768443554397521
  batch 247 loss: 0.5768426984910541
  batch 248 loss: 0.576881613462202
  batch 249 loss: 0.5768857449891577
  batch 250 loss: 0.5768660266399384
  batch 251 loss: 0.5769240958282197
  batch 252 loss: 0.5769493657918203
  batch 253 loss: 0.5768716427177308
  batch 254 loss: 0.576852097286014
  batch 255 loss: 0.5768017920793271
  batch 256 loss: 0.5767793958075345
  batch 257 loss: 0.5769808269196447
  batch 258 loss: 0.5769300945969515
  batch 259 loss: 0.5768631687495699
  batch 260 loss: 0.5767990896335015
  batch 261 loss: 0.5767747867153066
  batch 262 loss: 0.5767710700289894
  batch 263 loss: 0.5767140202649192
  batch 264 loss: 0.5765960029128826
  batch 265 loss: 0.5764708156855601
  batch 266 loss: 0.5765534334612968
  batch 267 loss: 0.5767174235890421
  batch 268 loss: 0.5765731270188716
  batch 269 loss: 0.5766091127377904
  batch 270 loss: 0.576632246043947
  batch 271 loss: 0.576605279287289
  batch 272 loss: 0.5766465872087899
  batch 273 loss: 0.5766723367757413
  batch 274 loss: 0.5767320699065271
  batch 275 loss: 0.5768399516018954
  batch 276 loss: 0.5768665826838949
  batch 277 loss: 0.5768421726967023
  batch 278 loss: 0.5768676179347278
  batch 279 loss: 0.5768986775883637
  batch 280 loss: 0.5769097051450185
  batch 281 loss: 0.5768854011420254
  batch 282 loss: 0.5768138631015804
  batch 283 loss: 0.576685365434249
  batch 284 loss: 0.5767392146755272
  batch 285 loss: 0.5768677305756954
  batch 286 loss: 0.5767803667308568
  batch 287 loss: 0.576776591742911
  batch 288 loss: 0.5765897226002481
  batch 289 loss: 0.5766187572149257
  batch 290 loss: 0.5764038092103497
  batch 291 loss: 0.5763750045569902
  batch 292 loss: 0.5765088521046181
  batch 293 loss: 0.5765657402549588
  batch 294 loss: 0.5765455910543196
  batch 295 loss: 0.576540020360785
  batch 296 loss: 0.576571827401986
  batch 297 loss: 0.5765608665517685
  batch 298 loss: 0.5764720819940503
  batch 299 loss: 0.5764899646558092
  batch 300 loss: 0.5765322768688201
  batch 301 loss: 0.5764878845690097
  batch 302 loss: 0.5764187294126346
  batch 303 loss: 0.576461376923539
  batch 304 loss: 0.5764056432404017
  batch 305 loss: 0.5762154817581177
  batch 306 loss: 0.5761649483948751
  batch 307 loss: 0.576200234579341
  batch 308 loss: 0.5762503460630194
  batch 309 loss: 0.576148731037251
  batch 310 loss: 0.5761541264672433
  batch 311 loss: 0.5762734361400175
  batch 312 loss: 0.5762714413114083
  batch 313 loss: 0.5763418253618308
  batch 314 loss: 0.5763363509800783
  batch 315 loss: 0.5762775392759414
  batch 316 loss: 0.576220977721335
  batch 317 loss: 0.5763285850124781
  batch 318 loss: 0.5762225841201326
  batch 319 loss: 0.5761849898903347
  batch 320 loss: 0.576163325086236
  batch 321 loss: 0.5761081897581106
  batch 322 loss: 0.5761925015390289
  batch 323 loss: 0.5762572015402118
  batch 324 loss: 0.576261270561336
  batch 325 loss: 0.5763729880406306
  batch 326 loss: 0.576345626196247
  batch 327 loss: 0.5763280829158398
  batch 328 loss: 0.5762972333809224
  batch 329 loss: 0.5763243610735722
  batch 330 loss: 0.5763833766633814
  batch 331 loss: 0.576430693493869
  batch 332 loss: 0.5764903402831181
  batch 333 loss: 0.5764936357289105
  batch 334 loss: 0.5764845506159845
  batch 335 loss: 0.5764508382597966
  batch 336 loss: 0.5764238617959476
  batch 337 loss: 0.5763468162242312
  batch 338 loss: 0.5764079795786615
  batch 339 loss: 0.5764373094283023
  batch 340 loss: 0.576478896947468
  batch 341 loss: 0.5764385126203386
  batch 342 loss: 0.5764382610544126
  batch 343 loss: 0.5764937338259061
  batch 344 loss: 0.5765287637017494
  batch 345 loss: 0.5766212069469949
  batch 346 loss: 0.5765057161364252
  batch 347 loss: 0.5765403198233943
  batch 348 loss: 0.5766065351921936
  batch 349 loss: 0.5765736036450951
  batch 350 loss: 0.5766520137446267
  batch 351 loss: 0.5767123461448909
  batch 352 loss: 0.5767282862216234
  batch 353 loss: 0.5766666224252739
  batch 354 loss: 0.5767831211372957
  batch 355 loss: 0.5768766549271597
  batch 356 loss: 0.5768766394826803
  batch 357 loss: 0.57681737543822
  batch 358 loss: 0.5768427903758747
  batch 359 loss: 0.5769275938235949
  batch 360 loss: 0.5770105299022462
  batch 361 loss: 0.5769447259955789
  batch 362 loss: 0.576987791621224
  batch 363 loss: 0.5770003386765472
  batch 364 loss: 0.5769364321297341
  batch 365 loss: 0.5769757272445992
  batch 366 loss: 0.5771392349336968
  batch 367 loss: 0.5770412204376033
  batch 368 loss: 0.5769935561263043
  batch 369 loss: 0.5770017128326705
  batch 370 loss: 0.5770494093766083
  batch 371 loss: 0.5771365401879797
  batch 372 loss: 0.5771326714305467
  batch 373 loss: 0.5771682236852979
  batch 374 loss: 0.5771423740820452
  batch 375 loss: 0.577145427385966
  batch 376 loss: 0.5772277199207468
  batch 377 loss: 0.5772525435733542
  batch 378 loss: 0.5771784399236951
  batch 379 loss: 0.577216086255529
  batch 380 loss: 0.5772394123830293
  batch 381 loss: 0.5771434895322705
  batch 382 loss: 0.5771456014423471
  batch 383 loss: 0.5771650517889476
  batch 384 loss: 0.5772289726883173
  batch 385 loss: 0.577294557435172
  batch 386 loss: 0.5772374965675137
  batch 387 loss: 0.577222893250389
  batch 388 loss: 0.5772699156065577
  batch 389 loss: 0.5773280233834274
  batch 390 loss: 0.5773976518557622
  batch 391 loss: 0.5774096832860767
  batch 392 loss: 0.5773459295837247
  batch 393 loss: 0.577393989223257
  batch 394 loss: 0.5774395269185758
  batch 395 loss: 0.5774637928491906
  batch 396 loss: 0.5774747133255005
  batch 397 loss: 0.5774210135942742
  batch 398 loss: 0.5773347133967146
  batch 399 loss: 0.5773940852710179
  batch 400 loss: 0.5773287796974182
  batch 401 loss: 0.5772258380702011
  batch 402 loss: 0.5771693615474511
  batch 403 loss: 0.5771650201629468
  batch 404 loss: 0.5772070658974128
  batch 405 loss: 0.5771414678773762
  batch 406 loss: 0.5771602926583126
  batch 407 loss: 0.5771359780789593
  batch 408 loss: 0.577197439968586
  batch 409 loss: 0.5772308471150387
  batch 410 loss: 0.5771903341863214
  batch 411 loss: 0.577219489282065
  batch 412 loss: 0.577214856604928
  batch 413 loss: 0.5772649859400696
  batch 414 loss: 0.5773095102701786
  batch 415 loss: 0.5773639905883605
  batch 416 loss: 0.5773095448429768
  batch 417 loss: 0.5773265547603726
  batch 418 loss: 0.5773952822936209
  batch 419 loss: 0.5775046987294582
  batch 420 loss: 0.577581253931636
  batch 421 loss: 0.5775979302841241
  batch 422 loss: 0.577653535310691
  batch 423 loss: 0.5776920055103076
  batch 424 loss: 0.5776949523473686
  batch 425 loss: 0.5778316687135135
  batch 426 loss: 0.5778839028497257
  batch 427 loss: 0.577914758783872
  batch 428 loss: 0.577856022899396
  batch 429 loss: 0.5778811435043673
  batch 430 loss: 0.5778707799523376
  batch 431 loss: 0.5778930344880319
  batch 432 loss: 0.5779170330475878
  batch 433 loss: 0.5778686785532751
  batch 434 loss: 0.5778802348996088
  batch 435 loss: 0.5778942398641301
  batch 436 loss: 0.5778658467968669
  batch 437 loss: 0.5779865224519638
  batch 438 loss: 0.5780856198371818
  batch 439 loss: 0.5780266020998597
  batch 440 loss: 0.5779711976647377
  batch 441 loss: 0.5779634145111724
  batch 442 loss: 0.577914781025632
  batch 443 loss: 0.5778727064552479
  batch 444 loss: 0.577908579293672
  batch 445 loss: 0.5778803340504678
  batch 446 loss: 0.5778827514883649
  batch 447 loss: 0.5778373882541187
  batch 448 loss: 0.57789475923138
  batch 449 loss: 0.5779057786300081
  batch 450 loss: 0.5779023859235976
  batch 451 loss: 0.577906853872498
  batch 452 loss: 0.5778860424735904
  batch 453 loss: 0.5778966450007019
  batch 454 loss: 0.5779480661064518
  batch 455 loss: 0.5780456597988423
  batch 456 loss: 0.5780917847888511
  batch 457 loss: 0.578187008655306
  batch 458 loss: 0.5781912054036903
  batch 459 loss: 0.5782123936547173
  batch 460 loss: 0.5782527140949083
  batch 461 loss: 0.5782952701709275
  batch 462 loss: 0.5782996216119626
  batch 463 loss: 0.57835232889678
  batch 464 loss: 0.5784455941155039
  batch 465 loss: 0.5784443647630753
  batch 466 loss: 0.5784407101987258
  batch 467 loss: 0.5784645435386347
  batch 468 loss: 0.5784526546286721
  batch 469 loss: 0.5784986910026974
  batch 470 loss: 0.5784564819741757
  batch 471 loss: 0.5784502145844154
  batch 472 loss: 0.5784580018055641
LOSS train 0.5784580018055641 valid 0.47238802909851074
LOSS train 0.5784580018055641 valid 0.47901850938796997
LOSS train 0.5784580018055641 valid 0.472355713446935
LOSS train 0.5784580018055641 valid 0.4705989137291908
LOSS train 0.5784580018055641 valid 0.4671146094799042
LOSS train 0.5784580018055641 valid 0.4715470572312673
LOSS train 0.5784580018055641 valid 0.4762407030378069
LOSS train 0.5784580018055641 valid 0.4759177155792713
LOSS train 0.5784580018055641 valid 0.4760056436061859
LOSS train 0.5784580018055641 valid 0.4773634970188141
LOSS train 0.5784580018055641 valid 0.4803715781732039
LOSS train 0.5784580018055641 valid 0.4795769726236661
LOSS train 0.5784580018055641 valid 0.48116804315493655
LOSS train 0.5784580018055641 valid 0.4816822430917195
LOSS train 0.5784580018055641 valid 0.48240387439727783
LOSS train 0.5784580018055641 valid 0.4813857488334179
LOSS train 0.5784580018055641 valid 0.4825669071253608
LOSS train 0.5784580018055641 valid 0.4823938210805257
LOSS train 0.5784580018055641 valid 0.48166846287877935
LOSS train 0.5784580018055641 valid 0.4822386890649796
LOSS train 0.5784580018055641 valid 0.48226984058107647
LOSS train 0.5784580018055641 valid 0.48103146932341834
LOSS train 0.5784580018055641 valid 0.4811652315699536
LOSS train 0.5784580018055641 valid 0.48067853475610417
LOSS train 0.5784580018055641 valid 0.48002689719200137
LOSS train 0.5784580018055641 valid 0.4792462598818999
LOSS train 0.5784580018055641 valid 0.479252306399522
LOSS train 0.5784580018055641 valid 0.4794575997761318
LOSS train 0.5784580018055641 valid 0.47833405075402097
LOSS train 0.5784580018055641 valid 0.47871502141157785
LOSS train 0.5784580018055641 valid 0.47956901884848074
LOSS train 0.5784580018055641 valid 0.4793755253776908
LOSS train 0.5784580018055641 valid 0.4802840866825797
LOSS train 0.5784580018055641 valid 0.48132487517945904
LOSS train 0.5784580018055641 valid 0.48197687779154097
LOSS train 0.5784580018055641 valid 0.4822777865661515
LOSS train 0.5784580018055641 valid 0.482323286501137
LOSS train 0.5784580018055641 valid 0.482279520285757
LOSS train 0.5784580018055641 valid 0.48198047356727797
LOSS train 0.5784580018055641 valid 0.4823189750313759
LOSS train 0.5784580018055641 valid 0.482484667766385
LOSS train 0.5784580018055641 valid 0.4824252000876835
LOSS train 0.5784580018055641 valid 0.48224751963171847
LOSS train 0.5784580018055641 valid 0.4822933728044683
LOSS train 0.5784580018055641 valid 0.4819630013571845
LOSS train 0.5784580018055641 valid 0.4823400650335395
LOSS train 0.5784580018055641 valid 0.4825822159330896
LOSS train 0.5784580018055641 valid 0.48309547640383244
LOSS train 0.5784580018055641 valid 0.4835894442334467
LOSS train 0.5784580018055641 valid 0.4829950088262558
LOSS train 0.5784580018055641 valid 0.4834885579698226
LOSS train 0.5784580018055641 valid 0.4836252967898662
LOSS train 0.5784580018055641 valid 0.4833363789432454
LOSS train 0.5784580018055641 valid 0.4829752726687325
LOSS train 0.5784580018055641 valid 0.48324902545322074
LOSS train 0.5784580018055641 valid 0.48302809468337465
LOSS train 0.5784580018055641 valid 0.4828887670709376
LOSS train 0.5784580018055641 valid 0.4827456186557638
LOSS train 0.5784580018055641 valid 0.4830573938660703
LOSS train 0.5784580018055641 valid 0.4829649984836578
LOSS train 0.5784580018055641 valid 0.4821845473813229
LOSS train 0.5784580018055641 valid 0.4822815954685211
LOSS train 0.5784580018055641 valid 0.4821494354142083
LOSS train 0.5784580018055641 valid 0.48254450131207705
LOSS train 0.5784580018055641 valid 0.48290838369956385
LOSS train 0.5784580018055641 valid 0.48278291613766644
LOSS train 0.5784580018055641 valid 0.48270844701510757
LOSS train 0.5784580018055641 valid 0.48290270523113366
LOSS train 0.5784580018055641 valid 0.4829186758269434
LOSS train 0.5784580018055641 valid 0.48260599843093327
LOSS train 0.5784580018055641 valid 0.4824681647226844
LOSS train 0.5784580018055641 valid 0.48231904043091667
LOSS train 0.5784580018055641 valid 0.4825569815831642
LOSS train 0.5784580018055641 valid 0.482276117479479
LOSS train 0.5784580018055641 valid 0.4822332032521566
LOSS train 0.5784580018055641 valid 0.48251250464665263
LOSS train 0.5784580018055641 valid 0.4824353092676633
LOSS train 0.5784580018055641 valid 0.48248249750870925
LOSS train 0.5784580018055641 valid 0.482292085508757
LOSS train 0.5784580018055641 valid 0.48207031711936
LOSS train 0.5784580018055641 valid 0.48180209817709746
LOSS train 0.5784580018055641 valid 0.4816863711287336
LOSS train 0.5784580018055641 valid 0.48154349678970243
LOSS train 0.5784580018055641 valid 0.4816407085884185
LOSS train 0.5784580018055641 valid 0.4813991585198571
LOSS train 0.5784580018055641 valid 0.48136997361515843
LOSS train 0.5784580018055641 valid 0.4814278298410876
LOSS train 0.5784580018055641 valid 0.4813624078577215
LOSS train 0.5784580018055641 valid 0.4814322480324949
LOSS train 0.5784580018055641 valid 0.4816759702232149
LOSS train 0.5784580018055641 valid 0.48189940917622914
LOSS train 0.5784580018055641 valid 0.48183117094247235
LOSS train 0.5784580018055641 valid 0.4816867032999633
LOSS train 0.5784580018055641 valid 0.4816120767847021
LOSS train 0.5784580018055641 valid 0.4814964219143516
LOSS train 0.5784580018055641 valid 0.4812562720229228
LOSS train 0.5784580018055641 valid 0.4813455810251924
LOSS train 0.5784580018055641 valid 0.4811478582571964
LOSS train 0.5784580018055641 valid 0.4813978235528927
LOSS train 0.5784580018055641 valid 0.48147516906261445
LOSS train 0.5784580018055641 valid 0.4816491624506393
LOSS train 0.5784580018055641 valid 0.48166683433102625
LOSS train 0.5784580018055641 valid 0.48191485879490675
LOSS train 0.5784580018055641 valid 0.4818480842961715
LOSS train 0.5784580018055641 valid 0.48189234251067753
LOSS train 0.5784580018055641 valid 0.48195718650547964
LOSS train 0.5784580018055641 valid 0.481780929821674
LOSS train 0.5784580018055641 valid 0.481851562305733
LOSS train 0.5784580018055641 valid 0.48206522486625464
LOSS train 0.5784580018055641 valid 0.4822796247222207
LOSS train 0.5784580018055641 valid 0.48238103695817897
LOSS train 0.5784580018055641 valid 0.48251295808170525
LOSS train 0.5784580018055641 valid 0.4825521747095395
LOSS train 0.5784580018055641 valid 0.4823312939781892
LOSS train 0.5784580018055641 valid 0.4824428493561952
LOSS train 0.5784580018055641 valid 0.4826254215219925
LOSS train 0.5784580018055641 valid 0.48257415442385226
LOSS train 0.5784580018055641 valid 0.482480847987078
LOSS train 0.5784580018055641 valid 0.48249802694601174
LOSS train 0.5784580018055641 valid 0.48253767266869546
LOSS train 0.5784580018055641 valid 0.482509951946164
LOSS train 0.5784580018055641 valid 0.48240834425707335
LOSS train 0.5784580018055641 valid 0.4824275248418979
LOSS train 0.5784580018055641 valid 0.48250322476510077
LOSS train 0.5784580018055641 valid 0.4825646533966064
LOSS train 0.5784580018055641 valid 0.48257157301145887
LOSS train 0.5784580018055641 valid 0.4826758217623853
LOSS train 0.5784580018055641 valid 0.48293536715209484
LOSS train 0.5784580018055641 valid 0.4830089929954026
LOSS train 0.5784580018055641 valid 0.4829415644590671
LOSS train 0.5784580018055641 valid 0.48292624518161514
LOSS train 0.5784580018055641 valid 0.4827511872757565
LOSS train 0.5784580018055641 valid 0.4826479244949226
LOSS train 0.5784580018055641 valid 0.48273384637797057
LOSS train 0.5784580018055641 valid 0.4828004669260096
LOSS train 0.5784580018055641 valid 0.48278893880984364
LOSS train 0.5784580018055641 valid 0.48266006690742325
LOSS train 0.5784580018055641 valid 0.4824802469516146
LOSS train 0.5784580018055641 valid 0.4823495647032484
LOSS train 0.5784580018055641 valid 0.4823304350887026
LOSS train 0.5784580018055641 valid 0.48242155414946536
LOSS train 0.5784580018055641 valid 0.4825689796830567
LOSS train 0.5784580018055641 valid 0.4824744667206611
LOSS train 0.5784580018055641 valid 0.482530168361134
LOSS train 0.5784580018055641 valid 0.48237095454643514
LOSS train 0.5784580018055641 valid 0.48255231078356914
LOSS train 0.5784580018055641 valid 0.4823756595047153
LOSS train 0.5784580018055641 valid 0.4826696954063467
LOSS train 0.5784580018055641 valid 0.48268332617394877
LOSS train 0.5784580018055641 valid 0.4827557224035263
LOSS train 0.5784580018055641 valid 0.4828447342313678
LOSS train 0.5784580018055641 valid 0.4827187545597553
LOSS train 0.5784580018055641 valid 0.48266248512112236
LOSS train 0.5784580018055641 valid 0.48276983936885737
LOSS train 0.5784580018055641 valid 0.4826058937657264
LOSS train 0.5784580018055641 valid 0.4828459540238747
LOSS train 0.5784580018055641 valid 0.48287617192146887
LOSS train 0.5784580018055641 valid 0.4829385623901705
LOSS train 0.5784580018055641 valid 0.4828511379050009
LOSS train 0.5784580018055641 valid 0.48287711553275586
LOSS train 0.5784580018055641 valid 0.4829259348211822
LOSS train 0.5784580018055641 valid 0.48282990558647815
LOSS train 0.5784580018055641 valid 0.48282749283533155
LOSS train 0.5784580018055641 valid 0.48275884931407326
LOSS train 0.5784580018055641 valid 0.4826216719367287
LOSS train 0.5784580018055641 valid 0.48248585017330675
LOSS train 0.5784580018055641 valid 0.4826110551457205
LOSS train 0.5784580018055641 valid 0.4826821046216147
LOSS train 0.5784580018055641 valid 0.4826728987270558
LOSS train 0.5784580018055641 valid 0.4826391514609842
LOSS train 0.5784580018055641 valid 0.482852612322534
LOSS train 0.5784580018055641 valid 0.4829322633355163
LOSS train 0.5784580018055641 valid 0.48303276610512264
LOSS train 0.5784580018055641 valid 0.48309274308982936
LOSS train 0.5784580018055641 valid 0.4831329582418714
LOSS train 0.5784580018055641 valid 0.4832313076000322
LOSS train 0.5784580018055641 valid 0.48324197362371757
LOSS train 0.5784580018055641 valid 0.48339937376172354
LOSS train 0.5784580018055641 valid 0.48349881305374914
LOSS train 0.5784580018055641 valid 0.48362227181593576
LOSS train 0.5784580018055641 valid 0.4837074931813867
LOSS train 0.5784580018055641 valid 0.4837245510502176
LOSS train 0.5784580018055641 valid 0.48376400923468377
LOSS train 0.5784580018055641 valid 0.4837782219376253
LOSS train 0.5784580018055641 valid 0.48368076972059304
LOSS train 0.5784580018055641 valid 0.483709525196783
LOSS train 0.5784580018055641 valid 0.4839213144651709
LOSS train 0.5784580018055641 valid 0.4839841715515928
LOSS train 0.5784580018055641 valid 0.48394729867183345
LOSS train 0.5784580018055641 valid 0.48387438764697627
LOSS train 0.5784580018055641 valid 0.48402508656391924
LOSS train 0.5784580018055641 valid 0.48410154320299625
LOSS train 0.5784580018055641 valid 0.4841516285053807
LOSS train 0.5784580018055641 valid 0.48406303036458714
LOSS train 0.5784580018055641 valid 0.48398295564529226
LOSS train 0.5784580018055641 valid 0.4840344076558035
LOSS train 0.5784580018055641 valid 0.4840838959071842
LOSS train 0.5784580018055641 valid 0.4839945656783653
LOSS train 0.5784580018055641 valid 0.4840645525024165
LOSS train 0.5784580018055641 valid 0.4840752643346786
LOSS train 0.5784580018055641 valid 0.484003299949181
LOSS train 0.5784580018055641 valid 0.48407001144225054
LOSS train 0.5784580018055641 valid 0.4840685253953699
LOSS train 0.5784580018055641 valid 0.48410336059682507
LOSS train 0.5784580018055641 valid 0.4840484057984701
LOSS train 0.5784580018055641 valid 0.4841272434563313
LOSS train 0.5784580018055641 valid 0.4841586990632873
LOSS train 0.5784580018055641 valid 0.4841714445501566
LOSS train 0.5784580018055641 valid 0.48401485048412707
LOSS train 0.5784580018055641 valid 0.48395332339264097
LOSS train 0.5784580018055641 valid 0.4840045072738593
LOSS train 0.5784580018055641 valid 0.48405428722781957
LOSS train 0.5784580018055641 valid 0.4840789276389449
LOSS train 0.5784580018055641 valid 0.4840470226568596
LOSS train 0.5784580018055641 valid 0.4839404437431069
LOSS train 0.5784580018055641 valid 0.4839559280210071
LOSS train 0.5784580018055641 valid 0.48406734224838044
LOSS train 0.5784580018055641 valid 0.48408604529472665
LOSS train 0.5784580018055641 valid 0.4841280578206119
LOSS train 0.5784580018055641 valid 0.4841135484251109
LOSS train 0.5784580018055641 valid 0.48415463070524223
LOSS train 0.5784580018055641 valid 0.484262352725407
LOSS train 0.5784580018055641 valid 0.4843819698678004
LOSS train 0.5784580018055641 valid 0.484388650128884
LOSS train 0.5784580018055641 valid 0.4843254697322845
LOSS train 0.5784580018055641 valid 0.4842090378556631
LOSS train 0.5784580018055641 valid 0.4843582777462342
LOSS train 0.5784580018055641 valid 0.48442772070043966
LOSS train 0.5784580018055641 valid 0.48448869807230854
LOSS train 0.5784580018055641 valid 0.48463699092035706
LOSS train 0.5784580018055641 valid 0.4845379427139893
LOSS train 0.5784580018055641 valid 0.4845604491901809
LOSS train 0.5784580018055641 valid 0.4844286785872709
LOSS train 0.5784580018055641 valid 0.4844458542573146
LOSS train 0.5784580018055641 valid 0.4845286395955593
LOSS train 0.5784580018055641 valid 0.48450453730963045
LOSS train 0.5784580018055641 valid 0.48447636687805884
LOSS train 0.5784580018055641 valid 0.48443277004887075
LOSS train 0.5784580018055641 valid 0.48443493858042125
LOSS train 0.5784580018055641 valid 0.48436350052555405
LOSS train 0.5784580018055641 valid 0.4844351574098421
LOSS train 0.5784580018055641 valid 0.484412694026616
LOSS train 0.5784580018055641 valid 0.48441643945474194
LOSS train 0.5784580018055641 valid 0.484431371214937
LOSS train 0.5784580018055641 valid 0.4844306003074257
LOSS train 0.5784580018055641 valid 0.4844027094966997
LOSS train 0.5784580018055641 valid 0.48460015003015156
LOSS train 0.5784580018055641 valid 0.4845649792302039
LOSS train 0.5784580018055641 valid 0.48451171318689984
LOSS train 0.5784580018055641 valid 0.4846010231971741
LOSS train 0.5784580018055641 valid 0.4845430444911182
LOSS train 0.5784580018055641 valid 0.48456504195928574
LOSS train 0.5784580018055641 valid 0.4846374504415414
LOSS train 0.5784580018055641 valid 0.48463095396053135
LOSS train 0.5784580018055641 valid 0.48459276790712397
LOSS train 0.5784580018055641 valid 0.4845802045892924
LOSS train 0.5784580018055641 valid 0.4845651483257457
LOSS train 0.5784580018055641 valid 0.48458346054535506
LOSS train 0.5784580018055641 valid 0.48460113783600706
LOSS train 0.5784580018055641 valid 0.4846020797124276
LOSS train 0.5784580018055641 valid 0.48465236724564853
LOSS train 0.5784580018055641 valid 0.4847190424458671
LOSS train 0.5784580018055641 valid 0.4847469965541317
LOSS train 0.5784580018055641 valid 0.48478460605397367
LOSS train 0.5784580018055641 valid 0.4848034788977425
LOSS train 0.5784580018055641 valid 0.484818970686511
LOSS train 0.5784580018055641 valid 0.48480400923039585
LOSS train 0.5784580018055641 valid 0.4847295266478809
LOSS train 0.5784580018055641 valid 0.48486849344352806
LOSS train 0.5784580018055641 valid 0.4848662231807356
LOSS train 0.5784580018055641 valid 0.4849107481016884
LOSS train 0.5784580018055641 valid 0.4849401509717983
LOSS train 0.5784580018055641 valid 0.48503786161705686
LOSS train 0.5784580018055641 valid 0.4849618635255925
LOSS train 0.5784580018055641 valid 0.4849234991723841
LOSS train 0.5784580018055641 valid 0.4849554914711178
LOSS train 0.5784580018055641 valid 0.48504915919544894
LOSS train 0.5784580018055641 valid 0.4850126007478014
LOSS train 0.5784580018055641 valid 0.4850991165338879
LOSS train 0.5784580018055641 valid 0.4850976335150855
LOSS train 0.5784580018055641 valid 0.484946589028708
LOSS train 0.5784580018055641 valid 0.4848900068524881
LOSS train 0.5784580018055641 valid 0.48484550421735
LOSS train 0.5784580018055641 valid 0.48491744014998556
LOSS train 0.5784580018055641 valid 0.48496100850272594
LOSS train 0.5784580018055641 valid 0.48493043515648876
LOSS train 0.5784580018055641 valid 0.48489761715982016
LOSS train 0.5784580018055641 valid 0.4849143454598056
LOSS train 0.5784580018055641 valid 0.4848541245122269
LOSS train 0.5784580018055641 valid 0.4848364784799773
LOSS train 0.5784580018055641 valid 0.4846972429875246
LOSS train 0.5784580018055641 valid 0.48467462826265045
LOSS train 0.5784580018055641 valid 0.4846198259767005
LOSS train 0.5784580018055641 valid 0.48459461432735934
LOSS train 0.5784580018055641 valid 0.4847146884869721
LOSS train 0.5784580018055641 valid 0.4847612417227513
LOSS train 0.5784580018055641 valid 0.48472292776461
LOSS train 0.5784580018055641 valid 0.48473247325660396
LOSS train 0.5784580018055641 valid 0.4848221988980985
LOSS train 0.5784580018055641 valid 0.4847939079999924
LOSS train 0.5784580018055641 valid 0.4847964816711274
LOSS train 0.5784580018055641 valid 0.48473379479733525
LOSS train 0.5784580018055641 valid 0.4847908278699755
LOSS train 0.5784580018055641 valid 0.4847775049703686
LOSS train 0.5784580018055641 valid 0.48475125705609556
LOSS train 0.5784580018055641 valid 0.484728671659052
LOSS train 0.5784580018055641 valid 0.4847241846862756
LOSS train 0.5784580018055641 valid 0.48473770877757627
LOSS train 0.5784580018055641 valid 0.4847581367276633
LOSS train 0.5784580018055641 valid 0.48474773495428025
LOSS train 0.5784580018055641 valid 0.4846958123219358
LOSS train 0.5784580018055641 valid 0.48475031573802996
LOSS train 0.5784580018055641 valid 0.48483526268706156
LOSS train 0.5784580018055641 valid 0.4848916073133991
LOSS train 0.5784580018055641 valid 0.48496709040233066
LOSS train 0.5784580018055641 valid 0.48488790853114067
LOSS train 0.5784580018055641 valid 0.4849202648886371
LOSS train 0.5784580018055641 valid 0.4848826626936595
LOSS train 0.5784580018055641 valid 0.4849328099747063
LOSS train 0.5784580018055641 valid 0.4848728232085705
LOSS train 0.5784580018055641 valid 0.48486803848052695
LOSS train 0.5784580018055641 valid 0.4848574673907357
LOSS train 0.5784580018055641 valid 0.484832134593751
LOSS train 0.5784580018055641 valid 0.48481709519286215
LOSS train 0.5784580018055641 valid 0.48479735493659976
LOSS train 0.5784580018055641 valid 0.48487092700838313
LOSS train 0.5784580018055641 valid 0.48491156265276286
LOSS train 0.5784580018055641 valid 0.4850168557065289
LOSS train 0.5784580018055641 valid 0.485039482000751
LOSS train 0.5784580018055641 valid 0.48504988433736745
LOSS train 0.5784580018055641 valid 0.4850051652448775
LOSS train 0.5784580018055641 valid 0.4849312818014478
LOSS train 0.5784580018055641 valid 0.4849357442096905
LOSS train 0.5784580018055641 valid 0.485026882972546
LOSS train 0.5784580018055641 valid 0.48497636300414354
LOSS train 0.5784580018055641 valid 0.48501341843179296
LOSS train 0.5784580018055641 valid 0.48498905120688307
LOSS train 0.5784580018055641 valid 0.4849841087703874
LOSS train 0.5784580018055641 valid 0.48492694982385215
LOSS train 0.5784580018055641 valid 0.48489103019237517
LOSS train 0.5784580018055641 valid 0.4848450034245018
LOSS train 0.5784580018055641 valid 0.48482508451966516
LOSS train 0.5784580018055641 valid 0.4848498051263848
LOSS train 0.5784580018055641 valid 0.4849325474784818
LOSS train 0.5784580018055641 valid 0.4849516656087792
LOSS train 0.5784580018055641 valid 0.484957132208554
LOSS train 0.5784580018055641 valid 0.48490029075303753
LOSS train 0.5784580018055641 valid 0.4849423346505768
LOSS train 0.5784580018055641 valid 0.48495045005421245
LOSS train 0.5784580018055641 valid 0.4849640018599374
LOSS train 0.5784580018055641 valid 0.48492244947330226
LOSS train 0.5784580018055641 valid 0.4849448066035455
LOSS train 0.5784580018055641 valid 0.4849597429249847
LOSS train 0.5784580018055641 valid 0.4849827212970809
LOSS train 0.5784580018055641 valid 0.4850263789506026
LOSS train 0.5784580018055641 valid 0.4851096562957496
LOSS train 0.5784580018055641 valid 0.485060192707206
LOSS train 0.5784580018055641 valid 0.48500524194879907
LOSS train 0.5784580018055641 valid 0.4850051100871689
LOSS train 0.5784580018055641 valid 0.4849993838204278
LOSS train 0.5784580018055641 valid 0.48505101144478924
LOSS train 0.5784580018055641 valid 0.48508830393216884
LOSS train 0.5784580018055641 valid 0.4851283558308257
LOSS train 0.5784580018055641 valid 0.48511455617435684
LOSS train 0.5784580018055641 valid 0.4851526288137044
LOSS train 0.5784580018055641 valid 0.4851224754677444
LOSS train 0.5784580018055641 valid 0.48508448805406246
LOSS train 0.5784580018055641 valid 0.4850992293947417
LOSS train 0.5784580018055641 valid 0.4850821592781925
EPOCH 13:
  batch 1 loss: 0.5738943219184875
  batch 2 loss: 0.5686540901660919
  batch 3 loss: 0.5778529445330302
  batch 4 loss: 0.5860223472118378
  batch 5 loss: 0.587440824508667
  batch 6 loss: 0.5850602984428406
  batch 7 loss: 0.5870830842426845
  batch 8 loss: 0.5852979049086571
  batch 9 loss: 0.5834154486656189
  batch 10 loss: 0.5783179819583892
  batch 11 loss: 0.5788749618963762
  batch 12 loss: 0.5808543016513189
  batch 13 loss: 0.5811476569909316
  batch 14 loss: 0.5819423241274697
  batch 15 loss: 0.5833603819211324
  batch 16 loss: 0.5833367295563221
  batch 17 loss: 0.5833029922317056
  batch 18 loss: 0.5823379854361216
  batch 19 loss: 0.581624266348387
  batch 20 loss: 0.5824315875768662
  batch 21 loss: 0.5824301555043175
  batch 22 loss: 0.5819337666034698
  batch 23 loss: 0.581214435722517
  batch 24 loss: 0.5810454910000166
  batch 25 loss: 0.5825432825088501
  batch 26 loss: 0.5810300432718717
  batch 27 loss: 0.5809450546900431
  batch 28 loss: 0.5793102255889347
  batch 29 loss: 0.5793770510574867
  batch 30 loss: 0.5779608766237895
  batch 31 loss: 0.5773213236562668
  batch 32 loss: 0.5766651723533869
  batch 33 loss: 0.5769699522943208
  batch 34 loss: 0.5768520551569322
  batch 35 loss: 0.5779812097549438
  batch 36 loss: 0.5774845596816804
  batch 37 loss: 0.5781962066083342
  batch 38 loss: 0.5776127765053197
  batch 39 loss: 0.5775659313568702
  batch 40 loss: 0.5769437566399575
  batch 41 loss: 0.5768379307374721
  batch 42 loss: 0.5770113822959718
  batch 43 loss: 0.5768767775491227
  batch 44 loss: 0.576539008454843
  batch 45 loss: 0.5764729857444764
  batch 46 loss: 0.5759655846201855
  batch 47 loss: 0.5759577573613918
  batch 48 loss: 0.5760276094079018
  batch 49 loss: 0.5754908201645832
  batch 50 loss: 0.5760875976085663
  batch 51 loss: 0.575836787036821
  batch 52 loss: 0.5764179275586054
  batch 53 loss: 0.576406145995518
  batch 54 loss: 0.5764085540065059
  batch 55 loss: 0.5761324947530573
  batch 56 loss: 0.5761252620390483
  batch 57 loss: 0.5761482841090152
  batch 58 loss: 0.5760215407815473
  batch 59 loss: 0.5759298185170707
  batch 60 loss: 0.575902580221494
  batch 61 loss: 0.5758457887368124
  batch 62 loss: 0.5759947501843975
  batch 63 loss: 0.5760891730823214
  batch 64 loss: 0.5759483193978667
  batch 65 loss: 0.5759202572015616
  batch 66 loss: 0.5757777943755641
  batch 67 loss: 0.5762644463510656
  batch 68 loss: 0.5765332737389732
  batch 69 loss: 0.5767247417698735
  batch 70 loss: 0.577145288671766
  batch 71 loss: 0.5772938812282723
  batch 72 loss: 0.5770978348122703
  batch 73 loss: 0.5770294192719133
  batch 74 loss: 0.5770435091611501
  batch 75 loss: 0.5772736469904581
  batch 76 loss: 0.5774878098776466
  batch 77 loss: 0.5772416243305454
  batch 78 loss: 0.5767935353976029
  batch 79 loss: 0.5770653961580011
  batch 80 loss: 0.5768198579549789
  batch 81 loss: 0.5768941949915003
  batch 82 loss: 0.5772280547677017
  batch 83 loss: 0.5773299616503428
  batch 84 loss: 0.5775934528736841
  batch 85 loss: 0.5770303438691532
  batch 86 loss: 0.5772964379122091
  batch 87 loss: 0.5775237631523746
  batch 88 loss: 0.5774605199694633
  batch 89 loss: 0.5774760293156913
  batch 90 loss: 0.5773398035102421
  batch 91 loss: 0.5776306292512915
  batch 92 loss: 0.5775681144517401
  batch 93 loss: 0.5777970943399655
  batch 94 loss: 0.5777570732096409
  batch 95 loss: 0.5779976305208708
  batch 96 loss: 0.5779708114763101
  batch 97 loss: 0.5777593347215161
  batch 98 loss: 0.5779868668439437
  batch 99 loss: 0.5779468375022965
  batch 100 loss: 0.5778665709495544
  batch 101 loss: 0.577832034318754
  batch 102 loss: 0.5777754877127853
  batch 103 loss: 0.5778082551308048
  batch 104 loss: 0.5779768102444135
  batch 105 loss: 0.5781188800221397
  batch 106 loss: 0.5781436253268764
  batch 107 loss: 0.5779762379476957
  batch 108 loss: 0.5777565014583094
  batch 109 loss: 0.5776905472125482
  batch 110 loss: 0.578045433217829
  batch 111 loss: 0.5780391177615604
  batch 112 loss: 0.5779478358370918
  batch 113 loss: 0.578005797040146
  batch 114 loss: 0.5782978388301113
  batch 115 loss: 0.5782021714293438
  batch 116 loss: 0.5783691914944813
  batch 117 loss: 0.5784827210964301
  batch 118 loss: 0.5785470322027044
  batch 119 loss: 0.5785213157910258
  batch 120 loss: 0.5785763323307037
  batch 121 loss: 0.5785384917062176
  batch 122 loss: 0.5785153029394932
  batch 123 loss: 0.5785862246179968
  batch 124 loss: 0.5787361624740786
  batch 125 loss: 0.5788887848854065
  batch 126 loss: 0.5787779868595184
  batch 127 loss: 0.5788086347692595
  batch 128 loss: 0.5785734807141125
  batch 129 loss: 0.5783062415529591
  batch 130 loss: 0.5782741014774029
  batch 131 loss: 0.5781329824724271
  batch 132 loss: 0.5781502850127943
  batch 133 loss: 0.5782819412704697
  batch 134 loss: 0.5781819170980311
  batch 135 loss: 0.5782620981887535
  batch 136 loss: 0.5783020503380719
  batch 137 loss: 0.5783743562489531
  batch 138 loss: 0.5784174765365712
  batch 139 loss: 0.5784618528626806
  batch 140 loss: 0.5783442642007556
  batch 141 loss: 0.578357698224115
  batch 142 loss: 0.5784630481625946
  batch 143 loss: 0.5783931700499741
  batch 144 loss: 0.5782988882727094
  batch 145 loss: 0.5784148471108799
  batch 146 loss: 0.5783722645615879
  batch 147 loss: 0.5784132168406532
  batch 148 loss: 0.5785176383482443
  batch 149 loss: 0.5784185604761111
  batch 150 loss: 0.5783520718415578
  batch 151 loss: 0.5783310169415758
  batch 152 loss: 0.5783697198096075
  batch 153 loss: 0.5782409583041871
  batch 154 loss: 0.5781456545575873
  batch 155 loss: 0.5781891519023526
  batch 156 loss: 0.5782229598516073
  batch 157 loss: 0.5782302466167766
  batch 158 loss: 0.5781390836721734
  batch 159 loss: 0.5781307145484589
  batch 160 loss: 0.5781453751027584
  batch 161 loss: 0.5782633968021559
  batch 162 loss: 0.5781377999135006
  batch 163 loss: 0.5780311661995262
  batch 164 loss: 0.5777751098318797
  batch 165 loss: 0.5777693040443189
  batch 166 loss: 0.577735662101263
  batch 167 loss: 0.5776462779787486
  batch 168 loss: 0.5777225473097393
  batch 169 loss: 0.5776632498707291
  batch 170 loss: 0.5777076521340538
  batch 171 loss: 0.5777319861434357
  batch 172 loss: 0.5776839744906093
  batch 173 loss: 0.5778042701627478
  batch 174 loss: 0.5776985859733889
  batch 175 loss: 0.5775757724898202
  batch 176 loss: 0.5775038075040687
  batch 177 loss: 0.5772831396194501
  batch 178 loss: 0.5770949657713429
  batch 179 loss: 0.5771030990105102
  batch 180 loss: 0.5769943515459697
  batch 181 loss: 0.5770199670976038
  batch 182 loss: 0.5768347962217016
  batch 183 loss: 0.5769404036099793
  batch 184 loss: 0.5768418425451154
  batch 185 loss: 0.5769159513550836
  batch 186 loss: 0.5768966517781698
  batch 187 loss: 0.5768769000940782
  batch 188 loss: 0.5767323304998114
  batch 189 loss: 0.5764697190945741
  batch 190 loss: 0.5763314466727407
  batch 191 loss: 0.5763151502109947
  batch 192 loss: 0.5764553261299928
  batch 193 loss: 0.5764192654678859
  batch 194 loss: 0.576465911779207
  batch 195 loss: 0.5764928958354852
  batch 196 loss: 0.5764412332554253
  batch 197 loss: 0.5763926082456172
  batch 198 loss: 0.5764245794276999
  batch 199 loss: 0.5764337214992274
  batch 200 loss: 0.5763834634423256
  batch 201 loss: 0.5763227954432739
  batch 202 loss: 0.5762772096855806
  batch 203 loss: 0.5762986734582873
  batch 204 loss: 0.5762731073533788
  batch 205 loss: 0.5762258538385717
  batch 206 loss: 0.5760881863172772
  batch 207 loss: 0.5760514597961868
  batch 208 loss: 0.575958920786014
  batch 209 loss: 0.5758647622103896
  batch 210 loss: 0.575838435831524
  batch 211 loss: 0.5758694811454882
  batch 212 loss: 0.5757628071982905
  batch 213 loss: 0.5758645965459761
  batch 214 loss: 0.575645963443774
  batch 215 loss: 0.5754099277562873
  batch 216 loss: 0.575398742876671
  batch 217 loss: 0.5752947838625051
  batch 218 loss: 0.5752747780686125
  batch 219 loss: 0.5752047305782092
  batch 220 loss: 0.575190086256374
  batch 221 loss: 0.5752064707052654
  batch 222 loss: 0.5752821151200715
  batch 223 loss: 0.5752754470692621
  batch 224 loss: 0.5753817757857698
  batch 225 loss: 0.5752329532305399
  batch 226 loss: 0.5753291921805491
  batch 227 loss: 0.5752257801887748
  batch 228 loss: 0.5751006373187952
  batch 229 loss: 0.5750822000628476
  batch 230 loss: 0.5750144652698351
  batch 231 loss: 0.5751216530283808
  batch 232 loss: 0.5750329728270399
  batch 233 loss: 0.5749708851519573
  batch 234 loss: 0.574867371055815
  batch 235 loss: 0.5749788870202734
  batch 236 loss: 0.5748924388218735
  batch 237 loss: 0.5749780369710319
  batch 238 loss: 0.5749389932436102
  batch 239 loss: 0.5749057389203475
  batch 240 loss: 0.5748490288853645
  batch 241 loss: 0.5748402523301944
  batch 242 loss: 0.5747288871895183
  batch 243 loss: 0.5746596043492541
  batch 244 loss: 0.5747534811008171
  batch 245 loss: 0.5746436087452635
  batch 246 loss: 0.5747526755662469
  batch 247 loss: 0.5746580615700015
  batch 248 loss: 0.5745729200782315
  batch 249 loss: 0.5746407233567602
  batch 250 loss: 0.5746411306858062
  batch 251 loss: 0.5746615020877337
  batch 252 loss: 0.5746289548419771
  batch 253 loss: 0.5745232929825311
  batch 254 loss: 0.5745307338519359
  batch 255 loss: 0.5744915041269041
  batch 256 loss: 0.5743722766637802
  batch 257 loss: 0.5745667854635632
  batch 258 loss: 0.5744881519051486
  batch 259 loss: 0.5743717024225066
  batch 260 loss: 0.5742998267595585
  batch 261 loss: 0.5742624977539326
  batch 262 loss: 0.5742466765960664
  batch 263 loss: 0.5741727130041376
  batch 264 loss: 0.5740734444874706
  batch 265 loss: 0.573968036444682
  batch 266 loss: 0.573969943182809
  batch 267 loss: 0.574019899082541
  batch 268 loss: 0.5738865439571551
  batch 269 loss: 0.5739562682059618
  batch 270 loss: 0.5739553846694805
  batch 271 loss: 0.573959877570177
  batch 272 loss: 0.57397940316621
  batch 273 loss: 0.5739760045166854
  batch 274 loss: 0.5740479380980025
  batch 275 loss: 0.5741937799887223
  batch 276 loss: 0.5742540929628455
  batch 277 loss: 0.5741740482378522
  batch 278 loss: 0.574194118273344
  batch 279 loss: 0.574196125657755
  batch 280 loss: 0.5742126522319657
  batch 281 loss: 0.5741534366726451
  batch 282 loss: 0.5740858124080279
  batch 283 loss: 0.5738940430614216
  batch 284 loss: 0.5739262366378811
  batch 285 loss: 0.573995736398195
  batch 286 loss: 0.573926497797866
  batch 287 loss: 0.573961554088659
  batch 288 loss: 0.5738354228023026
  batch 289 loss: 0.5738823956271769
  batch 290 loss: 0.5736783646304032
  batch 291 loss: 0.5736485826190805
  batch 292 loss: 0.5737186688674639
  batch 293 loss: 0.5738015864489429
  batch 294 loss: 0.5737289652532461
  batch 295 loss: 0.5737316786232641
  batch 296 loss: 0.5737167204151282
  batch 297 loss: 0.5736608322621998
  batch 298 loss: 0.5736169389030278
  batch 299 loss: 0.5736865225842964
  batch 300 loss: 0.5737762115399043
  batch 301 loss: 0.5736552261038872
  batch 302 loss: 0.5735751603612836
  batch 303 loss: 0.5736322983263349
  batch 304 loss: 0.5735903656796405
  batch 305 loss: 0.5733489536848224
  batch 306 loss: 0.5733270645141602
  batch 307 loss: 0.5733493945109339
  batch 308 loss: 0.5734088507952628
  batch 309 loss: 0.5733161933213762
  batch 310 loss: 0.5732982952748575
  batch 311 loss: 0.5734060740164239
  batch 312 loss: 0.5733186359970998
  batch 313 loss: 0.5733363500799233
  batch 314 loss: 0.5733259756853626
  batch 315 loss: 0.5732684182742286
  batch 316 loss: 0.5731522099503988
  batch 317 loss: 0.5731923429747862
  batch 318 loss: 0.573070339811673
  batch 319 loss: 0.5729647704800095
  batch 320 loss: 0.5728947527706623
  batch 321 loss: 0.5727998137102691
  batch 322 loss: 0.5728950089549426
  batch 323 loss: 0.5729470444906607
  batch 324 loss: 0.5729255558531962
  batch 325 loss: 0.5730264386763939
  batch 326 loss: 0.5729899393634562
  batch 327 loss: 0.5729603324461421
  batch 328 loss: 0.5729013228925263
  batch 329 loss: 0.5728704675715021
  batch 330 loss: 0.5728987527616096
  batch 331 loss: 0.5729051088278387
  batch 332 loss: 0.5729437791798488
  batch 333 loss: 0.5729506069475466
  batch 334 loss: 0.5728999554754017
  batch 335 loss: 0.5728324925721582
  batch 336 loss: 0.5727955826691219
  batch 337 loss: 0.5727008515720198
  batch 338 loss: 0.5727195090796116
  batch 339 loss: 0.5727413774943282
  batch 340 loss: 0.5727819770574569
  batch 341 loss: 0.5727429601453966
  batch 342 loss: 0.5727184043641675
  batch 343 loss: 0.5727288954111994
  batch 344 loss: 0.5727535115424977
  batch 345 loss: 0.5728424607843593
  batch 346 loss: 0.5727271761508347
  batch 347 loss: 0.5727297552037308
  batch 348 loss: 0.5727854946563984
  batch 349 loss: 0.5727853479562994
  batch 350 loss: 0.5728713306358882
  batch 351 loss: 0.5729450250622893
  batch 352 loss: 0.5729433733292602
  batch 353 loss: 0.5728898740692787
  batch 354 loss: 0.5729391238110214
  batch 355 loss: 0.5729958232019988
  batch 356 loss: 0.5730105360572257
  batch 357 loss: 0.5729270575761127
  batch 358 loss: 0.5729962340946304
  batch 359 loss: 0.5730579905523231
  batch 360 loss: 0.5731083999077479
  batch 361 loss: 0.5730474358450343
  batch 362 loss: 0.5730897845154967
  batch 363 loss: 0.5730912785556362
  batch 364 loss: 0.5730142820994932
  batch 365 loss: 0.5730258103919356
  batch 366 loss: 0.5731307458682139
  batch 367 loss: 0.5730068396157725
  batch 368 loss: 0.5729235230904558
  batch 369 loss: 0.5729768767266415
  batch 370 loss: 0.573055954237242
  batch 371 loss: 0.5731350315227662
  batch 372 loss: 0.5731189103536708
  batch 373 loss: 0.5731059908866882
  batch 374 loss: 0.5730863248600679
  batch 375 loss: 0.5730890628496805
  batch 376 loss: 0.5731364902346692
  batch 377 loss: 0.5731133976728909
  batch 378 loss: 0.5730079533877196
  batch 379 loss: 0.573058658665277
  batch 380 loss: 0.5731388747692108
  batch 381 loss: 0.5730321352563192
  batch 382 loss: 0.5730176251284115
  batch 383 loss: 0.5730376011709009
  batch 384 loss: 0.573072784114629
  batch 385 loss: 0.5731364250183105
  batch 386 loss: 0.5730760990029172
  batch 387 loss: 0.573022374349047
  batch 388 loss: 0.5730620618026281
  batch 389 loss: 0.5731391771900011
  batch 390 loss: 0.573174312328681
  batch 391 loss: 0.5731596750066713
  batch 392 loss: 0.5730822291605326
  batch 393 loss: 0.5731401997061479
  batch 394 loss: 0.5731821193307789
  batch 395 loss: 0.5732096570956556
  batch 396 loss: 0.5731787499454286
  batch 397 loss: 0.5731664396052997
  batch 398 loss: 0.5730646975974941
  batch 399 loss: 0.5731254208058044
  batch 400 loss: 0.5730586741864682
  batch 401 loss: 0.5729914105443883
  batch 402 loss: 0.5729499199793706
  batch 403 loss: 0.5729090429417253
  batch 404 loss: 0.5729404770501769
  batch 405 loss: 0.572896761364407
  batch 406 loss: 0.5729261407711236
  batch 407 loss: 0.5728690259579652
  batch 408 loss: 0.5729098365295167
  batch 409 loss: 0.5729103072348317
  batch 410 loss: 0.5729117235032524
  batch 411 loss: 0.5729427191172783
  batch 412 loss: 0.5729375050484555
  batch 413 loss: 0.5729506624812941
  batch 414 loss: 0.572987097904878
  batch 415 loss: 0.573044579862112
  batch 416 loss: 0.5729871582812988
  batch 417 loss: 0.5729732450535543
  batch 418 loss: 0.5729991200437956
  batch 419 loss: 0.5730303992519515
  batch 420 loss: 0.5730662473610469
  batch 421 loss: 0.5730804060530492
  batch 422 loss: 0.5730700122801613
  batch 423 loss: 0.5731031469137674
  batch 424 loss: 0.5730277222563636
  batch 425 loss: 0.5730716586112976
  batch 426 loss: 0.5730489464432981
  batch 427 loss: 0.5730178956404782
  batch 428 loss: 0.5729866579314259
  batch 429 loss: 0.5730178014381783
  batch 430 loss: 0.5730249422927235
  batch 431 loss: 0.573028621291893
  batch 432 loss: 0.5730175691898223
  batch 433 loss: 0.5729856426390985
  batch 434 loss: 0.5730072384880435
  batch 435 loss: 0.5730410220979274
  batch 436 loss: 0.5729713646370337
  batch 437 loss: 0.5730958736461141
  batch 438 loss: 0.5732113211394445
  batch 439 loss: 0.5731466024231531
  batch 440 loss: 0.5731593111699278
  batch 441 loss: 0.5731473901644856
  batch 442 loss: 0.5730693793404695
  batch 443 loss: 0.573032802437552
  batch 444 loss: 0.5730957740598971
  batch 445 loss: 0.5731281663594621
  batch 446 loss: 0.5732064542481717
  batch 447 loss: 0.5731370194379649
  batch 448 loss: 0.573165357778115
  batch 449 loss: 0.5731984091495352
  batch 450 loss: 0.5732145641909705
  batch 451 loss: 0.5732267721000638
  batch 452 loss: 0.5732114677671838
  batch 453 loss: 0.5731712178415547
  batch 454 loss: 0.5731863968960514
  batch 455 loss: 0.5732470648629325
  batch 456 loss: 0.573293381354265
  batch 457 loss: 0.573369168739611
  batch 458 loss: 0.5733528428723198
  batch 459 loss: 0.5733529382541549
  batch 460 loss: 0.5734139774156654
  batch 461 loss: 0.5734577824133337
  batch 462 loss: 0.5734797877408725
  batch 463 loss: 0.5735224737719378
  batch 464 loss: 0.5736041816657987
  batch 465 loss: 0.5735590739916729
  batch 466 loss: 0.5735431223979836
  batch 467 loss: 0.5735628005013476
  batch 468 loss: 0.5734992366061251
  batch 469 loss: 0.5735125578542762
  batch 470 loss: 0.5734484964228691
  batch 471 loss: 0.5735190380404203
  batch 472 loss: 0.5735038458290747
LOSS train 0.5735038458290747 valid 0.39018774032592773
LOSS train 0.5735038458290747 valid 0.40134136378765106
LOSS train 0.5735038458290747 valid 0.39563973744710285
LOSS train 0.5735038458290747 valid 0.39756128191947937
LOSS train 0.5735038458290747 valid 0.39484128952026365
LOSS train 0.5735038458290747 valid 0.39988013605276745
LOSS train 0.5735038458290747 valid 0.40383398958614897
LOSS train 0.5735038458290747 valid 0.4027109816670418
LOSS train 0.5735038458290747 valid 0.4041639698876275
LOSS train 0.5735038458290747 valid 0.4055933028459549
LOSS train 0.5735038458290747 valid 0.4078150527043776
LOSS train 0.5735038458290747 valid 0.4064175859093666
LOSS train 0.5735038458290747 valid 0.4088810361348666
LOSS train 0.5735038458290747 valid 0.4103304786341531
LOSS train 0.5735038458290747 valid 0.41182479659716287
LOSS train 0.5735038458290747 valid 0.410675385966897
LOSS train 0.5735038458290747 valid 0.4111640330623178
LOSS train 0.5735038458290747 valid 0.41104256610075635
LOSS train 0.5735038458290747 valid 0.41089745728593124
LOSS train 0.5735038458290747 valid 0.41154337078332903
LOSS train 0.5735038458290747 valid 0.41141158768108915
LOSS train 0.5735038458290747 valid 0.41046805544333026
LOSS train 0.5735038458290747 valid 0.41017425060272217
LOSS train 0.5735038458290747 valid 0.4096204253534476
LOSS train 0.5735038458290747 valid 0.4083937680721283
LOSS train 0.5735038458290747 valid 0.4078193295460481
LOSS train 0.5735038458290747 valid 0.4074426569320537
LOSS train 0.5735038458290747 valid 0.4074693279606955
LOSS train 0.5735038458290747 valid 0.4068136276869938
LOSS train 0.5735038458290747 valid 0.40743811925252277
LOSS train 0.5735038458290747 valid 0.40876314140135245
LOSS train 0.5735038458290747 valid 0.4087103120982647
LOSS train 0.5735038458290747 valid 0.4093289239840074
LOSS train 0.5735038458290747 valid 0.41029612281743216
LOSS train 0.5735038458290747 valid 0.411365646975381
LOSS train 0.5735038458290747 valid 0.41143058323197895
LOSS train 0.5735038458290747 valid 0.41212965266124624
LOSS train 0.5735038458290747 valid 0.4122232410468553
LOSS train 0.5735038458290747 valid 0.4120231370131175
LOSS train 0.5735038458290747 valid 0.4124958597123623
LOSS train 0.5735038458290747 valid 0.41258076850960895
LOSS train 0.5735038458290747 valid 0.4126719598259245
LOSS train 0.5735038458290747 valid 0.41256079770797904
LOSS train 0.5735038458290747 valid 0.4124808900735595
LOSS train 0.5735038458290747 valid 0.4120248523023393
LOSS train 0.5735038458290747 valid 0.4125628011382144
LOSS train 0.5735038458290747 valid 0.4124883939611151
LOSS train 0.5735038458290747 valid 0.41298719433446723
LOSS train 0.5735038458290747 valid 0.413761418084709
LOSS train 0.5735038458290747 valid 0.41313413441181185
LOSS train 0.5735038458290747 valid 0.41353438823830846
LOSS train 0.5735038458290747 valid 0.41359535776651823
LOSS train 0.5735038458290747 valid 0.41354921066536093
LOSS train 0.5735038458290747 valid 0.4131710816312719
LOSS train 0.5735038458290747 valid 0.41343925974585793
LOSS train 0.5735038458290747 valid 0.4134057419640677
LOSS train 0.5735038458290747 valid 0.4131855582981779
LOSS train 0.5735038458290747 valid 0.41313315722449073
LOSS train 0.5735038458290747 valid 0.41347441834918525
LOSS train 0.5735038458290747 valid 0.4132562652230263
LOSS train 0.5735038458290747 valid 0.41244784632667164
LOSS train 0.5735038458290747 valid 0.41264087009814476
LOSS train 0.5735038458290747 valid 0.4125727192750053
LOSS train 0.5735038458290747 valid 0.4129478740505874
LOSS train 0.5735038458290747 valid 0.4131585602576916
LOSS train 0.5735038458290747 valid 0.4129648186040647
LOSS train 0.5735038458290747 valid 0.41278090761668645
LOSS train 0.5735038458290747 valid 0.41290238455814476
LOSS train 0.5735038458290747 valid 0.41290845819141553
LOSS train 0.5735038458290747 valid 0.41262304612568446
LOSS train 0.5735038458290747 valid 0.41219050615606173
LOSS train 0.5735038458290747 valid 0.41214078416426975
LOSS train 0.5735038458290747 valid 0.41243736629616723
LOSS train 0.5735038458290747 valid 0.41204173742113887
LOSS train 0.5735038458290747 valid 0.4119430490334829
LOSS train 0.5735038458290747 valid 0.4120812937617302
LOSS train 0.5735038458290747 valid 0.4120439329704681
LOSS train 0.5735038458290747 valid 0.41200862672084415
LOSS train 0.5735038458290747 valid 0.41189877028706706
LOSS train 0.5735038458290747 valid 0.41171554625034334
LOSS train 0.5735038458290747 valid 0.41140572082849197
LOSS train 0.5735038458290747 valid 0.41145862820671825
LOSS train 0.5735038458290747 valid 0.41122254980615824
LOSS train 0.5735038458290747 valid 0.4113114341383889
LOSS train 0.5735038458290747 valid 0.41108020298621234
LOSS train 0.5735038458290747 valid 0.41094063361023747
LOSS train 0.5735038458290747 valid 0.4110323581202277
LOSS train 0.5735038458290747 valid 0.4110756848346103
LOSS train 0.5735038458290747 valid 0.4112213153517648
LOSS train 0.5735038458290747 valid 0.4115124503771464
LOSS train 0.5735038458290747 valid 0.4116939957980271
LOSS train 0.5735038458290747 valid 0.41164847592944687
LOSS train 0.5735038458290747 valid 0.4114672451890925
LOSS train 0.5735038458290747 valid 0.4114607914965204
LOSS train 0.5735038458290747 valid 0.41135997333024676
LOSS train 0.5735038458290747 valid 0.41123682508865994
LOSS train 0.5735038458290747 valid 0.411287257966307
LOSS train 0.5735038458290747 valid 0.4112103213461078
LOSS train 0.5735038458290747 valid 0.41163285001359806
LOSS train 0.5735038458290747 valid 0.41166447669267653
LOSS train 0.5735038458290747 valid 0.4117623422995652
LOSS train 0.5735038458290747 valid 0.4118327927940032
LOSS train 0.5735038458290747 valid 0.4120777032329041
LOSS train 0.5735038458290747 valid 0.41209446495542157
LOSS train 0.5735038458290747 valid 0.4120928548631214
LOSS train 0.5735038458290747 valid 0.412287673860226
LOSS train 0.5735038458290747 valid 0.4121415080311142
LOSS train 0.5735038458290747 valid 0.41225393061284665
LOSS train 0.5735038458290747 valid 0.4123934810861535
LOSS train 0.5735038458290747 valid 0.4125880566510287
LOSS train 0.5735038458290747 valid 0.4125961113620449
LOSS train 0.5735038458290747 valid 0.41270396885062965
LOSS train 0.5735038458290747 valid 0.4128563691556981
LOSS train 0.5735038458290747 valid 0.41261239611265954
LOSS train 0.5735038458290747 valid 0.4127270864403766
LOSS train 0.5735038458290747 valid 0.41293904904661505
LOSS train 0.5735038458290747 valid 0.4128743471243443
LOSS train 0.5735038458290747 valid 0.41276822403325875
LOSS train 0.5735038458290747 valid 0.4127844441838625
LOSS train 0.5735038458290747 valid 0.4128414606054624
LOSS train 0.5735038458290747 valid 0.41270937727502555
LOSS train 0.5735038458290747 valid 0.4126762007592154
LOSS train 0.5735038458290747 valid 0.4127846306901637
LOSS train 0.5735038458290747 valid 0.41288830436045126
LOSS train 0.5735038458290747 valid 0.41297178363800047
LOSS train 0.5735038458290747 valid 0.4129060000654251
LOSS train 0.5735038458290747 valid 0.41315743913800695
LOSS train 0.5735038458290747 valid 0.4133226862177253
LOSS train 0.5735038458290747 valid 0.41352054684661155
LOSS train 0.5735038458290747 valid 0.41342234955384183
LOSS train 0.5735038458290747 valid 0.4133856478538222
LOSS train 0.5735038458290747 valid 0.4131996733221141
LOSS train 0.5735038458290747 valid 0.41310562899238185
LOSS train 0.5735038458290747 valid 0.41310308495564246
LOSS train 0.5735038458290747 valid 0.41315272737432407
LOSS train 0.5735038458290747 valid 0.4130985379657325
LOSS train 0.5735038458290747 valid 0.41295139676462994
LOSS train 0.5735038458290747 valid 0.41280818460644153
LOSS train 0.5735038458290747 valid 0.412754217068926
LOSS train 0.5735038458290747 valid 0.4128039949706623
LOSS train 0.5735038458290747 valid 0.41284063204805904
LOSS train 0.5735038458290747 valid 0.4128845600594937
LOSS train 0.5735038458290747 valid 0.4128297469415865
LOSS train 0.5735038458290747 valid 0.4128786480675141
LOSS train 0.5735038458290747 valid 0.41277126793203683
LOSS train 0.5735038458290747 valid 0.41297085174959
LOSS train 0.5735038458290747 valid 0.4127953457994526
LOSS train 0.5735038458290747 valid 0.41304395166603297
LOSS train 0.5735038458290747 valid 0.4129764205657396
LOSS train 0.5735038458290747 valid 0.41307589928309124
LOSS train 0.5735038458290747 valid 0.4131358368507284
LOSS train 0.5735038458290747 valid 0.4130052069300099
LOSS train 0.5735038458290747 valid 0.4130330566876854
LOSS train 0.5735038458290747 valid 0.41312329916210916
LOSS train 0.5735038458290747 valid 0.4129970339036757
LOSS train 0.5735038458290747 valid 0.4132129981731757
LOSS train 0.5735038458290747 valid 0.41319433519035387
LOSS train 0.5735038458290747 valid 0.413327697145788
LOSS train 0.5735038458290747 valid 0.41319248979946355
LOSS train 0.5735038458290747 valid 0.41313483100384474
LOSS train 0.5735038458290747 valid 0.413194674697722
LOSS train 0.5735038458290747 valid 0.41316079357523977
LOSS train 0.5735038458290747 valid 0.413156853497394
LOSS train 0.5735038458290747 valid 0.41300779181282693
LOSS train 0.5735038458290747 valid 0.41295691511847754
LOSS train 0.5735038458290747 valid 0.41276458354599505
LOSS train 0.5735038458290747 valid 0.412923690266238
LOSS train 0.5735038458290747 valid 0.4130264770771776
LOSS train 0.5735038458290747 valid 0.41299161914537647
LOSS train 0.5735038458290747 valid 0.4129875682732638
LOSS train 0.5735038458290747 valid 0.41324589004990653
LOSS train 0.5735038458290747 valid 0.41338713467121124
LOSS train 0.5735038458290747 valid 0.41352329123226894
LOSS train 0.5735038458290747 valid 0.41355804705071725
LOSS train 0.5735038458290747 valid 0.4136066244329725
LOSS train 0.5735038458290747 valid 0.4136428282680837
LOSS train 0.5735038458290747 valid 0.4137021018623632
LOSS train 0.5735038458290747 valid 0.41390619418594277
LOSS train 0.5735038458290747 valid 0.41398534977902246
LOSS train 0.5735038458290747 valid 0.41403927803039553
LOSS train 0.5735038458290747 valid 0.41405488081399905
LOSS train 0.5735038458290747 valid 0.414073299903136
LOSS train 0.5735038458290747 valid 0.41406056301189903
LOSS train 0.5735038458290747 valid 0.4140885618069898
LOSS train 0.5735038458290747 valid 0.41400995963328596
LOSS train 0.5735038458290747 valid 0.4140846504960009
LOSS train 0.5735038458290747 valid 0.4143041138024254
LOSS train 0.5735038458290747 valid 0.4143844730359443
LOSS train 0.5735038458290747 valid 0.414277850635468
LOSS train 0.5735038458290747 valid 0.4142096963367964
LOSS train 0.5735038458290747 valid 0.4143469378898281
LOSS train 0.5735038458290747 valid 0.41440171919142205
LOSS train 0.5735038458290747 valid 0.41442298441353237
LOSS train 0.5735038458290747 valid 0.41431832374985683
LOSS train 0.5735038458290747 valid 0.4142467290927202
LOSS train 0.5735038458290747 valid 0.41423712214645075
LOSS train 0.5735038458290747 valid 0.4142614996372746
LOSS train 0.5735038458290747 valid 0.4141234385244774
LOSS train 0.5735038458290747 valid 0.41421341087350894
LOSS train 0.5735038458290747 valid 0.4142210519313812
LOSS train 0.5735038458290747 valid 0.41416884951330535
LOSS train 0.5735038458290747 valid 0.41417863315874986
LOSS train 0.5735038458290747 valid 0.4141290926287327
LOSS train 0.5735038458290747 valid 0.4140842806767015
LOSS train 0.5735038458290747 valid 0.41411874221592415
LOSS train 0.5735038458290747 valid 0.41423294526859394
LOSS train 0.5735038458290747 valid 0.41427876494356974
LOSS train 0.5735038458290747 valid 0.41423449765604275
LOSS train 0.5735038458290747 valid 0.4140802854271026
LOSS train 0.5735038458290747 valid 0.4140154709418615
LOSS train 0.5735038458290747 valid 0.414072591264101
LOSS train 0.5735038458290747 valid 0.41409819980837265
LOSS train 0.5735038458290747 valid 0.41408520950957645
LOSS train 0.5735038458290747 valid 0.4139671877165821
LOSS train 0.5735038458290747 valid 0.41388750963432847
LOSS train 0.5735038458290747 valid 0.41387792787066213
LOSS train 0.5735038458290747 valid 0.4140003455399368
LOSS train 0.5735038458290747 valid 0.413989943648697
LOSS train 0.5735038458290747 valid 0.4140400915113214
LOSS train 0.5735038458290747 valid 0.41403018764474175
LOSS train 0.5735038458290747 valid 0.4140298959896036
LOSS train 0.5735038458290747 valid 0.4141050254976427
LOSS train 0.5735038458290747 valid 0.4142267186812756
LOSS train 0.5735038458290747 valid 0.41423079398061546
LOSS train 0.5735038458290747 valid 0.41419605082935756
LOSS train 0.5735038458290747 valid 0.4140939305050183
LOSS train 0.5735038458290747 valid 0.41423042374560487
LOSS train 0.5735038458290747 valid 0.4142922407440972
LOSS train 0.5735038458290747 valid 0.4143249024210018
LOSS train 0.5735038458290747 valid 0.41444924823615864
LOSS train 0.5735038458290747 valid 0.41440200766959745
LOSS train 0.5735038458290747 valid 0.41438128657895945
LOSS train 0.5735038458290747 valid 0.4142286933542833
LOSS train 0.5735038458290747 valid 0.4142856903565236
LOSS train 0.5735038458290747 valid 0.41435809236891724
LOSS train 0.5735038458290747 valid 0.41435118676242183
LOSS train 0.5735038458290747 valid 0.414347691374992
LOSS train 0.5735038458290747 valid 0.4142488326345171
LOSS train 0.5735038458290747 valid 0.4142233950074248
LOSS train 0.5735038458290747 valid 0.414185693860054
LOSS train 0.5735038458290747 valid 0.4142734044815
LOSS train 0.5735038458290747 valid 0.41422294856103
LOSS train 0.5735038458290747 valid 0.4142096010745798
LOSS train 0.5735038458290747 valid 0.41421856670106044
LOSS train 0.5735038458290747 valid 0.4141589116077034
LOSS train 0.5735038458290747 valid 0.4141521211562118
LOSS train 0.5735038458290747 valid 0.41432857308310533
LOSS train 0.5735038458290747 valid 0.41427908393163837
LOSS train 0.5735038458290747 valid 0.4142633577187856
LOSS train 0.5735038458290747 valid 0.41438442170619966
LOSS train 0.5735038458290747 valid 0.4143271395172256
LOSS train 0.5735038458290747 valid 0.4143829801016384
LOSS train 0.5735038458290747 valid 0.4144688713927514
LOSS train 0.5735038458290747 valid 0.4145019098998993
LOSS train 0.5735038458290747 valid 0.41449770319695567
LOSS train 0.5735038458290747 valid 0.4144776244647801
LOSS train 0.5735038458290747 valid 0.4143794037488648
LOSS train 0.5735038458290747 valid 0.41437940195549366
LOSS train 0.5735038458290747 valid 0.41438830635262275
LOSS train 0.5735038458290747 valid 0.4144004739247836
LOSS train 0.5735038458290747 valid 0.41446176982017313
LOSS train 0.5735038458290747 valid 0.41452032828148994
LOSS train 0.5735038458290747 valid 0.4145710801443673
LOSS train 0.5735038458290747 valid 0.4145709201693535
LOSS train 0.5735038458290747 valid 0.4145812524939483
LOSS train 0.5735038458290747 valid 0.4146038068640501
LOSS train 0.5735038458290747 valid 0.41460539261053564
LOSS train 0.5735038458290747 valid 0.4145374309215973
LOSS train 0.5735038458290747 valid 0.4146338014354493
LOSS train 0.5735038458290747 valid 0.4146397699912389
LOSS train 0.5735038458290747 valid 0.4146668396312812
LOSS train 0.5735038458290747 valid 0.4146834995378466
LOSS train 0.5735038458290747 valid 0.41478402295828737
LOSS train 0.5735038458290747 valid 0.4147251908579012
LOSS train 0.5735038458290747 valid 0.4147170785340396
LOSS train 0.5735038458290747 valid 0.4147583843357321
LOSS train 0.5735038458290747 valid 0.41481385807698384
LOSS train 0.5735038458290747 valid 0.41478727757930756
LOSS train 0.5735038458290747 valid 0.4148604657273993
LOSS train 0.5735038458290747 valid 0.41483459057552474
LOSS train 0.5735038458290747 valid 0.41471035380804666
LOSS train 0.5735038458290747 valid 0.4146238443910653
LOSS train 0.5735038458290747 valid 0.41457546315429067
LOSS train 0.5735038458290747 valid 0.41465509095242326
LOSS train 0.5735038458290747 valid 0.4147142677976374
LOSS train 0.5735038458290747 valid 0.41466468697661285
LOSS train 0.5735038458290747 valid 0.4146400249793554
LOSS train 0.5735038458290747 valid 0.4146759386898743
LOSS train 0.5735038458290747 valid 0.41460234236139737
LOSS train 0.5735038458290747 valid 0.4145628665027947
LOSS train 0.5735038458290747 valid 0.4144541827059284
LOSS train 0.5735038458290747 valid 0.4143989433164466
LOSS train 0.5735038458290747 valid 0.41437873539257375
LOSS train 0.5735038458290747 valid 0.4143956528634441
LOSS train 0.5735038458290747 valid 0.414463530152531
LOSS train 0.5735038458290747 valid 0.414504564090355
LOSS train 0.5735038458290747 valid 0.41448795544579375
LOSS train 0.5735038458290747 valid 0.41449421934233416
LOSS train 0.5735038458290747 valid 0.4145659872122034
LOSS train 0.5735038458290747 valid 0.4145516182978948
LOSS train 0.5735038458290747 valid 0.41458393885843775
LOSS train 0.5735038458290747 valid 0.41455641250736663
LOSS train 0.5735038458290747 valid 0.41456241871264116
LOSS train 0.5735038458290747 valid 0.4145634982146715
LOSS train 0.5735038458290747 valid 0.41449769354257426
LOSS train 0.5735038458290747 valid 0.4144654524287367
LOSS train 0.5735038458290747 valid 0.4144708349184415
LOSS train 0.5735038458290747 valid 0.4144489260075928
LOSS train 0.5735038458290747 valid 0.4144301698045823
LOSS train 0.5735038458290747 valid 0.4144047642907789
LOSS train 0.5735038458290747 valid 0.4143424628248552
LOSS train 0.5735038458290747 valid 0.41438169748737264
LOSS train 0.5735038458290747 valid 0.41448356901494837
LOSS train 0.5735038458290747 valid 0.4145082247674845
LOSS train 0.5735038458290747 valid 0.4145917508337233
LOSS train 0.5735038458290747 valid 0.4145113047731074
LOSS train 0.5735038458290747 valid 0.41456967470021655
LOSS train 0.5735038458290747 valid 0.4145236104351919
LOSS train 0.5735038458290747 valid 0.41454982580062366
LOSS train 0.5735038458290747 valid 0.4144947365857661
LOSS train 0.5735038458290747 valid 0.4144959292864874
LOSS train 0.5735038458290747 valid 0.41447248527352115
LOSS train 0.5735038458290747 valid 0.41444743205519285
LOSS train 0.5735038458290747 valid 0.4144492926604954
LOSS train 0.5735038458290747 valid 0.41445072274941663
LOSS train 0.5735038458290747 valid 0.4145360147477659
LOSS train 0.5735038458290747 valid 0.4145726416635951
LOSS train 0.5735038458290747 valid 0.4146952057575307
LOSS train 0.5735038458290747 valid 0.41471479593076965
LOSS train 0.5735038458290747 valid 0.4147123949997353
LOSS train 0.5735038458290747 valid 0.41465377771602296
LOSS train 0.5735038458290747 valid 0.4145555469286011
LOSS train 0.5735038458290747 valid 0.4145218096337877
LOSS train 0.5735038458290747 valid 0.4146337311067981
LOSS train 0.5735038458290747 valid 0.4145811587127287
LOSS train 0.5735038458290747 valid 0.4146079280014549
LOSS train 0.5735038458290747 valid 0.4145738320640711
LOSS train 0.5735038458290747 valid 0.41456748959580825
LOSS train 0.5735038458290747 valid 0.4144775457790116
LOSS train 0.5735038458290747 valid 0.41439515746691646
LOSS train 0.5735038458290747 valid 0.4143373310740742
LOSS train 0.5735038458290747 valid 0.4143600090902451
LOSS train 0.5735038458290747 valid 0.41438415081785995
LOSS train 0.5735038458290747 valid 0.41446299478411674
LOSS train 0.5735038458290747 valid 0.4144708477068638
LOSS train 0.5735038458290747 valid 0.41448013820400126
LOSS train 0.5735038458290747 valid 0.4144201314758499
LOSS train 0.5735038458290747 valid 0.41447623947571066
LOSS train 0.5735038458290747 valid 0.4145025601530485
LOSS train 0.5735038458290747 valid 0.4144815641641617
LOSS train 0.5735038458290747 valid 0.41443059154045886
LOSS train 0.5735038458290747 valid 0.4144742594693195
LOSS train 0.5735038458290747 valid 0.4145219025463288
LOSS train 0.5735038458290747 valid 0.41455771550957093
LOSS train 0.5735038458290747 valid 0.41462038033445114
LOSS train 0.5735038458290747 valid 0.41467744170614845
LOSS train 0.5735038458290747 valid 0.41461291600342226
LOSS train 0.5735038458290747 valid 0.4145724428765601
LOSS train 0.5735038458290747 valid 0.4145863495331289
LOSS train 0.5735038458290747 valid 0.4146218268407716
LOSS train 0.5735038458290747 valid 0.41465178165079153
LOSS train 0.5735038458290747 valid 0.41467514872880273
LOSS train 0.5735038458290747 valid 0.4146862043165307
LOSS train 0.5735038458290747 valid 0.4146773689887026
LOSS train 0.5735038458290747 valid 0.4146868203600792
LOSS train 0.5735038458290747 valid 0.4146701285585028
LOSS train 0.5735038458290747 valid 0.4145907875789933
LOSS train 0.5735038458290747 valid 0.4145935659661241
LOSS train 0.5735038458290747 valid 0.4145769852448285
EPOCH 14:
  batch 1 loss: 0.5566632747650146
  batch 2 loss: 0.5636432468891144
  batch 3 loss: 0.5676898161570231
  batch 4 loss: 0.5817212611436844
  batch 5 loss: 0.5791345000267029
  batch 6 loss: 0.5758862396081289
  batch 7 loss: 0.5786084447588239
  batch 8 loss: 0.5748094469308853
  batch 9 loss: 0.5749341381920708
  batch 10 loss: 0.5751067340373993
  batch 11 loss: 0.5753970525481484
  batch 12 loss: 0.5764016558726629
  batch 13 loss: 0.5768352792813227
  batch 14 loss: 0.5765797708715711
  batch 15 loss: 0.5785502394040426
  batch 16 loss: 0.5774412900209427
  batch 17 loss: 0.5777550585129682
  batch 18 loss: 0.5763660934236314
  batch 19 loss: 0.5757027519376654
  batch 20 loss: 0.5762299627065659
  batch 21 loss: 0.577255251861754
  batch 22 loss: 0.5766522125764326
  batch 23 loss: 0.5760091232216876
  batch 24 loss: 0.5759452283382416
  batch 25 loss: 0.5787149667739868
  batch 26 loss: 0.5776863189843985
  batch 27 loss: 0.5777386426925659
  batch 28 loss: 0.5762367908443723
  batch 29 loss: 0.5767982067732975
  batch 30 loss: 0.5765543341636657
  batch 31 loss: 0.5765371188040702
  batch 32 loss: 0.5763147454708815
  batch 33 loss: 0.5768037709322843
  batch 34 loss: 0.5764751855064841
  batch 35 loss: 0.5779640095574515
  batch 36 loss: 0.577870539493031
  batch 37 loss: 0.5776965908102087
  batch 38 loss: 0.5771777033805847
  batch 39 loss: 0.576980227079147
  batch 40 loss: 0.5763786658644676
  batch 41 loss: 0.5761517228149786
  batch 42 loss: 0.575962830157507
  batch 43 loss: 0.5762725209080896
  batch 44 loss: 0.5756053314967589
  batch 45 loss: 0.5755866871939765
  batch 46 loss: 0.5754648239716239
  batch 47 loss: 0.5749865440612144
  batch 48 loss: 0.5750486391286055
  batch 49 loss: 0.5745586947518952
  batch 50 loss: 0.5750645089149475
  batch 51 loss: 0.5744723829568601
  batch 52 loss: 0.5750647645730239
  batch 53 loss: 0.575117013364468
  batch 54 loss: 0.5750663821344022
  batch 55 loss: 0.574612149325284
  batch 56 loss: 0.5748033587421689
  batch 57 loss: 0.5748957207328395
  batch 58 loss: 0.5748322965769932
  batch 59 loss: 0.5749349159709478
  batch 60 loss: 0.5750524113575618
  batch 61 loss: 0.5747011225731646
  batch 62 loss: 0.5748548421167559
  batch 63 loss: 0.5749923284091647
  batch 64 loss: 0.5748807080090046
  batch 65 loss: 0.5748579465425931
  batch 66 loss: 0.5745882500301708
  batch 67 loss: 0.5749937625073674
  batch 68 loss: 0.5752741194823209
  batch 69 loss: 0.5754497439964957
  batch 70 loss: 0.5758480046476636
  batch 71 loss: 0.5759623478835737
  batch 72 loss: 0.5757250189781189
  batch 73 loss: 0.5757547143387468
  batch 74 loss: 0.5759138303834039
  batch 75 loss: 0.576179256439209
  batch 76 loss: 0.5760116773216348
  batch 77 loss: 0.5759650755238224
  batch 78 loss: 0.5754765012325385
  batch 79 loss: 0.575501955008205
  batch 80 loss: 0.5752430103719235
  batch 81 loss: 0.575082704608823
  batch 82 loss: 0.5759664984737954
  batch 83 loss: 0.5757754674877029
  batch 84 loss: 0.5759885715586799
  batch 85 loss: 0.5755788193029516
  batch 86 loss: 0.5758253121098806
  batch 87 loss: 0.5759685046371372
  batch 88 loss: 0.5762046765197407
  batch 89 loss: 0.5762229461348458
  batch 90 loss: 0.5761623501777648
  batch 91 loss: 0.5763288900092408
  batch 92 loss: 0.5763198202070983
  batch 93 loss: 0.5767701518151068
  batch 94 loss: 0.5766936737172147
  batch 95 loss: 0.5768356003259357
  batch 96 loss: 0.5767782647162676
  batch 97 loss: 0.5765103660907942
  batch 98 loss: 0.5767528639764202
  batch 99 loss: 0.576755004097717
  batch 100 loss: 0.5766615349054337
  batch 101 loss: 0.5767814151131281
  batch 102 loss: 0.5766451154269424
  batch 103 loss: 0.5767987474654485
  batch 104 loss: 0.5769860394872152
  batch 105 loss: 0.5771038134892782
  batch 106 loss: 0.5770920650014337
  batch 107 loss: 0.5768329941223715
  batch 108 loss: 0.5765846757977097
  batch 109 loss: 0.5764475196873377
  batch 110 loss: 0.5766477584838867
  batch 111 loss: 0.5767695882298924
  batch 112 loss: 0.5765575543045998
  batch 113 loss: 0.5764518448736815
  batch 114 loss: 0.576825970097592
  batch 115 loss: 0.576849857620571
  batch 116 loss: 0.5770638400110705
  batch 117 loss: 0.5771617115053356
  batch 118 loss: 0.5771045472662327
  batch 119 loss: 0.5771050302922225
  batch 120 loss: 0.5769592449069023
  batch 121 loss: 0.5768283709021639
  batch 122 loss: 0.5768449926962618
  batch 123 loss: 0.5768037956904589
  batch 124 loss: 0.5768561959266663
  batch 125 loss: 0.5769887771606446
  batch 126 loss: 0.5769150928845481
  batch 127 loss: 0.577094481216641
  batch 128 loss: 0.5767503455281258
  batch 129 loss: 0.576575240423513
  batch 130 loss: 0.5766062035010411
  batch 131 loss: 0.5764563056348845
  batch 132 loss: 0.5763689229885737
  batch 133 loss: 0.5765166627733331
  batch 134 loss: 0.5763837628400148
  batch 135 loss: 0.5766903148757087
  batch 136 loss: 0.5766312738551813
  batch 137 loss: 0.5767417436968671
  batch 138 loss: 0.5768014175304468
  batch 139 loss: 0.5767808921045536
  batch 140 loss: 0.5766566549028669
  batch 141 loss: 0.5767169150900333
  batch 142 loss: 0.5767633629516816
  batch 143 loss: 0.5766606355880524
  batch 144 loss: 0.5766102112829685
  batch 145 loss: 0.5766106716517745
  batch 146 loss: 0.576454662705121
  batch 147 loss: 0.5765563456379638
  batch 148 loss: 0.5766570994982848
  batch 149 loss: 0.5766075945540563
  batch 150 loss: 0.5764650019009908
  batch 151 loss: 0.5764637174985267
  batch 152 loss: 0.5764835014155036
  batch 153 loss: 0.5763616382686141
  batch 154 loss: 0.576202277239267
  batch 155 loss: 0.5762735024575264
  batch 156 loss: 0.5763085388984436
  batch 157 loss: 0.5764221716078983
  batch 158 loss: 0.5763668980025038
  batch 159 loss: 0.5763817549501575
  batch 160 loss: 0.5764692176133395
  batch 161 loss: 0.5767009387845579
  batch 162 loss: 0.5766127300851139
  batch 163 loss: 0.5765733429990663
  batch 164 loss: 0.5764282138609305
  batch 165 loss: 0.5765023751692339
  batch 166 loss: 0.5764965497585665
  batch 167 loss: 0.5765041344893906
  batch 168 loss: 0.5767741845477194
  batch 169 loss: 0.5768019754505722
  batch 170 loss: 0.5768548576270833
  batch 171 loss: 0.5769992184917829
  batch 172 loss: 0.5770348747109257
  batch 173 loss: 0.5770315090355845
  batch 174 loss: 0.5769601084035019
  batch 175 loss: 0.5768800902366639
  batch 176 loss: 0.5767790461805734
  batch 177 loss: 0.5766137323137057
  batch 178 loss: 0.576525333557236
  batch 179 loss: 0.5766120586315346
  batch 180 loss: 0.5765250023868349
  batch 181 loss: 0.576522073363731
  batch 182 loss: 0.5763700326065441
  batch 183 loss: 0.5763828389631594
  batch 184 loss: 0.5763043579847916
  batch 185 loss: 0.5763213106103846
  batch 186 loss: 0.5763927303975628
  batch 187 loss: 0.5764249834147367
  batch 188 loss: 0.5763104237774586
  batch 189 loss: 0.57612398850224
  batch 190 loss: 0.575995662651564
  batch 191 loss: 0.5761066416171209
  batch 192 loss: 0.5760512820755442
  batch 193 loss: 0.5760844776049797
  batch 194 loss: 0.5761398553233785
  batch 195 loss: 0.5762121182221632
  batch 196 loss: 0.576093710806905
  batch 197 loss: 0.5759711595356162
  batch 198 loss: 0.5760411364261551
  batch 199 loss: 0.576140105125293
  batch 200 loss: 0.5761067911982536
  batch 201 loss: 0.5760721573189124
  batch 202 loss: 0.5761602249475989
  batch 203 loss: 0.5762420742969795
  batch 204 loss: 0.5762612603458703
  batch 205 loss: 0.5764111199030062
  batch 206 loss: 0.5762961801973362
  batch 207 loss: 0.5762195031424076
  batch 208 loss: 0.5761982652430351
  batch 209 loss: 0.5760611843264274
  batch 210 loss: 0.576151194458916
  batch 211 loss: 0.576276767875346
  batch 212 loss: 0.5762589312386963
  batch 213 loss: 0.5763246652106164
  batch 214 loss: 0.5761852840953898
  batch 215 loss: 0.5760559872139331
  batch 216 loss: 0.575981655606517
  batch 217 loss: 0.5759619166774135
  batch 218 loss: 0.5759035460992691
  batch 219 loss: 0.5758047425039282
  batch 220 loss: 0.575759888237173
  batch 221 loss: 0.5756740807408122
  batch 222 loss: 0.5757326027294537
  batch 223 loss: 0.5758025130348889
  batch 224 loss: 0.5759305823594332
  batch 225 loss: 0.5757963066630893
  batch 226 loss: 0.5759204101246015
  batch 227 loss: 0.5758225432051436
  batch 228 loss: 0.5757592317827961
  batch 229 loss: 0.5757323638841054
  batch 230 loss: 0.5757046847239785
  batch 231 loss: 0.5757744410337308
  batch 232 loss: 0.5757373453214251
  batch 233 loss: 0.5756892774238095
  batch 234 loss: 0.5755453873903323
  batch 235 loss: 0.575611109936491
  batch 236 loss: 0.5755310111631782
  batch 237 loss: 0.5755706198104826
  batch 238 loss: 0.5755033846161947
  batch 239 loss: 0.5754923079801902
  batch 240 loss: 0.5754722483456135
  batch 241 loss: 0.5754990134991056
  batch 242 loss: 0.5753503902391954
  batch 243 loss: 0.5752839065873574
  batch 244 loss: 0.5753809311350838
  batch 245 loss: 0.5753116257336675
  batch 246 loss: 0.5754191369060578
  batch 247 loss: 0.575402522859303
  batch 248 loss: 0.5753794533591117
  batch 249 loss: 0.5754607063699438
  batch 250 loss: 0.5754127266407013
  batch 251 loss: 0.5755297703097066
  batch 252 loss: 0.575520697567198
  batch 253 loss: 0.5754623142155734
  batch 254 loss: 0.5754718069485792
  batch 255 loss: 0.5754132605066486
  batch 256 loss: 0.5753574573900551
  batch 257 loss: 0.5755435861502176
  batch 258 loss: 0.5754362333190534
  batch 259 loss: 0.57529671265812
  batch 260 loss: 0.5751813205388876
  batch 261 loss: 0.5751041429709658
  batch 262 loss: 0.5751077965015673
  batch 263 loss: 0.5750663978518642
  batch 264 loss: 0.5749749746738058
  batch 265 loss: 0.5749104272644475
  batch 266 loss: 0.5748836613239202
  batch 267 loss: 0.5749290467201548
  batch 268 loss: 0.5748334482534608
  batch 269 loss: 0.5748833519818615
  batch 270 loss: 0.5749246742990282
  batch 271 loss: 0.5750046346020434
  batch 272 loss: 0.5750146302230218
  batch 273 loss: 0.5750366471189282
  batch 274 loss: 0.5751004312595311
  batch 275 loss: 0.5751961014487527
  batch 276 loss: 0.5752229699190112
  batch 277 loss: 0.5751814114918348
  batch 278 loss: 0.5751755374798672
  batch 279 loss: 0.5752030734947505
  batch 280 loss: 0.5752264874322074
  batch 281 loss: 0.575203856963704
  batch 282 loss: 0.5751275775280404
  batch 283 loss: 0.574981705460026
  batch 284 loss: 0.5750480399165355
  batch 285 loss: 0.575119063519595
  batch 286 loss: 0.5751202829651065
  batch 287 loss: 0.5751803261893136
  batch 288 loss: 0.5750399062203037
  batch 289 loss: 0.5751198653943811
  batch 290 loss: 0.5748444616794586
  batch 291 loss: 0.5748113203294498
  batch 292 loss: 0.5748661227830468
  batch 293 loss: 0.5749323770861576
  batch 294 loss: 0.574869152437262
  batch 295 loss: 0.5748696973768331
  batch 296 loss: 0.5748119265646547
  batch 297 loss: 0.5747203955345283
  batch 298 loss: 0.5746975917144109
  batch 299 loss: 0.5747511984911252
  batch 300 loss: 0.574738231698672
  batch 301 loss: 0.5747032278399927
  batch 302 loss: 0.5745975793592187
  batch 303 loss: 0.5746239502437831
  batch 304 loss: 0.574561812767857
  batch 305 loss: 0.5743642259816655
  batch 306 loss: 0.5742983638850692
  batch 307 loss: 0.5743281485980031
  batch 308 loss: 0.5744197225415861
  batch 309 loss: 0.5743463346101705
  batch 310 loss: 0.5743562817573548
  batch 311 loss: 0.5744420772963398
  batch 312 loss: 0.5743822340781872
  batch 313 loss: 0.5744378564837641
  batch 314 loss: 0.5744647372300458
  batch 315 loss: 0.5744000340264941
  batch 316 loss: 0.5742695448519308
  batch 317 loss: 0.5742608675445292
  batch 318 loss: 0.5741764595673519
  batch 319 loss: 0.5740784855098187
  batch 320 loss: 0.5739371040835977
  batch 321 loss: 0.5738487085820729
  batch 322 loss: 0.573909199200802
  batch 323 loss: 0.5739683682335419
  batch 324 loss: 0.5738787763280633
  batch 325 loss: 0.5739483468349164
  batch 326 loss: 0.5738904861950436
  batch 327 loss: 0.5737876797305699
  batch 328 loss: 0.5737464180806788
  batch 329 loss: 0.5737860978193197
  batch 330 loss: 0.5738753452445522
  batch 331 loss: 0.5739088038663489
  batch 332 loss: 0.5739210204905775
  batch 333 loss: 0.5739720830688247
  batch 334 loss: 0.5739132899367166
  batch 335 loss: 0.5738462786176312
  batch 336 loss: 0.5738029059554849
  batch 337 loss: 0.5737381338719444
  batch 338 loss: 0.5738168254759185
  batch 339 loss: 0.5738315172603349
  batch 340 loss: 0.5738528870484408
  batch 341 loss: 0.5737920634208187
  batch 342 loss: 0.5737756548220652
  batch 343 loss: 0.5738360257955056
  batch 344 loss: 0.5738164765197177
  batch 345 loss: 0.5738924254541812
  batch 346 loss: 0.573773278321834
  batch 347 loss: 0.5737821135122425
  batch 348 loss: 0.5737854435868647
  batch 349 loss: 0.5737567822366184
  batch 350 loss: 0.5738722429956709
  batch 351 loss: 0.5739262268753813
  batch 352 loss: 0.573906911875714
  batch 353 loss: 0.5738508267375633
  batch 354 loss: 0.5739085787096939
  batch 355 loss: 0.5739473902003865
  batch 356 loss: 0.5739493962754024
  batch 357 loss: 0.5738819229836557
  batch 358 loss: 0.5739424584964135
  batch 359 loss: 0.5739725438001096
  batch 360 loss: 0.5740547890464465
  batch 361 loss: 0.5739934497262632
  batch 362 loss: 0.5740555498481456
  batch 363 loss: 0.574049910894767
  batch 364 loss: 0.5739609797249784
  batch 365 loss: 0.5739482193777006
  batch 366 loss: 0.5739851880594681
  batch 367 loss: 0.5738744636647383
  batch 368 loss: 0.5737841816052146
  batch 369 loss: 0.5738003074638243
  batch 370 loss: 0.5739275556963843
  batch 371 loss: 0.5739973463780796
  batch 372 loss: 0.5739470481552104
  batch 373 loss: 0.5739055822426129
  batch 374 loss: 0.573843175236554
  batch 375 loss: 0.5738103165626526
  batch 376 loss: 0.5738295690810427
  batch 377 loss: 0.5737956616859538
  batch 378 loss: 0.5736859032401332
  batch 379 loss: 0.5737436904441713
  batch 380 loss: 0.57379026381593
  batch 381 loss: 0.5736844952650896
  batch 382 loss: 0.5736385404439497
  batch 383 loss: 0.5737067892096995
  batch 384 loss: 0.5736912655023237
  batch 385 loss: 0.5737326423843185
  batch 386 loss: 0.5736351865560897
  batch 387 loss: 0.5735723216096252
  batch 388 loss: 0.5736254246271763
  batch 389 loss: 0.5736759340242126
  batch 390 loss: 0.573673223837828
  batch 391 loss: 0.5736555983038509
  batch 392 loss: 0.5736049389352604
  batch 393 loss: 0.573649881146943
  batch 394 loss: 0.5736253458231234
  batch 395 loss: 0.5736232321473617
  batch 396 loss: 0.5736234809714135
  batch 397 loss: 0.5735872628106278
  batch 398 loss: 0.5734647319244979
  batch 399 loss: 0.5735221036095965
  batch 400 loss: 0.5734645438194275
  batch 401 loss: 0.573413236182824
  batch 402 loss: 0.5734048515409973
  batch 403 loss: 0.5733691474640044
  batch 404 loss: 0.5734026564819978
  batch 405 loss: 0.5733588645487656
  batch 406 loss: 0.5733700377013295
  batch 407 loss: 0.5733571087698972
  batch 408 loss: 0.5734131257323658
  batch 409 loss: 0.57341777899446
  batch 410 loss: 0.5734245275578848
  batch 411 loss: 0.5734389047263022
  batch 412 loss: 0.5734211948600788
  batch 413 loss: 0.5734497180285234
  batch 414 loss: 0.573490823092668
  batch 415 loss: 0.5735611776271499
  batch 416 loss: 0.5735340263121403
  batch 417 loss: 0.5734714082390856
  batch 418 loss: 0.5734538611327632
  batch 419 loss: 0.5735217556179566
  batch 420 loss: 0.5735547023160117
  batch 421 loss: 0.573517898199394
  batch 422 loss: 0.5734941460792488
  batch 423 loss: 0.5735216676202508
  batch 424 loss: 0.5734440808026295
  batch 425 loss: 0.5735015616697423
  batch 426 loss: 0.5734720224505859
  batch 427 loss: 0.5734322551262742
  batch 428 loss: 0.5733946302783823
  batch 429 loss: 0.5734316330133896
  batch 430 loss: 0.5734146233214888
  batch 431 loss: 0.5733985459721559
  batch 432 loss: 0.5733642466366291
  batch 433 loss: 0.5732940775417565
  batch 434 loss: 0.573326918249306
  batch 435 loss: 0.573363538035031
  batch 436 loss: 0.5732780387368771
  batch 437 loss: 0.5733901580083834
  batch 438 loss: 0.5734554783666514
  batch 439 loss: 0.5734426284162222
  batch 440 loss: 0.5734180329875512
  batch 441 loss: 0.5733991146357962
  batch 442 loss: 0.5733178410325115
  batch 443 loss: 0.5732835720947042
  batch 444 loss: 0.5732926733053483
  batch 445 loss: 0.5732588012566727
  batch 446 loss: 0.5732966209740916
  batch 447 loss: 0.5732242686369808
  batch 448 loss: 0.5732563477275627
  batch 449 loss: 0.5732669092233569
  batch 450 loss: 0.5732581787639194
  batch 451 loss: 0.5732637575090328
  batch 452 loss: 0.5732272542947161
  batch 453 loss: 0.5731937128713326
  batch 454 loss: 0.5732481814428573
  batch 455 loss: 0.5733217561637962
  batch 456 loss: 0.5733280223712587
  batch 457 loss: 0.5733854121139326
  batch 458 loss: 0.5734317297498212
  batch 459 loss: 0.5734246169300121
  batch 460 loss: 0.5735243711782538
  batch 461 loss: 0.5735771045767563
  batch 462 loss: 0.5736012123363875
  batch 463 loss: 0.5736328129119543
  batch 464 loss: 0.5737139341132395
  batch 465 loss: 0.5736777487621513
  batch 466 loss: 0.5736680688264544
  batch 467 loss: 0.5736703091566261
  batch 468 loss: 0.5736173318746762
  batch 469 loss: 0.5735975792413073
  batch 470 loss: 0.5735509172398994
  batch 471 loss: 0.5735966872004693
  batch 472 loss: 0.5735473524210817
LOSS train 0.5735473524210817 valid 0.445120245218277
LOSS train 0.5735473524210817 valid 0.45832596719264984
LOSS train 0.5735473524210817 valid 0.4536753495534261
LOSS train 0.5735473524210817 valid 0.4545416384935379
LOSS train 0.5735473524210817 valid 0.4504472553730011
LOSS train 0.5735473524210817 valid 0.45493360857168835
LOSS train 0.5735473524210817 valid 0.45871264168194364
LOSS train 0.5735473524210817 valid 0.45854122564196587
LOSS train 0.5735473524210817 valid 0.4597976903120677
LOSS train 0.5735473524210817 valid 0.4615014284849167
LOSS train 0.5735473524210817 valid 0.463557476347143
LOSS train 0.5735473524210817 valid 0.4626927524805069
LOSS train 0.5735473524210817 valid 0.4653785503827609
LOSS train 0.5735473524210817 valid 0.4662181905337742
LOSS train 0.5735473524210817 valid 0.46747245589892067
LOSS train 0.5735473524210817 valid 0.466288547962904
LOSS train 0.5735473524210817 valid 0.46688539140364704
LOSS train 0.5735473524210817 valid 0.4665462176005046
LOSS train 0.5735473524210817 valid 0.4665471550665404
LOSS train 0.5735473524210817 valid 0.4678434535861015
LOSS train 0.5735473524210817 valid 0.4677482318310511
LOSS train 0.5735473524210817 valid 0.4667358249425888
LOSS train 0.5735473524210817 valid 0.4665076305036959
LOSS train 0.5735473524210817 valid 0.4660917880634467
LOSS train 0.5735473524210817 valid 0.4652042531967163
LOSS train 0.5735473524210817 valid 0.4646651813617119
LOSS train 0.5735473524210817 valid 0.4642529288927714
LOSS train 0.5735473524210817 valid 0.4645980511392866
LOSS train 0.5735473524210817 valid 0.4639236053516125
LOSS train 0.5735473524210817 valid 0.46468808452288307
LOSS train 0.5735473524210817 valid 0.4661578805215897
LOSS train 0.5735473524210817 valid 0.46596007980406284
LOSS train 0.5735473524210817 valid 0.4663998033061172
LOSS train 0.5735473524210817 valid 0.467087530037936
LOSS train 0.5735473524210817 valid 0.46807500634874616
LOSS train 0.5735473524210817 valid 0.46805598586797714
LOSS train 0.5735473524210817 valid 0.4686088819761534
LOSS train 0.5735473524210817 valid 0.4688967913389206
LOSS train 0.5735473524210817 valid 0.46856106855930424
LOSS train 0.5735473524210817 valid 0.46915980875492097
LOSS train 0.5735473524210817 valid 0.46934106364482786
LOSS train 0.5735473524210817 valid 0.46923884962286266
LOSS train 0.5735473524210817 valid 0.4689991702867109
LOSS train 0.5735473524210817 valid 0.4690227420492606
LOSS train 0.5735473524210817 valid 0.4686436474323273
LOSS train 0.5735473524210817 valid 0.46914996271548065
LOSS train 0.5735473524210817 valid 0.46919236855303986
LOSS train 0.5735473524210817 valid 0.46980002149939537
LOSS train 0.5735473524210817 valid 0.47049656571174153
LOSS train 0.5735473524210817 valid 0.4699216973781586
LOSS train 0.5735473524210817 valid 0.4705459756009719
LOSS train 0.5735473524210817 valid 0.4707630815414282
LOSS train 0.5735473524210817 valid 0.47071789064497316
LOSS train 0.5735473524210817 valid 0.4703475992988657
LOSS train 0.5735473524210817 valid 0.47059601924636146
LOSS train 0.5735473524210817 valid 0.4705312214791775
LOSS train 0.5735473524210817 valid 0.47045682449089854
LOSS train 0.5735473524210817 valid 0.4704374958728922
LOSS train 0.5735473524210817 valid 0.4709097874366631
LOSS train 0.5735473524210817 valid 0.47071626285711926
LOSS train 0.5735473524210817 valid 0.4699282401897868
LOSS train 0.5735473524210817 valid 0.47014636233929663
LOSS train 0.5735473524210817 valid 0.47014000160353525
LOSS train 0.5735473524210817 valid 0.4705862053669989
LOSS train 0.5735473524210817 valid 0.47081596484551064
LOSS train 0.5735473524210817 valid 0.4705122953111475
LOSS train 0.5735473524210817 valid 0.4703785403450923
LOSS train 0.5735473524210817 valid 0.47045112182112303
LOSS train 0.5735473524210817 valid 0.47037695413050445
LOSS train 0.5735473524210817 valid 0.4700965826000486
LOSS train 0.5735473524210817 valid 0.4697908897634963
LOSS train 0.5735473524210817 valid 0.4697190129922496
LOSS train 0.5735473524210817 valid 0.4699759642555289
LOSS train 0.5735473524210817 valid 0.4695122600407214
LOSS train 0.5735473524210817 valid 0.4694008473555247
LOSS train 0.5735473524210817 valid 0.4695551567956021
LOSS train 0.5735473524210817 valid 0.469460260558438
LOSS train 0.5735473524210817 valid 0.46950642726360226
LOSS train 0.5735473524210817 valid 0.4694434528863883
LOSS train 0.5735473524210817 valid 0.46928045600652696
LOSS train 0.5735473524210817 valid 0.46889463324605685
LOSS train 0.5735473524210817 valid 0.4690333902835846
LOSS train 0.5735473524210817 valid 0.468805454940681
LOSS train 0.5735473524210817 valid 0.4689657280132884
LOSS train 0.5735473524210817 valid 0.46870096992043886
LOSS train 0.5735473524210817 valid 0.4685868697110997
LOSS train 0.5735473524210817 valid 0.4686525498313465
LOSS train 0.5735473524210817 valid 0.46875129640102386
LOSS train 0.5735473524210817 valid 0.46898585624909134
LOSS train 0.5735473524210817 valid 0.46919794347551136
LOSS train 0.5735473524210817 valid 0.4694072774478367
LOSS train 0.5735473524210817 valid 0.4693545501517213
LOSS train 0.5735473524210817 valid 0.4690792454827216
LOSS train 0.5735473524210817 valid 0.46913625109702983
LOSS train 0.5735473524210817 valid 0.46908003562375117
LOSS train 0.5735473524210817 valid 0.46897387877106667
LOSS train 0.5735473524210817 valid 0.46906104837496254
LOSS train 0.5735473524210817 valid 0.4689712132118186
LOSS train 0.5735473524210817 valid 0.4693522570711194
LOSS train 0.5735473524210817 valid 0.4694074574112892
LOSS train 0.5735473524210817 valid 0.4694720769282615
LOSS train 0.5735473524210817 valid 0.46952006775958866
LOSS train 0.5735473524210817 valid 0.46974655407146343
LOSS train 0.5735473524210817 valid 0.4698112366291193
LOSS train 0.5735473524210817 valid 0.4698132974760873
LOSS train 0.5735473524210817 valid 0.4699523373032516
LOSS train 0.5735473524210817 valid 0.46981564999740816
LOSS train 0.5735473524210817 valid 0.46982218849438206
LOSS train 0.5735473524210817 valid 0.4699655801331231
LOSS train 0.5735473524210817 valid 0.4701345687562769
LOSS train 0.5735473524210817 valid 0.47012952480230247
LOSS train 0.5735473524210817 valid 0.4701302812567779
LOSS train 0.5735473524210817 valid 0.4702448541611697
LOSS train 0.5735473524210817 valid 0.47000405584511
LOSS train 0.5735473524210817 valid 0.4701000278410704
LOSS train 0.5735473524210817 valid 0.47031006294077843
LOSS train 0.5735473524210817 valid 0.47024460608123714
LOSS train 0.5735473524210817 valid 0.47009792772390074
LOSS train 0.5735473524210817 valid 0.4700606986254203
LOSS train 0.5735473524210817 valid 0.47012145866950356
LOSS train 0.5735473524210817 valid 0.46996918443805913
LOSS train 0.5735473524210817 valid 0.46994018017268574
LOSS train 0.5735473524210817 valid 0.4699334417416797
LOSS train 0.5735473524210817 valid 0.47002489408177717
LOSS train 0.5735473524210817 valid 0.4701502695083618
LOSS train 0.5735473524210817 valid 0.4701380109976208
LOSS train 0.5735473524210817 valid 0.4703495516551761
LOSS train 0.5735473524210817 valid 0.4704671064391732
LOSS train 0.5735473524210817 valid 0.47062596886657004
LOSS train 0.5735473524210817 valid 0.4705554680182384
LOSS train 0.5735473524210817 valid 0.47058292586384837
LOSS train 0.5735473524210817 valid 0.4704091147039876
LOSS train 0.5735473524210817 valid 0.4703174860853898
LOSS train 0.5735473524210817 valid 0.470345773803654
LOSS train 0.5735473524210817 valid 0.4703871042640121
LOSS train 0.5735473524210817 valid 0.4703454235020806
LOSS train 0.5735473524210817 valid 0.47019410046347737
LOSS train 0.5735473524210817 valid 0.47008688186389813
LOSS train 0.5735473524210817 valid 0.47005809082401745
LOSS train 0.5735473524210817 valid 0.470103779222284
LOSS train 0.5735473524210817 valid 0.47011159138476594
LOSS train 0.5735473524210817 valid 0.4701424165510795
LOSS train 0.5735473524210817 valid 0.47009048553613514
LOSS train 0.5735473524210817 valid 0.47011837363243103
LOSS train 0.5735473524210817 valid 0.4700108026636058
LOSS train 0.5735473524210817 valid 0.4702069534830851
LOSS train 0.5735473524210817 valid 0.47002855328475535
LOSS train 0.5735473524210817 valid 0.47030086855630615
LOSS train 0.5735473524210817 valid 0.4702750878446054
LOSS train 0.5735473524210817 valid 0.47030430773893994
LOSS train 0.5735473524210817 valid 0.4703484651268713
LOSS train 0.5735473524210817 valid 0.4702096273632426
LOSS train 0.5735473524210817 valid 0.47022772906652466
LOSS train 0.5735473524210817 valid 0.4702973979247081
LOSS train 0.5735473524210817 valid 0.4701708987835915
LOSS train 0.5735473524210817 valid 0.4703820334413113
LOSS train 0.5735473524210817 valid 0.47035628993799733
LOSS train 0.5735473524210817 valid 0.47045156095601337
LOSS train 0.5735473524210817 valid 0.4703213853656121
LOSS train 0.5735473524210817 valid 0.47024738136678934
LOSS train 0.5735473524210817 valid 0.47036158964500663
LOSS train 0.5735473524210817 valid 0.4702785250581341
LOSS train 0.5735473524210817 valid 0.47030423572458374
LOSS train 0.5735473524210817 valid 0.4701274375363094
LOSS train 0.5735473524210817 valid 0.4700508171861822
LOSS train 0.5735473524210817 valid 0.469866480812969
LOSS train 0.5735473524210817 valid 0.4700138144150466
LOSS train 0.5735473524210817 valid 0.47010031307027456
LOSS train 0.5735473524210817 valid 0.4700980479195273
LOSS train 0.5735473524210817 valid 0.4700824977720485
LOSS train 0.5735473524210817 valid 0.470314983213157
LOSS train 0.5735473524210817 valid 0.4704799040458923
LOSS train 0.5735473524210817 valid 0.47060533462232246
LOSS train 0.5735473524210817 valid 0.47064184594428404
LOSS train 0.5735473524210817 valid 0.4706958590235029
LOSS train 0.5735473524210817 valid 0.4707880531522361
LOSS train 0.5735473524210817 valid 0.47081560805692513
LOSS train 0.5735473524210817 valid 0.4710260308190678
LOSS train 0.5735473524210817 valid 0.4711164925351489
LOSS train 0.5735473524210817 valid 0.47119889540804755
LOSS train 0.5735473524210817 valid 0.4712154995341327
LOSS train 0.5735473524210817 valid 0.47128182305739474
LOSS train 0.5735473524210817 valid 0.47126333619076044
LOSS train 0.5735473524210817 valid 0.47127803010137187
LOSS train 0.5735473524210817 valid 0.471162258612143
LOSS train 0.5735473524210817 valid 0.47123014173840966
LOSS train 0.5735473524210817 valid 0.47142553536649695
LOSS train 0.5735473524210817 valid 0.4715522513427633
LOSS train 0.5735473524210817 valid 0.47142499858740144
LOSS train 0.5735473524210817 valid 0.471353669386161
LOSS train 0.5735473524210817 valid 0.4714705174818089
LOSS train 0.5735473524210817 valid 0.47154773290579516
LOSS train 0.5735473524210817 valid 0.4715873683981327
LOSS train 0.5735473524210817 valid 0.4714976369412904
LOSS train 0.5735473524210817 valid 0.4713988421819149
LOSS train 0.5735473524210817 valid 0.47136950356011487
LOSS train 0.5735473524210817 valid 0.4713957129698719
LOSS train 0.5735473524210817 valid 0.47124183719808405
LOSS train 0.5735473524210817 valid 0.4713352538233426
LOSS train 0.5735473524210817 valid 0.47134045988321305
LOSS train 0.5735473524210817 valid 0.47126650365430917
LOSS train 0.5735473524210817 valid 0.4713057635149153
LOSS train 0.5735473524210817 valid 0.4713053079367858
LOSS train 0.5735473524210817 valid 0.4713511611608898
LOSS train 0.5735473524210817 valid 0.471398877952157
LOSS train 0.5735473524210817 valid 0.4715163278058895
LOSS train 0.5735473524210817 valid 0.47156377906960567
LOSS train 0.5735473524210817 valid 0.4715391490608454
LOSS train 0.5735473524210817 valid 0.4713448063608562
LOSS train 0.5735473524210817 valid 0.4712767731575739
LOSS train 0.5735473524210817 valid 0.4713254474915599
LOSS train 0.5735473524210817 valid 0.47130682277229596
LOSS train 0.5735473524210817 valid 0.47133444424526233
LOSS train 0.5735473524210817 valid 0.4712428379560185
LOSS train 0.5735473524210817 valid 0.47111588758091594
LOSS train 0.5735473524210817 valid 0.47111783356026365
LOSS train 0.5735473524210817 valid 0.4711814959477719
LOSS train 0.5735473524210817 valid 0.47117904594185156
LOSS train 0.5735473524210817 valid 0.47119035486761296
LOSS train 0.5735473524210817 valid 0.47116983492266046
LOSS train 0.5735473524210817 valid 0.47118074012018435
LOSS train 0.5735473524210817 valid 0.47123346202545335
LOSS train 0.5735473524210817 valid 0.4713483758838722
LOSS train 0.5735473524210817 valid 0.4713298591918179
LOSS train 0.5735473524210817 valid 0.4712988120979733
LOSS train 0.5735473524210817 valid 0.47120629949907283
LOSS train 0.5735473524210817 valid 0.4713305534245159
LOSS train 0.5735473524210817 valid 0.4714068318145317
LOSS train 0.5735473524210817 valid 0.47141066779215784
LOSS train 0.5735473524210817 valid 0.4714910783197569
LOSS train 0.5735473524210817 valid 0.4714218331621839
LOSS train 0.5735473524210817 valid 0.4714443848050874
LOSS train 0.5735473524210817 valid 0.47127616981068393
LOSS train 0.5735473524210817 valid 0.4712868655084545
LOSS train 0.5735473524210817 valid 0.4713598179056289
LOSS train 0.5735473524210817 valid 0.4713516154531705
LOSS train 0.5735473524210817 valid 0.4713374383841889
LOSS train 0.5735473524210817 valid 0.4712582199262972
LOSS train 0.5735473524210817 valid 0.47126590981144284
LOSS train 0.5735473524210817 valid 0.4712379320214192
LOSS train 0.5735473524210817 valid 0.47134685652384617
LOSS train 0.5735473524210817 valid 0.47132943459778776
LOSS train 0.5735473524210817 valid 0.47135645739826154
LOSS train 0.5735473524210817 valid 0.4713436046340426
LOSS train 0.5735473524210817 valid 0.4712914065438874
LOSS train 0.5735473524210817 valid 0.47126843798451307
LOSS train 0.5735473524210817 valid 0.47141773256695707
LOSS train 0.5735473524210817 valid 0.4713879959477532
LOSS train 0.5735473524210817 valid 0.4713823500886021
LOSS train 0.5735473524210817 valid 0.4714691376686096
LOSS train 0.5735473524210817 valid 0.47143680332191434
LOSS train 0.5735473524210817 valid 0.47147770367917563
LOSS train 0.5735473524210817 valid 0.471551596058216
LOSS train 0.5735473524210817 valid 0.4716146861709009
LOSS train 0.5735473524210817 valid 0.4715690664216584
LOSS train 0.5735473524210817 valid 0.4715526202926412
LOSS train 0.5735473524210817 valid 0.4714676045490146
LOSS train 0.5735473524210817 valid 0.47147713231947996
LOSS train 0.5735473524210817 valid 0.47147673587081057
LOSS train 0.5735473524210817 valid 0.4714746696444658
LOSS train 0.5735473524210817 valid 0.4715267246253646
LOSS train 0.5735473524210817 valid 0.47158515419213826
LOSS train 0.5735473524210817 valid 0.4716243135385187
LOSS train 0.5735473524210817 valid 0.4716108866939039
LOSS train 0.5735473524210817 valid 0.4716259833776726
LOSS train 0.5735473524210817 valid 0.4716283434763887
LOSS train 0.5735473524210817 valid 0.47161742263518913
LOSS train 0.5735473524210817 valid 0.4715577189379664
LOSS train 0.5735473524210817 valid 0.4716663009393614
LOSS train 0.5735473524210817 valid 0.4716457182610476
LOSS train 0.5735473524210817 valid 0.4716829311143868
LOSS train 0.5735473524210817 valid 0.47170139126041355
LOSS train 0.5735473524210817 valid 0.4717853190479698
LOSS train 0.5735473524210817 valid 0.4717554783951627
LOSS train 0.5735473524210817 valid 0.47172333229671826
LOSS train 0.5735473524210817 valid 0.4717723648401274
LOSS train 0.5735473524210817 valid 0.47182602798465356
LOSS train 0.5735473524210817 valid 0.4717647730232143
LOSS train 0.5735473524210817 valid 0.4718443805812508
LOSS train 0.5735473524210817 valid 0.4718239522406033
LOSS train 0.5735473524210817 valid 0.4716867272115687
LOSS train 0.5735473524210817 valid 0.47162900452918194
LOSS train 0.5735473524210817 valid 0.4716033162582047
LOSS train 0.5735473524210817 valid 0.4716932012791365
LOSS train 0.5735473524210817 valid 0.4717530632228182
LOSS train 0.5735473524210817 valid 0.47170828491240946
LOSS train 0.5735473524210817 valid 0.47167710165528887
LOSS train 0.5735473524210817 valid 0.4717092737555504
LOSS train 0.5735473524210817 valid 0.4716564805656156
LOSS train 0.5735473524210817 valid 0.4716344822069694
LOSS train 0.5735473524210817 valid 0.47151237634039417
LOSS train 0.5735473524210817 valid 0.47147054378300496
LOSS train 0.5735473524210817 valid 0.47145101733175154
LOSS train 0.5735473524210817 valid 0.47151375597431544
LOSS train 0.5735473524210817 valid 0.47158945162417526
LOSS train 0.5735473524210817 valid 0.47163679561502225
LOSS train 0.5735473524210817 valid 0.4716133847581818
LOSS train 0.5735473524210817 valid 0.47164822424818204
LOSS train 0.5735473524210817 valid 0.47171305852590195
LOSS train 0.5735473524210817 valid 0.4716763271888097
LOSS train 0.5735473524210817 valid 0.47169716126498984
LOSS train 0.5735473524210817 valid 0.47165159772563453
LOSS train 0.5735473524210817 valid 0.4716417198330656
LOSS train 0.5735473524210817 valid 0.4716734595988926
LOSS train 0.5735473524210817 valid 0.47161882490408225
LOSS train 0.5735473524210817 valid 0.47157634327224657
LOSS train 0.5735473524210817 valid 0.4715823075864525
LOSS train 0.5735473524210817 valid 0.47158413748075434
LOSS train 0.5735473524210817 valid 0.47158923532970515
LOSS train 0.5735473524210817 valid 0.4715725003711639
LOSS train 0.5735473524210817 valid 0.4715116354621875
LOSS train 0.5735473524210817 valid 0.4715366724591989
LOSS train 0.5735473524210817 valid 0.4716449292323079
LOSS train 0.5735473524210817 valid 0.47168666342641136
LOSS train 0.5735473524210817 valid 0.4717435155596052
LOSS train 0.5735473524210817 valid 0.47166372288631486
LOSS train 0.5735473524210817 valid 0.4717172503659402
LOSS train 0.5735473524210817 valid 0.471686416358318
LOSS train 0.5735473524210817 valid 0.47170962201764216
LOSS train 0.5735473524210817 valid 0.4716816076077521
LOSS train 0.5735473524210817 valid 0.47166805930226763
LOSS train 0.5735473524210817 valid 0.4716451272646092
LOSS train 0.5735473524210817 valid 0.47162234386423424
LOSS train 0.5735473524210817 valid 0.47159887565138897
LOSS train 0.5735473524210817 valid 0.47159061450224654
LOSS train 0.5735473524210817 valid 0.47167610134815147
LOSS train 0.5735473524210817 valid 0.471684192572165
LOSS train 0.5735473524210817 valid 0.47180751066018894
LOSS train 0.5735473524210817 valid 0.4718242629139619
LOSS train 0.5735473524210817 valid 0.4718341860807303
LOSS train 0.5735473524210817 valid 0.47177809449841246
LOSS train 0.5735473524210817 valid 0.47166881809033545
LOSS train 0.5735473524210817 valid 0.4716316385491116
LOSS train 0.5735473524210817 valid 0.4717496345321575
LOSS train 0.5735473524210817 valid 0.4717149469389844
LOSS train 0.5735473524210817 valid 0.4717361834787187
LOSS train 0.5735473524210817 valid 0.4716862339294275
LOSS train 0.5735473524210817 valid 0.4716967857448307
LOSS train 0.5735473524210817 valid 0.4716105298482563
LOSS train 0.5735473524210817 valid 0.47153419790899054
LOSS train 0.5735473524210817 valid 0.4714929009637525
LOSS train 0.5735473524210817 valid 0.4715057922559872
LOSS train 0.5735473524210817 valid 0.4715134498850597
LOSS train 0.5735473524210817 valid 0.47158486231468444
LOSS train 0.5735473524210817 valid 0.4715713257374971
LOSS train 0.5735473524210817 valid 0.471581535101626
LOSS train 0.5735473524210817 valid 0.47154475503764853
LOSS train 0.5735473524210817 valid 0.47157964427238225
LOSS train 0.5735473524210817 valid 0.4716250967330441
LOSS train 0.5735473524210817 valid 0.4716143990414483
LOSS train 0.5735473524210817 valid 0.4715770502545555
LOSS train 0.5735473524210817 valid 0.47159646739336575
LOSS train 0.5735473524210817 valid 0.4716271271786676
LOSS train 0.5735473524210817 valid 0.47166606480792417
LOSS train 0.5735473524210817 valid 0.47171700420513957
LOSS train 0.5735473524210817 valid 0.4717701626627633
LOSS train 0.5735473524210817 valid 0.47173649648658367
LOSS train 0.5735473524210817 valid 0.4716917195633137
LOSS train 0.5735473524210817 valid 0.47170069506573475
LOSS train 0.5735473524210817 valid 0.4717194143268797
LOSS train 0.5735473524210817 valid 0.47174775806820624
LOSS train 0.5735473524210817 valid 0.4718092392656685
LOSS train 0.5735473524210817 valid 0.4718181000760764
LOSS train 0.5735473524210817 valid 0.47182143332211524
LOSS train 0.5735473524210817 valid 0.47184595563640336
LOSS train 0.5735473524210817 valid 0.47183380679028936
LOSS train 0.5735473524210817 valid 0.4717638617640295
LOSS train 0.5735473524210817 valid 0.471770693588516
LOSS train 0.5735473524210817 valid 0.47176251211140535
EPOCH 15:
  batch 1 loss: 0.5586730241775513
  batch 2 loss: 0.5501580834388733
  batch 3 loss: 0.5605294307072958
  batch 4 loss: 0.5720262229442596
  batch 5 loss: 0.5714357256889343
  batch 6 loss: 0.5684557259082794
  batch 7 loss: 0.5742619718824115
  batch 8 loss: 0.572445884346962
  batch 9 loss: 0.5741394890679253
  batch 10 loss: 0.5743469774723053
  batch 11 loss: 0.5756057392467152
  batch 12 loss: 0.5761785705884298
  batch 13 loss: 0.5768890426709101
  batch 14 loss: 0.5766857394150325
  batch 15 loss: 0.5800739487012228
  batch 16 loss: 0.578804362565279
  batch 17 loss: 0.579519485726076
  batch 18 loss: 0.5794195665253533
  batch 19 loss: 0.5785141430403057
  batch 20 loss: 0.5790639787912368
  batch 21 loss: 0.5799790592420668
  batch 22 loss: 0.5790277204730294
  batch 23 loss: 0.578405859677688
  batch 24 loss: 0.5779488310217857
  batch 25 loss: 0.5798043417930603
  batch 26 loss: 0.5789278218379388
  batch 27 loss: 0.5789964088687191
  batch 28 loss: 0.5774789942162377
  batch 29 loss: 0.5777702023243082
  batch 30 loss: 0.5771004637082418
  batch 31 loss: 0.57643933257749
  batch 32 loss: 0.5762641597539186
  batch 33 loss: 0.5762018633611274
  batch 34 loss: 0.5761825898114372
  batch 35 loss: 0.5777608701160976
  batch 36 loss: 0.5772765990760591
  batch 37 loss: 0.5772928514996091
  batch 38 loss: 0.5765203802209151
  batch 39 loss: 0.5762031995333158
  batch 40 loss: 0.5752523988485336
  batch 41 loss: 0.5751314977320229
  batch 42 loss: 0.5751442767324901
  batch 43 loss: 0.5751898371896078
  batch 44 loss: 0.5745421620932493
  batch 45 loss: 0.5745723618401422
  batch 46 loss: 0.5741807028003361
  batch 47 loss: 0.5736636088249532
  batch 48 loss: 0.5737637418011824
  batch 49 loss: 0.5735694924179389
  batch 50 loss: 0.5739189553260803
  batch 51 loss: 0.5734163312351003
  batch 52 loss: 0.5736264460361921
  batch 53 loss: 0.5736856460571289
  batch 54 loss: 0.5736949090604428
  batch 55 loss: 0.5733124429529364
  batch 56 loss: 0.5730842117752347
  batch 57 loss: 0.5729595527314303
  batch 58 loss: 0.5729806484847233
  batch 59 loss: 0.5732566047522981
  batch 60 loss: 0.5731019149223964
  batch 61 loss: 0.5728575802240216
  batch 62 loss: 0.5727388599226552
  batch 63 loss: 0.5729245817850507
  batch 64 loss: 0.5727611146867275
  batch 65 loss: 0.5729020852309007
  batch 66 loss: 0.5727507363666188
  batch 67 loss: 0.5729137605695582
  batch 68 loss: 0.5734042428872165
  batch 69 loss: 0.5736110625059708
  batch 70 loss: 0.5739493591444833
  batch 71 loss: 0.5740231082473003
  batch 72 loss: 0.573772651453813
  batch 73 loss: 0.5736075803025128
  batch 74 loss: 0.5736886077635998
  batch 75 loss: 0.5741165773073832
  batch 76 loss: 0.5739884745133551
  batch 77 loss: 0.5739385818506216
  batch 78 loss: 0.5734948607591482
  batch 79 loss: 0.5736236579810516
  batch 80 loss: 0.5732642896473408
  batch 81 loss: 0.5731707789279796
  batch 82 loss: 0.5738451626242661
  batch 83 loss: 0.5738453426993037
  batch 84 loss: 0.5741387839828219
  batch 85 loss: 0.5734869529219234
  batch 86 loss: 0.5737717103126437
  batch 87 loss: 0.5739212906223604
  batch 88 loss: 0.5739091661843386
  batch 89 loss: 0.573876776052325
  batch 90 loss: 0.5738479011588626
  batch 91 loss: 0.573916223022964
  batch 92 loss: 0.5738480803759202
  batch 93 loss: 0.5740894092026577
  batch 94 loss: 0.5739916651806933
  batch 95 loss: 0.5741194511714734
  batch 96 loss: 0.5740899766484896
  batch 97 loss: 0.5739451339564372
  batch 98 loss: 0.5742615972246442
  batch 99 loss: 0.5741553752109257
  batch 100 loss: 0.5740902543067932
  batch 101 loss: 0.5740811960531933
  batch 102 loss: 0.574049742198458
  batch 103 loss: 0.5739994500447245
  batch 104 loss: 0.57420075742098
  batch 105 loss: 0.5744402970586504
  batch 106 loss: 0.5744248398070065
  batch 107 loss: 0.5742580205480629
  batch 108 loss: 0.5740373598204719
  batch 109 loss: 0.57387819858866
  batch 110 loss: 0.5742404569279064
  batch 111 loss: 0.5743768263507534
  batch 112 loss: 0.5744440236261913
  batch 113 loss: 0.5743696784551164
  batch 114 loss: 0.5746108659526759
  batch 115 loss: 0.5745641843132351
  batch 116 loss: 0.5748909372707893
  batch 117 loss: 0.5750183590456971
  batch 118 loss: 0.5751248658713648
  batch 119 loss: 0.5751156316084021
  batch 120 loss: 0.575028624633948
  batch 121 loss: 0.5749432681020626
  batch 122 loss: 0.5749840482336576
  batch 123 loss: 0.5750463871451897
  batch 124 loss: 0.5751284457022144
  batch 125 loss: 0.5752299938201905
  batch 126 loss: 0.5751210545736646
  batch 127 loss: 0.5752264871372013
  batch 128 loss: 0.5748962601646781
  batch 129 loss: 0.5747536947560865
  batch 130 loss: 0.5747532977507664
  batch 131 loss: 0.574680881190846
  batch 132 loss: 0.5746300956516555
  batch 133 loss: 0.5748353963507745
  batch 134 loss: 0.5747890143252131
  batch 135 loss: 0.5749151569825631
  batch 136 loss: 0.5747408498735989
  batch 137 loss: 0.5749650427894871
  batch 138 loss: 0.5752761700878972
  batch 139 loss: 0.5752345812406471
  batch 140 loss: 0.5752044022083282
  batch 141 loss: 0.5751241830223841
  batch 142 loss: 0.5752187539154375
  batch 143 loss: 0.5751547438281399
  batch 144 loss: 0.574915151629183
  batch 145 loss: 0.5751124118936473
  batch 146 loss: 0.5749626376040994
  batch 147 loss: 0.5750329960771159
  batch 148 loss: 0.5751200137106148
  batch 149 loss: 0.5750144364049771
  batch 150 loss: 0.5750130319595337
  batch 151 loss: 0.5750687761812021
  batch 152 loss: 0.5751331483847216
  batch 153 loss: 0.5750484754836637
  batch 154 loss: 0.5751226292802142
  batch 155 loss: 0.5751799841080942
  batch 156 loss: 0.5753740588059792
  batch 157 loss: 0.5754951910608134
  batch 158 loss: 0.5754656169233443
  batch 159 loss: 0.575447216348828
  batch 160 loss: 0.5755188673734665
  batch 161 loss: 0.5756537558869546
  batch 162 loss: 0.5755401467099602
  batch 163 loss: 0.5754528652670925
  batch 164 loss: 0.5752813598004783
  batch 165 loss: 0.5752362988211892
  batch 166 loss: 0.5752619627010391
  batch 167 loss: 0.5751786703121162
  batch 168 loss: 0.5753907405194782
  batch 169 loss: 0.5754061746879442
  batch 170 loss: 0.5754140082527609
  batch 171 loss: 0.5753952703977886
  batch 172 loss: 0.575361312821854
  batch 173 loss: 0.5754091932594432
  batch 174 loss: 0.5753385705509405
  batch 175 loss: 0.5752008444922311
  batch 176 loss: 0.5751480541445992
  batch 177 loss: 0.5750329066804574
  batch 178 loss: 0.5749354975277119
  batch 179 loss: 0.5751408421793464
  batch 180 loss: 0.5751168095403247
  batch 181 loss: 0.5752201534766519
  batch 182 loss: 0.5752088846741142
  batch 183 loss: 0.5752631523570076
  batch 184 loss: 0.5752095479680144
  batch 185 loss: 0.5753312069016534
  batch 186 loss: 0.575381511962542
  batch 187 loss: 0.5754401126009895
  batch 188 loss: 0.5752701128416873
  batch 189 loss: 0.5751211040865176
  batch 190 loss: 0.5749944404551858
  batch 191 loss: 0.5750119670523399
  batch 192 loss: 0.5750070900345842
  batch 193 loss: 0.5750472629008515
  batch 194 loss: 0.5750496915935241
  batch 195 loss: 0.5751931523665403
  batch 196 loss: 0.575124798684704
  batch 197 loss: 0.5750782423213049
  batch 198 loss: 0.5752071286692764
  batch 199 loss: 0.5752226419784315
  batch 200 loss: 0.5751662707328796
  batch 201 loss: 0.5751698610201403
  batch 202 loss: 0.5751260356737835
  batch 203 loss: 0.5752755588498609
  batch 204 loss: 0.575284376448276
  batch 205 loss: 0.5752942666774843
  batch 206 loss: 0.5751262081479563
  batch 207 loss: 0.5751310454474555
  batch 208 loss: 0.5750517266301008
  batch 209 loss: 0.5749199612859334
  batch 210 loss: 0.5748304191089811
  batch 211 loss: 0.5748453959469547
  batch 212 loss: 0.5747361722982155
  batch 213 loss: 0.5748302315322447
  batch 214 loss: 0.5746416739214246
  batch 215 loss: 0.5745313186978185
  batch 216 loss: 0.5744610006610552
  batch 217 loss: 0.5743898661455251
  batch 218 loss: 0.5743896542885981
  batch 219 loss: 0.5744232007357628
  batch 220 loss: 0.5744039489464327
  batch 221 loss: 0.5744303483768826
  batch 222 loss: 0.5745080244970752
  batch 223 loss: 0.5746482861950793
  batch 224 loss: 0.5747719832829067
  batch 225 loss: 0.5746824378437466
  batch 226 loss: 0.5746886126235523
  batch 227 loss: 0.5745972822941348
  batch 228 loss: 0.5744778594949789
  batch 229 loss: 0.5744681105863579
  batch 230 loss: 0.5744649962238644
  batch 231 loss: 0.5745637501989093
  batch 232 loss: 0.5744749284509955
  batch 233 loss: 0.5744319271632019
  batch 234 loss: 0.5743681768066863
  batch 235 loss: 0.574504314584935
  batch 236 loss: 0.5743642237226841
  batch 237 loss: 0.5744719696447316
  batch 238 loss: 0.5743918003154402
  batch 239 loss: 0.5743631887635426
  batch 240 loss: 0.5743630041678747
  batch 241 loss: 0.574268854999938
  batch 242 loss: 0.5741360847615014
  batch 243 loss: 0.5741337049645161
  batch 244 loss: 0.5742126471195065
  batch 245 loss: 0.5741248376515447
  batch 246 loss: 0.5742408318248221
  batch 247 loss: 0.5742737440927791
  batch 248 loss: 0.5742722269027464
  batch 249 loss: 0.5743328495676737
  batch 250 loss: 0.5743266432285309
  batch 251 loss: 0.5742933168354263
  batch 252 loss: 0.5742321965240297
  batch 253 loss: 0.5741635483244191
  batch 254 loss: 0.5741805633691353
  batch 255 loss: 0.5741189351268843
  batch 256 loss: 0.57405965635553
  batch 257 loss: 0.5742204711131085
  batch 258 loss: 0.5741182230701742
  batch 259 loss: 0.5740232753017234
  batch 260 loss: 0.5739509201966799
  batch 261 loss: 0.5739143433698749
  batch 262 loss: 0.5739120690877201
  batch 263 loss: 0.5739315721018686
  batch 264 loss: 0.5738908160816539
  batch 265 loss: 0.5737733768966963
  batch 266 loss: 0.5738058733312708
  batch 267 loss: 0.5738640878530924
  batch 268 loss: 0.5738024709384832
  batch 269 loss: 0.5738184214967778
  batch 270 loss: 0.5738530501171395
  batch 271 loss: 0.5738912211572992
  batch 272 loss: 0.5739625484189567
  batch 273 loss: 0.5739562234162411
  batch 274 loss: 0.5740150380743682
  batch 275 loss: 0.5742045812173323
  batch 276 loss: 0.5742744451415711
  batch 277 loss: 0.5743032545389252
  batch 278 loss: 0.5743666014654173
  batch 279 loss: 0.5745056656099135
  batch 280 loss: 0.5745464893324035
  batch 281 loss: 0.5745254042309799
  batch 282 loss: 0.5744999306844482
  batch 283 loss: 0.5743410564142908
  batch 284 loss: 0.5743852224148495
  batch 285 loss: 0.5744929347121924
  batch 286 loss: 0.5744248945396263
  batch 287 loss: 0.5743812065091283
  batch 288 loss: 0.5742869853145547
  batch 289 loss: 0.5743353408100695
  batch 290 loss: 0.5741615566714057
  batch 291 loss: 0.5741195226043361
  batch 292 loss: 0.5742284471858038
  batch 293 loss: 0.5742578286766599
  batch 294 loss: 0.574222499415988
  batch 295 loss: 0.5742711139937579
  batch 296 loss: 0.5742257452897124
  batch 297 loss: 0.5741527090570341
  batch 298 loss: 0.5741648872026661
  batch 299 loss: 0.5741533453647907
  batch 300 loss: 0.5742048192024231
  batch 301 loss: 0.5740963887930709
  batch 302 loss: 0.5740276332327862
  batch 303 loss: 0.5740793607022503
  batch 304 loss: 0.5740396950982118
  batch 305 loss: 0.5738322377204895
  batch 306 loss: 0.5737654549234054
  batch 307 loss: 0.5737276432568553
  batch 308 loss: 0.573830910510831
  batch 309 loss: 0.5737369209045731
  batch 310 loss: 0.5737601868567929
  batch 311 loss: 0.5738776690323636
  batch 312 loss: 0.5738001796297538
  batch 313 loss: 0.5738847524213334
  batch 314 loss: 0.5738709999877176
  batch 315 loss: 0.5737588587261382
  batch 316 loss: 0.5736958959811851
  batch 317 loss: 0.573681811052918
  batch 318 loss: 0.5736144436230449
  batch 319 loss: 0.5735454701330969
  batch 320 loss: 0.573486584238708
  batch 321 loss: 0.5734278565255281
  batch 322 loss: 0.5734599297461302
  batch 323 loss: 0.573511448622488
  batch 324 loss: 0.5733925624762053
  batch 325 loss: 0.5734558129310607
  batch 326 loss: 0.5734021592359602
  batch 327 loss: 0.5733331389018884
  batch 328 loss: 0.5733601370962654
  batch 329 loss: 0.5733587455604576
  batch 330 loss: 0.5733946500402508
  batch 331 loss: 0.5734065229078794
  batch 332 loss: 0.5734342973993485
  batch 333 loss: 0.573478717703719
  batch 334 loss: 0.5734367984497618
  batch 335 loss: 0.5733682239233557
  batch 336 loss: 0.5732805696981293
  batch 337 loss: 0.5731371856938484
  batch 338 loss: 0.5731555667854625
  batch 339 loss: 0.5732032588097902
  batch 340 loss: 0.5732330243377125
  batch 341 loss: 0.5732037257239266
  batch 342 loss: 0.5732127844590192
  batch 343 loss: 0.573241227396028
  batch 344 loss: 0.5732326422666394
  batch 345 loss: 0.5732803063116212
  batch 346 loss: 0.5732010811395039
  batch 347 loss: 0.5731687459890712
  batch 348 loss: 0.5731965625423124
  batch 349 loss: 0.5731464375055964
  batch 350 loss: 0.5732675002302442
  batch 351 loss: 0.5733059748285516
  batch 352 loss: 0.573294245722619
  batch 353 loss: 0.5732557530443662
  batch 354 loss: 0.5732593666025474
  batch 355 loss: 0.5733096908515608
  batch 356 loss: 0.5733040509264121
  batch 357 loss: 0.5732801249381207
  batch 358 loss: 0.5732963518057456
  batch 359 loss: 0.5733493055141736
  batch 360 loss: 0.5734263158506817
  batch 361 loss: 0.5734012899636561
  batch 362 loss: 0.5734139405890722
  batch 363 loss: 0.5734205288663712
  batch 364 loss: 0.5733678223012568
  batch 365 loss: 0.5733504821176398
  batch 366 loss: 0.5733983303354087
  batch 367 loss: 0.5732774989481518
  batch 368 loss: 0.5731608508073766
  batch 369 loss: 0.5732230913994435
  batch 370 loss: 0.57331455076063
  batch 371 loss: 0.5733865335623851
  batch 372 loss: 0.5733406357867743
  batch 373 loss: 0.5733374326861895
  batch 374 loss: 0.5732757983041957
  batch 375 loss: 0.5732698973019917
  batch 376 loss: 0.573332722675293
  batch 377 loss: 0.5732517749940685
  batch 378 loss: 0.5731300479835935
  batch 379 loss: 0.5731742223208687
  batch 380 loss: 0.5731959242569773
  batch 381 loss: 0.5730986879879408
  batch 382 loss: 0.5730523532597807
  batch 383 loss: 0.573088046153594
  batch 384 loss: 0.5730969893435637
  batch 385 loss: 0.5731539927519761
  batch 386 loss: 0.5730800918964525
  batch 387 loss: 0.5730486054753148
  batch 388 loss: 0.573131356042685
  batch 389 loss: 0.5731880272568651
  batch 390 loss: 0.5732517700928909
  batch 391 loss: 0.5732172009585154
  batch 392 loss: 0.573146328786198
  batch 393 loss: 0.5732333385610702
  batch 394 loss: 0.5732195622424789
  batch 395 loss: 0.5732035371321667
  batch 396 loss: 0.5731643215574399
  batch 397 loss: 0.5731659927956704
  batch 398 loss: 0.5730544219364473
  batch 399 loss: 0.5730739830430588
  batch 400 loss: 0.5729995955526829
  batch 401 loss: 0.5729335265563907
  batch 402 loss: 0.5728938199987459
  batch 403 loss: 0.5728488222836856
  batch 404 loss: 0.5728424305077826
  batch 405 loss: 0.5727742458567208
  batch 406 loss: 0.5727774989722397
  batch 407 loss: 0.5727442207148972
  batch 408 loss: 0.5727824820022956
  batch 409 loss: 0.5728128896365831
  batch 410 loss: 0.572789550845216
  batch 411 loss: 0.5727805619982327
  batch 412 loss: 0.5727039215344827
  batch 413 loss: 0.5726968504614749
  batch 414 loss: 0.5726959483635022
  batch 415 loss: 0.5727107504764235
  batch 416 loss: 0.5726652967815216
  batch 417 loss: 0.5726093934308425
  batch 418 loss: 0.5725910144559504
  batch 419 loss: 0.5726584816320415
  batch 420 loss: 0.5727105995019277
  batch 421 loss: 0.5726922849578132
  batch 422 loss: 0.5726246017415376
  batch 423 loss: 0.572628441150025
  batch 424 loss: 0.5725557815353826
  batch 425 loss: 0.57263095294728
  batch 426 loss: 0.572584716926718
  batch 427 loss: 0.5725482632460583
  batch 428 loss: 0.5724932861940883
  batch 429 loss: 0.5725525587033002
  batch 430 loss: 0.572581935206125
  batch 431 loss: 0.5725768273501828
  batch 432 loss: 0.5725768023618946
  batch 433 loss: 0.5725272067975227
  batch 434 loss: 0.5725581950855695
  batch 435 loss: 0.5725812339234626
  batch 436 loss: 0.5725450949111116
  batch 437 loss: 0.572594828545638
  batch 438 loss: 0.5726367097739216
  batch 439 loss: 0.5726243778893507
  batch 440 loss: 0.572611230476336
  batch 441 loss: 0.572576489578299
  batch 442 loss: 0.5725082631024839
  batch 443 loss: 0.5724748670382102
  batch 444 loss: 0.5724966170283051
  batch 445 loss: 0.5725001513288263
  batch 446 loss: 0.5725941838437666
  batch 447 loss: 0.5725064460329828
  batch 448 loss: 0.5725588606936591
  batch 449 loss: 0.5726235563346166
  batch 450 loss: 0.5726473561922709
  batch 451 loss: 0.5726198240817254
  batch 452 loss: 0.5725442835714964
  batch 453 loss: 0.5725537128006386
  batch 454 loss: 0.572561202857988
  batch 455 loss: 0.5725982854654501
  batch 456 loss: 0.5726277009959806
  batch 457 loss: 0.5727203907017113
  batch 458 loss: 0.5727081021627485
  batch 459 loss: 0.5726840363608466
  batch 460 loss: 0.5727459590072217
  batch 461 loss: 0.5727679849705314
  batch 462 loss: 0.5727448629868495
  batch 463 loss: 0.572798971352258
  batch 464 loss: 0.5728642713150074
  batch 465 loss: 0.5728253819609201
  batch 466 loss: 0.5727923165830932
  batch 467 loss: 0.5727869873383826
  batch 468 loss: 0.5727237828521647
  batch 469 loss: 0.5726824334181194
  batch 470 loss: 0.5726409200658189
  batch 471 loss: 0.572668893448613
  batch 472 loss: 0.572637336360196
LOSS train 0.572637336360196 valid 0.41014841198921204
LOSS train 0.572637336360196 valid 0.4194469153881073
LOSS train 0.572637336360196 valid 0.41746532917022705
LOSS train 0.572637336360196 valid 0.4157198965549469
LOSS train 0.572637336360196 valid 0.412647008895874
LOSS train 0.572637336360196 valid 0.41777874032656354
LOSS train 0.572637336360196 valid 0.4220442090715681
LOSS train 0.572637336360196 valid 0.4232424348592758
LOSS train 0.572637336360196 valid 0.4246852861510383
LOSS train 0.572637336360196 valid 0.42831977009773253
LOSS train 0.572637336360196 valid 0.43051043152809143
LOSS train 0.572637336360196 valid 0.4298243646820386
LOSS train 0.572637336360196 valid 0.4325392177471748
LOSS train 0.572637336360196 valid 0.434403549347605
LOSS train 0.572637336360196 valid 0.4357219715913137
LOSS train 0.572637336360196 valid 0.43434246070683
LOSS train 0.572637336360196 valid 0.4353954353753258
LOSS train 0.572637336360196 valid 0.43517350157101947
LOSS train 0.572637336360196 valid 0.43464669585227966
LOSS train 0.572637336360196 valid 0.4354384496808052
LOSS train 0.572637336360196 valid 0.4352163686638787
LOSS train 0.572637336360196 valid 0.4338777417486364
LOSS train 0.572637336360196 valid 0.4337904725385749
LOSS train 0.572637336360196 valid 0.43331024795770645
LOSS train 0.572637336360196 valid 0.432522212266922
LOSS train 0.572637336360196 valid 0.43152659787581515
LOSS train 0.572637336360196 valid 0.4307618891751325
LOSS train 0.572637336360196 valid 0.4309722472514425
LOSS train 0.572637336360196 valid 0.4300639033317566
LOSS train 0.572637336360196 valid 0.43118067383766173
LOSS train 0.572637336360196 valid 0.4323142497770248
LOSS train 0.572637336360196 valid 0.43236431665718555
LOSS train 0.572637336360196 valid 0.4333996122533625
LOSS train 0.572637336360196 valid 0.43420681883307066
LOSS train 0.572637336360196 valid 0.435434422322682
LOSS train 0.572637336360196 valid 0.43566614472203785
LOSS train 0.572637336360196 valid 0.43608305985863144
LOSS train 0.572637336360196 valid 0.43614579658759267
LOSS train 0.572637336360196 valid 0.436068336168925
LOSS train 0.572637336360196 valid 0.43660298436880113
LOSS train 0.572637336360196 valid 0.436561298079607
LOSS train 0.572637336360196 valid 0.4365788066671008
LOSS train 0.572637336360196 valid 0.4364978955235592
LOSS train 0.572637336360196 valid 0.43642906505953183
LOSS train 0.572637336360196 valid 0.4361290395259857
LOSS train 0.572637336360196 valid 0.43665849644204846
LOSS train 0.572637336360196 valid 0.4367672788335922
LOSS train 0.572637336360196 valid 0.43744911439716816
LOSS train 0.572637336360196 valid 0.4381472663003571
LOSS train 0.572637336360196 valid 0.4374274551868439
LOSS train 0.572637336360196 valid 0.4381860985475428
LOSS train 0.572637336360196 valid 0.4384325020588361
LOSS train 0.572637336360196 valid 0.4382637098150433
LOSS train 0.572637336360196 valid 0.4377661479843987
LOSS train 0.572637336360196 valid 0.437938193841414
LOSS train 0.572637336360196 valid 0.43774317896791864
LOSS train 0.572637336360196 valid 0.43740944642769664
LOSS train 0.572637336360196 valid 0.4374727766061651
LOSS train 0.572637336360196 valid 0.4380229984299611
LOSS train 0.572637336360196 valid 0.4376255134741465
LOSS train 0.572637336360196 valid 0.43666426861872437
LOSS train 0.572637336360196 valid 0.4369666230294012
LOSS train 0.572637336360196 valid 0.4367933065172226
LOSS train 0.572637336360196 valid 0.43717158352956176
LOSS train 0.572637336360196 valid 0.4373177537551293
LOSS train 0.572637336360196 valid 0.43695304971752746
LOSS train 0.572637336360196 valid 0.43670584595025475
LOSS train 0.572637336360196 valid 0.4367620809113278
LOSS train 0.572637336360196 valid 0.4366844534010127
LOSS train 0.572637336360196 valid 0.43617474266460965
LOSS train 0.572637336360196 valid 0.4358491221783866
LOSS train 0.572637336360196 valid 0.43579092373450595
LOSS train 0.572637336360196 valid 0.4362118970857908
LOSS train 0.572637336360196 valid 0.43566127806096466
LOSS train 0.572637336360196 valid 0.4357024463017782
LOSS train 0.572637336360196 valid 0.43600336932822276
LOSS train 0.572637336360196 valid 0.43588755347511987
LOSS train 0.572637336360196 valid 0.43588947714903414
LOSS train 0.572637336360196 valid 0.43563094848318945
LOSS train 0.572637336360196 valid 0.43542147874832154
LOSS train 0.572637336360196 valid 0.4349141761108681
LOSS train 0.572637336360196 valid 0.43504869792519546
LOSS train 0.572637336360196 valid 0.434797901705087
LOSS train 0.572637336360196 valid 0.43494360006990884
LOSS train 0.572637336360196 valid 0.43462420772103705
LOSS train 0.572637336360196 valid 0.43443195764408554
LOSS train 0.572637336360196 valid 0.43443105686670064
LOSS train 0.572637336360196 valid 0.43442311781373893
LOSS train 0.572637336360196 valid 0.4346630362312445
LOSS train 0.572637336360196 valid 0.43498922487099967
LOSS train 0.572637336360196 valid 0.4351609896172534
LOSS train 0.572637336360196 valid 0.4350560534259547
LOSS train 0.572637336360196 valid 0.4348565955315867
LOSS train 0.572637336360196 valid 0.4348309078115098
LOSS train 0.572637336360196 valid 0.4347578911404861
LOSS train 0.572637336360196 valid 0.43465597089380026
LOSS train 0.572637336360196 valid 0.4346909562951511
LOSS train 0.572637336360196 valid 0.43448348647477675
LOSS train 0.572637336360196 valid 0.4349502120355163
LOSS train 0.572637336360196 valid 0.4351072835922241
LOSS train 0.572637336360196 valid 0.43507421282258363
LOSS train 0.572637336360196 valid 0.4351339565188277
LOSS train 0.572637336360196 valid 0.43537901992936734
LOSS train 0.572637336360196 valid 0.4354781061410904
LOSS train 0.572637336360196 valid 0.4356042771112351
LOSS train 0.572637336360196 valid 0.4357558966807599
LOSS train 0.572637336360196 valid 0.4355907810625629
LOSS train 0.572637336360196 valid 0.435549462834994
LOSS train 0.572637336360196 valid 0.4357529747376748
LOSS train 0.572637336360196 valid 0.43602646372535014
LOSS train 0.572637336360196 valid 0.43597402497454807
LOSS train 0.572637336360196 valid 0.4359741990587541
LOSS train 0.572637336360196 valid 0.43612401174233023
LOSS train 0.572637336360196 valid 0.43583456753638755
LOSS train 0.572637336360196 valid 0.43590241463288015
LOSS train 0.572637336360196 valid 0.4361222293870202
LOSS train 0.572637336360196 valid 0.4361145037871141
LOSS train 0.572637336360196 valid 0.4360353577945192
LOSS train 0.572637336360196 valid 0.436002525461822
LOSS train 0.572637336360196 valid 0.43594782749811806
LOSS train 0.572637336360196 valid 0.43578153306787665
LOSS train 0.572637336360196 valid 0.43562467054265447
LOSS train 0.572637336360196 valid 0.43572624548663935
LOSS train 0.572637336360196 valid 0.43582810822033113
LOSS train 0.572637336360196 valid 0.436017272233963
LOSS train 0.572637336360196 valid 0.4359737062265003
LOSS train 0.572637336360196 valid 0.43617633337110984
LOSS train 0.572637336360196 valid 0.4363903487101197
LOSS train 0.572637336360196 valid 0.4365730054618776
LOSS train 0.572637336360196 valid 0.43650983021809503
LOSS train 0.572637336360196 valid 0.43655892228352206
LOSS train 0.572637336360196 valid 0.4363653330188809
LOSS train 0.572637336360196 valid 0.4362464762271795
LOSS train 0.572637336360196 valid 0.4362536886734749
LOSS train 0.572637336360196 valid 0.4363954336554916
LOSS train 0.572637336360196 valid 0.4363364943248384
LOSS train 0.572637336360196 valid 0.43615646410162434
LOSS train 0.572637336360196 valid 0.43596658348173334
LOSS train 0.572637336360196 valid 0.43593076042991746
LOSS train 0.572637336360196 valid 0.435952283016273
LOSS train 0.572637336360196 valid 0.43608367886949095
LOSS train 0.572637336360196 valid 0.43617953968719697
LOSS train 0.572637336360196 valid 0.4360610692651122
LOSS train 0.572637336360196 valid 0.436111091532641
LOSS train 0.572637336360196 valid 0.4358882741681461
LOSS train 0.572637336360196 valid 0.43607747840554745
LOSS train 0.572637336360196 valid 0.4357960694501189
LOSS train 0.572637336360196 valid 0.43615828494767883
LOSS train 0.572637336360196 valid 0.43611178862168487
LOSS train 0.572637336360196 valid 0.4361416435241699
LOSS train 0.572637336360196 valid 0.436153895807582
LOSS train 0.572637336360196 valid 0.43595651282291664
LOSS train 0.572637336360196 valid 0.4359579758316863
LOSS train 0.572637336360196 valid 0.43606547275920965
LOSS train 0.572637336360196 valid 0.4359322819017595
LOSS train 0.572637336360196 valid 0.4362020116203871
LOSS train 0.572637336360196 valid 0.4362310943709817
LOSS train 0.572637336360196 valid 0.43636732727666444
LOSS train 0.572637336360196 valid 0.43621559637897417
LOSS train 0.572637336360196 valid 0.43615542724728584
LOSS train 0.572637336360196 valid 0.4362719836442367
LOSS train 0.572637336360196 valid 0.4361758969816161
LOSS train 0.572637336360196 valid 0.43614613333362745
LOSS train 0.572637336360196 valid 0.4360217479307477
LOSS train 0.572637336360196 valid 0.43587799343195827
LOSS train 0.572637336360196 valid 0.43568726835480653
LOSS train 0.572637336360196 valid 0.43580154815833727
LOSS train 0.572637336360196 valid 0.43599820137023926
LOSS train 0.572637336360196 valid 0.43606975868608827
LOSS train 0.572637336360196 valid 0.4360573368913987
LOSS train 0.572637336360196 valid 0.43629850159611616
LOSS train 0.572637336360196 valid 0.4364471575895021
LOSS train 0.572637336360196 valid 0.43657917731759177
LOSS train 0.572637336360196 valid 0.4366176356186812
LOSS train 0.572637336360196 valid 0.4366713304179055
LOSS train 0.572637336360196 valid 0.4367671024731614
LOSS train 0.572637336360196 valid 0.4368271930406323
LOSS train 0.572637336360196 valid 0.4370437420151207
LOSS train 0.572637336360196 valid 0.4371310792155772
LOSS train 0.572637336360196 valid 0.43721220824453566
LOSS train 0.572637336360196 valid 0.43729935380635343
LOSS train 0.572637336360196 valid 0.43732942477032377
LOSS train 0.572637336360196 valid 0.43730593167367526
LOSS train 0.572637336360196 valid 0.43728579289239383
LOSS train 0.572637336360196 valid 0.43722830720849937
LOSS train 0.572637336360196 valid 0.437261359826211
LOSS train 0.572637336360196 valid 0.43745226512618246
LOSS train 0.572637336360196 valid 0.4374936100967387
LOSS train 0.572637336360196 valid 0.4373294652769805
LOSS train 0.572637336360196 valid 0.4372661673708966
LOSS train 0.572637336360196 valid 0.43749915554885466
LOSS train 0.572637336360196 valid 0.4375453010822336
LOSS train 0.572637336360196 valid 0.4375879511314353
LOSS train 0.572637336360196 valid 0.4374538597065149
LOSS train 0.572637336360196 valid 0.4372693677743276
LOSS train 0.572637336360196 valid 0.43728282697954957
LOSS train 0.572637336360196 valid 0.4373288537342536
LOSS train 0.572637336360196 valid 0.4372218010401485
LOSS train 0.572637336360196 valid 0.4373508032841898
LOSS train 0.572637336360196 valid 0.4373737283051014
LOSS train 0.572637336360196 valid 0.4373174186666213
LOSS train 0.572637336360196 valid 0.4373470136139653
LOSS train 0.572637336360196 valid 0.4373175098097383
LOSS train 0.572637336360196 valid 0.43747032258440466
LOSS train 0.572637336360196 valid 0.4374820879319819
LOSS train 0.572637336360196 valid 0.4376456780919751
LOSS train 0.572637336360196 valid 0.43764840174412384
LOSS train 0.572637336360196 valid 0.4376188659897217
LOSS train 0.572637336360196 valid 0.43741994383232446
LOSS train 0.572637336360196 valid 0.4373276770114899
LOSS train 0.572637336360196 valid 0.43747870941862677
LOSS train 0.572637336360196 valid 0.4374594248409541
LOSS train 0.572637336360196 valid 0.4374548382882221
LOSS train 0.572637336360196 valid 0.4373871005862673
LOSS train 0.572637336360196 valid 0.43719713660173637
LOSS train 0.572637336360196 valid 0.43717775162723327
LOSS train 0.572637336360196 valid 0.4372414919088513
LOSS train 0.572637336360196 valid 0.4371885304604102
LOSS train 0.572637336360196 valid 0.43726121072899804
LOSS train 0.572637336360196 valid 0.4372157898816195
LOSS train 0.572637336360196 valid 0.437309502746185
LOSS train 0.572637336360196 valid 0.43746491837071944
LOSS train 0.572637336360196 valid 0.43763880398241395
LOSS train 0.572637336360196 valid 0.43766483651208027
LOSS train 0.572637336360196 valid 0.4376394697030385
LOSS train 0.572637336360196 valid 0.43753477548603464
LOSS train 0.572637336360196 valid 0.43764505945638416
LOSS train 0.572637336360196 valid 0.4377292679590091
LOSS train 0.572637336360196 valid 0.4376933641048498
LOSS train 0.572637336360196 valid 0.43778519254663717
LOSS train 0.572637336360196 valid 0.43770340859115897
LOSS train 0.572637336360196 valid 0.43774239243618374
LOSS train 0.572637336360196 valid 0.43755070206433405
LOSS train 0.572637336360196 valid 0.43755695809665907
LOSS train 0.572637336360196 valid 0.4376237706935152
LOSS train 0.572637336360196 valid 0.43763115395933894
LOSS train 0.572637336360196 valid 0.4376233960757276
LOSS train 0.572637336360196 valid 0.4375552657772513
LOSS train 0.572637336360196 valid 0.43761601894470437
LOSS train 0.572637336360196 valid 0.43760003161927064
LOSS train 0.572637336360196 valid 0.4377134773741125
LOSS train 0.572637336360196 valid 0.43769996680996637
LOSS train 0.572637336360196 valid 0.43769647248487903
LOSS train 0.572637336360196 valid 0.4376888112699399
LOSS train 0.572637336360196 valid 0.43764187231355783
LOSS train 0.572637336360196 valid 0.43761693886140496
LOSS train 0.572637336360196 valid 0.43778755778243184
LOSS train 0.572637336360196 valid 0.4377454360646586
LOSS train 0.572637336360196 valid 0.43773055435663244
LOSS train 0.572637336360196 valid 0.43786326837539674
LOSS train 0.572637336360196 valid 0.43785374240571284
LOSS train 0.572637336360196 valid 0.43788290827993365
LOSS train 0.572637336360196 valid 0.43795581745064777
LOSS train 0.572637336360196 valid 0.4380055759835431
LOSS train 0.572637336360196 valid 0.43798832168766094
LOSS train 0.572637336360196 valid 0.437967341276817
LOSS train 0.572637336360196 valid 0.43790984165343794
LOSS train 0.572637336360196 valid 0.4379026490126469
LOSS train 0.572637336360196 valid 0.4379403432363709
LOSS train 0.572637336360196 valid 0.4379474224952551
LOSS train 0.572637336360196 valid 0.4380105384464922
LOSS train 0.572637336360196 valid 0.43804521983816425
LOSS train 0.572637336360196 valid 0.43810096825030365
LOSS train 0.572637336360196 valid 0.43808794676354434
LOSS train 0.572637336360196 valid 0.4381209057457042
LOSS train 0.572637336360196 valid 0.4381165291581835
LOSS train 0.572637336360196 valid 0.4380681405353189
LOSS train 0.572637336360196 valid 0.43802774730903
LOSS train 0.572637336360196 valid 0.438217072460288
LOSS train 0.572637336360196 valid 0.4382595401119303
LOSS train 0.572637336360196 valid 0.4383456310003006
LOSS train 0.572637336360196 valid 0.4383670538663864
LOSS train 0.572637336360196 valid 0.4384500707462157
LOSS train 0.572637336360196 valid 0.43843482249844684
LOSS train 0.572637336360196 valid 0.43838266481052746
LOSS train 0.572637336360196 valid 0.4384845249030901
LOSS train 0.572637336360196 valid 0.43853651896280504
LOSS train 0.572637336360196 valid 0.4384978686948474
LOSS train 0.572637336360196 valid 0.43856501312238766
LOSS train 0.572637336360196 valid 0.4385565760944571
LOSS train 0.572637336360196 valid 0.43836863842723206
LOSS train 0.572637336360196 valid 0.4382783098423735
LOSS train 0.572637336360196 valid 0.4382182344952236
LOSS train 0.572637336360196 valid 0.43827676573689556
LOSS train 0.572637336360196 valid 0.43832262011996487
LOSS train 0.572637336360196 valid 0.4382668128172001
LOSS train 0.572637336360196 valid 0.4382546038370099
LOSS train 0.572637336360196 valid 0.43825769600354963
LOSS train 0.572637336360196 valid 0.4382119134429417
LOSS train 0.572637336360196 valid 0.43817949901367054
LOSS train 0.572637336360196 valid 0.43808829415704786
LOSS train 0.572637336360196 valid 0.43803816104996696
LOSS train 0.572637336360196 valid 0.4380341126446838
LOSS train 0.572637336360196 valid 0.4381188224164807
LOSS train 0.572637336360196 valid 0.43824361209142004
LOSS train 0.572637336360196 valid 0.43829223543808266
LOSS train 0.572637336360196 valid 0.4382506080147393
LOSS train 0.572637336360196 valid 0.4382672229869254
LOSS train 0.572637336360196 valid 0.43835156717428
LOSS train 0.572637336360196 valid 0.43829468965530394
LOSS train 0.572637336360196 valid 0.4383332733300041
LOSS train 0.572637336360196 valid 0.4382924646731244
LOSS train 0.572637336360196 valid 0.4382989323965394
LOSS train 0.572637336360196 valid 0.438275882974267
LOSS train 0.572637336360196 valid 0.4382131042050534
LOSS train 0.572637336360196 valid 0.43815792317873514
LOSS train 0.572637336360196 valid 0.4381192649808691
LOSS train 0.572637336360196 valid 0.4381461972733597
LOSS train 0.572637336360196 valid 0.4381846578182912
LOSS train 0.572637336360196 valid 0.438126996063417
LOSS train 0.572637336360196 valid 0.438059623697563
LOSS train 0.572637336360196 valid 0.43805181177762836
LOSS train 0.572637336360196 valid 0.43816050487204483
LOSS train 0.572637336360196 valid 0.43821999848268595
LOSS train 0.572637336360196 valid 0.4382740477720896
LOSS train 0.572637336360196 valid 0.43819153884166406
LOSS train 0.572637336360196 valid 0.43825738465748376
LOSS train 0.572637336360196 valid 0.43819573512242277
LOSS train 0.572637336360196 valid 0.43828104198165824
LOSS train 0.572637336360196 valid 0.438188046682626
LOSS train 0.572637336360196 valid 0.4381420974419496
LOSS train 0.572637336360196 valid 0.43812254654324573
LOSS train 0.572637336360196 valid 0.4380439234776394
LOSS train 0.572637336360196 valid 0.43800153988011087
LOSS train 0.572637336360196 valid 0.43798025883161107
LOSS train 0.572637336360196 valid 0.4380815293342789
LOSS train 0.572637336360196 valid 0.43811695528322037
LOSS train 0.572637336360196 valid 0.43822599093361597
LOSS train 0.572637336360196 valid 0.4382819180068274
LOSS train 0.572637336360196 valid 0.4383545369812937
LOSS train 0.572637336360196 valid 0.43829295732463597
LOSS train 0.572637336360196 valid 0.4381710744227271
LOSS train 0.572637336360196 valid 0.43816794226835437
LOSS train 0.572637336360196 valid 0.4382987412328492
LOSS train 0.572637336360196 valid 0.4382914485326454
LOSS train 0.572637336360196 valid 0.43835289944850264
LOSS train 0.572637336360196 valid 0.4382870798648642
LOSS train 0.572637336360196 valid 0.43829413040502535
LOSS train 0.572637336360196 valid 0.43817914534459074
LOSS train 0.572637336360196 valid 0.4380987484665478
LOSS train 0.572637336360196 valid 0.4380214229182414
LOSS train 0.572637336360196 valid 0.4380315466408144
LOSS train 0.572637336360196 valid 0.4380512804922488
LOSS train 0.572637336360196 valid 0.43815311746195307
LOSS train 0.572637336360196 valid 0.4381240751432336
LOSS train 0.572637336360196 valid 0.4381559196579663
LOSS train 0.572637336360196 valid 0.4381336571503785
LOSS train 0.572637336360196 valid 0.4381826501125577
LOSS train 0.572637336360196 valid 0.4382463171010714
LOSS train 0.572637336360196 valid 0.43822362882750376
LOSS train 0.572637336360196 valid 0.43816002159037143
LOSS train 0.572637336360196 valid 0.43817549605261197
LOSS train 0.572637336360196 valid 0.4382456583274323
LOSS train 0.572637336360196 valid 0.43829364047548863
LOSS train 0.572637336360196 valid 0.43837371258668495
LOSS train 0.572637336360196 valid 0.43844247023376187
LOSS train 0.572637336360196 valid 0.4383888449154648
LOSS train 0.572637336360196 valid 0.43832547554756673
LOSS train 0.572637336360196 valid 0.438298322032089
LOSS train 0.572637336360196 valid 0.43831920855575135
LOSS train 0.572637336360196 valid 0.4383717978429926
LOSS train 0.572637336360196 valid 0.4384638834230149
LOSS train 0.572637336360196 valid 0.43847892263047294
LOSS train 0.572637336360196 valid 0.43848565081646157
LOSS train 0.572637336360196 valid 0.43853204119695377
LOSS train 0.572637336360196 valid 0.43852114563431244
LOSS train 0.572637336360196 valid 0.43846730956914315
LOSS train 0.572637336360196 valid 0.43846145409928716
LOSS train 0.572637336360196 valid 0.4384756581731605
Training bichrom
DEVICE = mps
####################
Total Parameters = 606342
Total Trainable Parameters = 1157
bimodal_network(
  (base_model): bichrom_seq(
    (conv1d): Conv1d(4, 256, kernel_size=(24,), stride=(1,))
    (relu): ReLU()
    (batchNorm1d): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (maxPool1d): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=True)
    (lstm): LSTM(256, 32, batch_first=True)
    (tanh): Tanh()
    (model_dense_repeat): Sequential(
      (0): Linear(in_features=32, out_features=512, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=512, out_features=512, bias=True)
      (4): ReLU()
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=512, out_features=512, bias=True)
      (7): ReLU()
      (8): Dropout(p=0.5, inplace=False)
    )
    (linear): Linear(in_features=512, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
  (linear): Linear(in_features=512, out_features=1, bias=True)
  (tanh): Tanh()
  (model): bichrom_chrom(
    (_reshape): _reshape()
    (conv1d): Conv1d(12, 15, kernel_size=(1,), stride=(1,), padding=valid)
    (relu): ReLU()
    (lstm): LSTM(15, 5, batch_first=True)
    (relu2): ReLU()
    (linear): Linear(in_features=5, out_features=1, bias=True)
    (tanh): Tanh()
  )
  (linear2): Linear(in_features=2, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
base_model.conv1d.weight False
base_model.conv1d.bias False
base_model.batchNorm1d.weight False
base_model.batchNorm1d.bias False
base_model.lstm.weight_ih_l0 False
base_model.lstm.weight_hh_l0 False
base_model.lstm.bias_ih_l0 False
base_model.lstm.bias_hh_l0 False
base_model.model_dense_repeat.0.weight False
base_model.model_dense_repeat.0.bias False
base_model.model_dense_repeat.3.weight False
base_model.model_dense_repeat.3.bias False
base_model.model_dense_repeat.6.weight False
base_model.model_dense_repeat.6.bias False
base_model.linear.weight False
base_model.linear.bias False
linear.weight True
linear.bias True
model.conv1d.weight True
model.conv1d.bias True
model.lstm.weight_ih_l0 True
model.lstm.weight_hh_l0 True
model.lstm.bias_ih_l0 True
model.lstm.bias_hh_l0 True
model.linear.weight True
model.linear.bias True
linear2.weight True
linear2.bias True
####################
EPOCH 1:
  batch 1 loss: 0.6933368444442749
####################
/Users/spg5958/research/bichrom/bichrom-Pytorch/trainNN/train_sc.py:179: UserWarning: The operator 'aten::linalg_vector_norm' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1679382518396/work/aten/src/ATen/mps/MPSFallback.mm:12.)
  print("Base Model Weight Norm = "+str(torch.linalg.norm(torch.sub(w1,w2))))
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.6936355233192444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.6933570702870687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.6928405314683914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.6928568482398987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.6927612622578939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.6925274644579206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.6923875510692596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.6921199825074937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.6919704973697662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.6916308999061584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.6912869065999985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.6910358438125024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.6908056054796491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.6905378778775533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.6901165209710598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.689741734196158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.6893642379177941
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.688980569964961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.688422703742981
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.6879920959472656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.6875308426943693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.6871105406595313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.6866582160194715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.6860894179344177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.6856143910151261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.685069391021022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.6843856658254351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.6837669631530499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.6831120908260345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.6824064100942304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.6817900277674198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.6809825969464851
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.6803062400397133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.6796630706105914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.678840825955073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.6779713405145181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.6770497058567247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.6762152161353674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.6753810077905655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.6744777502083197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.6734899395988101
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.6727382000102553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.6718750514767386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.6709281444549561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.6698749246804611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.6688968932374995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.6680071006218592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.6670431409563337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.6661278414726257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.6649842273955252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.6638574863855655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.6626890998966289
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.661512146393458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.6602141033519399
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.6590806118079594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.6580355617037991
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.6567934792617272
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.6555580910989793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.6544770648082098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.6533071613702618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.652306959513695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.6512791609007215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.6501546362414956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.6490720180364755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.647686731634718
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.6464888569134385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.6454105973243713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.6441609660784403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.6431080673422133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.641946147025471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.6406026209394137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.6396908915206178
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.6385687146637891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.6374017914136251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.636569080384154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.6353064729021741
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.6341399091940659
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.6330568730076657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.6318681374192238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.630871448987796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.6297222768388143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.6288758473223951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.627664891736848
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.6265702850678387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.6256756068662156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.6247890865665743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.6239317919720303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.6229057646869274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.6218895210160149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.6208942977936713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.6200313445018686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.6191903500146764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.6182625781982503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.6174388214161521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.6168745793402195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.6159882496312722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.6150330000994156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.6141788598262903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.6133365094661712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.6123306526996122
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.6115359243224648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.6107777160348244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.6099718751815649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.6092706969806126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.6083179003787491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.6074045072092074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.606725651356909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.6059547531495401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.6052763651717793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.604443354112608
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.6036563409226281
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.6030913892045485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.602298183922182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.601381282184435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.6006437062189497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.6002308023281586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.5994414500260757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.5988617349071663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.5980417733391126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.5974205274227237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.5968798911962353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.5963789195549197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.5956159512842855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.5950822262763977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.5945067575999669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.5938138079455518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.5933756185695529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.5927017552908077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.5921849420437446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.591517120372248
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.5908441837086822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.5901708620831483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.5894192523920714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.5887610907907839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.5882003806969699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.587685323109592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.5870217041692872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.5866469119092543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.5861892695937838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.5855819075665576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.5851274800132698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.5846608918863576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.5843196188410124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.5838888102564318
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.5831655817080851
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.5828418279586195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.5825156140569094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.5819761919095212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.5813102598985036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.5808455182227078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.5803919262007663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.5800280399571837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.5794686853111565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.5791482025577176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.5789037102308029
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.5784548418537067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.5781600124473814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.5777596553916451
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.5774314071983099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.576823406893274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.5763547919046732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.5759930945247229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.5755945842077093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.5752049234780399
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.5748679040067167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.5744761547999467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.5738382960359255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.5734394718204024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.5731434050728293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.5726993697428564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.5723220324793528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.5718157663510713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.5714683525863735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.5709571804319109
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.5704647793688558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.5700524957840052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.5697461855545473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.5694529823750757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.5690122763315837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.568626159462481
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.5682585648782961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.5678311750862768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.567411056517259
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.5671420398596171
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.5667789402187512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.5663946441469345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.5659510583636609
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.5656405461843682
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.5651791498849267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.5647808205706911
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.564297241003563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.5640885794409816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.5638284844528768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.5634460389614105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.5631740246804393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.562972185121575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.5627488332866418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.5624575676330968
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.5622538612782955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.5619421745117624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.5616103217448338
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.561084477625457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.5608182612295244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.5605131473483109
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.5601053956932235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.5598094127892296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.5594206227419468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.5593297822338542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.5590833143109367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.5587875369883262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.5586848504981905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.558424323797226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.5580650377217854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.5578628621822179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.5575253691662241
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.557232183108132
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.5572265500048978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.5571680786130635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.55698125701059
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.5565827425518727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.5562270009839857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.5560659640573066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.5558934046753815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.5555067920684814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.5552630814830813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.5550335824227018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.5546360334806275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.5543748463085124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.5542467542316603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.5540130455772598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.5539296978506548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.5536130126965404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.5533901975195632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.5532735109329223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.5530140705532947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.5528012234953386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.5525129888238025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.5523392483280294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.5522341010471185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.5520934764280359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.5517911979974794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.5516441697446407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.551482474706212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.5513902060839595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.5513152397745024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.5511625841078971
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.5508247794162843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.5507851961147354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.5505924003124237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.550440210032748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.5501826919970059
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.5501008204556266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.5498283695517563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.5496015410797269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.5494031520793214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.5491044817035764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.548893000843913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.5489461517472065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.5488373177555891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.5486993665211045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.5484703266211138
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.5483717099115423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.5482080947946418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.5478367732380921
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.5477087541406316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.5475440486316824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.5472659994639567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.5470056436318891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.5468704925643073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.5467451377548415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.5464561189360478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.5461877673973531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.5458199554768792
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.5455173362385143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.5453746698904729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.545213502236652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.5450133850677408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.5448914042083166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.544712582975626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.5445781851790553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.5444320608326729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.5441983808687635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.5440306605797418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.5439225373560922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.5437819206422859
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.5436264043901025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.543517891317606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.5433138284097493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.5432473903072291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.5430368706327943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.5429395952657478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.542871422836805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.5427612870120678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.5425588901770317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.5423602791049996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.5422948156342362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.5421295339029107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.5418965830452067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.5417303097248077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.541690162646018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.5414619143830229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.5412553232101718
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.5411527715623379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.5410618826991221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.5408590474939035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.5406854174036156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.5405503881055039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.5404271342607764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.5402527941811469
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.5401741655309867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.5399562445206519
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.5397802433266807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.5395773336955696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.5394177890013134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.5393316780653181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.5392174575043025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.539102463321116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.5389702072524726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.5388892936520279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.5386451725090775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.5385684059088275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.5386051001378995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.5384567606228369
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.5382968279031607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.53818879079965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.5381106748857994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.5380518200193963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.5378600353527939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.5378506042740562
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.5377507892260018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.5375919909362333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.5374906191954741
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.5373198116967778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.537172652714288
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.5371323472687176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.5369244378822847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.5367392409129961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.5364899802348607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.5364371766062344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.5363488036516475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.5362964568779482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.5360851085394533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.5359673811945804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.5358569649682529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.5358247250490795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.5357738863837822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.5357032894403085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.5355309965275762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.5353826657363346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.535177755135077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.5350690357048403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.5349819054009218
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.534821443133435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.5346878938271966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.5345070075787856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.534413997365647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.5343710815107356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.5342337944049357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.5340242438846164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.5338785677240165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.5338063356132139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.533722693187803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.5335433773778298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.5334592094976608
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.533319249260621
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.5331864011060314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.533100284959959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.5329912358183202
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.5328954732901341
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.5327946415166006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.5326612034151631
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.5325874056637128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.5324859321117401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.5323671511809032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.532242348378009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.5321571251441692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.5321122814738561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.5320661807123149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.5319085624657179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.5318256934170961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.5316567069884994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.5316440553329009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.5315560553378115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.531434308321445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.5313889046870365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.5312758396916303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.531262642252691
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.531130924246305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.5310312854938019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.5309210308372517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.5308761940318711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.5307459708388526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.5306374528988969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.530514792777315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.5304798031545649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.5304392140067795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.5304513039750669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.5304109151650193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.5302880998700857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.5301042069074816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.5299153247875954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.5298061332395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.5296639724090548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.5295734224496065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.529505670951505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.5293845703472962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.5292798487433031
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.5291473334313604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.52906160987005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.5290223523213046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.5289823734789219
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.5288380310841392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.5288612846878992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.5288488268852234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.528811479990299
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.5286928005069852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.5286068386580955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.528602506849817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.5285058532442365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.5285301944705483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.5285355615389855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.5283901773164177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.5283342907732388
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.5282413789805244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.5280564526716868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.5279701067357209
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.5278323058770081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.5276628284604399
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.527674597709678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.527557551238487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.5275072369172618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.5273615476303233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.5273008867754915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.527111779752819
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.5271293047234553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.5270562035540967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.5269504965848575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.526804367950131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.5267291573638265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.5266783851750043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.5266048954083369
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.5265583321956695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.5264452157525329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.526498214984208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.5263257703572646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.526325510318914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.5263083404861391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.526282614549178
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.5261810942490895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.5260596821154829
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.5260425116372319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.5259621801228976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.525850796226888
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.5257783826890883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.5256447173785745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.5255178746561514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.5254641444662252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.525358985452091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.5253961953132049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.5253255159115325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.5252444486726414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.5252046827749867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.5251478875248596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.5250507627764056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.5250102344244847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.5248926321495269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.5249069483361692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.5248760569578549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.5248809563352707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.5248117586103468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.5247875448253195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.5247875448253195 valid 0.4950634837150574
LOSS train 0.5247875448253195 valid 0.5102842152118683
LOSS train 0.5247875448253195 valid 0.5103123386700948
LOSS train 0.5247875448253195 valid 0.5082099586725235
LOSS train 0.5247875448253195 valid 0.5033507525920868
LOSS train 0.5247875448253195 valid 0.5073096603155136
LOSS train 0.5247875448253195 valid 0.5135116704872676
LOSS train 0.5247875448253195 valid 0.5154757611453533
LOSS train 0.5247875448253195 valid 0.5171440144379934
LOSS train 0.5247875448253195 valid 0.521072444319725
LOSS train 0.5247875448253195 valid 0.5248744135553186
LOSS train 0.5247875448253195 valid 0.5236758117874464
LOSS train 0.5247875448253195 valid 0.5272948260490711
LOSS train 0.5247875448253195 valid 0.5295987193073545
LOSS train 0.5247875448253195 valid 0.5307531416416168
LOSS train 0.5247875448253195 valid 0.5288998913019896
LOSS train 0.5247875448253195 valid 0.5307954076458427
LOSS train 0.5247875448253195 valid 0.5307556307978101
LOSS train 0.5247875448253195 valid 0.5300354000769163
LOSS train 0.5247875448253195 valid 0.5308817580342293
LOSS train 0.5247875448253195 valid 0.5308195508661724
LOSS train 0.5247875448253195 valid 0.5296589501879432
LOSS train 0.5247875448253195 valid 0.529976091955019
LOSS train 0.5247875448253195 valid 0.5290002462764581
LOSS train 0.5247875448253195 valid 0.528048003911972
LOSS train 0.5247875448253195 valid 0.5266394741260089
LOSS train 0.5247875448253195 valid 0.5259496028776522
LOSS train 0.5247875448253195 valid 0.5265321912510055
LOSS train 0.5247875448253195 valid 0.5255646530924172
LOSS train 0.5247875448253195 valid 0.5270247012376785
LOSS train 0.5247875448253195 valid 0.5282124117497475
LOSS train 0.5247875448253195 valid 0.5287176733836532
LOSS train 0.5247875448253195 valid 0.5299663624980233
LOSS train 0.5247875448253195 valid 0.5310704015633639
LOSS train 0.5247875448253195 valid 0.5322910470621927
LOSS train 0.5247875448253195 valid 0.5325968008902338
LOSS train 0.5247875448253195 valid 0.5328778326511383
LOSS train 0.5247875448253195 valid 0.53310379778084
LOSS train 0.5247875448253195 valid 0.5329371835940924
LOSS train 0.5247875448253195 valid 0.5334692172706127
LOSS train 0.5247875448253195 valid 0.5335836970224613
LOSS train 0.5247875448253195 valid 0.5334054281314214
LOSS train 0.5247875448253195 valid 0.5333751959856167
LOSS train 0.5247875448253195 valid 0.533481892536987
LOSS train 0.5247875448253195 valid 0.5332988891336653
LOSS train 0.5247875448253195 valid 0.5339075994232426
LOSS train 0.5247875448253195 valid 0.5340833074234902
LOSS train 0.5247875448253195 valid 0.5350213466833035
LOSS train 0.5247875448253195 valid 0.5359631284159057
LOSS train 0.5247875448253195 valid 0.5353610628843307
LOSS train 0.5247875448253195 valid 0.5361058460731133
LOSS train 0.5247875448253195 valid 0.5364484632244477
LOSS train 0.5247875448253195 valid 0.5364055279290901
LOSS train 0.5247875448253195 valid 0.5358749799154423
LOSS train 0.5247875448253195 valid 0.5360285742716355
LOSS train 0.5247875448253195 valid 0.5357948546963078
LOSS train 0.5247875448253195 valid 0.5354330513560981
LOSS train 0.5247875448253195 valid 0.5356864502717709
LOSS train 0.5247875448253195 valid 0.5362619025222326
LOSS train 0.5247875448253195 valid 0.5357936337590218
LOSS train 0.5247875448253195 valid 0.5346206177453525
LOSS train 0.5247875448253195 valid 0.5347840367786346
LOSS train 0.5247875448253195 valid 0.5346119408569638
LOSS train 0.5247875448253195 valid 0.534936644602567
LOSS train 0.5247875448253195 valid 0.5353552914582766
LOSS train 0.5247875448253195 valid 0.5347276009393461
LOSS train 0.5247875448253195 valid 0.5344630813420709
LOSS train 0.5247875448253195 valid 0.5344628985313808
LOSS train 0.5247875448253195 valid 0.5345156292120615
LOSS train 0.5247875448253195 valid 0.5338896636451994
LOSS train 0.5247875448253195 valid 0.5334395694900567
LOSS train 0.5247875448253195 valid 0.533260502335098
LOSS train 0.5247875448253195 valid 0.5337183602052192
LOSS train 0.5247875448253195 valid 0.5330464622458896
LOSS train 0.5247875448253195 valid 0.5331171043713887
LOSS train 0.5247875448253195 valid 0.5333429025976282
LOSS train 0.5247875448253195 valid 0.5332123010189502
LOSS train 0.5247875448253195 valid 0.5332892391926203
LOSS train 0.5247875448253195 valid 0.5329548158223116
LOSS train 0.5247875448253195 valid 0.5328232534229755
LOSS train 0.5247875448253195 valid 0.53244952287203
LOSS train 0.5247875448253195 valid 0.5325826762652979
LOSS train 0.5247875448253195 valid 0.5322882281728538
LOSS train 0.5247875448253195 valid 0.5324228434335618
LOSS train 0.5247875448253195 valid 0.5321013689041137
LOSS train 0.5247875448253195 valid 0.5319073671518371
LOSS train 0.5247875448253195 valid 0.5318658262833782
LOSS train 0.5247875448253195 valid 0.5319067280400883
LOSS train 0.5247875448253195 valid 0.531972306497981
LOSS train 0.5247875448253195 valid 0.532406833436754
LOSS train 0.5247875448253195 valid 0.5326289141571129
LOSS train 0.5247875448253195 valid 0.5325208513633065
LOSS train 0.5247875448253195 valid 0.532303867160633
LOSS train 0.5247875448253195 valid 0.5322798611001766
LOSS train 0.5247875448253195 valid 0.5320905854827479
LOSS train 0.5247875448253195 valid 0.5319639928638935
LOSS train 0.5247875448253195 valid 0.5320046341296324
LOSS train 0.5247875448253195 valid 0.5317920786993844
LOSS train 0.5247875448253195 valid 0.5322887789119374
LOSS train 0.5247875448253195 valid 0.5324691569805146
LOSS train 0.5247875448253195 valid 0.5323791598329449
LOSS train 0.5247875448253195 valid 0.5324157125809613
LOSS train 0.5247875448253195 valid 0.532730483314366
LOSS train 0.5247875448253195 valid 0.5329063603511224
LOSS train 0.5247875448253195 valid 0.5330260628745669
LOSS train 0.5247875448253195 valid 0.5331026726173904
LOSS train 0.5247875448253195 valid 0.532986970148354
LOSS train 0.5247875448253195 valid 0.5329695465388121
LOSS train 0.5247875448253195 valid 0.5332282814410848
LOSS train 0.5247875448253195 valid 0.5335364650596272
LOSS train 0.5247875448253195 valid 0.5334955964002523
LOSS train 0.5247875448253195 valid 0.5334502123296261
LOSS train 0.5247875448253195 valid 0.5336544482053909
LOSS train 0.5247875448253195 valid 0.5332320750805369
LOSS train 0.5247875448253195 valid 0.5333099297855212
LOSS train 0.5247875448253195 valid 0.5335240328106386
LOSS train 0.5247875448253195 valid 0.5334299298433157
LOSS train 0.5247875448253195 valid 0.5333812822729854
LOSS train 0.5247875448253195 valid 0.5333556963616058
LOSS train 0.5247875448253195 valid 0.5333082139492035
LOSS train 0.5247875448253195 valid 0.5331379155482142
LOSS train 0.5247875448253195 valid 0.5329467810568262
LOSS train 0.5247875448253195 valid 0.5329983273172766
LOSS train 0.5247875448253195 valid 0.5331270252504656
LOSS train 0.5247875448253195 valid 0.5333388404846191
LOSS train 0.5247875448253195 valid 0.5333546953541892
LOSS train 0.5247875448253195 valid 0.5334849981811103
LOSS train 0.5247875448253195 valid 0.5337193454615772
LOSS train 0.5247875448253195 valid 0.5338696555573811
LOSS train 0.5247875448253195 valid 0.5338217185093806
LOSS train 0.5247875448253195 valid 0.5338747023626138
LOSS train 0.5247875448253195 valid 0.5336371402848851
LOSS train 0.5247875448253195 valid 0.5335599959344792
LOSS train 0.5247875448253195 valid 0.5335719763343014
LOSS train 0.5247875448253195 valid 0.5336881928973728
LOSS train 0.5247875448253195 valid 0.5336948168628356
LOSS train 0.5247875448253195 valid 0.5334659475479683
LOSS train 0.5247875448253195 valid 0.533257797576379
LOSS train 0.5247875448253195 valid 0.5331943253819034
LOSS train 0.5247875448253195 valid 0.5332312055996486
LOSS train 0.5247875448253195 valid 0.5333801617859103
LOSS train 0.5247875448253195 valid 0.5335554698823204
LOSS train 0.5247875448253195 valid 0.5334592945092208
LOSS train 0.5247875448253195 valid 0.533524329877562
LOSS train 0.5247875448253195 valid 0.5332776673908891
LOSS train 0.5247875448253195 valid 0.5335296437348405
LOSS train 0.5247875448253195 valid 0.5332554963981213
LOSS train 0.5247875448253195 valid 0.5335767357736021
LOSS train 0.5247875448253195 valid 0.5334992008721269
LOSS train 0.5247875448253195 valid 0.5335431830088297
LOSS train 0.5247875448253195 valid 0.5335242677208604
LOSS train 0.5247875448253195 valid 0.533319365037115
LOSS train 0.5247875448253195 valid 0.5332692261614831
LOSS train 0.5247875448253195 valid 0.5333902247540363
LOSS train 0.5247875448253195 valid 0.5333295545270366
LOSS train 0.5247875448253195 valid 0.5337167557997581
LOSS train 0.5247875448253195 valid 0.5337260460398
LOSS train 0.5247875448253195 valid 0.5338408230226251
LOSS train 0.5247875448253195 valid 0.5336554185399469
LOSS train 0.5247875448253195 valid 0.5335455320775508
LOSS train 0.5247875448253195 valid 0.5337239955522999
LOSS train 0.5247875448253195 valid 0.5335988468594022
LOSS train 0.5247875448253195 valid 0.533610860994257
LOSS train 0.5247875448253195 valid 0.5334800794357206
LOSS train 0.5247875448253195 valid 0.5332806995420745
LOSS train 0.5247875448253195 valid 0.5330790990447424
LOSS train 0.5247875448253195 valid 0.5332588487399552
LOSS train 0.5247875448253195 valid 0.5334001380418029
LOSS train 0.5247875448253195 valid 0.5334091410481718
LOSS train 0.5247875448253195 valid 0.5334261920522241
LOSS train 0.5247875448253195 valid 0.5336757213400122
LOSS train 0.5247875448253195 valid 0.5338169521717138
LOSS train 0.5247875448253195 valid 0.5338816792634181
LOSS train 0.5247875448253195 valid 0.5339540724439182
LOSS train 0.5247875448253195 valid 0.5340724650451115
LOSS train 0.5247875448253195 valid 0.5341859112747691
LOSS train 0.5247875448253195 valid 0.5343132791882854
LOSS train 0.5247875448253195 valid 0.5345250265986732
LOSS train 0.5247875448253195 valid 0.5346241172132545
LOSS train 0.5247875448253195 valid 0.5346820902493264
LOSS train 0.5247875448253195 valid 0.5347162490062292
LOSS train 0.5247875448253195 valid 0.5347868110779878
LOSS train 0.5247875448253195 valid 0.5347584337810349
LOSS train 0.5247875448253195 valid 0.5347773210833902
LOSS train 0.5247875448253195 valid 0.5347001067689947
LOSS train 0.5247875448253195 valid 0.5347240286809142
LOSS train 0.5247875448253195 valid 0.5349255100609784
LOSS train 0.5247875448253195 valid 0.5349763944110972
LOSS train 0.5247875448253195 valid 0.534838000144908
LOSS train 0.5247875448253195 valid 0.5347366582406194
LOSS train 0.5247875448253195 valid 0.534976497214502
LOSS train 0.5247875448253195 valid 0.5351241629881164
LOSS train 0.5247875448253195 valid 0.5351816411154258
LOSS train 0.5247875448253195 valid 0.5350411548135207
LOSS train 0.5247875448253195 valid 0.5348089079062144
LOSS train 0.5247875448253195 valid 0.5347843341985528
LOSS train 0.5247875448253195 valid 0.5347989974590728
LOSS train 0.5247875448253195 valid 0.5347039439160415
LOSS train 0.5247875448253195 valid 0.5348175247410434
LOSS train 0.5247875448253195 valid 0.5348713354766369
LOSS train 0.5247875448253195 valid 0.5347812408535042
LOSS train 0.5247875448253195 valid 0.5348510339413539
LOSS train 0.5247875448253195 valid 0.5347792202322353
LOSS train 0.5247875448253195 valid 0.5349341524290103
LOSS train 0.5247875448253195 valid 0.5349109089956051
LOSS train 0.5247875448253195 valid 0.5351447250368526
LOSS train 0.5247875448253195 valid 0.535114839601056
LOSS train 0.5247875448253195 valid 0.5350556916628892
LOSS train 0.5247875448253195 valid 0.5348212777427509
LOSS train 0.5247875448253195 valid 0.5347184548775356
LOSS train 0.5247875448253195 valid 0.5348857786700624
LOSS train 0.5247875448253195 valid 0.5348556543577392
LOSS train 0.5247875448253195 valid 0.5348766858868755
LOSS train 0.5247875448253195 valid 0.5348326573583567
LOSS train 0.5247875448253195 valid 0.5346223215724146
LOSS train 0.5247875448253195 valid 0.5345902614019535
LOSS train 0.5247875448253195 valid 0.5347190243857247
LOSS train 0.5247875448253195 valid 0.5346391559193987
LOSS train 0.5247875448253195 valid 0.5347368238179107
LOSS train 0.5247875448253195 valid 0.5346908645196394
LOSS train 0.5247875448253195 valid 0.5348224413340987
LOSS train 0.5247875448253195 valid 0.5349985699395876
LOSS train 0.5247875448253195 valid 0.5351508580515737
LOSS train 0.5247875448253195 valid 0.5351552651929004
LOSS train 0.5247875448253195 valid 0.5351158587137858
LOSS train 0.5247875448253195 valid 0.5350532130857485
LOSS train 0.5247875448253195 valid 0.5351885714719999
LOSS train 0.5247875448253195 valid 0.5353126060544399
LOSS train 0.5247875448253195 valid 0.5352889341037866
LOSS train 0.5247875448253195 valid 0.5354107934495677
LOSS train 0.5247875448253195 valid 0.5353000814264471
LOSS train 0.5247875448253195 valid 0.5353876246974386
LOSS train 0.5247875448253195 valid 0.5351843012760638
LOSS train 0.5247875448253195 valid 0.5351421555392762
LOSS train 0.5247875448253195 valid 0.5352102018417196
LOSS train 0.5247875448253195 valid 0.5352374431440385
LOSS train 0.5247875448253195 valid 0.5351894932960156
LOSS train 0.5247875448253195 valid 0.5351407683196188
LOSS train 0.5247875448253195 valid 0.5351725876580721
LOSS train 0.5247875448253195 valid 0.5351473174989223
LOSS train 0.5247875448253195 valid 0.535267153221542
LOSS train 0.5247875448253195 valid 0.5353066793158034
LOSS train 0.5247875448253195 valid 0.5352608588497334
LOSS train 0.5247875448253195 valid 0.5352572911098356
LOSS train 0.5247875448253195 valid 0.5352505956377301
LOSS train 0.5247875448253195 valid 0.5351964402489546
LOSS train 0.5247875448253195 valid 0.5353480613666025
LOSS train 0.5247875448253195 valid 0.5353262667213717
LOSS train 0.5247875448253195 valid 0.5353437446686159
LOSS train 0.5247875448253195 valid 0.5354938004016876
LOSS train 0.5247875448253195 valid 0.5354660082148366
LOSS train 0.5247875448253195 valid 0.5355606537962717
LOSS train 0.5247875448253195 valid 0.5356295514012513
LOSS train 0.5247875448253195 valid 0.5356478864752402
LOSS train 0.5247875448253195 valid 0.5356399365499908
LOSS train 0.5247875448253195 valid 0.5356244731228799
LOSS train 0.5247875448253195 valid 0.5355838249629573
LOSS train 0.5247875448253195 valid 0.5356073160042134
LOSS train 0.5247875448253195 valid 0.5356610168821563
LOSS train 0.5247875448253195 valid 0.5356795180302399
LOSS train 0.5247875448253195 valid 0.5357355288162086
LOSS train 0.5247875448253195 valid 0.5358018545249036
LOSS train 0.5247875448253195 valid 0.535854612693134
LOSS train 0.5247875448253195 valid 0.5358316078782082
LOSS train 0.5247875448253195 valid 0.5358923473448124
LOSS train 0.5247875448253195 valid 0.5358978955817402
LOSS train 0.5247875448253195 valid 0.5358491756496359
LOSS train 0.5247875448253195 valid 0.5358080948466686
LOSS train 0.5247875448253195 valid 0.5360324152340233
LOSS train 0.5247875448253195 valid 0.5361040892424407
LOSS train 0.5247875448253195 valid 0.5362081756451034
LOSS train 0.5247875448253195 valid 0.5362187119967797
LOSS train 0.5247875448253195 valid 0.5363181209389544
LOSS train 0.5247875448253195 valid 0.5363167785380009
LOSS train 0.5247875448253195 valid 0.5362558031082153
LOSS train 0.5247875448253195 valid 0.5363616545995077
LOSS train 0.5247875448253195 valid 0.5364520487372195
LOSS train 0.5247875448253195 valid 0.5364227089092886
LOSS train 0.5247875448253195 valid 0.5365084572077652
LOSS train 0.5247875448253195 valid 0.5365061811038426
LOSS train 0.5247875448253195 valid 0.5363038594824564
LOSS train 0.5247875448253195 valid 0.5362043764362944
LOSS train 0.5247875448253195 valid 0.5361135615687488
LOSS train 0.5247875448253195 valid 0.5361741981665853
LOSS train 0.5247875448253195 valid 0.5362034692053209
LOSS train 0.5247875448253195 valid 0.5361555223906791
LOSS train 0.5247875448253195 valid 0.5361326495737149
LOSS train 0.5247875448253195 valid 0.5361205965487493
LOSS train 0.5247875448253195 valid 0.5361171883489021
LOSS train 0.5247875448253195 valid 0.5360937423747162
LOSS train 0.5247875448253195 valid 0.5359874436330959
LOSS train 0.5247875448253195 valid 0.5359465170600642
LOSS train 0.5247875448253195 valid 0.5359416993608247
LOSS train 0.5247875448253195 valid 0.5360139911474825
LOSS train 0.5247875448253195 valid 0.5361409543934516
LOSS train 0.5247875448253195 valid 0.5361880932909411
LOSS train 0.5247875448253195 valid 0.5361632928503082
LOSS train 0.5247875448253195 valid 0.536170044901387
LOSS train 0.5247875448253195 valid 0.5362525212525524
LOSS train 0.5247875448253195 valid 0.5361629051963488
LOSS train 0.5247875448253195 valid 0.5362091035739924
LOSS train 0.5247875448253195 valid 0.5361495780826404
LOSS train 0.5247875448253195 valid 0.5361879217152549
LOSS train 0.5247875448253195 valid 0.5361589184521061
LOSS train 0.5247875448253195 valid 0.5360899308665854
LOSS train 0.5247875448253195 valid 0.5360313031603309
LOSS train 0.5247875448253195 valid 0.5359835707209397
LOSS train 0.5247875448253195 valid 0.5360061130546904
LOSS train 0.5247875448253195 valid 0.5360601128690837
LOSS train 0.5247875448253195 valid 0.5359859757846401
LOSS train 0.5247875448253195 valid 0.5359330431249747
LOSS train 0.5247875448253195 valid 0.535980070153108
LOSS train 0.5247875448253195 valid 0.5361106680414547
LOSS train 0.5247875448253195 valid 0.5361802163207607
LOSS train 0.5247875448253195 valid 0.5362513847767361
LOSS train 0.5247875448253195 valid 0.536171249102188
LOSS train 0.5247875448253195 valid 0.5362416924174276
LOSS train 0.5247875448253195 valid 0.5361584849515051
LOSS train 0.5247875448253195 valid 0.5362473474961463
LOSS train 0.5247875448253195 valid 0.5361356905661523
LOSS train 0.5247875448253195 valid 0.5360814010799859
LOSS train 0.5247875448253195 valid 0.5360610722940161
LOSS train 0.5247875448253195 valid 0.5359704329317937
LOSS train 0.5247875448253195 valid 0.5358978952338667
LOSS train 0.5247875448253195 valid 0.5358680243675525
LOSS train 0.5247875448253195 valid 0.5359985306401925
LOSS train 0.5247875448253195 valid 0.5360211661649407
LOSS train 0.5247875448253195 valid 0.5361561034692497
LOSS train 0.5247875448253195 valid 0.53621338991771
LOSS train 0.5247875448253195 valid 0.5362466673959385
LOSS train 0.5247875448253195 valid 0.5361904477604926
LOSS train 0.5247875448253195 valid 0.5360544626432729
LOSS train 0.5247875448253195 valid 0.5360741557122709
LOSS train 0.5247875448253195 valid 0.5362357378541353
LOSS train 0.5247875448253195 valid 0.5362580654336445
LOSS train 0.5247875448253195 valid 0.5363220529009899
LOSS train 0.5247875448253195 valid 0.5362760135434148
LOSS train 0.5247875448253195 valid 0.5362650091655156
LOSS train 0.5247875448253195 valid 0.5361276486102811
LOSS train 0.5247875448253195 valid 0.5360490273903398
LOSS train 0.5247875448253195 valid 0.5359595067515052
LOSS train 0.5247875448253195 valid 0.5359680684860687
LOSS train 0.5247875448253195 valid 0.5359743698866652
LOSS train 0.5247875448253195 valid 0.5360624522490557
LOSS train 0.5247875448253195 valid 0.5360301379708277
LOSS train 0.5247875448253195 valid 0.5360764202182693
LOSS train 0.5247875448253195 valid 0.5360792862407069
LOSS train 0.5247875448253195 valid 0.5361765959653361
LOSS train 0.5247875448253195 valid 0.5362536098519847
LOSS train 0.5247875448253195 valid 0.5362419980764389
LOSS train 0.5247875448253195 valid 0.5361881384312936
LOSS train 0.5247875448253195 valid 0.5361707170747898
LOSS train 0.5247875448253195 valid 0.53624286167007
LOSS train 0.5247875448253195 valid 0.5362680693299083
LOSS train 0.5247875448253195 valid 0.5363766936349197
LOSS train 0.5247875448253195 valid 0.5364356356557836
LOSS train 0.5247875448253195 valid 0.5363867752859238
LOSS train 0.5247875448253195 valid 0.5362981397179918
LOSS train 0.5247875448253195 valid 0.5363277252504088
LOSS train 0.5247875448253195 valid 0.5363439284265041
LOSS train 0.5247875448253195 valid 0.5364154487270397
LOSS train 0.5247875448253195 valid 0.5365014529853894
LOSS train 0.5247875448253195 valid 0.5365407024369095
LOSS train 0.5247875448253195 valid 0.5365325111772988
LOSS train 0.5247875448253195 valid 0.5365952355404423
LOSS train 0.5247875448253195 valid 0.5365797640358816
LOSS train 0.5247875448253195 valid 0.5365143742320972
LOSS train 0.5247875448253195 valid 0.5365164075046778
LOSS train 0.5247875448253195 valid 0.5365382522586885
EPOCH 2:
  batch 1 loss: 0.48232677578926086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.5093667656183243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.506145695845286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.5031526684761047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.5012772977352142
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.49922946592171985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.49670652406556265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4978950805962086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.49556275208791095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4918068528175354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4905079792846333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4897657458980878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.48815006705430836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.4889090380498341
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4908611873785655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.49126300401985645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4893672483808854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4890991598367691
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.49023552474222687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4900158911943436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.48989823034831453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4898698058995334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4907135652459186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4902639389038086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4897080087661743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.49024056929808396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.49145237384019075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4900221771427563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4898965759523984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4902586390574773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.49003984562812314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.49036109913140535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.48956988887353375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.48999521048629985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4910905233451298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.49079559991757077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.49002938737740387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4891563246124669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4894900062145331
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4895012751221657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4892557408751511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4892471155950001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.49072931464328323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.491034253754399
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.49112579888767666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.49044738256413006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.49029774932151143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4907455202192068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4910076582918362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.49164036571979525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4910248886136448
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.49095257830161315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4906430306299677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.49041905833615196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.48949154832146385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.48968785469021114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.48995730019452277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.48970846061048834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.48936443207627633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.48965578675270083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.48950328396969156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4899026415040416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.49013516921845696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.49028196092695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4906013718018165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.48988475808591553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4897685482430814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.48990656479316597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4896224486655083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4897587805986404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.489732993740431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.489312208775017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4895327438230384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.489415355228089
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4892822496096293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.48973701580574636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4894439663205828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.48909950982301664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.48913498203965683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4888952195644379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4889538398495427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.48868508964050106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4888976130140833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4887149642620768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4886480226236231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.488838569369427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4890204606385067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.48917583376169205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4890556184763319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4890494730737474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4889818868794284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.48919070479662524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.48926093309156354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.489330752098814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.48929787529142277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4897356533134977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4897449898351099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.489659204470868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4897188487077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4897874844074249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4895932084262961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4896584205767688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4898204415747263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4897705820890573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4898869866416568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4896846298339232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4895012754703236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4896722378002273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4896501488641861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.489783787727356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4895956500156506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4896347607885088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.48992316385286044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4898498798148674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.48959237414857615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.48956094836366587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4899338198523236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.48985269514180846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4900389744454071
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4897771884997686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4897524239110553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4899903342860644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.49016172057244833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4900074978509257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.49012173247337343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4902226430556131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4901769792470406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4904516462702304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.49034030030864156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4904672971138587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4903571648907115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.49020209614977694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.49014428347573247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.489977741196974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.48987686258775215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4899054813910933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.49000497586535713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4898476946181145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4900666672548802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4901434642927987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.49001527043944554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.49001176088628634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4900700154004397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.49023009919457966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.49026766563283986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4900006239544855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.49018132646067614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4904268798795906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4903171976540713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4900725048780441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4900471765473978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.49007661307328626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.49011459868717816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.48998030517008395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4901787757873535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.49039349074547106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4903775392823918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.49052875743636604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.49064948573802253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.49068871047347784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.49048032357085564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.49036847790818155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.49037835916127165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.49027749532606546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.49022483735373523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.49036480917269926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.490462574951663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.49018702957601773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.49018491866320546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4902881965917699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4901869903530991
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.49010373340096586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.49000280492567605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.49005154597348183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4898835117476327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.48976529254154727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4896555617030731
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4897030452998836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4897462649052369
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4897149246599939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.48963219635394395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4895864400889847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.48946545130568125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.48940489846079244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.48944796082135794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.48934034410343374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.48927029521070065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4891200385829236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.48910317660639524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4889735080693897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.48884917943889555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4886185747260849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.48867785282085596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4887212434994806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4886393053409381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.48866977040864984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4887815662446966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.48885950205302
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.48886476000349727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.48890661358833315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.48887760959454435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4888437506881091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.48858599695078847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4885614515811789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4885213388175499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.48834135188061056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.48828312178740757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.48813565361958283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.48831556516400937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.48832260427020846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4882927291201189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.488467757150812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4884921972740424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4883575350324684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.48842117065607116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.48834005895036237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.488320203832767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4885230842260046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.48879067661011055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4888413594527678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4886468276718623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.48854510848586624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4885995094017063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.488635183578091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.488481580681271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4883940200098848
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.48839680200631397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4882073814147397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.488177774644835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.48828339926574543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.48822395122928536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4883754886686802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4882734062333987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4883093831376133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4883641950627591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.48834616867667535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4883617968750402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.48828430649112253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.48826702481533196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.48838861448069415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.48844406330239226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4883824393522641
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.48846959393210865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4884978078427862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4885917957948179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.488741879298435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.48876910822594216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4886416898619744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.48877626729298784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.48879074013233187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.48883962833073985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4888094915520577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4888898875166776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4887838056237679
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4887413895597645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4887357181869447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4886259218598154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.48857566402402036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.488791457359395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4888789148284839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.48887276809334296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.48880460016600047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4888480149294487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.48885506549567886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48869027754045885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4887159544050245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4887069115478001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.48859193821006747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4885102365318284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4885246715059987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4885543072355629
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4884226396679878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.48832851069750804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4881259480314533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4879524379426783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.48802139739627426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.48803177809457055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4879515634166251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.48795627436757516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4879426667732852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4879747514622916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.487991434673891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4879253112806448
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4879391974126789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.48798361012810154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4879795940189095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.48798291712272457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4880464302582873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.48797336231053495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4880430398316219
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.48798018376442165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4880079503541123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.48807120638495827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4881573768497324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.48812473295098646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4880838902616823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.48814402274812513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4881067835044541
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4880386608898839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.48799122184515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4880966572864507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.48799592246677703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.48791675333536105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4879418677209239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.48799851478123274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4879603418065052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.48792591409496844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4879573274935995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.48798130621416286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4879442685073422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.48800148793355447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.48789152741814273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.48781823969115845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.48773801203366296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.48770101325852533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4877543712529955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.48778774460031404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.48780236322924775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4878072900271341
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4878790813498199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.48774637240115726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4877953943998917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4879594161045441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.487919171191292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.48788802889677196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.48789804415103116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.48792278429419256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4880034991699021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4879144580530903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4880177667646697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4880651143742472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4880155898540853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.48804199310752366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4879798658058315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.48795444707372293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.48802561552396845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4879307420565042
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4878813699328688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.487783565018381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4878190526190926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4878158786954069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4878349625750592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4877126428024414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4876898183205793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.48768352114635966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4877439334213389
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4877847060346466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4878187005718549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.48775912526685394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4877355138744627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.48765028796644294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.48765342293137853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4876975499874472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.48762234624496287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.48758414244987597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4874866713633698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4874794989072976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4875447115751618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4874981404347008
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.48740074212352436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.487344277615032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4873689723442931
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.48739314596515054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.48732631424298656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4873542210010633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4873166102203515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4872575649935803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.48724909960899665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4872374583065994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.48723718942822636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.48723214109631563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.48720674288849675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.487242159750762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4872346674216622
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.487207990248998
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.48717554198934676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4871730372823518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4872422445388067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4872791436857158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.48718930890685636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4871902019176583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4871021689388764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4871613765354256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.48716659339455265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.487140300908646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4872160560880918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4871781348258026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.48725885475419234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.48724454618358365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4872491227510648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4872374627596277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4872434850097919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4872138916536142
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.48718350830719553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4871216370335108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4871999363255019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4872470965763784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.48733379261278026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4873819478920528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4873546100407839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4872730901265085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.487136173233464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.48712296772831426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.48706290457803425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.48704741494155224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4870802223535594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4870454407587684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4870294964342725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.48696396308598133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.4869639281819506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4870165976584683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4870511888010988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4869940389155187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4871030182078265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4871738577463541
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4872350452037958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4871915153605189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4871786569721961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.48723954865642266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4872140052063125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.48731897187346235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4874048865095699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4873182746817316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4873307244676464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.48728676143814537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.48717606214570325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4871629070342285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4870828388032512
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.48699092420386825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.48707533880721693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.487023494912964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4870219029210232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.48693452930340314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.48695005346003767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.48686166412528903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.48694012115854735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.48693310280140806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4868708623054365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.48678878934073827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4867789520458742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4867942790055221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4867955856193784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.48682474874750487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.48673784732818604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.48686000122113177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4867580972043923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4868153393001898
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4868660221275474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4868686830413368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.48683483395311566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.486790800900787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4868248649007451
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.48679365082818676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4867384001153156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4867167663443219
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.48667011089753687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4866003955610471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.48661815345807885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4865701809557954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.48667243259108584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.48665971255612733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4866304982018161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.48663782976873493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.48663548193871975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4866100816957412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4866097158244751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4865673857659293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4866217408552129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.486644585313065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.48671497163620403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.48669619943685594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.48673840264900253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.48673840264900253 valid 0.4860517978668213
LOSS train 0.48673840264900253 valid 0.5008153319358826
LOSS train 0.48673840264900253 valid 0.49976417422294617
LOSS train 0.48673840264900253 valid 0.4965231567621231
LOSS train 0.48673840264900253 valid 0.4913576364517212
LOSS train 0.48673840264900253 valid 0.49621276060740155
LOSS train 0.48673840264900253 valid 0.5029399224690029
LOSS train 0.48673840264900253 valid 0.5052836239337921
LOSS train 0.48673840264900253 valid 0.5071522527270846
LOSS train 0.48673840264900253 valid 0.5111274659633637
LOSS train 0.48673840264900253 valid 0.5147328322583978
LOSS train 0.48673840264900253 valid 0.5135466406742731
LOSS train 0.48673840264900253 valid 0.5177036615518423
LOSS train 0.48673840264900253 valid 0.5200704719339099
LOSS train 0.48673840264900253 valid 0.5213699658711751
LOSS train 0.48673840264900253 valid 0.5193959306925535
LOSS train 0.48673840264900253 valid 0.5217316764242509
LOSS train 0.48673840264900253 valid 0.5220853669775857
LOSS train 0.48673840264900253 valid 0.5210376962235099
LOSS train 0.48673840264900253 valid 0.5219406083226203
LOSS train 0.48673840264900253 valid 0.5217572635128385
LOSS train 0.48673840264900253 valid 0.5204808210784738
LOSS train 0.48673840264900253 valid 0.5206435439379319
LOSS train 0.48673840264900253 valid 0.5195324396093687
LOSS train 0.48673840264900253 valid 0.5184687435626983
LOSS train 0.48673840264900253 valid 0.5169469358829352
LOSS train 0.48673840264900253 valid 0.516479656652168
LOSS train 0.48673840264900253 valid 0.5171039796301297
LOSS train 0.48673840264900253 valid 0.5160751394156752
LOSS train 0.48673840264900253 valid 0.5174675951401393
LOSS train 0.48673840264900253 valid 0.518702938672035
LOSS train 0.48673840264900253 valid 0.5191112970933318
LOSS train 0.48673840264900253 valid 0.5204286096674023
LOSS train 0.48673840264900253 valid 0.5213416735915577
LOSS train 0.48673840264900253 valid 0.5228239323411669
LOSS train 0.48673840264900253 valid 0.5232091902030839
LOSS train 0.48673840264900253 valid 0.5235103521798108
LOSS train 0.48673840264900253 valid 0.5238667295167321
LOSS train 0.48673840264900253 valid 0.5237215306514349
LOSS train 0.48673840264900253 valid 0.5243123330175876
LOSS train 0.48673840264900253 valid 0.5244233441062089
LOSS train 0.48673840264900253 valid 0.5243523780788694
LOSS train 0.48673840264900253 valid 0.5243726726188216
LOSS train 0.48673840264900253 valid 0.5244664705612443
LOSS train 0.48673840264900253 valid 0.5243844343556299
LOSS train 0.48673840264900253 valid 0.5250700109678766
LOSS train 0.48673840264900253 valid 0.5251886584657304
LOSS train 0.48673840264900253 valid 0.5260389540344477
LOSS train 0.48673840264900253 valid 0.5271064669502025
LOSS train 0.48673840264900253 valid 0.5264777332544327
LOSS train 0.48673840264900253 valid 0.5272145066775528
LOSS train 0.48673840264900253 valid 0.5276238683324593
LOSS train 0.48673840264900253 valid 0.527514931728255
LOSS train 0.48673840264900253 valid 0.5269366784228219
LOSS train 0.48673840264900253 valid 0.5270236876877872
LOSS train 0.48673840264900253 valid 0.5267060404377324
LOSS train 0.48673840264900253 valid 0.5262985276548486
LOSS train 0.48673840264900253 valid 0.5265057133189563
LOSS train 0.48673840264900253 valid 0.5270808970524092
LOSS train 0.48673840264900253 valid 0.5265404601891835
LOSS train 0.48673840264900253 valid 0.5252975836151936
LOSS train 0.48673840264900253 valid 0.5254082050054304
LOSS train 0.48673840264900253 valid 0.5252335038450029
LOSS train 0.48673840264900253 valid 0.5256079738028347
LOSS train 0.48673840264900253 valid 0.5259588521260482
LOSS train 0.48673840264900253 valid 0.5252735691540169
LOSS train 0.48673840264900253 valid 0.5250889841300338
LOSS train 0.48673840264900253 valid 0.5250627332750488
LOSS train 0.48673840264900253 valid 0.5250913202762604
LOSS train 0.48673840264900253 valid 0.5244161763361522
LOSS train 0.48673840264900253 valid 0.523889914784633
LOSS train 0.48673840264900253 valid 0.5236584912571642
LOSS train 0.48673840264900253 valid 0.5241132423485795
LOSS train 0.48673840264900253 valid 0.5234034697751742
LOSS train 0.48673840264900253 valid 0.5234508728981018
LOSS train 0.48673840264900253 valid 0.5237054024872027
LOSS train 0.48673840264900253 valid 0.5235695537034567
LOSS train 0.48673840264900253 valid 0.523631079074664
LOSS train 0.48673840264900253 valid 0.5232653202889841
LOSS train 0.48673840264900253 valid 0.5231330908834935
LOSS train 0.48673840264900253 valid 0.522710551450282
LOSS train 0.48673840264900253 valid 0.522822981927453
LOSS train 0.48673840264900253 valid 0.5225080912371716
LOSS train 0.48673840264900253 valid 0.5226020500773475
LOSS train 0.48673840264900253 valid 0.5222869627615985
LOSS train 0.48673840264900253 valid 0.5220328285250553
LOSS train 0.48673840264900253 valid 0.5219539006551107
LOSS train 0.48673840264900253 valid 0.5220030708746477
LOSS train 0.48673840264900253 valid 0.5220822685220269
LOSS train 0.48673840264900253 valid 0.5225728657510545
LOSS train 0.48673840264900253 valid 0.522743991443089
LOSS train 0.48673840264900253 valid 0.5225808192854342
LOSS train 0.48673840264900253 valid 0.5223623680812056
LOSS train 0.48673840264900253 valid 0.5222639891695469
LOSS train 0.48673840264900253 valid 0.5220542625377053
LOSS train 0.48673840264900253 valid 0.5219861511141062
LOSS train 0.48673840264900253 valid 0.5220404132125304
LOSS train 0.48673840264900253 valid 0.5217923984235647
LOSS train 0.48673840264900253 valid 0.5223100871750803
LOSS train 0.48673840264900253 valid 0.5225428956747055
LOSS train 0.48673840264900253 valid 0.5224395937258655
LOSS train 0.48673840264900253 valid 0.5224885601623386
LOSS train 0.48673840264900253 valid 0.5228094545382898
LOSS train 0.48673840264900253 valid 0.522993405851034
LOSS train 0.48673840264900253 valid 0.5231509901228405
LOSS train 0.48673840264900253 valid 0.5233021311040195
LOSS train 0.48673840264900253 valid 0.5231823252740307
LOSS train 0.48673840264900253 valid 0.5231352729929818
LOSS train 0.48673840264900253 valid 0.5233636640627449
LOSS train 0.48673840264900253 valid 0.5236922410401431
LOSS train 0.48673840264900253 valid 0.5236070462175317
LOSS train 0.48673840264900253 valid 0.5235005963061538
LOSS train 0.48673840264900253 valid 0.5236938901707134
LOSS train 0.48673840264900253 valid 0.5232329969866234
LOSS train 0.48673840264900253 valid 0.5232874875483305
LOSS train 0.48673840264900253 valid 0.5235440561483646
LOSS train 0.48673840264900253 valid 0.5234182701151595
LOSS train 0.48673840264900253 valid 0.5233221448073953
LOSS train 0.48673840264900253 valid 0.5232580709858101
LOSS train 0.48673840264900253 valid 0.523221438129743
LOSS train 0.48673840264900253 valid 0.5230545337535133
LOSS train 0.48673840264900253 valid 0.5228592804709419
LOSS train 0.48673840264900253 valid 0.5229239446845481
LOSS train 0.48673840264900253 valid 0.5231003581035522
LOSS train 0.48673840264900253 valid 0.5233035128116608
LOSS train 0.48673840264900253 valid 0.5233310037662112
LOSS train 0.48673840264900253 valid 0.5235016958450708
LOSS train 0.48673840264900253 valid 0.5237422261852771
LOSS train 0.48673840264900253 valid 0.5238634521184966
LOSS train 0.48673840264900253 valid 0.5237975961886919
LOSS train 0.48673840264900253 valid 0.5238302434218749
LOSS train 0.48673840264900253 valid 0.5235724663644126
LOSS train 0.48673840264900253 valid 0.5235016325810798
LOSS train 0.48673840264900253 valid 0.5234833793408835
LOSS train 0.48673840264900253 valid 0.5236235413286421
LOSS train 0.48673840264900253 valid 0.523630243671291
LOSS train 0.48673840264900253 valid 0.5233886148372706
LOSS train 0.48673840264900253 valid 0.5231380680764931
LOSS train 0.48673840264900253 valid 0.5230456678558597
LOSS train 0.48673840264900253 valid 0.5230647285069738
LOSS train 0.48673840264900253 valid 0.5232161243333884
LOSS train 0.48673840264900253 valid 0.5233751936277873
LOSS train 0.48673840264900253 valid 0.5232755114565363
LOSS train 0.48673840264900253 valid 0.5232972662068076
LOSS train 0.48673840264900253 valid 0.5230193355987812
LOSS train 0.48673840264900253 valid 0.523306375088757
LOSS train 0.48673840264900253 valid 0.5230266620107249
LOSS train 0.48673840264900253 valid 0.523379409031288
LOSS train 0.48673840264900253 valid 0.5232877233284432
LOSS train 0.48673840264900253 valid 0.5233918998638789
LOSS train 0.48673840264900253 valid 0.5233766699074119
LOSS train 0.48673840264900253 valid 0.5231178232321614
LOSS train 0.48673840264900253 valid 0.5230754865150825
LOSS train 0.48673840264900253 valid 0.523212467888733
LOSS train 0.48673840264900253 valid 0.5231401545386161
LOSS train 0.48673840264900253 valid 0.523539339693693
LOSS train 0.48673840264900253 valid 0.523529033182533
LOSS train 0.48673840264900253 valid 0.5236228940230382
LOSS train 0.48673840264900253 valid 0.5234053789069818
LOSS train 0.48673840264900253 valid 0.5233153754845261
LOSS train 0.48673840264900253 valid 0.5235079262197387
LOSS train 0.48673840264900253 valid 0.5233745183105822
LOSS train 0.48673840264900253 valid 0.5233318972075643
LOSS train 0.48673840264900253 valid 0.52318647031377
LOSS train 0.48673840264900253 valid 0.5229444380962487
LOSS train 0.48673840264900253 valid 0.5227232088884676
LOSS train 0.48673840264900253 valid 0.5229226316877468
LOSS train 0.48673840264900253 valid 0.5230924173125199
LOSS train 0.48673840264900253 valid 0.5231484095373097
LOSS train 0.48673840264900253 valid 0.5231762624838773
LOSS train 0.48673840264900253 valid 0.523433333077626
LOSS train 0.48673840264900253 valid 0.523570908190206
LOSS train 0.48673840264900253 valid 0.5236308883035803
LOSS train 0.48673840264900253 valid 0.5236928742164852
LOSS train 0.48673840264900253 valid 0.5237956031731197
LOSS train 0.48673840264900253 valid 0.5239101863381538
LOSS train 0.48673840264900253 valid 0.5240613126148612
LOSS train 0.48673840264900253 valid 0.5242990119738525
LOSS train 0.48673840264900253 valid 0.5243915271159657
LOSS train 0.48673840264900253 valid 0.5244434325231446
LOSS train 0.48673840264900253 valid 0.524472475545841
LOSS train 0.48673840264900253 valid 0.5245261236534013
LOSS train 0.48673840264900253 valid 0.5244850615660349
LOSS train 0.48673840264900253 valid 0.5245229852912219
LOSS train 0.48673840264900253 valid 0.524440498448707
LOSS train 0.48673840264900253 valid 0.5244959555966879
LOSS train 0.48673840264900253 valid 0.5247101370982308
LOSS train 0.48673840264900253 valid 0.5247569732526516
LOSS train 0.48673840264900253 valid 0.5246022994871493
LOSS train 0.48673840264900253 valid 0.5245007820819554
LOSS train 0.48673840264900253 valid 0.524752318391001
LOSS train 0.48673840264900253 valid 0.5248895723683139
LOSS train 0.48673840264900253 valid 0.5249526980936219
LOSS train 0.48673840264900253 valid 0.5247991742547026
LOSS train 0.48673840264900253 valid 0.5245729073500022
LOSS train 0.48673840264900253 valid 0.5245588592120579
LOSS train 0.48673840264900253 valid 0.5245975903448115
LOSS train 0.48673840264900253 valid 0.5244901794375796
LOSS train 0.48673840264900253 valid 0.5246101770568733
LOSS train 0.48673840264900253 valid 0.5246362718939781
LOSS train 0.48673840264900253 valid 0.524517466179767
LOSS train 0.48673840264900253 valid 0.5245921396382964
LOSS train 0.48673840264900253 valid 0.5245080675397601
LOSS train 0.48673840264900253 valid 0.5246966980835971
LOSS train 0.48673840264900253 valid 0.5246691953845141
LOSS train 0.48673840264900253 valid 0.5248953425189824
LOSS train 0.48673840264900253 valid 0.5248613043683739
LOSS train 0.48673840264900253 valid 0.5248169131003894
LOSS train 0.48673840264900253 valid 0.5245564096567163
LOSS train 0.48673840264900253 valid 0.5244626810153326
LOSS train 0.48673840264900253 valid 0.5246474187803495
LOSS train 0.48673840264900253 valid 0.5246203337919038
LOSS train 0.48673840264900253 valid 0.5246279047968242
LOSS train 0.48673840264900253 valid 0.5245768376321436
LOSS train 0.48673840264900253 valid 0.524358790281207
LOSS train 0.48673840264900253 valid 0.5242885736127695
LOSS train 0.48673840264900253 valid 0.5244244330215014
LOSS train 0.48673840264900253 valid 0.5243616745286032
LOSS train 0.48673840264900253 valid 0.5244529635122378
LOSS train 0.48673840264900253 valid 0.5243945946747607
LOSS train 0.48673840264900253 valid 0.5245219481207127
LOSS train 0.48673840264900253 valid 0.5246959128626832
LOSS train 0.48673840264900253 valid 0.5248667625835658
LOSS train 0.48673840264900253 valid 0.5248806986159512
LOSS train 0.48673840264900253 valid 0.5248364860481686
LOSS train 0.48673840264900253 valid 0.5247736909484442
LOSS train 0.48673840264900253 valid 0.5249159812664671
LOSS train 0.48673840264900253 valid 0.5250581498993071
LOSS train 0.48673840264900253 valid 0.525027657830559
LOSS train 0.48673840264900253 valid 0.5251468571631804
LOSS train 0.48673840264900253 valid 0.525046330896807
LOSS train 0.48673840264900253 valid 0.525109431481567
LOSS train 0.48673840264900253 valid 0.5248985754829619
LOSS train 0.48673840264900253 valid 0.5248714854829332
LOSS train 0.48673840264900253 valid 0.5249563860132339
LOSS train 0.48673840264900253 valid 0.5249712410367141
LOSS train 0.48673840264900253 valid 0.5249366291213137
LOSS train 0.48673840264900253 valid 0.5248899661442813
LOSS train 0.48673840264900253 valid 0.524931126683327
LOSS train 0.48673840264900253 valid 0.5249127602825562
LOSS train 0.48673840264900253 valid 0.525068429866767
LOSS train 0.48673840264900253 valid 0.5251071249896829
LOSS train 0.48673840264900253 valid 0.5250653954445089
LOSS train 0.48673840264900253 valid 0.5250735736039819
LOSS train 0.48673840264900253 valid 0.5250454171579712
LOSS train 0.48673840264900253 valid 0.5249858393174845
LOSS train 0.48673840264900253 valid 0.5251639339364009
LOSS train 0.48673840264900253 valid 0.5251498925349405
LOSS train 0.48673840264900253 valid 0.5251361262128056
LOSS train 0.48673840264900253 valid 0.5252997392416
LOSS train 0.48673840264900253 valid 0.5252616195327258
LOSS train 0.48673840264900253 valid 0.5253596884154138
LOSS train 0.48673840264900253 valid 0.5254326216552568
LOSS train 0.48673840264900253 valid 0.5254348827393975
LOSS train 0.48673840264900253 valid 0.5254196186860403
LOSS train 0.48673840264900253 valid 0.5253889757441357
LOSS train 0.48673840264900253 valid 0.5253495118265485
LOSS train 0.48673840264900253 valid 0.5253723796254904
LOSS train 0.48673840264900253 valid 0.5254290252348631
LOSS train 0.48673840264900253 valid 0.5254263415932655
LOSS train 0.48673840264900253 valid 0.525487386061314
LOSS train 0.48673840264900253 valid 0.5255498245699715
LOSS train 0.48673840264900253 valid 0.5256020679446681
LOSS train 0.48673840264900253 valid 0.5255837102956844
LOSS train 0.48673840264900253 valid 0.5256552418447891
LOSS train 0.48673840264900253 valid 0.5256528600042027
LOSS train 0.48673840264900253 valid 0.5255930844540899
LOSS train 0.48673840264900253 valid 0.5255901807946946
LOSS train 0.48673840264900253 valid 0.5258162135749944
LOSS train 0.48673840264900253 valid 0.5258997156664177
LOSS train 0.48673840264900253 valid 0.5260035440710638
LOSS train 0.48673840264900253 valid 0.5260082988397163
LOSS train 0.48673840264900253 valid 0.5261310268016088
LOSS train 0.48673840264900253 valid 0.5261188985875053
LOSS train 0.48673840264900253 valid 0.5260805850679224
LOSS train 0.48673840264900253 valid 0.5262016300921855
LOSS train 0.48673840264900253 valid 0.5262765530429592
LOSS train 0.48673840264900253 valid 0.5262429558759113
LOSS train 0.48673840264900253 valid 0.5263261059065446
LOSS train 0.48673840264900253 valid 0.5263295321592263
LOSS train 0.48673840264900253 valid 0.5261052728123512
LOSS train 0.48673840264900253 valid 0.5259889932811683
LOSS train 0.48673840264900253 valid 0.5258864568737286
LOSS train 0.48673840264900253 valid 0.5259524325669651
LOSS train 0.48673840264900253 valid 0.5259824892930817
LOSS train 0.48673840264900253 valid 0.5259235574232115
LOSS train 0.48673840264900253 valid 0.5259044805885608
LOSS train 0.48673840264900253 valid 0.5258863545540307
LOSS train 0.48673840264900253 valid 0.525892498996431
LOSS train 0.48673840264900253 valid 0.5258708329036318
LOSS train 0.48673840264900253 valid 0.5257612346988363
LOSS train 0.48673840264900253 valid 0.5257165173757566
LOSS train 0.48673840264900253 valid 0.5257145938409473
LOSS train 0.48673840264900253 valid 0.5257927752068253
LOSS train 0.48673840264900253 valid 0.5259263637712446
LOSS train 0.48673840264900253 valid 0.5259719475902416
LOSS train 0.48673840264900253 valid 0.5259326290000569
LOSS train 0.48673840264900253 valid 0.5259421368773352
LOSS train 0.48673840264900253 valid 0.5260478233214605
LOSS train 0.48673840264900253 valid 0.5259564670920372
LOSS train 0.48673840264900253 valid 0.5259986049511108
LOSS train 0.48673840264900253 valid 0.5259330074321356
LOSS train 0.48673840264900253 valid 0.5259587702774765
LOSS train 0.48673840264900253 valid 0.5259285197642288
LOSS train 0.48673840264900253 valid 0.5258455265740879
LOSS train 0.48673840264900253 valid 0.52579122947322
LOSS train 0.48673840264900253 valid 0.525735532713247
LOSS train 0.48673840264900253 valid 0.5257649296870479
LOSS train 0.48673840264900253 valid 0.5258040986593487
LOSS train 0.48673840264900253 valid 0.5257453338753793
LOSS train 0.48673840264900253 valid 0.5256747790279879
LOSS train 0.48673840264900253 valid 0.5257213833049322
LOSS train 0.48673840264900253 valid 0.5258585392667082
LOSS train 0.48673840264900253 valid 0.5259308741920313
LOSS train 0.48673840264900253 valid 0.5260028446477557
LOSS train 0.48673840264900253 valid 0.5259292673649667
LOSS train 0.48673840264900253 valid 0.5260024635761694
LOSS train 0.48673840264900253 valid 0.525907686015345
LOSS train 0.48673840264900253 valid 0.5260096964978126
LOSS train 0.48673840264900253 valid 0.5258968723006546
LOSS train 0.48673840264900253 valid 0.5258387742198516
LOSS train 0.48673840264900253 valid 0.525809468967574
LOSS train 0.48673840264900253 valid 0.5257008788939969
LOSS train 0.48673840264900253 valid 0.5256540912352963
LOSS train 0.48673840264900253 valid 0.5256201765170464
LOSS train 0.48673840264900253 valid 0.5257663199323818
LOSS train 0.48673840264900253 valid 0.5257858068024347
LOSS train 0.48673840264900253 valid 0.5259219739676976
LOSS train 0.48673840264900253 valid 0.5260003465468398
LOSS train 0.48673840264900253 valid 0.5260534262115305
LOSS train 0.48673840264900253 valid 0.5259988953519804
LOSS train 0.48673840264900253 valid 0.5258632426161364
LOSS train 0.48673840264900253 valid 0.5258911855227955
LOSS train 0.48673840264900253 valid 0.5260684147566378
LOSS train 0.48673840264900253 valid 0.5260898679050047
LOSS train 0.48673840264900253 valid 0.5261703575296062
LOSS train 0.48673840264900253 valid 0.5261220620718483
LOSS train 0.48673840264900253 valid 0.5261181823953369
LOSS train 0.48673840264900253 valid 0.5259700989828701
LOSS train 0.48673840264900253 valid 0.5258881120997316
LOSS train 0.48673840264900253 valid 0.5258034179287572
LOSS train 0.48673840264900253 valid 0.5258072281790058
LOSS train 0.48673840264900253 valid 0.5258235571683322
LOSS train 0.48673840264900253 valid 0.5259173718649287
LOSS train 0.48673840264900253 valid 0.5258840579917465
LOSS train 0.48673840264900253 valid 0.5259387057296113
LOSS train 0.48673840264900253 valid 0.5259371868815134
LOSS train 0.48673840264900253 valid 0.5260319502531797
LOSS train 0.48673840264900253 valid 0.5261149650658441
LOSS train 0.48673840264900253 valid 0.5261020350456238
LOSS train 0.48673840264900253 valid 0.5260319047504001
LOSS train 0.48673840264900253 valid 0.5260171836072748
LOSS train 0.48673840264900253 valid 0.5261058751651991
LOSS train 0.48673840264900253 valid 0.5261520891539795
LOSS train 0.48673840264900253 valid 0.5262779366802162
LOSS train 0.48673840264900253 valid 0.5263463690709532
LOSS train 0.48673840264900253 valid 0.5262894737286394
LOSS train 0.48673840264900253 valid 0.5262045894421679
LOSS train 0.48673840264900253 valid 0.5262426834418581
LOSS train 0.48673840264900253 valid 0.5262502205868562
LOSS train 0.48673840264900253 valid 0.5263215665837074
LOSS train 0.48673840264900253 valid 0.526411254349993
LOSS train 0.48673840264900253 valid 0.5264482646770057
LOSS train 0.48673840264900253 valid 0.526440967979667
LOSS train 0.48673840264900253 valid 0.5265005814702544
LOSS train 0.48673840264900253 valid 0.5264955408097617
LOSS train 0.48673840264900253 valid 0.5264292387773946
LOSS train 0.48673840264900253 valid 0.5264227763628182
LOSS train 0.48673840264900253 valid 0.5264545996499256
EPOCH 3:
  batch 1 loss: 0.46336597204208374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.49619850516319275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.4947587251663208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.49299705773591995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.49183209538459777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.48778198659420013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4860323326928275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4863562807440758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.484190907743242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4795604765415192
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4779996004971591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4779910172025363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.47644887979214007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.4774186781474522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4801982879638672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.481063412502408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.47987549269900603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4800775994857152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.48165414992131683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.482047027349472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4819185705412002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4819204102862965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4828021992807803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4825149054328601
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.48187275648117067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.48227763634461623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.48317569494247437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4821349233388901
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.48228300337133734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4826389859120051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.48233012326302066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4826330132782459
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.48195114641478565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.48242434070390816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4834729952471597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.48339082549015683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.482341398258467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4814882772533517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4818070699007083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4819846570491791
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4816745984845045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.48152009220350356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.48308361824168716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4835432456298308
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.48360051446490815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4828176627988401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.48273147167043484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4832491800189018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4833339209459266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.48403995752334594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.48323310356514126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.48289268062664914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4823552010194311
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4821597227343806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.48131041635166516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.48144901703510967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.48187232488080073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4813702183550802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4808904836743565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4811250055829684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.48102236233773776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.48158106255915856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.48162354883693514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4816659935750067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.48217126910503094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4815634565823006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4814310051612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.48164692038998885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4814531323702439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.48154619889599937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.48157998835536797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4811519148449103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.48148487242933824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4813133264715607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.48116628726323446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.48168884060884776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4815350573558312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4812655246410614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4813109723073018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4812491964548826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4812094587602733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4809308524538831
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4810785033616675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4807664028235844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.48077092310961556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4810560123864995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4812599927529521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4814709343693473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4813271405991544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.48126995861530303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4811647138097784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.48138858799053275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.481524061131221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.48151920070039467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4815089589671085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4821002371609211
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4820954354153466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.48210489962782177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4822284260181465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.48232180953025816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4822165423100538
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.48227587692877827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4824596730250757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.48243902910214204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.48257591696012586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.48236846980058923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4821852790975125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.48242809816643045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.48239275047538477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.48246512521396984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.48232042574667716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4823450387588569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4825581644488647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4825554301864223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.48228913571523585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.48234156801782807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4827851046863784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4827523163314593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4829473392803128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4826840835313002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4827412044213823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.48291186890641197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4830573242369706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4828892239639836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4830525002479553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4831510115237463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.48314378721507517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.48342190915718675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.48333423313244367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4834463843932519
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.48332435484150893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.483230001772895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4832014540084323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4831023727779958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.48307370212343004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4830750551293878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.48325633306572907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4831311694089917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.48332578415493316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.48338660172053743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.48326879443851767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4832558976092809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4833125738830833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4835405552552806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4836018346506974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4834658530068724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4836583431480693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4838288585479195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48373897323672405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.48352582355340323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4835967490609908
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4835841645927806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.48362937004737605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4835475007821987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4837289216056947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.48395058035086364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4838898233167685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4840922836638704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.48425764164084906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4843290278688073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.48418204532646986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4840920854497839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4841292109226157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4840205580722995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.483932025866075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.48409183161804475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.48408149316639243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.48384436113493784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4838344886810822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4839486499043072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4838549137464044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.48377975180398586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.48370563846103026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.48376608819797123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4835814869403839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.48347800682214176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4834134129144378
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.48343086962619525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.48353050224607885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4835055359535747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.48342448028411655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4833409309714705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4832074826206666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.48316735822869383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4832546251851159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.48318605990179125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4831299805704923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4830136424366464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4829674295332066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4828485071659088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.482774315860259
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.48254687633986276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4825959583947078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4826659724577186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4825879905468378
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4825774253327019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4826851131649792
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.48282580830232064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.48283006153514035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4828823824226856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.48288115340085763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4828852578850076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4826493120839443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4826073900741689
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.48259536434964434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.48242708172612975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4823922147785408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.48226136356019056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4824711462242181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4825108926920664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4825195866455964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.48271188182088565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.48275237450017616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4826178818105537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.482663687439852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.48253560424954806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.48255753407280566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.48277053072911885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4830155579466798
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.483069848743352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.48286240079284254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4827730118691384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4828530475163139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.48287865958575693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4826880323886871
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4825835813463262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4826213229070151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.48244971481331606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.48242395387466297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4825381605521492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4825023528817412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.48263006657361984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.48248849866727905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.48252629291298044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.48259138452245837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.48257262524911915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.48256895071846523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.48248424925724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.48248978015269195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4826025106012821
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.48268233765210355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.48262820583729704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4827317821145548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4827411510661
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4828452581045579
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4829981432455342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4830442150594734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4829230363811216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4831366220631274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4831829125881195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.48325499690386403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4832658048660036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4833569423012111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4832435311294916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.48319862566742244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4831940315198153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4830853275751789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.48304111169752223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4832986315935275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4833794505550311
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.48336725205297215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.4832855679151666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.48332470519461107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4833149719193126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48317581707576535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.48320496216752473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4832087031910928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.48310986917410326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.483055750898269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4830755724951073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4830869856355815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.48296262871693163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.48291547678329133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4827127323968567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.48255831198258836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.482585350672404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.48261487225763205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.48255331835729615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4825590345808255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.48257198876568247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4826183977712516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4826196622341237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4825615903935247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4825825200114452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.48261292430392483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.48263220655751393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.4826323592496666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.48265836315436494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4825972897164962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.48265567021123296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.48260564933118133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4826171417554764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4827064447638931
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.48279071229250253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.48278005496930265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.48274535474342267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.48284542169233763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.48279137749399914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.48273981464746407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.482702791194121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.482829095418271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.48274327212611573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4826852547453575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4827103739310252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.48281020053097456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4827644410086613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.48273196971765947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.482790576850439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.48284406096804106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4828186127447313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.48289569359500306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.48279385593457097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4827339950080116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4826510421409728
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.48261084102448965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.48269717055785505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.48275223252149035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4827737628288989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4827943290102071
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4828695495612919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4827490774827583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.48280247888579875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4829791857177628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4829716252875917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.48295165116970357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4829664042939438
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4830003131055686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4830730099503587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4830030576074015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.48309459216666945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.48314245824007107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4831170046544937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4831372778694909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4830792685468754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.48307861018536696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4831427880341098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.48306096201480675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4830516462142651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4829621639399402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4830290679545963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4830391470812633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4830563571195156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.48294275955625593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4829227599466956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4829277479994124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.48300237212911507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4830550138304488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.48310023606166075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4830527418322413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4830344249520983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4829741848839654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.48297947899184446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4830198603716518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.48295563282602927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.48294867671711345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.48285369566652214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.48285659663483543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4829570984873692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.48290902849359435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4828157467146715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.48277167790154013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4828026294708252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.482830624114055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.48276454717903344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.48278862417560736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.482753233912864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.48272200899163126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4827243075908526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4827254750541232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.48272523533653566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4827550078498707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4827163755413025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4827644458245336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4827657277411956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4827582840124766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4827217455715575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.48271589119491276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4828118405171803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.48283687281105325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.48275365429489236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.482752003303663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4826717744947104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4827630759530528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4828049682546407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4827976052637224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.48288245869732893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.48286620444721645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4829539731144905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4829325275280175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4829453326188601
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4829335255391153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4829403303411542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4829046627644061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.48289349773511064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4828332142739356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.48290653022551777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4829556828632163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.4830609151915689
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4831064671352692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4830816293507814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.48300866162093203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4828727799861585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4828448595835021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4827946794800239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.48280597697069616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.48285239281619124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.48282071801602694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4828183659005399
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.48275782805491774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.48275466052497307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.48281165442617563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.48285891839022776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4827948380036158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.48292743223876766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.48300036393016216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4830814872223597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4830585678132604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4830674759366296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4831167448818826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.48309550696895237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.48321415692780195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4833126746082758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.48324822893379427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4832703582942486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4832390018771677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4831169204952571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4831292356344799
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4830650669809814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.48298195851988446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.48308832444423855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4830497016486325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.48305654656831865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4829825316372975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4830011951346551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.48290611046484144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4830021149384866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4829807859127254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.48294756925541515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.48286082974055905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.48283510174263605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4828535615046278
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.48286243052773886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4828825423464549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4828340877686535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.48299199188693187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.48288187658572945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4829764365483184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.48302153118753005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4830419209460108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4830238487323125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4829857614378707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.48302510255469683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4829945412297912
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4829469759690079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.48293211047465984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.48287164060431614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4828453215911039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4828573522609394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4828103855414588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4829184435631918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.48289204587646783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4828776022443524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4829023681243089
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4829184856137325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4829048019583507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.48290759612818135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.48288451687171574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.48296077543089533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4829862535889469
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.48305825210632164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.48304020757381577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4831032536418761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4831032536418761 valid 0.48551973700523376
LOSS train 0.4831032536418761 valid 0.5002976506948471
LOSS train 0.4831032536418761 valid 0.49863819281260174
LOSS train 0.4831032536418761 valid 0.4949359893798828
LOSS train 0.4831032536418761 valid 0.48965572118759154
LOSS train 0.4831032536418761 valid 0.4949442247549693
LOSS train 0.4831032536418761 valid 0.5017597930771964
LOSS train 0.4831032536418761 valid 0.5041658505797386
LOSS train 0.4831032536418761 valid 0.5060318244828118
LOSS train 0.4831032536418761 valid 0.5100522220134736
LOSS train 0.4831032536418761 valid 0.5136126334016974
LOSS train 0.4831032536418761 valid 0.5124308889110883
LOSS train 0.4831032536418761 valid 0.5168302632295169
LOSS train 0.4831032536418761 valid 0.5191699585744313
LOSS train 0.4831032536418761 valid 0.5204918682575226
LOSS train 0.4831032536418761 valid 0.5185047816485167
LOSS train 0.4831032536418761 valid 0.5208781659603119
LOSS train 0.4831032536418761 valid 0.5212928470638063
LOSS train 0.4831032536418761 valid 0.5202146721513647
LOSS train 0.4831032536418761 valid 0.5212038651108741
LOSS train 0.4831032536418761 valid 0.5209813103789375
LOSS train 0.4831032536418761 valid 0.5196579748933966
LOSS train 0.4831032536418761 valid 0.5197848703550256
LOSS train 0.4831032536418761 valid 0.5186629046996435
LOSS train 0.4831032536418761 valid 0.5175237870216369
LOSS train 0.4831032536418761 valid 0.5159588673940072
LOSS train 0.4831032536418761 valid 0.5155623742827663
LOSS train 0.4831032536418761 valid 0.5162014822874751
LOSS train 0.4831032536418761 valid 0.5151840592252797
LOSS train 0.4831032536418761 valid 0.5165936489899953
LOSS train 0.4831032536418761 valid 0.5178449826855813
LOSS train 0.4831032536418761 valid 0.5182154159992933
LOSS train 0.4831032536418761 valid 0.5195476448897159
LOSS train 0.4831032536418761 valid 0.5204199920682346
LOSS train 0.4831032536418761 valid 0.521977835042136
LOSS train 0.4831032536418761 valid 0.5223892629146576
LOSS train 0.4831032536418761 valid 0.522711497706336
LOSS train 0.4831032536418761 valid 0.5230990365931862
LOSS train 0.4831032536418761 valid 0.5229769838161957
LOSS train 0.4831032536418761 valid 0.5235766977071762
LOSS train 0.4831032536418761 valid 0.5236814283743138
LOSS train 0.4831032536418761 valid 0.523621943734941
LOSS train 0.4831032536418761 valid 0.5236367306043935
LOSS train 0.4831032536418761 valid 0.5237295546314933
LOSS train 0.4831032536418761 valid 0.5236593577596876
LOSS train 0.4831032536418761 valid 0.5243789359279301
LOSS train 0.4831032536418761 valid 0.5244917653976603
LOSS train 0.4831032536418761 valid 0.5253459525605043
LOSS train 0.4831032536418761 valid 0.526462983111946
LOSS train 0.4831032536418761 valid 0.5258335304260254
LOSS train 0.4831032536418761 valid 0.5265614799424714
LOSS train 0.4831032536418761 valid 0.5269788916294391
LOSS train 0.4831032536418761 valid 0.5268402122101694
LOSS train 0.4831032536418761 valid 0.526244616066968
LOSS train 0.4831032536418761 valid 0.5263091499155218
LOSS train 0.4831032536418761 valid 0.5259751783949989
LOSS train 0.4831032536418761 valid 0.5255586034373233
LOSS train 0.4831032536418761 valid 0.5257392279033003
LOSS train 0.4831032536418761 valid 0.5263247894028485
LOSS train 0.4831032536418761 valid 0.525779110689958
LOSS train 0.4831032536418761 valid 0.5245173754262142
LOSS train 0.4831032536418761 valid 0.5246282984172145
LOSS train 0.4831032536418761 valid 0.5244528078843677
LOSS train 0.4831032536418761 valid 0.5248530204407871
LOSS train 0.4831032536418761 valid 0.5251873488609607
LOSS train 0.4831032536418761 valid 0.5244949369719534
LOSS train 0.4831032536418761 valid 0.524308469758105
LOSS train 0.4831032536418761 valid 0.5242761312162175
LOSS train 0.4831032536418761 valid 0.524288931618566
LOSS train 0.4831032536418761 valid 0.5236049847943443
LOSS train 0.4831032536418761 valid 0.5230594017136265
LOSS train 0.4831032536418761 valid 0.5228266525599692
LOSS train 0.4831032536418761 valid 0.5232798865396683
LOSS train 0.4831032536418761 valid 0.5225556005497236
LOSS train 0.4831032536418761 valid 0.5225786586602529
LOSS train 0.4831032536418761 valid 0.5228370290837789
LOSS train 0.4831032536418761 valid 0.522696863134186
LOSS train 0.4831032536418761 valid 0.5227529486784568
LOSS train 0.4831032536418761 valid 0.5223904474626614
LOSS train 0.4831032536418761 valid 0.5222608666867018
LOSS train 0.4831032536418761 valid 0.5218303004900614
LOSS train 0.4831032536418761 valid 0.5219333775159789
LOSS train 0.4831032536418761 valid 0.5216179849153542
LOSS train 0.4831032536418761 valid 0.5217056437617257
LOSS train 0.4831032536418761 valid 0.5213831123183755
LOSS train 0.4831032536418761 valid 0.521109951789989
LOSS train 0.4831032536418761 valid 0.5210240818988318
LOSS train 0.4831032536418761 valid 0.5210779471830889
LOSS train 0.4831032536418761 valid 0.5211787404638998
LOSS train 0.4831032536418761 valid 0.5216644287109375
LOSS train 0.4831032536418761 valid 0.5218215106607793
LOSS train 0.4831032536418761 valid 0.5216594526301259
LOSS train 0.4831032536418761 valid 0.5214439752281353
LOSS train 0.4831032536418761 valid 0.5213269179171705
LOSS train 0.4831032536418761 valid 0.5211176062885083
LOSS train 0.4831032536418761 valid 0.5210604754587015
LOSS train 0.4831032536418761 valid 0.5211163710073098
LOSS train 0.4831032536418761 valid 0.5208574016483463
LOSS train 0.4831032536418761 valid 0.5213823276336746
LOSS train 0.4831032536418761 valid 0.5216197723150253
LOSS train 0.4831032536418761 valid 0.5215038739808715
LOSS train 0.4831032536418761 valid 0.5215585634988897
LOSS train 0.4831032536418761 valid 0.5218818610154309
LOSS train 0.4831032536418761 valid 0.5220677617650765
LOSS train 0.4831032536418761 valid 0.5222294966379801
LOSS train 0.4831032536418761 valid 0.5223914334234202
LOSS train 0.4831032536418761 valid 0.5222660603924333
LOSS train 0.4831032536418761 valid 0.5222194680461177
LOSS train 0.4831032536418761 valid 0.5224410076753809
LOSS train 0.4831032536418761 valid 0.5227836603468115
LOSS train 0.4831032536418761 valid 0.522693208746008
LOSS train 0.4831032536418761 valid 0.5225700406091554
LOSS train 0.4831032536418761 valid 0.5227645709451321
LOSS train 0.4831032536418761 valid 0.5222877467933454
LOSS train 0.4831032536418761 valid 0.5223361797954725
LOSS train 0.4831032536418761 valid 0.5226070891166555
LOSS train 0.4831032536418761 valid 0.5224739909172058
LOSS train 0.4831032536418761 valid 0.5223693286968489
LOSS train 0.4831032536418761 valid 0.5222901080836769
LOSS train 0.4831032536418761 valid 0.5222612376014392
LOSS train 0.4831032536418761 valid 0.5220879912376404
LOSS train 0.4831032536418761 valid 0.5218883525641238
LOSS train 0.4831032536418761 valid 0.5219622285870033
LOSS train 0.4831032536418761 valid 0.5221504533002453
LOSS train 0.4831032536418761 valid 0.5223532888889313
LOSS train 0.4831032536418761 valid 0.52237883091919
LOSS train 0.4831032536418761 valid 0.5225696472201761
LOSS train 0.4831032536418761 valid 0.5228160063270479
LOSS train 0.4831032536418761 valid 0.5229405656803486
LOSS train 0.4831032536418761 valid 0.5228715545856035
LOSS train 0.4831032536418761 valid 0.5228974380110967
LOSS train 0.4831032536418761 valid 0.5226370624520562
LOSS train 0.4831032536418761 valid 0.5225671588030076
LOSS train 0.4831032536418761 valid 0.5225343357271223
LOSS train 0.4831032536418761 valid 0.5226705339219835
LOSS train 0.4831032536418761 valid 0.5226719129611465
LOSS train 0.4831032536418761 valid 0.5224256241408578
LOSS train 0.4831032536418761 valid 0.522161650052969
LOSS train 0.4831032536418761 valid 0.5220717294610662
LOSS train 0.4831032536418761 valid 0.5220930844545364
LOSS train 0.4831032536418761 valid 0.522248369159428
LOSS train 0.4831032536418761 valid 0.5224078725761091
LOSS train 0.4831032536418761 valid 0.5223073034019737
LOSS train 0.4831032536418761 valid 0.5223236075705953
LOSS train 0.4831032536418761 valid 0.5220370015193676
LOSS train 0.4831032536418761 valid 0.5223337193466213
LOSS train 0.4831032536418761 valid 0.5220557266757602
LOSS train 0.4831032536418761 valid 0.522421294168846
LOSS train 0.4831032536418761 valid 0.5223305731411748
LOSS train 0.4831032536418761 valid 0.5224490712086359
LOSS train 0.4831032536418761 valid 0.5224372418905725
LOSS train 0.4831032536418761 valid 0.5221674806977573
LOSS train 0.4831032536418761 valid 0.5221248152209264
LOSS train 0.4831032536418761 valid 0.5222628081773782
LOSS train 0.4831032536418761 valid 0.522189672147074
LOSS train 0.4831032536418761 valid 0.522598711725993
LOSS train 0.4831032536418761 valid 0.5225850393058388
LOSS train 0.4831032536418761 valid 0.5226736966567703
LOSS train 0.4831032536418761 valid 0.5224443034930799
LOSS train 0.4831032536418761 valid 0.522366620413959
LOSS train 0.4831032536418761 valid 0.5225644080165011
LOSS train 0.4831032536418761 valid 0.5224258139913465
LOSS train 0.4831032536418761 valid 0.5223668442547686
LOSS train 0.4831032536418761 valid 0.5222173235038432
LOSS train 0.4831032536418761 valid 0.5219611023411607
LOSS train 0.4831032536418761 valid 0.5217337640653174
LOSS train 0.4831032536418761 valid 0.5219364426807015
LOSS train 0.4831032536418761 valid 0.5221157914825848
LOSS train 0.4831032536418761 valid 0.5221919600780194
LOSS train 0.4831032536418761 valid 0.5222282865468193
LOSS train 0.4831032536418761 valid 0.5224915742874146
LOSS train 0.4831032536418761 valid 0.5226269946541897
LOSS train 0.4831032536418761 valid 0.5226875130151738
LOSS train 0.4831032536418761 valid 0.5227445432509499
LOSS train 0.4831032536418761 valid 0.5228409174510411
LOSS train 0.4831032536418761 valid 0.5229586051269011
LOSS train 0.4831032536418761 valid 0.52311670712832
LOSS train 0.4831032536418761 valid 0.5233677347724357
LOSS train 0.4831032536418761 valid 0.5234598670591856
LOSS train 0.4831032536418761 valid 0.5235092331965764
LOSS train 0.4831032536418761 valid 0.5235405465515938
LOSS train 0.4831032536418761 valid 0.5235899297090677
LOSS train 0.4831032536418761 valid 0.523546148519047
LOSS train 0.4831032536418761 valid 0.5235907341475072
LOSS train 0.4831032536418761 valid 0.5235061909701373
LOSS train 0.4831032536418761 valid 0.5235687686551002
LOSS train 0.4831032536418761 valid 0.5237874302634581
LOSS train 0.4831032536418761 valid 0.5238348182211531
LOSS train 0.4831032536418761 valid 0.5236742258387268
LOSS train 0.4831032536418761 valid 0.5235760909946341
LOSS train 0.4831032536418761 valid 0.5238384933683885
LOSS train 0.4831032536418761 valid 0.5239788208467265
LOSS train 0.4831032536418761 valid 0.5240377738994638
LOSS train 0.4831032536418761 valid 0.5238782605252315
LOSS train 0.4831032536418761 valid 0.5236492274663387
LOSS train 0.4831032536418761 valid 0.5236369397263138
LOSS train 0.4831032536418761 valid 0.5236847045155346
LOSS train 0.4831032536418761 valid 0.5235749484613689
LOSS train 0.4831032536418761 valid 0.5236963517402284
LOSS train 0.4831032536418761 valid 0.5237156002223492
LOSS train 0.4831032536418761 valid 0.5235893161439183
LOSS train 0.4831032536418761 valid 0.5236680653720799
LOSS train 0.4831032536418761 valid 0.5235807729765699
LOSS train 0.4831032536418761 valid 0.523773767054081
LOSS train 0.4831032536418761 valid 0.5237484366428561
LOSS train 0.4831032536418761 valid 0.5239712727590672
LOSS train 0.4831032536418761 valid 0.5239326382316829
LOSS train 0.4831032536418761 valid 0.5238877195291795
LOSS train 0.4831032536418761 valid 0.5236220783308932
LOSS train 0.4831032536418761 valid 0.523529811842101
LOSS train 0.4831032536418761 valid 0.5237160408383862
LOSS train 0.4831032536418761 valid 0.5236959624684082
LOSS train 0.4831032536418761 valid 0.5237034406740341
LOSS train 0.4831032536418761 valid 0.5236483621541584
LOSS train 0.4831032536418761 valid 0.5234315215155135
LOSS train 0.4831032536418761 valid 0.5233527317091271
LOSS train 0.4831032536418761 valid 0.5234944913793819
LOSS train 0.4831032536418761 valid 0.5234320508230716
LOSS train 0.4831032536418761 valid 0.5235196319344926
LOSS train 0.4831032536418761 valid 0.5234592231837186
LOSS train 0.4831032536418761 valid 0.5235828646707319
LOSS train 0.4831032536418761 valid 0.5237588600532429
LOSS train 0.4831032536418761 valid 0.5239382006662309
LOSS train 0.4831032536418761 valid 0.5239524144147124
LOSS train 0.4831032536418761 valid 0.5239081207911174
LOSS train 0.4831032536418761 valid 0.5238433786198101
LOSS train 0.4831032536418761 valid 0.5239887613031833
LOSS train 0.4831032536418761 valid 0.5241368849549377
LOSS train 0.4831032536418761 valid 0.5241036784700952
LOSS train 0.4831032536418761 valid 0.5242225475933241
LOSS train 0.4831032536418761 valid 0.5241232387947313
LOSS train 0.4831032536418761 valid 0.5241808870743061
LOSS train 0.4831032536418761 valid 0.5239664495247116
LOSS train 0.4831032536418761 valid 0.5239409694814274
LOSS train 0.4831032536418761 valid 0.5240319274841471
LOSS train 0.4831032536418761 valid 0.5240409710144592
LOSS train 0.4831032536418761 valid 0.5240073141166429
LOSS train 0.4831032536418761 valid 0.5239622735676646
LOSS train 0.4831032536418761 valid 0.5240069111520775
LOSS train 0.4831032536418761 valid 0.5239895823101203
LOSS train 0.4831032536418761 valid 0.5241531467536673
LOSS train 0.4831032536418761 valid 0.524191776090417
LOSS train 0.4831032536418761 valid 0.5241518138367453
LOSS train 0.4831032536418761 valid 0.5241590638141163
LOSS train 0.4831032536418761 valid 0.5241268019286953
LOSS train 0.4831032536418761 valid 0.524065317904077
LOSS train 0.4831032536418761 valid 0.5242504310994013
LOSS train 0.4831032536418761 valid 0.5242376135241601
LOSS train 0.4831032536418761 valid 0.5242129545135191
LOSS train 0.4831032536418761 valid 0.5243799569606781
LOSS train 0.4831032536418761 valid 0.5243401895481277
LOSS train 0.4831032536418761 valid 0.5244408519495101
LOSS train 0.4831032536418761 valid 0.5245189850509402
LOSS train 0.4831032536418761 valid 0.5245204614842032
LOSS train 0.4831032536418761 valid 0.5245031562505984
LOSS train 0.4831032536418761 valid 0.524467195617035
LOSS train 0.4831032536418761 valid 0.5244270389182094
LOSS train 0.4831032536418761 valid 0.5244531585264576
LOSS train 0.4831032536418761 valid 0.5245115124120675
LOSS train 0.4831032536418761 valid 0.524505172096766
LOSS train 0.4831032536418761 valid 0.5245696637365553
LOSS train 0.4831032536418761 valid 0.5246306741965636
LOSS train 0.4831032536418761 valid 0.5246838313091844
LOSS train 0.4831032536418761 valid 0.5246653480060173
LOSS train 0.4831032536418761 valid 0.5247427081162075
LOSS train 0.4831032536418761 valid 0.5247389237235364
LOSS train 0.4831032536418761 valid 0.5246722282988302
LOSS train 0.4831032536418761 valid 0.5246757469070491
LOSS train 0.4831032536418761 valid 0.5249056115912683
LOSS train 0.4831032536418761 valid 0.5249936006687306
LOSS train 0.4831032536418761 valid 0.5250974458082136
LOSS train 0.4831032536418761 valid 0.525102174238247
LOSS train 0.4831032536418761 valid 0.5252356173354628
LOSS train 0.4831032536418761 valid 0.5252208938128757
LOSS train 0.4831032536418761 valid 0.5251853793317621
LOSS train 0.4831032536418761 valid 0.5253122338782186
LOSS train 0.4831032536418761 valid 0.5253855136327364
LOSS train 0.4831032536418761 valid 0.5253498215469525
LOSS train 0.4831032536418761 valid 0.5254319278142785
LOSS train 0.4831032536418761 valid 0.5254368345652308
LOSS train 0.4831032536418761 valid 0.5252086358986715
LOSS train 0.4831032536418761 valid 0.5250863255338466
LOSS train 0.4831032536418761 valid 0.5249808398026038
LOSS train 0.4831032536418761 valid 0.5250498726963997
LOSS train 0.4831032536418761 valid 0.5250809756287357
LOSS train 0.4831032536418761 valid 0.5250215704416061
LOSS train 0.4831032536418761 valid 0.5250022310620817
LOSS train 0.4831032536418761 valid 0.5249862413232526
LOSS train 0.4831032536418761 valid 0.5249892843429605
LOSS train 0.4831032536418761 valid 0.5249689919167552
LOSS train 0.4831032536418761 valid 0.5248604661615444
LOSS train 0.4831032536418761 valid 0.5248151053100416
LOSS train 0.4831032536418761 valid 0.5248163603881927
LOSS train 0.4831032536418761 valid 0.5249002323466905
LOSS train 0.4831032536418761 valid 0.5250367262605894
LOSS train 0.4831032536418761 valid 0.5250825244631316
LOSS train 0.4831032536418761 valid 0.5250375462501539
LOSS train 0.4831032536418761 valid 0.5250515172745558
LOSS train 0.4831032536418761 valid 0.5251645785709688
LOSS train 0.4831032536418761 valid 0.5250759805242221
LOSS train 0.4831032536418761 valid 0.5251181237523342
LOSS train 0.4831032536418761 valid 0.5250521962413724
LOSS train 0.4831032536418761 valid 0.5250730369940843
LOSS train 0.4831032536418761 valid 0.525038410664389
LOSS train 0.4831032536418761 valid 0.5249517349923243
LOSS train 0.4831032536418761 valid 0.5248982098951839
LOSS train 0.4831032536418761 valid 0.5248414506158922
LOSS train 0.4831032536418761 valid 0.5248719495418784
LOSS train 0.4831032536418761 valid 0.5249073000980427
LOSS train 0.4831032536418761 valid 0.5248502067019862
LOSS train 0.4831032536418761 valid 0.5247729515531055
LOSS train 0.4831032536418761 valid 0.5248199060368233
LOSS train 0.4831032536418761 valid 0.5249560165900392
LOSS train 0.4831032536418761 valid 0.5250300245869691
LOSS train 0.4831032536418761 valid 0.5251028408133794
LOSS train 0.4831032536418761 valid 0.5250289591995976
LOSS train 0.4831032536418761 valid 0.5251017469524961
LOSS train 0.4831032536418761 valid 0.5250026648336986
LOSS train 0.4831032536418761 valid 0.5251072070628499
LOSS train 0.4831032536418761 valid 0.5249912420287728
LOSS train 0.4831032536418761 valid 0.5249343195065531
LOSS train 0.4831032536418761 valid 0.5249018900512908
LOSS train 0.4831032536418761 valid 0.5247859307117876
LOSS train 0.4831032536418761 valid 0.5247437359742176
LOSS train 0.4831032536418761 valid 0.5247105624125554
LOSS train 0.4831032536418761 valid 0.5248572486309917
LOSS train 0.4831032536418761 valid 0.5248779720122662
LOSS train 0.4831032536418761 valid 0.5250112532479007
LOSS train 0.4831032536418761 valid 0.5250976315747641
LOSS train 0.4831032536418761 valid 0.5251542954733878
LOSS train 0.4831032536418761 valid 0.5250992281559371
LOSS train 0.4831032536418761 valid 0.5249569385525692
LOSS train 0.4831032536418761 valid 0.524984615343111
LOSS train 0.4831032536418761 valid 0.5251639970762287
LOSS train 0.4831032536418761 valid 0.5251796871868533
LOSS train 0.4831032536418761 valid 0.5252671390771866
LOSS train 0.4831032536418761 valid 0.5252161011851506
LOSS train 0.4831032536418761 valid 0.5252170396979744
LOSS train 0.4831032536418761 valid 0.5250650781445798
LOSS train 0.4831032536418761 valid 0.5249814271050341
LOSS train 0.4831032536418761 valid 0.5248975532670175
LOSS train 0.4831032536418761 valid 0.5248995298704906
LOSS train 0.4831032536418761 valid 0.5249184798394974
LOSS train 0.4831032536418761 valid 0.5250142231410326
LOSS train 0.4831032536418761 valid 0.5249769396540047
LOSS train 0.4831032536418761 valid 0.5250335514028638
LOSS train 0.4831032536418761 valid 0.5250307628160251
LOSS train 0.4831032536418761 valid 0.525126446680776
LOSS train 0.4831032536418761 valid 0.5252123393950968
LOSS train 0.4831032536418761 valid 0.525195181114333
LOSS train 0.4831032536418761 valid 0.5251201739338388
LOSS train 0.4831032536418761 valid 0.5251041472974148
LOSS train 0.4831032536418761 valid 0.5251996763704856
LOSS train 0.4831032536418761 valid 0.5252509393260978
LOSS train 0.4831032536418761 valid 0.525379872489983
LOSS train 0.4831032536418761 valid 0.5254508682181326
LOSS train 0.4831032536418761 valid 0.5253938827194086
LOSS train 0.4831032536418761 valid 0.5253098442234807
LOSS train 0.4831032536418761 valid 0.5253526598298118
LOSS train 0.4831032536418761 valid 0.5253589065538512
LOSS train 0.4831032536418761 valid 0.5254314399822266
LOSS train 0.4831032536418761 valid 0.525524772168523
LOSS train 0.4831032536418761 valid 0.5255593634505574
LOSS train 0.4831032536418761 valid 0.5255527534000166
LOSS train 0.4831032536418761 valid 0.5256118289411884
LOSS train 0.4831032536418761 valid 0.5256087081354173
LOSS train 0.4831032536418761 valid 0.5255410961948883
LOSS train 0.4831032536418761 valid 0.5255322015803793
LOSS train 0.4831032536418761 valid 0.5255631764083697
EPOCH 4:
  batch 1 loss: 0.46407800912857056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.4976239502429962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.49437816937764484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.49330151826143265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4927561044692993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4889868497848511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4862113169261387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4863700494170189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4839845399061839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.47919763028621676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.47808250513943756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4774195154507955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.47632105533893293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.47719977157456533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.47981258233388263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4805731996893883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.47859664348994985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47895337972376084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.48038309969400106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4806513786315918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4805138536861965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4802572496912696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.48169628563134564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.481149286031723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.48061815738677977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4809644795381106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.48227549261516994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.48130578867026735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4814034988140238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.48189729551474253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4816686068811724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4821661030873656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.48139844338099164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4817405693671283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.48288439001355854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4826947823166847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.48158907568132553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.48060531522098343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4810531613154289
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4812876619398594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.48071110030499903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.48066876119091395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4820196247378061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4825102504004132
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4824810332722134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4818076685718868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.48174270163191124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.48231158778071404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.48248239013613486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4832957988977432
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.482556293408076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4822921403325521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.48184702924962314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.48159665090066417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4807415848428553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.48098266177943777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4812447036567487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.48067315847709263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.48007117641174185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4804110124707222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.48031047328573756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4808986927232435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4810882357377855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.48117313301190734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.48150050227458663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4808229221539064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4807026915585817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.48082634061574936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4805207287055859
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.48062186922345845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4805672672432913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4801164186663098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.480343514517562
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4801572565291379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.480014762878418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4806180047361474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.48033956893078694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.48006447767600036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.48020076676260065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4800010517239571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.47999206332512845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4797967461551108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.48000700430697707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4797627932968594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.47965747117996216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4799845759258714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.48026871133124693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4803982756354592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.48025272669417135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4802147454685635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.48006374691868875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4803169246601022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.48057629600647955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.480577955220608
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.48062814850556224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4811638419826825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4810381414964027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4810591108944951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.48120706520899376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4812737774848938
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4810614556369215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4811088793417987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4812975670527486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4812874278196922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4814305603504181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4812743829668693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.48113208981317895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.48134030042975035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4813470099497279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.48144607516852295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.48130356325759543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4813467538250344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4815313328156429
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4814357833381285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.48123084695442864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.48130915750717296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4817733234829373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.48174111014705595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4819535417717044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.481670552243789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.48172898405839587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4819148693416939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4820974888355751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.48189848949832303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.48207376337051394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4821977054788953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.48218988058135265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.48243666253983974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4823506569215494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4824164248429812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.48232884784691205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.48219653580224875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4821778697178776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.48207161631157147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4820211785810965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.48200253616361055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.48217236647640704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4820502212514048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4822215894572169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.48223767131567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4821132782925951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4821516210344476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.48221161461376644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.48248749205635655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4825561474109518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4824279444674923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4826147771206032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.48282353016170293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4827127070634957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4825192521015803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4826163736400225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.48267634467859016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4826765857101266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.48260999519329567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4828213278324373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4829836069391324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4829285002438126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.48311499496804006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4832767827330895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4833551185205579
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4831723095097157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4830794069502089
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.48308546777151845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4829913806624529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.48294274734728265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4831236471612769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.483139851671493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.48288081355747725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4828582631765738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4829774285064024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.48292317115075406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.48288332878850226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.48277576672548506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4828628205704963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.48268550651414055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.48258499665693805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4824625908654962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4824879546178861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.48253000565081333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.48247371796104643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4823642119518301
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.48230574288211026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.48219588838639804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4821678050186323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.48224838069967324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4821699897768677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.48211214073839037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4819890967708953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.48200246329030033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.48190313138459856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4817814321418083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4815607611089945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.48160385081805096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.48164791191361617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.48155129643586964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4815938530527816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4816977551140761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4818729098999139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4818892703583492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4819365295767784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4819469466731323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.48193529528556484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.48172240201475586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.48170024127352473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4816587911873329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.48145866148101474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4813752437847248
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4812726268114952
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4814835580056934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4814787312632515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4814956138766772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4816806860408693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.48170142484382844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4815683132298639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4816494463488113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.481533111659465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.48158003341767097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.48180276633949454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.48205914222486484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4821263845671307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.48194819607885714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4818586145972346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4819551725024065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.48199697650436846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.481807814306683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4816881494711986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4817072760953777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.481567021524697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.481502921820728
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4816706400850545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4816258673544054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4817803581726962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.48168501014873194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4817278725214494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.48179213430019135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4817725177538597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4817748487247193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4816872486296822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4816926230197172
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4818055586268504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4818997292845081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4818555615411317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.48197937367384325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4820244644508987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4821265668285136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4822806168377884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.482330845676453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.48222012060784525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.48241233287087404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.48242876946926116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4824908882735735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4825077460162223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.48255078535777307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4824462759447849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.48239800450848597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.48242355638649315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4822955707863611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.48226790338061576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4825169507370953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.48264270092432315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4826195318808501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.48253373096462426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.48254829667820226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.48255726593461906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48241682479966363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4824542170180414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.48246987683049747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4823825032408558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.48233944975310544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4823403228212286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.48236078034907687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4822310773546205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.48217668714540785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4819670840553994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.481781000549143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4818384274840355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.481861369058974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.48180837639801793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.48183844145053606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.48185117095708846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4818921789155736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.48190237898775873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4818384319859764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4818758841761401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4819144768673077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.48193216521839993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.4819584128540983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4819751192505161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.48191078507364005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4819595782921232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4819082888131289
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4819133876733584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.481967458240815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4820457793214694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.48202808327594043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4819973904538799
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4820780280463222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.482026280772766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4819479146131305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4819230647881826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4820239464705965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.481911530459164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4818658107774879
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.48189159041564716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4819694521974345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4819304125955681
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4819014291809902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4819257756719342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.48196091042367384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4819495104974316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.48201663068636436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4819023362719096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.48182559775087397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.48175321775636853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4817278294336228
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4817870263057419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.48183597525587596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.48186327620122416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4818551094741283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4819397528655827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4818093090599571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4818871738562673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.48206046445081846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4820488228658099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.48203120222458473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.48205785371043197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4820935331535631
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4821786923197711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.48210323210182887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4821930671280081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.48224301118504964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.48219691315688284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4822196003732023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4821531074846576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4821186573647741
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.48219889996662024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4821010843052001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.48207900615838856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.48198827265989813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.48204865683527554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4820466453204057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.48209770529242285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4819861099601835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.48196221298949665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.481971841359484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4820375412358025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.482082299007806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4821256543884332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.48204552290432773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.48200663702828545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4819296629850002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.48192782276733354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.48196442522340727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4819027320981699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.481891001697997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.481787151416366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4817964190862426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.48191416846307294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4818786886575162
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.48178902210460767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4817598337446884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4817920667196506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4818472055200046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.48176199124082103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.48179369715795123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4817747310862515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.48174041801967155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4817176004466803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4817092108532665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4817145474053718
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4817326780599404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4816940021450802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.48173011483839306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4817320707647558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4817118631998698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.48169080936845315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4816896737570472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4817840363140459
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4818269766886819
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4817559657912505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.48173267251550367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.48167465034267665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.48174691892790733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4817699477231751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4817522662800628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4818339697591999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.48180724045102913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4818914602558637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.48188706359091027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4818943568529227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.48187716377665624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.48189084330687715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4818730545407943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.48186453269217827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.48179118731353854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.481846521373349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4818952030288783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.48199807751418355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.48205064823454186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4820211123675108
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4819514783391929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4818110695822322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4817998820439758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4817750269528663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4817805134219888
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.48184388141913953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.48181263388521256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.481793134455003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.481733283451542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.48174097588876397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4817981640932914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.48186179612157415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.48178385418206093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4819355667501256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4820039546633341
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.48208074615551877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.48205897104825907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4820347988719575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.48209241651407575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.48206576321806227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4821841582266565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4822592215515426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4821832781706014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.48220303710901513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4821696901321411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4820687022987106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.48205559950243393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.48198149687497416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.48188165274811234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4819985972587452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.48195594742790454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.48196529445272907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.48188201205559744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4818830554661114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.48177823938172437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.48189045912628875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.48187984563666025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.48186158460296996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4817871255863772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4817631984976205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.48178508195206693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.48178764881052044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4818013451707551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4817375889098322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4818656149205197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4817828223977923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4818614303265642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.48190198286569547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4819113752225991
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4818876353237364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4818437044609941
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.48188518917402334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.48185643645838133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4818093787862341
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4818002339902815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4817303734782495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4816905765486494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4817017525694776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.48163967006606473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4817474071746287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4817248256372009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.48170164633880963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.48172228015782254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4817384733850586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.48170458187339127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4817347356434032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4817019275347732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4817719725080026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.48181240041372875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.48186279998180714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4818520070767453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.481895011802346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.481895011802346 valid 0.48318925499916077
LOSS train 0.481895011802346 valid 0.4978494197130203
LOSS train 0.481895011802346 valid 0.49586406350135803
LOSS train 0.481895011802346 valid 0.49211136996746063
LOSS train 0.481895011802346 valid 0.48682705163955686
LOSS train 0.481895011802346 valid 0.4923179546991984
LOSS train 0.481895011802346 valid 0.4991295507975987
LOSS train 0.481895011802346 valid 0.5015081837773323
LOSS train 0.481895011802346 valid 0.5033643245697021
LOSS train 0.481895011802346 valid 0.5074373304843902
LOSS train 0.481895011802346 valid 0.5109341957352378
LOSS train 0.481895011802346 valid 0.5097879519065222
LOSS train 0.481895011802346 valid 0.5142662112529461
LOSS train 0.481895011802346 valid 0.5165951124259404
LOSS train 0.481895011802346 valid 0.5179072976112366
LOSS train 0.481895011802346 valid 0.5159312784671783
LOSS train 0.481895011802346 valid 0.5183154414681828
LOSS train 0.481895011802346 valid 0.5187177525626289
LOSS train 0.481895011802346 valid 0.5176257616595218
LOSS train 0.481895011802346 valid 0.5186417013406753
LOSS train 0.481895011802346 valid 0.5184159307252794
LOSS train 0.481895011802346 valid 0.517095232551748
LOSS train 0.481895011802346 valid 0.5172051450480586
LOSS train 0.481895011802346 valid 0.5160966329276562
LOSS train 0.481895011802346 valid 0.5149120795726776
LOSS train 0.481895011802346 valid 0.5133371043663758
LOSS train 0.481895011802346 valid 0.5129478055017965
LOSS train 0.481895011802346 valid 0.5135690580521312
LOSS train 0.481895011802346 valid 0.5125527094150412
LOSS train 0.481895011802346 valid 0.5139682789643606
LOSS train 0.481895011802346 valid 0.5152299115734715
LOSS train 0.481895011802346 valid 0.5155742485076189
LOSS train 0.481895011802346 valid 0.5169146819548174
LOSS train 0.481895011802346 valid 0.5177671015262604
LOSS train 0.481895011802346 valid 0.5193587405341012
LOSS train 0.481895011802346 valid 0.5197721471389135
LOSS train 0.481895011802346 valid 0.5201070840294296
LOSS train 0.481895011802346 valid 0.5205235481262207
LOSS train 0.481895011802346 valid 0.5204085493699099
LOSS train 0.481895011802346 valid 0.5210104182362556
LOSS train 0.481895011802346 valid 0.521115499298747
LOSS train 0.481895011802346 valid 0.5210619469483694
LOSS train 0.481895011802346 valid 0.5210704734159071
LOSS train 0.481895011802346 valid 0.5211521346460689
LOSS train 0.481895011802346 valid 0.5210804237259758
LOSS train 0.481895011802346 valid 0.521809001331744
LOSS train 0.481895011802346 valid 0.5219114016979298
LOSS train 0.481895011802346 valid 0.5227723481754462
LOSS train 0.481895011802346 valid 0.523905064378466
LOSS train 0.481895011802346 valid 0.5232762432098389
LOSS train 0.481895011802346 valid 0.524010085592083
LOSS train 0.481895011802346 valid 0.5244318888737605
LOSS train 0.481895011802346 valid 0.5242752680238688
LOSS train 0.481895011802346 valid 0.5236670711526165
LOSS train 0.481895011802346 valid 0.5237211341207678
LOSS train 0.481895011802346 valid 0.5233899392187595
LOSS train 0.481895011802346 valid 0.5229727693817072
LOSS train 0.481895011802346 valid 0.5231417689857811
LOSS train 0.481895011802346 valid 0.5237394647072937
LOSS train 0.481895011802346 valid 0.5231940378745397
LOSS train 0.481895011802346 valid 0.5219216820646505
LOSS train 0.481895011802346 valid 0.5220372412473925
LOSS train 0.481895011802346 valid 0.5218585336965228
LOSS train 0.481895011802346 valid 0.5222708941437304
LOSS train 0.481895011802346 valid 0.5226028272738823
LOSS train 0.481895011802346 valid 0.5219088408983115
LOSS train 0.481895011802346 valid 0.5217042080502012
LOSS train 0.481895011802346 valid 0.5216758676311549
LOSS train 0.481895011802346 valid 0.521682969469955
LOSS train 0.481895011802346 valid 0.5209917728390012
LOSS train 0.481895011802346 valid 0.5204421760330737
LOSS train 0.481895011802346 valid 0.5202189824647374
LOSS train 0.481895011802346 valid 0.5206763556558792
LOSS train 0.481895011802346 valid 0.5199436980324823
LOSS train 0.481895011802346 valid 0.5199528582890829
LOSS train 0.481895011802346 valid 0.5202178806066513
LOSS train 0.481895011802346 valid 0.5200732420017193
LOSS train 0.481895011802346 valid 0.5201204464985774
LOSS train 0.481895011802346 valid 0.5197624073752874
LOSS train 0.481895011802346 valid 0.5196320861577988
LOSS train 0.481895011802346 valid 0.5191986237043216
LOSS train 0.481895011802346 valid 0.5192956422887197
LOSS train 0.481895011802346 valid 0.5189731501671205
LOSS train 0.481895011802346 valid 0.5190483622607731
LOSS train 0.481895011802346 valid 0.5187185476807987
LOSS train 0.481895011802346 valid 0.5184364301520724
LOSS train 0.481895011802346 valid 0.5183505679684124
LOSS train 0.481895011802346 valid 0.5184036679565907
LOSS train 0.481895011802346 valid 0.5185138961572325
LOSS train 0.481895011802346 valid 0.5189990397956636
LOSS train 0.481895011802346 valid 0.5191561150681842
LOSS train 0.481895011802346 valid 0.5189979099061178
LOSS train 0.481895011802346 valid 0.5187807932335843
LOSS train 0.481895011802346 valid 0.5186581012416394
LOSS train 0.481895011802346 valid 0.5184502171842675
LOSS train 0.481895011802346 valid 0.5183926718309522
LOSS train 0.481895011802346 valid 0.5184498217302499
LOSS train 0.481895011802346 valid 0.518186975802694
LOSS train 0.481895011802346 valid 0.518713944187068
LOSS train 0.481895011802346 valid 0.5189538684487343
LOSS train 0.481895011802346 valid 0.5188341409263044
LOSS train 0.481895011802346 valid 0.5188892808030633
LOSS train 0.481895011802346 valid 0.5192110940669347
LOSS train 0.481895011802346 valid 0.5193936661458932
LOSS train 0.481895011802346 valid 0.519560367436636
LOSS train 0.481895011802346 valid 0.5197235185582683
LOSS train 0.481895011802346 valid 0.519598623023969
LOSS train 0.481895011802346 valid 0.5195479037033187
LOSS train 0.481895011802346 valid 0.5197653461486922
LOSS train 0.481895011802346 valid 0.5201136076992209
LOSS train 0.481895011802346 valid 0.5200196056215612
LOSS train 0.481895011802346 valid 0.5198890388544116
LOSS train 0.481895011802346 valid 0.5200838116945419
LOSS train 0.481895011802346 valid 0.5195958789503365
LOSS train 0.481895011802346 valid 0.5196407035641049
LOSS train 0.481895011802346 valid 0.5199204881129593
LOSS train 0.481895011802346 valid 0.5197848909431033
LOSS train 0.481895011802346 valid 0.5196755399643365
LOSS train 0.481895011802346 valid 0.5195871844512074
LOSS train 0.481895011802346 valid 0.5195586976905664
LOSS train 0.481895011802346 valid 0.5193810455562654
LOSS train 0.481895011802346 valid 0.5191779420024059
LOSS train 0.481895011802346 valid 0.5192580901510347
LOSS train 0.481895011802346 valid 0.5194501948933448
LOSS train 0.481895011802346 valid 0.5196527762413025
LOSS train 0.481895011802346 valid 0.5196795174999843
LOSS train 0.481895011802346 valid 0.5198826832095469
LOSS train 0.481895011802346 valid 0.5201340052299201
LOSS train 0.481895011802346 valid 0.5202565978663837
LOSS train 0.481895011802346 valid 0.5201871175032395
LOSS train 0.481895011802346 valid 0.5202089411611776
LOSS train 0.481895011802346 valid 0.5199454553199537
LOSS train 0.481895011802346 valid 0.5198732444218227
LOSS train 0.481895011802346 valid 0.5198339179380617
LOSS train 0.481895011802346 valid 0.5199681414498223
LOSS train 0.481895011802346 valid 0.5199668424970963
LOSS train 0.481895011802346 valid 0.519721139086424
LOSS train 0.481895011802346 valid 0.519448972698571
LOSS train 0.481895011802346 valid 0.5193590954910937
LOSS train 0.481895011802346 valid 0.5193841857569558
LOSS train 0.481895011802346 valid 0.5195427017009004
LOSS train 0.481895011802346 valid 0.5197013994337807
LOSS train 0.481895011802346 valid 0.5196006248047301
LOSS train 0.481895011802346 valid 0.5196150773101382
LOSS train 0.481895011802346 valid 0.5193303342523246
LOSS train 0.481895011802346 valid 0.5196292241142221
LOSS train 0.481895011802346 valid 0.5193545394608764
LOSS train 0.481895011802346 valid 0.5197298710007925
LOSS train 0.481895011802346 valid 0.5196423356565053
LOSS train 0.481895011802346 valid 0.5197666130463282
LOSS train 0.481895011802346 valid 0.5197586952061053
LOSS train 0.481895011802346 valid 0.5194836229478058
LOSS train 0.481895011802346 valid 0.5194408911115983
LOSS train 0.481895011802346 valid 0.5195774507599992
LOSS train 0.481895011802346 valid 0.5195025376735195
LOSS train 0.481895011802346 valid 0.5199193566655501
LOSS train 0.481895011802346 valid 0.5199047773127343
LOSS train 0.481895011802346 valid 0.519997582216806
LOSS train 0.481895011802346 valid 0.5197647451979559
LOSS train 0.481895011802346 valid 0.5196906929835677
LOSS train 0.481895011802346 valid 0.519889604786168
LOSS train 0.481895011802346 valid 0.5197477802450274
LOSS train 0.481895011802346 valid 0.519682531525021
LOSS train 0.481895011802346 valid 0.519528886712179
LOSS train 0.481895011802346 valid 0.5192664332462079
LOSS train 0.481895011802346 valid 0.519035850483251
LOSS train 0.481895011802346 valid 0.5192396064361412
LOSS train 0.481895011802346 valid 0.5194220133125782
LOSS train 0.481895011802346 valid 0.5195118003695675
LOSS train 0.481895011802346 valid 0.5195480095989564
LOSS train 0.481895011802346 valid 0.5198156967846274
LOSS train 0.481895011802346 valid 0.5199491022977718
LOSS train 0.481895011802346 valid 0.5200164016616138
LOSS train 0.481895011802346 valid 0.5200711956311916
LOSS train 0.481895011802346 valid 0.5201637603555407
LOSS train 0.481895011802346 valid 0.5202793087810278
LOSS train 0.481895011802346 valid 0.5204375155564755
LOSS train 0.481895011802346 valid 0.5206943273209454
LOSS train 0.481895011802346 valid 0.5207881612817669
LOSS train 0.481895011802346 valid 0.5208384783731567
LOSS train 0.481895011802346 valid 0.5208728799174503
LOSS train 0.481895011802346 valid 0.5209198834804388
LOSS train 0.481895011802346 valid 0.5208750313422719
LOSS train 0.481895011802346 valid 0.5209218647492968
LOSS train 0.481895011802346 valid 0.5208373480551952
LOSS train 0.481895011802346 valid 0.5209037595859138
LOSS train 0.481895011802346 valid 0.5211261910869476
LOSS train 0.481895011802346 valid 0.5211742372905954
LOSS train 0.481895011802346 valid 0.5210115252033113
LOSS train 0.481895011802346 valid 0.5209151683669341
LOSS train 0.481895011802346 valid 0.521184908313901
LOSS train 0.481895011802346 valid 0.5213231476955116
LOSS train 0.481895011802346 valid 0.5213791652355787
LOSS train 0.481895011802346 valid 0.5212164747039068
LOSS train 0.481895011802346 valid 0.5209822118282318
LOSS train 0.481895011802346 valid 0.5209701452024129
LOSS train 0.481895011802346 valid 0.5210236318522904
LOSS train 0.481895011802346 valid 0.5209144075410534
LOSS train 0.481895011802346 valid 0.5210372085247806
LOSS train 0.481895011802346 valid 0.5210525606572628
LOSS train 0.481895011802346 valid 0.5209222876313907
LOSS train 0.481895011802346 valid 0.5210004057919625
LOSS train 0.481895011802346 valid 0.520914055884178
LOSS train 0.481895011802346 valid 0.5211088241023176
LOSS train 0.481895011802346 valid 0.5210855598856763
LOSS train 0.481895011802346 valid 0.5213070290470586
LOSS train 0.481895011802346 valid 0.5212635816871256
LOSS train 0.481895011802346 valid 0.5212169078966746
LOSS train 0.481895011802346 valid 0.5209497568424809
LOSS train 0.481895011802346 valid 0.5208572689976011
LOSS train 0.481895011802346 valid 0.5210426352317864
LOSS train 0.481895011802346 valid 0.5210245239003649
LOSS train 0.481895011802346 valid 0.5210326998166634
LOSS train 0.481895011802346 valid 0.5209781453709736
LOSS train 0.481895011802346 valid 0.5207611522009207
LOSS train 0.481895011802346 valid 0.5206778010836354
LOSS train 0.481895011802346 valid 0.5208228271677747
LOSS train 0.481895011802346 valid 0.5207614827593532
LOSS train 0.481895011802346 valid 0.5208506257566687
LOSS train 0.481895011802346 valid 0.5207889448512685
LOSS train 0.481895011802346 valid 0.5209104073533105
LOSS train 0.481895011802346 valid 0.5210888933491062
LOSS train 0.481895011802346 valid 0.5212738866763265
LOSS train 0.481895011802346 valid 0.5212878095252174
LOSS train 0.481895011802346 valid 0.5212452144092984
LOSS train 0.481895011802346 valid 0.5211793529776345
LOSS train 0.481895011802346 valid 0.5213253631990912
LOSS train 0.481895011802346 valid 0.5214774093607015
LOSS train 0.481895011802346 valid 0.521443848526634
LOSS train 0.481895011802346 valid 0.5215654217678568
LOSS train 0.481895011802346 valid 0.5214660779222265
LOSS train 0.481895011802346 valid 0.5215209226669937
LOSS train 0.481895011802346 valid 0.5213035268333337
LOSS train 0.481895011802346 valid 0.5212804287926763
LOSS train 0.481895011802346 valid 0.5213744150831344
LOSS train 0.481895011802346 valid 0.5213825144505096
LOSS train 0.481895011802346 valid 0.521345667446716
LOSS train 0.481895011802346 valid 0.5213016542066046
LOSS train 0.481895011802346 valid 0.5213468197000576
LOSS train 0.481895011802346 valid 0.5213296609620254
LOSS train 0.481895011802346 valid 0.5214965444877434
LOSS train 0.481895011802346 valid 0.5215331020434041
LOSS train 0.481895011802346 valid 0.5214918650717402
LOSS train 0.481895011802346 valid 0.5214975446951194
LOSS train 0.481895011802346 valid 0.521460530465963
LOSS train 0.481895011802346 valid 0.5213991619222532
LOSS train 0.481895011802346 valid 0.521587373998001
LOSS train 0.481895011802346 valid 0.521575192530309
LOSS train 0.481895011802346 valid 0.5215458671251932
LOSS train 0.481895011802346 valid 0.5217155978679657
LOSS train 0.481895011802346 valid 0.5216755451434162
LOSS train 0.481895011802346 valid 0.5217748376585188
LOSS train 0.481895011802346 valid 0.5218565268478846
LOSS train 0.481895011802346 valid 0.5218576713809817
LOSS train 0.481895011802346 valid 0.5218381767179452
LOSS train 0.481895011802346 valid 0.5218008875381202
LOSS train 0.481895011802346 valid 0.5217581753137047
LOSS train 0.481895011802346 valid 0.5217849041602408
LOSS train 0.481895011802346 valid 0.521845399873137
LOSS train 0.481895011802346 valid 0.5218372033192561
LOSS train 0.481895011802346 valid 0.5219054290618019
LOSS train 0.481895011802346 valid 0.5219643170596989
LOSS train 0.481895011802346 valid 0.5220171893050916
LOSS train 0.481895011802346 valid 0.5219989884080309
LOSS train 0.481895011802346 valid 0.522076645887123
LOSS train 0.481895011802346 valid 0.5220725478086257
LOSS train 0.481895011802346 valid 0.5220023994142197
LOSS train 0.481895011802346 valid 0.5220058504770051
LOSS train 0.481895011802346 valid 0.5222390739448008
LOSS train 0.481895011802346 valid 0.5223299962502939
LOSS train 0.481895011802346 valid 0.5224339139417529
LOSS train 0.481895011802346 valid 0.5224381823311833
LOSS train 0.481895011802346 valid 0.522574938915588
LOSS train 0.481895011802346 valid 0.5225587019520085
LOSS train 0.481895011802346 valid 0.5225229928710244
LOSS train 0.481895011802346 valid 0.5226520831170289
LOSS train 0.481895011802346 valid 0.5227243362351015
LOSS train 0.481895011802346 valid 0.5226892820365138
LOSS train 0.481895011802346 valid 0.5227701484516103
LOSS train 0.481895011802346 valid 0.5227739968470164
LOSS train 0.481895011802346 valid 0.522542330293893
LOSS train 0.481895011802346 valid 0.5224188253389183
LOSS train 0.481895011802346 valid 0.522311413983153
LOSS train 0.481895011802346 valid 0.5223807101728211
LOSS train 0.481895011802346 valid 0.5224107887661248
LOSS train 0.481895011802346 valid 0.5223520870183731
LOSS train 0.481895011802346 valid 0.522330177474105
LOSS train 0.481895011802346 valid 0.5223153081412116
LOSS train 0.481895011802346 valid 0.5223155816739818
LOSS train 0.481895011802346 valid 0.5222966238342482
LOSS train 0.481895011802346 valid 0.5221900084788856
LOSS train 0.481895011802346 valid 0.5221428212850061
LOSS train 0.481895011802346 valid 0.5221450559718617
LOSS train 0.481895011802346 valid 0.5222302874943026
LOSS train 0.481895011802346 valid 0.5223686267763882
LOSS train 0.481895011802346 valid 0.5224124711711664
LOSS train 0.481895011802346 valid 0.5223661343055943
LOSS train 0.481895011802346 valid 0.5223835023657587
LOSS train 0.481895011802346 valid 0.5224995327035719
LOSS train 0.481895011802346 valid 0.5224143223961194
LOSS train 0.481895011802346 valid 0.522457362508457
LOSS train 0.481895011802346 valid 0.5223924307436343
LOSS train 0.481895011802346 valid 0.522411464759619
LOSS train 0.481895011802346 valid 0.5223726390027686
LOSS train 0.481895011802346 valid 0.522285000906616
LOSS train 0.481895011802346 valid 0.5222309297011569
LOSS train 0.481895011802346 valid 0.5221734117801492
LOSS train 0.481895011802346 valid 0.5222055305327687
LOSS train 0.481895011802346 valid 0.5222406982411073
LOSS train 0.481895011802346 valid 0.522181867687933
LOSS train 0.481895011802346 valid 0.5221008661283941
LOSS train 0.481895011802346 valid 0.52214890689804
LOSS train 0.481895011802346 valid 0.5222841852579635
LOSS train 0.481895011802346 valid 0.5223589168422541
LOSS train 0.481895011802346 valid 0.5224327555724553
LOSS train 0.481895011802346 valid 0.5223571024363554
LOSS train 0.481895011802346 valid 0.5224289969314913
LOSS train 0.481895011802346 valid 0.5223283373147437
LOSS train 0.481895011802346 valid 0.5224341945401554
LOSS train 0.481895011802346 valid 0.5223167020827532
LOSS train 0.481895011802346 valid 0.5222605782505879
LOSS train 0.481895011802346 valid 0.5222267710274051
LOSS train 0.481895011802346 valid 0.5221075493115759
LOSS train 0.481895011802346 valid 0.5220668669100161
LOSS train 0.481895011802346 valid 0.5220334625244141
LOSS train 0.481895011802346 valid 0.5221785303273815
LOSS train 0.481895011802346 valid 0.522200704896851
LOSS train 0.481895011802346 valid 0.5223329143553246
LOSS train 0.481895011802346 valid 0.5224229369120033
LOSS train 0.481895011802346 valid 0.5224814675071022
LOSS train 0.481895011802346 valid 0.5224268440033374
LOSS train 0.481895011802346 valid 0.5222799460212868
LOSS train 0.481895011802346 valid 0.522307648494079
LOSS train 0.481895011802346 valid 0.5224883890080595
LOSS train 0.481895011802346 valid 0.522500649316987
LOSS train 0.481895011802346 valid 0.5225909331015178
LOSS train 0.481895011802346 valid 0.5225380335434254
LOSS train 0.481895011802346 valid 0.5225406096884485
LOSS train 0.481895011802346 valid 0.522386456836993
LOSS train 0.481895011802346 valid 0.5223021335461561
LOSS train 0.481895011802346 valid 0.5222165217497482
LOSS train 0.481895011802346 valid 0.5222176578309801
LOSS train 0.481895011802346 valid 0.5222385110382436
LOSS train 0.481895011802346 valid 0.5223361927756044
LOSS train 0.481895011802346 valid 0.5222965826158938
LOSS train 0.481895011802346 valid 0.5223539104695955
LOSS train 0.481895011802346 valid 0.522350478928096
LOSS train 0.481895011802346 valid 0.5224460579197983
LOSS train 0.481895011802346 valid 0.5225354740476198
LOSS train 0.481895011802346 valid 0.522516221659524
LOSS train 0.481895011802346 valid 0.5224379379185516
LOSS train 0.481895011802346 valid 0.5224196142093702
LOSS train 0.481895011802346 valid 0.5225178725996369
LOSS train 0.481895011802346 valid 0.5225713758145348
LOSS train 0.481895011802346 valid 0.5227016940922804
LOSS train 0.481895011802346 valid 0.5227740601207433
LOSS train 0.481895011802346 valid 0.5227166829990739
LOSS train 0.481895011802346 valid 0.5226330017910323
LOSS train 0.481895011802346 valid 0.5226769281297009
LOSS train 0.481895011802346 valid 0.5226832446124818
LOSS train 0.481895011802346 valid 0.5227559296378138
LOSS train 0.481895011802346 valid 0.5228512562111597
LOSS train 0.481895011802346 valid 0.5228854798745189
LOSS train 0.481895011802346 valid 0.5228771783493378
LOSS train 0.481895011802346 valid 0.5229372600986533
LOSS train 0.481895011802346 valid 0.5229373305547432
LOSS train 0.481895011802346 valid 0.5228686789888127
LOSS train 0.481895011802346 valid 0.5228577621443116
LOSS train 0.481895011802346 valid 0.5228876520786182
EPOCH 5:
  batch 1 loss: 0.460344135761261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.4960907995700836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.494095245997111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4941844195127487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.49163339138031004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.48743196328481037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.48444835203034536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4853152334690094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4826965199576484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4790287554264069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.47750144655054266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4768632451693217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4757069991185115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.47661096709115164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.47919852336247765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.47960306517779827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4776897658320034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47812509371174705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.47909214151533025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.47957475632429125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4793152922675723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.47895329242402856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4802691482979318
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.47986292218168575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4795789349079132
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4799636728488482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4810295380927898
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4801159288202013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4801850750528533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.480677064259847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.480581997863708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.48082415480166674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.479888660438133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.480425832026145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4814255177974701
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4812328178021643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.48022413898158717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4793125265523007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4798069504591135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4801815390586853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4798128110606496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.47973081327620004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.48113996206327925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4815153513442386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.48173170619540745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.48113968255727185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4810502884235788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.48154836272199947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.48161909166647465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.48240694165229797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4818128931756113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4814529837324069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.48095195192211077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4808155237524598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.48004578135230325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4802251176110336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4804797679708715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.47982159924918205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.47937085012258107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.47975329707066217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4796215750154902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.480143551384249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4802119027054499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4802687712945044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4807062327861786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.48008047315207397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.47994500798965567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4801150792661835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.47980076420134393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4798694291285106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.479955127121697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4794439495437675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4797316181333098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4796459533878275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.47953819314638774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.48013093479369817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4797729876908389
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4794400032514181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.479438189841524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4792011138051748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4791954281153502
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4788814903032489
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.47908178402716856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.47893173602365313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.478841553365483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.47910884195982023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4793195731338413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4796291616829959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.47956875971194063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4795480512910419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4795229863989484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.47980642091968784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.47998955044695124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.48002455462800697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4800093638269525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4806180267284314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.48050069010134827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4804424427601756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.48065533933013377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.48073084086179735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.48070323968877887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.48083475465868036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.48107145654345024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4810478495290646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4812016697156997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4809998538134233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4808740326177294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.48107310356917204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.48106958423185786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.48112857260487296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4809157238887237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4808702609900917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.48099937850395136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.48099121346808316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4807208276313284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4807235012794363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4810890443304665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4810398468526743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.48121203544760954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.48095067342122394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4810450288875044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.48130265464548205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.48151449168600685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.481342043847807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4815646650791168
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.48165892466666205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.48164020513925027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.48195924516767263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.481871763865153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4819525205172025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.48182796703950137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.48172846255880414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4816873228191433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.48159196194428117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4815306807005847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4816075756269343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4818006584244053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.48165572013544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.48178849610493335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4818151565534728
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.48170514774660694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4817643247439828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4817695248793889
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.48202982855339843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.482085598953839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.48190994540305987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4820872918278182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4823386947045455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48222019528382576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4819899773597717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.48206083407465194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4820493304807889
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4821217280197767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.48200087829843746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4822413738696806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.48244246974205357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4823587322311037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.48252766362473937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.48273855841384744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4828276615589857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4826782579007356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.482582598188777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4826040167384352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4824830775217312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.48240633841716885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.48254409863288145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4825524821609794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4823117995900767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4823027198483958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.48244767942849326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.48234969325232924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4822501692661019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4821242733153305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4821936265490521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4820036195005689
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4819089616225524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4818451089710839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.48186799096927213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.48191590432348197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.48186620821555454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4817880726321626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.48172158837973417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4815674611453802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4815064901890962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4815977119110726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4815121635954867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4814615241665254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4813496120115544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.48134577920827915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.48123360150738764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4811215659710749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4808767009526491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.48089692382614846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4809049389411494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4808155822448241
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.48077793069639985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.48089487646436935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.48106168451333287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4811005143064949
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.48112586528062823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4811201507772379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4811345040798187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4808961722651139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4808869786998805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.48086210969017773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4806734637438672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.48065059599669085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.48054113869483656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.48073807629671966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.48075905044873557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.48074289718510416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4808888561883063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4808968263612667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4807882471897892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.48084956643193266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4807585582689003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.48081209088250787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.48107485541509926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.48129011452470194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4813377196138555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.48115721223580893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4810580999196113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4811424567560444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.48122700436839033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4810657747586568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4809746341367738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4809914929751258
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.48082060340726585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4807672859799914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.48088879973992055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4808392901441236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4809598807117035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4808315963448373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4808656110977515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4809566539652804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4809692803833444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.48093231757984883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4808265177392158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.48083380463233055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.48088752614955105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.48094660723852417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4808872037928952
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4809956689185076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.48100516334420346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.48114439309859763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4812998198639087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4813046865617698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.48119556098695726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.48140324586366556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.481435022354126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.48149538633832895
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.481488140920798
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.48154084508126904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.48146320961591765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.48140001133376475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.48140135989524424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.48129538003108846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.48127626367779663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.48152778749300246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.48163176557192433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4816365884866751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.4815510976633043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.48155543502745973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4815862924989426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4814905879632482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4815207715321304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4815130527323105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.48139631447952186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.48136186655126095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.48136785869245174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4813763387088846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.48126059945891886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4811872053932358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4809568226337433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4808125831864097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4808593989498373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4809188387669381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.48084882716480776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.48087843355312143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4809164009988308
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4809616624884758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4809724303847509
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.48090240222405206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.48094998530938593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.48099074259138946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.48101724861385103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.48101700307600176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4810198526829481
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4809657234221594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.48103631179908224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4809851005314961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.48100937657976806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.48109650449134383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.48118241425274183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.48115874953189136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.48114822130348234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4812608215744648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.481223419008639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4811875206172267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4811484756072362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.48125109145807665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.48115329967429304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4810816201046355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.48109332079950134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.48118270616062353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.48114488307946646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.48111485658328773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.481154525434816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.48122153293739245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4811937386951139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.48128482699394226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4811659582341329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4810949374502078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.48101771342906224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4809859191614484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4810654416303091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4810836317035302
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4811016227464256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4811107662030522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4811908759176731
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4810844800925329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4811519425107826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.48131175270021515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.48128703199786904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.48126806754332324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.48128545878489326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.48135110371338846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4814454637831304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4813689887523651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.48143569113630236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4815121153510229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4814709725688739
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.48150633208386534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4814575985520186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4814353114633418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.48148047037067865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.48138859417035246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.48135962491557444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4812685879810018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4813127270516227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4813223231223322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4813348440050382
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.481215923329484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.48119283736098645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.48121394886486774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.48128254737468124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4813234215167483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4813653449902589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4813018524885861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.48129032441547936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.48120152321975795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.48121135410937393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4812733086918299
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4811988242265195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.48118280189138063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4810694819420911
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.48107560976546687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4811619859833957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.48112887459545084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4810344442725182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.48098785040121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.48102103898209103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4810427451100888
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4809783873158497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4810070186445158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.48095446483033605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.48091110692686867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.48091405484339467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.48090685415397166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.48089566875148465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.48091361344342604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.48089387331919003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4809408685636904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4809276796279744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4809165155092875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.48089109472137814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4808970562501042
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.48098752336211936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4810298454006618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4809628288212575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4809298535657367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.48085484868256834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.48093554875558103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4809663181658834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4809539559599641
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.48101693453566396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4809864791788796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.48106497387910624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4810604180345805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4810688515504201
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4810714622592682
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.48109881443028546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.48108138617971774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.48107377042625155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.48100708330733866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4810645392145773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4811419904682438
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.481237539394417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.48130252636166143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.48129192247986796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4812286636627226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.48109247568827956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.481085700447447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.48103632091885745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.48104673741776266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.48109882350625666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4810529983893073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4810478425785607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4809879361854497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.48098121445353437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.48104106625791304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4810898400915479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4810224391934947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4811480614010263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.48123073879494727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.48129199946729034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.48124661762937365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4812568948029331
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.481323043031169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.48128563506262645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4813963361703868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4815147093969499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.48144707527566466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4814822647087979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.481441892525729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4813501320674386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4813606489877232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4812892585575024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4811947427012704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.48128966432671216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4812286079897958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.48124500681404714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4811621327598431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.48117848296868637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.48106775064578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.48119226945649596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4811758842293676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4811339613781672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4810492806391184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4810288421809673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.481029860151598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.48102836007446187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4810468406494261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.48097159398031664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4810887855090452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.48099357932137804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.48109582939937345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4811349737324885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4811566109646668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.48112335602442424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4810748583990296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4811222739188017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4810780569680742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.48102836028594803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.48104171713629923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.48096519839345364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4809209159218769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.48093769787180374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4808687858591932
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.48097941590392074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.48096824843040514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4809641863876607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.48098423478412833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4809954225503165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4809500447524491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4809604093368473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4809335394257907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.48099890548704016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4810440425298361
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4811219019458649
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4811243147227415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.48118624678355154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.48118624678355154 valid 0.4844895601272583
LOSS train 0.48118624678355154 valid 0.49918121099472046
LOSS train 0.48118624678355154 valid 0.49707146485646564
LOSS train 0.48118624678355154 valid 0.49310918897390366
LOSS train 0.48118624678355154 valid 0.48786338567733767
LOSS train 0.48118624678355154 valid 0.4934009214242299
LOSS train 0.48118624678355154 valid 0.500189551285335
LOSS train 0.48118624678355154 valid 0.5025832578539848
LOSS train 0.48118624678355154 valid 0.5044233732753329
LOSS train 0.48118624678355154 valid 0.5085160970687866
LOSS train 0.48118624678355154 valid 0.5119292140007019
LOSS train 0.48118624678355154 valid 0.5108131617307663
LOSS train 0.48118624678355154 valid 0.5153059455064627
LOSS train 0.48118624678355154 valid 0.5176002170358386
LOSS train 0.48118624678355154 valid 0.5189184705416362
LOSS train 0.48118624678355154 valid 0.516927931457758
LOSS train 0.48118624678355154 valid 0.5193257787648369
LOSS train 0.48118624678355154 valid 0.5197441875934601
LOSS train 0.48118624678355154 valid 0.5186437760528765
LOSS train 0.48118624678355154 valid 0.5196605160832405
LOSS train 0.48118624678355154 valid 0.5194335821129027
LOSS train 0.48118624678355154 valid 0.5181168548085473
LOSS train 0.48118624678355154 valid 0.5182314502156299
LOSS train 0.48118624678355154 valid 0.5171240406731764
LOSS train 0.48118624678355154 valid 0.5159160077571869
LOSS train 0.48118624678355154 valid 0.514343396975444
LOSS train 0.48118624678355154 valid 0.5139693529517563
LOSS train 0.48118624678355154 valid 0.5145896737064634
LOSS train 0.48118624678355154 valid 0.5135828647120245
LOSS train 0.48118624678355154 valid 0.5149962484836579
LOSS train 0.48118624678355154 valid 0.5162602182357542
LOSS train 0.48118624678355154 valid 0.5165829304605722
LOSS train 0.48118624678355154 valid 0.5179131735454906
LOSS train 0.48118624678355154 valid 0.5187426998334772
LOSS train 0.48118624678355154 valid 0.5203537583351135
LOSS train 0.48118624678355154 valid 0.5207756906747818
LOSS train 0.48118624678355154 valid 0.5211048077892613
LOSS train 0.48118624678355154 valid 0.5215420832759455
LOSS train 0.48118624678355154 valid 0.521424664900853
LOSS train 0.48118624678355154 valid 0.5220256209373474
LOSS train 0.48118624678355154 valid 0.5221244416585783
LOSS train 0.48118624678355154 valid 0.5220802397955031
LOSS train 0.48118624678355154 valid 0.5220828804858896
LOSS train 0.48118624678355154 valid 0.5221695100719278
LOSS train 0.48118624678355154 valid 0.522108272711436
LOSS train 0.48118624678355154 valid 0.5228356615356777
LOSS train 0.48118624678355154 valid 0.5229284725290664
LOSS train 0.48118624678355154 valid 0.5237864156564077
LOSS train 0.48118624678355154 valid 0.5249296584907843
LOSS train 0.48118624678355154 valid 0.5243012261390686
LOSS train 0.48118624678355154 valid 0.525028035921209
LOSS train 0.48118624678355154 valid 0.5254460103236712
LOSS train 0.48118624678355154 valid 0.5252802945532888
LOSS train 0.48118624678355154 valid 0.5246723062462277
LOSS train 0.48118624678355154 valid 0.5247160792350769
LOSS train 0.48118624678355154 valid 0.5243775514619691
LOSS train 0.48118624678355154 valid 0.5239614279646623
LOSS train 0.48118624678355154 valid 0.5241181346876868
LOSS train 0.48118624678355154 valid 0.5247200848692555
LOSS train 0.48118624678355154 valid 0.5241775254408518
LOSS train 0.48118624678355154 valid 0.5229107805939971
LOSS train 0.48118624678355154 valid 0.523023453450972
LOSS train 0.48118624678355154 valid 0.5228473203522819
LOSS train 0.48118624678355154 valid 0.5232656821608543
LOSS train 0.48118624678355154 valid 0.5235883639408991
LOSS train 0.48118624678355154 valid 0.5228926905176856
LOSS train 0.48118624678355154 valid 0.5226871971763781
LOSS train 0.48118624678355154 valid 0.5226557934108902
LOSS train 0.48118624678355154 valid 0.522651760906413
LOSS train 0.48118624678355154 valid 0.5219585418701171
LOSS train 0.48118624678355154 valid 0.5214076201680681
LOSS train 0.48118624678355154 valid 0.5211876200305091
LOSS train 0.48118624678355154 valid 0.5216429886752612
LOSS train 0.48118624678355154 valid 0.5209061672558656
LOSS train 0.48118624678355154 valid 0.5209071079889933
LOSS train 0.48118624678355154 valid 0.5211728764207739
LOSS train 0.48118624678355154 valid 0.521029649616836
LOSS train 0.48118624678355154 valid 0.5210749804973602
LOSS train 0.48118624678355154 valid 0.5207200623765776
LOSS train 0.48118624678355154 valid 0.5205938383936882
LOSS train 0.48118624678355154 valid 0.5201601187388102
LOSS train 0.48118624678355154 valid 0.5202526515576897
LOSS train 0.48118624678355154 valid 0.5199358150901565
LOSS train 0.48118624678355154 valid 0.5200056188872882
LOSS train 0.48118624678355154 valid 0.519676155202529
LOSS train 0.48118624678355154 valid 0.5193876343411069
LOSS train 0.48118624678355154 valid 0.51929847228116
LOSS train 0.48118624678355154 valid 0.5193474397740581
LOSS train 0.48118624678355154 valid 0.5194601460119311
LOSS train 0.48118624678355154 valid 0.5199432329999076
LOSS train 0.48118624678355154 valid 0.5200950500074324
LOSS train 0.48118624678355154 valid 0.5199383707798045
LOSS train 0.48118624678355154 valid 0.5197193545679892
LOSS train 0.48118624678355154 valid 0.5195901463640497
LOSS train 0.48118624678355154 valid 0.5193817383364627
LOSS train 0.48118624678355154 valid 0.5193254562715689
LOSS train 0.48118624678355154 valid 0.519385638925218
LOSS train 0.48118624678355154 valid 0.519123624782173
LOSS train 0.48118624678355154 valid 0.5196466626542987
LOSS train 0.48118624678355154 valid 0.5198889189958572
LOSS train 0.48118624678355154 valid 0.5197665933335182
LOSS train 0.48118624678355154 valid 0.5198222772747862
LOSS train 0.48118624678355154 valid 0.5201418752809173
LOSS train 0.48118624678355154 valid 0.5203231424093246
LOSS train 0.48118624678355154 valid 0.5204924038478307
LOSS train 0.48118624678355154 valid 0.5206606500553634
LOSS train 0.48118624678355154 valid 0.5205342557942756
LOSS train 0.48118624678355154 valid 0.520482306127195
LOSS train 0.48118624678355154 valid 0.5206944461262554
LOSS train 0.48118624678355154 valid 0.5210429289124229
LOSS train 0.48118624678355154 valid 0.5209473989031337
LOSS train 0.48118624678355154 valid 0.5208138403083596
LOSS train 0.48118624678355154 valid 0.5210058525600264
LOSS train 0.48118624678355154 valid 0.5205162251204775
LOSS train 0.48118624678355154 valid 0.5205594736596812
LOSS train 0.48118624678355154 valid 0.5208411535312389
LOSS train 0.48118624678355154 valid 0.5207016875601223
LOSS train 0.48118624678355154 valid 0.5205889909954394
LOSS train 0.48118624678355154 valid 0.5204951953487236
LOSS train 0.48118624678355154 valid 0.520467239121596
LOSS train 0.48118624678355154 valid 0.5202886013945273
LOSS train 0.48118624678355154 valid 0.5200845596731686
LOSS train 0.48118624678355154 valid 0.520167675202455
LOSS train 0.48118624678355154 valid 0.5203647904338375
LOSS train 0.48118624678355154 valid 0.5205649306774139
LOSS train 0.48118624678355154 valid 0.5205925762180298
LOSS train 0.48118624678355154 valid 0.5207978625466504
LOSS train 0.48118624678355154 valid 0.5210498140659183
LOSS train 0.48118624678355154 valid 0.5211719845154489
LOSS train 0.48118624678355154 valid 0.5210993260145187
LOSS train 0.48118624678355154 valid 0.5211189910200716
LOSS train 0.48118624678355154 valid 0.520855947200096
LOSS train 0.48118624678355154 valid 0.5207834703133518
LOSS train 0.48118624678355154 valid 0.5207397343952265
LOSS train 0.48118624678355154 valid 0.5208719529487469
LOSS train 0.48118624678355154 valid 0.5208702142186025
LOSS train 0.48118624678355154 valid 0.5206258627620056
LOSS train 0.48118624678355154 valid 0.520350234448046
LOSS train 0.48118624678355154 valid 0.520259491188063
LOSS train 0.48118624678355154 valid 0.520284352345126
LOSS train 0.48118624678355154 valid 0.5204449471429731
LOSS train 0.48118624678355154 valid 0.5206033207581077
LOSS train 0.48118624678355154 valid 0.520502482886081
LOSS train 0.48118624678355154 valid 0.5205135566906797
LOSS train 0.48118624678355154 valid 0.5202300832189363
LOSS train 0.48118624678355154 valid 0.5205297580320541
LOSS train 0.48118624678355154 valid 0.5202584282881548
LOSS train 0.48118624678355154 valid 0.520637109875679
LOSS train 0.48118624678355154 valid 0.5205482504511839
LOSS train 0.48118624678355154 valid 0.5206790089607238
LOSS train 0.48118624678355154 valid 0.5206731084166774
LOSS train 0.48118624678355154 valid 0.5203945503423089
LOSS train 0.48118624678355154 valid 0.5203519408998926
LOSS train 0.48118624678355154 valid 0.5204872516068545
LOSS train 0.48118624678355154 valid 0.5204124446838133
LOSS train 0.48118624678355154 valid 0.5208297933523471
LOSS train 0.48118624678355154 valid 0.5208152270620796
LOSS train 0.48118624678355154 valid 0.5209055478814282
LOSS train 0.48118624678355154 valid 0.5206715129081558
LOSS train 0.48118624678355154 valid 0.520602342672646
LOSS train 0.48118624678355154 valid 0.5208037153164052
LOSS train 0.48118624678355154 valid 0.5206608214864025
LOSS train 0.48118624678355154 valid 0.520590785273745
LOSS train 0.48118624678355154 valid 0.5204362064236547
LOSS train 0.48118624678355154 valid 0.5201701599540133
LOSS train 0.48118624678355154 valid 0.5199390240462429
LOSS train 0.48118624678355154 valid 0.5201433450875882
LOSS train 0.48118624678355154 valid 0.5203276744910649
LOSS train 0.48118624678355154 valid 0.5204254321798065
LOSS train 0.48118624678355154 valid 0.5204623271437252
LOSS train 0.48118624678355154 valid 0.5207304630363196
LOSS train 0.48118624678355154 valid 0.5208608081867528
LOSS train 0.48118624678355154 valid 0.5209292280191631
LOSS train 0.48118624678355154 valid 0.5209803135915735
LOSS train 0.48118624678355154 valid 0.5210691070556641
LOSS train 0.48118624678355154 valid 0.5211858674883842
LOSS train 0.48118624678355154 valid 0.5213442431331354
LOSS train 0.48118624678355154 valid 0.5216032845920391
LOSS train 0.48118624678355154 valid 0.52169586526615
LOSS train 0.48118624678355154 valid 0.5217435959312651
LOSS train 0.48118624678355154 valid 0.5217791282011001
LOSS train 0.48118624678355154 valid 0.5218242095721947
LOSS train 0.48118624678355154 valid 0.5217793199533973
LOSS train 0.48118624678355154 valid 0.5218259915709496
LOSS train 0.48118624678355154 valid 0.5217411108919092
LOSS train 0.48118624678355154 valid 0.5218082704851704
LOSS train 0.48118624678355154 valid 0.5220303771330074
LOSS train 0.48118624678355154 valid 0.5220784919059023
LOSS train 0.48118624678355154 valid 0.5219150854166222
LOSS train 0.48118624678355154 valid 0.521821538711849
LOSS train 0.48118624678355154 valid 0.522092921883648
LOSS train 0.48118624678355154 valid 0.5222296866898736
LOSS train 0.48118624678355154 valid 0.5222832257883536
LOSS train 0.48118624678355154 valid 0.5221202616224584
LOSS train 0.48118624678355154 valid 0.5218870835426527
LOSS train 0.48118624678355154 valid 0.5218767742721402
LOSS train 0.48118624678355154 valid 0.5219354224083993
LOSS train 0.48118624678355154 valid 0.5218257530771121
LOSS train 0.48118624678355154 valid 0.5219485133736577
LOSS train 0.48118624678355154 valid 0.5219621565937996
LOSS train 0.48118624678355154 valid 0.5218294424500631
LOSS train 0.48118624678355154 valid 0.5219076026489239
LOSS train 0.48118624678355154 valid 0.5218196630184286
LOSS train 0.48118624678355154 valid 0.5220137736668774
LOSS train 0.48118624678355154 valid 0.5219918400776096
LOSS train 0.48118624678355154 valid 0.5222113585298501
LOSS train 0.48118624678355154 valid 0.5221669421967677
LOSS train 0.48118624678355154 valid 0.5221203532643043
LOSS train 0.48118624678355154 valid 0.5218540631127699
LOSS train 0.48118624678355154 valid 0.5217639737185977
LOSS train 0.48118624678355154 valid 0.5219490184885631
LOSS train 0.48118624678355154 valid 0.5219321991756277
LOSS train 0.48118624678355154 valid 0.5219388264165797
LOSS train 0.48118624678355154 valid 0.5218840379302747
LOSS train 0.48118624678355154 valid 0.5216701126375863
LOSS train 0.48118624678355154 valid 0.5215855534705851
LOSS train 0.48118624678355154 valid 0.5217320708909892
LOSS train 0.48118624678355154 valid 0.5216716018018372
LOSS train 0.48118624678355154 valid 0.5217586808825192
LOSS train 0.48118624678355154 valid 0.5216971666975455
LOSS train 0.48118624678355154 valid 0.5218165928152352
LOSS train 0.48118624678355154 valid 0.5219947554775186
LOSS train 0.48118624678355154 valid 0.5221833390238039
LOSS train 0.48118624678355154 valid 0.5221970516390034
LOSS train 0.48118624678355154 valid 0.5221555679374271
LOSS train 0.48118624678355154 valid 0.5220897146294602
LOSS train 0.48118624678355154 valid 0.5222351205769089
LOSS train 0.48118624678355154 valid 0.5223877389441457
LOSS train 0.48118624678355154 valid 0.522353286436031
LOSS train 0.48118624678355154 valid 0.5224747195192005
LOSS train 0.48118624678355154 valid 0.5223761375074263
LOSS train 0.48118624678355154 valid 0.5224292477400139
LOSS train 0.48118624678355154 valid 0.5222111997942045
LOSS train 0.48118624678355154 valid 0.5221893294499471
LOSS train 0.48118624678355154 valid 0.5222842894970102
LOSS train 0.48118624678355154 valid 0.522289239122706
LOSS train 0.48118624678355154 valid 0.5222522006507664
LOSS train 0.48118624678355154 valid 0.522209899390445
LOSS train 0.48118624678355154 valid 0.5222556592280895
LOSS train 0.48118624678355154 valid 0.52223819407324
LOSS train 0.48118624678355154 valid 0.5224057397654442
LOSS train 0.48118624678355154 valid 0.5224404245122405
LOSS train 0.48118624678355154 valid 0.5224005787215605
LOSS train 0.48118624678355154 valid 0.522406486336325
LOSS train 0.48118624678355154 valid 0.5223673996876698
LOSS train 0.48118624678355154 valid 0.522307345658783
LOSS train 0.48118624678355154 valid 0.52249731696569
LOSS train 0.48118624678355154 valid 0.5224860972694813
LOSS train 0.48118624678355154 valid 0.5224537912860931
LOSS train 0.48118624678355154 valid 0.5226238230466843
LOSS train 0.48118624678355154 valid 0.5225837858787096
LOSS train 0.48118624678355154 valid 0.5226824334453023
LOSS train 0.48118624678355154 valid 0.5227653404233955
LOSS train 0.48118624678355154 valid 0.5227658822545855
LOSS train 0.48118624678355154 valid 0.522745416094275
LOSS train 0.48118624678355154 valid 0.5227065914077684
LOSS train 0.48118624678355154 valid 0.522664192701592
LOSS train 0.48118624678355154 valid 0.5226911732623744
LOSS train 0.48118624678355154 valid 0.5227522795955186
LOSS train 0.48118624678355154 valid 0.5227430913310784
LOSS train 0.48118624678355154 valid 0.5228130512538998
LOSS train 0.48118624678355154 valid 0.5228709047304765
LOSS train 0.48118624678355154 valid 0.5229233128263017
LOSS train 0.48118624678355154 valid 0.5229042821535559
LOSS train 0.48118624678355154 valid 0.5229819436118288
LOSS train 0.48118624678355154 valid 0.5229770051581519
LOSS train 0.48118624678355154 valid 0.5229045160477528
LOSS train 0.48118624678355154 valid 0.522911133050029
LOSS train 0.48118624678355154 valid 0.5231424566759939
LOSS train 0.48118624678355154 valid 0.5232340235401083
LOSS train 0.48118624678355154 valid 0.5233355920033261
LOSS train 0.48118624678355154 valid 0.5233392944449887
LOSS train 0.48118624678355154 valid 0.5234784478451306
LOSS train 0.48118624678355154 valid 0.5234614568252633
LOSS train 0.48118624678355154 valid 0.5234266804565083
LOSS train 0.48118624678355154 valid 0.5235568322781203
LOSS train 0.48118624678355154 valid 0.5236279055314804
LOSS train 0.48118624678355154 valid 0.5235926692219947
LOSS train 0.48118624678355154 valid 0.5236720482294704
LOSS train 0.48118624678355154 valid 0.5236745867346014
LOSS train 0.48118624678355154 valid 0.5234417227027255
LOSS train 0.48118624678355154 valid 0.5233172825042237
LOSS train 0.48118624678355154 valid 0.5232090803633309
LOSS train 0.48118624678355154 valid 0.5232791427365491
LOSS train 0.48118624678355154 valid 0.5233091562463527
LOSS train 0.48118624678355154 valid 0.5232511984926838
LOSS train 0.48118624678355154 valid 0.523229333477984
LOSS train 0.48118624678355154 valid 0.5232151091719667
LOSS train 0.48118624678355154 valid 0.5232143555751722
LOSS train 0.48118624678355154 valid 0.5231956310313324
LOSS train 0.48118624678355154 valid 0.5230905633816605
LOSS train 0.48118624678355154 valid 0.5230430651405086
LOSS train 0.48118624678355154 valid 0.5230454345815417
LOSS train 0.48118624678355154 valid 0.5231306087605807
LOSS train 0.48118624678355154 valid 0.523268439102981
LOSS train 0.48118624678355154 valid 0.5233120339343676
LOSS train 0.48118624678355154 valid 0.5232643237218311
LOSS train 0.48118624678355154 valid 0.5232827962444933
LOSS train 0.48118624678355154 valid 0.5234008890928632
LOSS train 0.48118624678355154 valid 0.5233167617519696
LOSS train 0.48118624678355154 valid 0.5233591178128886
LOSS train 0.48118624678355154 valid 0.5232941108626246
LOSS train 0.48118624678355154 valid 0.5233117130526616
LOSS train 0.48118624678355154 valid 0.5232708882540464
LOSS train 0.48118624678355154 valid 0.5231828639741803
LOSS train 0.48118624678355154 valid 0.523129896498194
LOSS train 0.48118624678355154 valid 0.5230729687679863
LOSS train 0.48118624678355154 valid 0.5231038243933157
LOSS train 0.48118624678355154 valid 0.5231382404137583
LOSS train 0.48118624678355154 valid 0.5230803867501598
LOSS train 0.48118624678355154 valid 0.522998152821777
LOSS train 0.48118624678355154 valid 0.5230468798142213
LOSS train 0.48118624678355154 valid 0.523180175132264
LOSS train 0.48118624678355154 valid 0.52325536680829
LOSS train 0.48118624678355154 valid 0.5233280961475675
LOSS train 0.48118624678355154 valid 0.5232523185542867
LOSS train 0.48118624678355154 valid 0.5233235765330799
LOSS train 0.48118624678355154 valid 0.5232223689368686
LOSS train 0.48118624678355154 valid 0.523328337269517
LOSS train 0.48118624678355154 valid 0.5232123713940382
LOSS train 0.48118624678355154 valid 0.5231562609613127
LOSS train 0.48118624678355154 valid 0.5231219165443634
LOSS train 0.48118624678355154 valid 0.5230002676370343
LOSS train 0.48118624678355154 valid 0.5229627519478033
LOSS train 0.48118624678355154 valid 0.522929466504317
LOSS train 0.48118624678355154 valid 0.5230733655347415
LOSS train 0.48118624678355154 valid 0.5230962881983603
LOSS train 0.48118624678355154 valid 0.5232260190859074
LOSS train 0.48118624678355154 valid 0.523318475502965
LOSS train 0.48118624678355154 valid 0.5233787258466085
LOSS train 0.48118624678355154 valid 0.523324185267676
LOSS train 0.48118624678355154 valid 0.5231761514961001
LOSS train 0.48118624678355154 valid 0.5232037505409023
LOSS train 0.48118624678355154 valid 0.5233837575791125
LOSS train 0.48118624678355154 valid 0.5233951032161712
LOSS train 0.48118624678355154 valid 0.5234876726532266
LOSS train 0.48118624678355154 valid 0.5234349867887242
LOSS train 0.48118624678355154 valid 0.5234394218971038
LOSS train 0.48118624678355154 valid 0.5232854567270363
LOSS train 0.48118624678355154 valid 0.5232014012687346
LOSS train 0.48118624678355154 valid 0.52311546021193
LOSS train 0.48118624678355154 valid 0.52311604700939
LOSS train 0.48118624678355154 valid 0.523138460977432
LOSS train 0.48118624678355154 valid 0.5232365759479445
LOSS train 0.48118624678355154 valid 0.5231956881889398
LOSS train 0.48118624678355154 valid 0.5232542988365096
LOSS train 0.48118624678355154 valid 0.5232505658346226
LOSS train 0.48118624678355154 valid 0.5233452694340684
LOSS train 0.48118624678355154 valid 0.5234356379953018
LOSS train 0.48118624678355154 valid 0.5234158469097955
LOSS train 0.48118624678355154 valid 0.523336261510849
LOSS train 0.48118624678355154 valid 0.5233171576295387
LOSS train 0.48118624678355154 valid 0.5234167872170888
LOSS train 0.48118624678355154 valid 0.523471519687755
LOSS train 0.48118624678355154 valid 0.5236026823520661
LOSS train 0.48118624678355154 valid 0.5236759874760435
LOSS train 0.48118624678355154 valid 0.5236179687562776
LOSS train 0.48118624678355154 valid 0.5235344496186219
LOSS train 0.48118624678355154 valid 0.5235791126665631
LOSS train 0.48118624678355154 valid 0.5235843810770247
LOSS train 0.48118624678355154 valid 0.5236557514053303
LOSS train 0.48118624678355154 valid 0.5237514113194376
LOSS train 0.48118624678355154 valid 0.5237849563278114
LOSS train 0.48118624678355154 valid 0.523775978730275
LOSS train 0.48118624678355154 valid 0.5238360516012531
LOSS train 0.48118624678355154 valid 0.5238376445457583
LOSS train 0.48118624678355154 valid 0.5237683208826777
LOSS train 0.48118624678355154 valid 0.5237564538484034
LOSS train 0.48118624678355154 valid 0.5237870184063589
EPOCH 6:
  batch 1 loss: 0.46798479557037354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.5000749826431274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.49577341477076214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4923388361930847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.49050005674362185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.48578206698099774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4830095725400107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4837763197720051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4814029700226254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4773807555437088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.47546442259441724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4746714308857918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.47387755146393407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.4753329860312598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.47812198996543886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.47842143662273884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4767813717617708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47737425731288063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4788894480780551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.479356986284256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.47882582602046786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4786838794296438
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.479563277700673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4792571986714999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.47878345251083376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.47908344635596645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4803148905436198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.47953976052148
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4797587014477828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.48014770448207855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4800477547030295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4805815741419792
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.47979955330039514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.47988283020608563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.48080634645053316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4807974108391338
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4798081557492952
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4790072699910716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4793810149033864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4798278994858265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.47940970630180546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4793430751278287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.481045056221097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4815292033282193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.48173222409354316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.48092206988645636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4808515582947021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4813245056817929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.48132286570510086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4821242767572403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4813719748281965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.48110700169434917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4806100146950416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.48030630581908756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4795444266362624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4797901777284486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.48006335894266766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.47946383213174754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4789934021941686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4794216101368268
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.47934552245452755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.47994580432291956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.48010706570413375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4801181289367378
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.48069971662301286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4800549154028748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4798341322301039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.47992924732320447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.47973837282346643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.47993190331118446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4798714900520486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.47935957916908795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.47962322667853474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.47949279240659765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4792693773905436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.47987764760067586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4796213298648983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.47920723526905745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4794119886959655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4792051248252392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4792564202238012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4790182895049816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.47907383973339956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4788633357910883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.47873799380134135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.47900965601898904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.47924642624526187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.47946571389382536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4793724263651987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.47938394281599256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4792454072407314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4794876076605009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.47965791212615144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.47966518110417306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4795930856152585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4801167193800211
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.48004905341826765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4800682481454343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.48022388870065863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4803125965595245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.48017366628835695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4803044316815395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.48047430249093803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.48040560231759
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4806070997601464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4803242230752729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4801693310804456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.48039907686136385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.48034603798061337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4803696483373642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4802049556830982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4802357397441353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4803791476034485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.48030912170284673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.48010083566541256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4801979858813615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4805875132735978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.48049549808946707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.480666135289088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4803645136455695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.48047468386405756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4807343385258659
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.480953192323204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4807850338758961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.480910674571991
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.48104515340593124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.480982185583415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.48125049262307584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4811555010865825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4812334920351322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4811017233451814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4809967638416724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4809610901918626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4808066169272608
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4807264471495593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4808416007196202
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.48106256627688443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4809057455563891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4811090104442706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4811404883861542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4810159629118358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4810500854337719
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4811086865155013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.48133678092724747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.48137397745559957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4811891499039245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.48136070451768886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.48159718211438207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4814733184824054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4812268183628718
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4813066359782061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4813004536064048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4813367582224553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4812030339395845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.48144745980539627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4816910586295984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4816387462767826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.48177731829353526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4819191982911068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.48198841884732246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4817984566925475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4816837209610291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.48170491467955656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4816393692318986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.48158353314255226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.48171441346766003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4816821410270508
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4814173522449675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4814279894151631
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4815563037114985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4814813649445249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4813990861523983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.48128509917700224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.48138060994531917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4812380930355617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4811075150289319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4810019909998791
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4810626838314399
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.48115408254069325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4811689588758681
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4810663333255283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4809868137587558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4808424662371151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4808098435725855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4809011923300253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4808559875975373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.48084414164650247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.480700801661674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.48068546901934994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.48058484980934546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.48044186331214705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.48022465873509645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4802440486732542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.48031680961859596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.480262795319924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4802522676027551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4803141142208564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4804609991384275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.480466979682146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4804858918488026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.48049001062094276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.48052413997673754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4802840701464949
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.48027557981949226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4802221277864968
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.48002119767434387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.47996928107335374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.47982924703795177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4800121081217624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4800384380987712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4800479832983695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4802794369324198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.48030000645230075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4802002009944381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.48024962710779767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4802224482927058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4802659391532845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.48053053281175984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4808032508582285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4808356207880107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.48062557588875027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.48049539341045927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4805895615318965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.48061444809926407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.48045384420288934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4803456354193983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.48036997460058606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.48020007971086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4801374819601467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.48026231112687484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.48021481034559604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.48034131976551026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4802144631551571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.48021289706230164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.48028806879165326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.48028393847457435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4802650404378835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.48016889067758034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.48015588609244536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4802373471359412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.48034606484456677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4802766661506054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4804208151106972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.480435024763717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4805577365719542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4807381096894179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4807824943712366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4806671010390405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.48084647612399367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4809163780212402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4809917766022017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.48098552227020264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.481013871699925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4808797293056653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.48081467981431997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4808478847844526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4807145016898441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4806832078584405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.48091279183115276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.48102476975092523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.481020482449696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.48094035719187206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.48093363042113446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4809470141701626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48081973431245334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.480847440267864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4808324426970678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.48077245423598075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4807267675390917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4807612336344189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4807736289677145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4806409877012758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4805677299534445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.48033876521308927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4801459806615656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4802220999330714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.48029938544607337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4802477525935756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4802570785245588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.480269051023892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4803405635297511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4803528143159041
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.48030526183098027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4803077592186525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4803256274315349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4803619439993705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.48034856938318926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4803860657331016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4803384717772989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.48040275748433736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.48034135306004394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4803859522081401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4804631003747621
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.480547177953785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.48053540607630196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.48052189358182856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.48060858530628964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.48057098736698994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4805289179983745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4805049655834834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4805722610895024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.480470911161789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4804492004633737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.48048027957740586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.48053845137846274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.48052306716738186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4805171474183421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4805614545747831
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4806159740512811
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4805884333387498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4806626313560645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.48056446827757054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4804847787934751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4804188335777088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.48038292442049296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.48044902670987044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.48048433407624064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4805106144843611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4805149874156545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4805880761705339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.48047692140686177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.48055550715197687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4807352966199349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4807067953142119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.48067746327473565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.48068095368841673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.48071533040533737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4808126588056727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4807392588864706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.48082098906690424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4808857354512748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4808639616492283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.480895310819328
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.48083441298521923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4808310380622522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.48085778969384374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4807512328603501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4807204815762988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4806326537181494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.48069564147907146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.48067484826636103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.48070544588286973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4806013744183254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4805828940209954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4805939391903255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.48068514216497454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4807296668418203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4807861577505353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4807256176683486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4807051245655332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4806265855616654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4806363315067508
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4806879939506142
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4806419868590468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4806325483490044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4805550812168068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.48055831683116135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4806609887151079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.48062877228333095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.48054777656992276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4805074971468495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4805211945133315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4805544586877849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4804702880945835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4804724411605156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.48041738716305277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.48036204493662965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4803570896873008
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4803318120438232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.48034658802522195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4803785784546577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4803493574101438
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.48040965670874547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.48040681599295715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.48039268191655476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4803999401628971
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4804210723711262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.48051056415631027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4805532144996925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.48048883802012393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4804723938619058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4803990757590189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4804864096268039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4805116190109402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.48050944286507447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4805877277424916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4805657095071265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.48065632904313277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4806283978999121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.48063360101137403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4806295479350078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.48063775585318097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4806342768760128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.48061559761538725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4805536164513117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.48060379290219507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.48067122412568675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.48076875230774807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.480843294533273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.480833006426692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.48075688487276474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4806018972129964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.48059497806925333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.48056125264651706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.48057294576256365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4806307858874645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.48059005416581907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4805605726353094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.48050523124872035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.4805107148682199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4805749786741252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4806346198887501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4805521058689884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.48069018283903886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.48077512807156664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4808553421440033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4808199843771452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.48081547627893934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.48085325785639177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4808331901118869
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.48096327119088794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.48104471448473457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4809648025402222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4810072920232449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.48098107800764195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.48087201865626056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4808679121160396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4807937099972618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.48072124229166613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4808196017215418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4807785781243008
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.48077914615472156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.48070547803720204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4807378056411919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.48063790181587485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.48073884694401275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.48072003622622456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4806883652188462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.48061140652126494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4805878929793835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.48061389413550326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4806018710406118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4806291024383519
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.48054278474133294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4806874881969409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.48059526660517193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4806936863284783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.48072753726903883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.48072621319235564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4806951242685318
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.48066304911530994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.48072360706540335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.48069710730190573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4806509873284117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4806636848947504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.48060704931093934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.48055964395306044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4805818362137116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4805161836749848
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.48062203014674393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4805978745416033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.48058565031914485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.48061896233012813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.48061630707876435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4805833327513869
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4806062524794509
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4805829161877806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4806484654545784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4806968503033937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.48078103401559463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4807701093122964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.48081968156463006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.48081968156463006 valid 0.48523738980293274
LOSS train 0.48081968156463006 valid 0.4999683350324631
LOSS train 0.48081968156463006 valid 0.4978412389755249
LOSS train 0.48081968156463006 valid 0.4937502592802048
LOSS train 0.48081968156463006 valid 0.48854378461837766
LOSS train 0.48081968156463006 valid 0.49411935607592267
LOSS train 0.48081968156463006 valid 0.5008785894938877
LOSS train 0.48081968156463006 valid 0.5032805576920509
LOSS train 0.48081968156463006 valid 0.5051093962457445
LOSS train 0.48081968156463006 valid 0.5092247307300568
LOSS train 0.48081968156463006 valid 0.5125828168608926
LOSS train 0.48081968156463006 valid 0.5114966010053953
LOSS train 0.48081968156463006 valid 0.5159948491133176
LOSS train 0.48081968156463006 valid 0.5182626311268125
LOSS train 0.48081968156463006 valid 0.5195856829484303
LOSS train 0.48081968156463006 valid 0.5175914186984301
LOSS train 0.48081968156463006 valid 0.5199929668622858
LOSS train 0.48081968156463006 valid 0.5204134302006828
LOSS train 0.48081968156463006 valid 0.51930738279694
LOSS train 0.48081968156463006 valid 0.5203246966004371
LOSS train 0.48081968156463006 valid 0.5201019517013005
LOSS train 0.48081968156463006 valid 0.5187876170331781
LOSS train 0.48081968156463006 valid 0.5189059454461803
LOSS train 0.48081968156463006 valid 0.5178048312664032
LOSS train 0.48081968156463006 valid 0.5165861105918884
LOSS train 0.48081968156463006 valid 0.5150183485104487
LOSS train 0.48081968156463006 valid 0.5146456868560226
LOSS train 0.48081968156463006 valid 0.5152588252510343
LOSS train 0.48081968156463006 valid 0.5142630163965554
LOSS train 0.48081968156463006 valid 0.5156749119361241
LOSS train 0.48081968156463006 valid 0.5169382431814747
LOSS train 0.48081968156463006 valid 0.517244509421289
LOSS train 0.48081968156463006 valid 0.518570604649457
LOSS train 0.48081968156463006 valid 0.5193833086420508
LOSS train 0.48081968156463006 valid 0.5210068268435342
LOSS train 0.48081968156463006 valid 0.5214342350761095
LOSS train 0.48081968156463006 valid 0.521761384364721
LOSS train 0.48081968156463006 valid 0.5222152777408299
LOSS train 0.48081968156463006 valid 0.5220965552024353
LOSS train 0.48081968156463006 valid 0.5226958118379116
LOSS train 0.48081968156463006 valid 0.5227916262498716
LOSS train 0.48081968156463006 valid 0.5227516740560532
LOSS train 0.48081968156463006 valid 0.522749089224394
LOSS train 0.48081968156463006 valid 0.5228354422883554
LOSS train 0.48081968156463006 valid 0.5227797912226783
LOSS train 0.48081968156463006 valid 0.5235044392554656
LOSS train 0.48081968156463006 valid 0.5235884348128704
LOSS train 0.48081968156463006 valid 0.5244473051279783
LOSS train 0.48081968156463006 valid 0.5255963346179651
LOSS train 0.48081968156463006 valid 0.5249673372507095
LOSS train 0.48081968156463006 valid 0.5256900723073997
LOSS train 0.48081968156463006 valid 0.5261047614308504
LOSS train 0.48081968156463006 valid 0.5259324981356567
LOSS train 0.48081968156463006 valid 0.5253243330452178
LOSS train 0.48081968156463006 valid 0.5253601870753548
LOSS train 0.48081968156463006 valid 0.5250200059797082
LOSS train 0.48081968156463006 valid 0.52460487003912
LOSS train 0.48081968156463006 valid 0.5247531363676334
LOSS train 0.48081968156463006 valid 0.5253596725100178
LOSS train 0.48081968156463006 valid 0.524820298453172
LOSS train 0.48081968156463006 valid 0.5235596782848483
LOSS train 0.48081968156463006 valid 0.5236724716040396
LOSS train 0.48081968156463006 valid 0.5234970275371794
LOSS train 0.48081968156463006 valid 0.5239211251027882
LOSS train 0.48081968156463006 valid 0.5242376909806178
LOSS train 0.48081968156463006 valid 0.5235427487077136
LOSS train 0.48081968156463006 valid 0.5233333924813057
LOSS train 0.48081968156463006 valid 0.5233010803075397
LOSS train 0.48081968156463006 valid 0.5232895262863325
LOSS train 0.48081968156463006 valid 0.5225947367293494
LOSS train 0.48081968156463006 valid 0.5220442300950977
LOSS train 0.48081968156463006 valid 0.5218289374477334
LOSS train 0.48081968156463006 valid 0.5222828277986343
LOSS train 0.48081968156463006 valid 0.5215425962531889
LOSS train 0.48081968156463006 valid 0.5215383613109589
LOSS train 0.48081968156463006 valid 0.5218059283338095
LOSS train 0.48081968156463006 valid 0.5216644874640873
LOSS train 0.48081968156463006 valid 0.521706923078268
LOSS train 0.48081968156463006 valid 0.521354851466191
LOSS train 0.48081968156463006 valid 0.5212317313998938
LOSS train 0.48081968156463006 valid 0.5207989289436812
LOSS train 0.48081968156463006 valid 0.5208895162838262
LOSS train 0.48081968156463006 valid 0.5205768368330347
LOSS train 0.48081968156463006 valid 0.5206426772333327
LOSS train 0.48081968156463006 valid 0.520314125103109
LOSS train 0.48081968156463006 valid 0.5200204596269963
LOSS train 0.48081968156463006 valid 0.5199295744813722
LOSS train 0.48081968156463006 valid 0.5199746066196398
LOSS train 0.48081968156463006 valid 0.520090160410056
LOSS train 0.48081968156463006 valid 0.520571818947792
LOSS train 0.48081968156463006 valid 0.520720987202047
LOSS train 0.48081968156463006 valid 0.5205659357749898
LOSS train 0.48081968156463006 valid 0.5203462252693791
LOSS train 0.48081968156463006 valid 0.5202125491614037
LOSS train 0.48081968156463006 valid 0.520004664910467
LOSS train 0.48081968156463006 valid 0.5199484648182988
LOSS train 0.48081968156463006 valid 0.5200117786520535
LOSS train 0.48081968156463006 valid 0.5197509153156864
LOSS train 0.48081968156463006 valid 0.5202712088522284
LOSS train 0.48081968156463006 valid 0.520514649450779
LOSS train 0.48081968156463006 valid 0.5203911257852422
LOSS train 0.48081968156463006 valid 0.5204477687092388
LOSS train 0.48081968156463006 valid 0.5207655976698237
LOSS train 0.48081968156463006 valid 0.5209451624407218
LOSS train 0.48081968156463006 valid 0.5211164993899209
LOSS train 0.48081968156463006 valid 0.5212866155044088
LOSS train 0.48081968156463006 valid 0.5211583172606531
LOSS train 0.48081968156463006 valid 0.5211050292408025
LOSS train 0.48081968156463006 valid 0.5213132322928228
LOSS train 0.48081968156463006 valid 0.5216616546565837
LOSS train 0.48081968156463006 valid 0.521563673073107
LOSS train 0.48081968156463006 valid 0.5214298029563257
LOSS train 0.48081968156463006 valid 0.5216194594328383
LOSS train 0.48081968156463006 valid 0.5211285049455208
LOSS train 0.48081968156463006 valid 0.5211704202320264
LOSS train 0.48081968156463006 valid 0.5214529366328798
LOSS train 0.48081968156463006 valid 0.5213118465537698
LOSS train 0.48081968156463006 valid 0.5211967502610159
LOSS train 0.48081968156463006 valid 0.5211000427478502
LOSS train 0.48081968156463006 valid 0.521072256565094
LOSS train 0.48081968156463006 valid 0.5208919543372698
LOSS train 0.48081968156463006 valid 0.5206869501070898
LOSS train 0.48081968156463006 valid 0.5207725407146826
LOSS train 0.48081968156463006 valid 0.5209727789605817
LOSS train 0.48081968156463006 valid 0.5211711409091949
LOSS train 0.48081968156463006 valid 0.5211994191483845
LOSS train 0.48081968156463006 valid 0.5214063213096829
LOSS train 0.48081968156463006 valid 0.5216587332542986
LOSS train 0.48081968156463006 valid 0.5217804010062255
LOSS train 0.48081968156463006 valid 0.5217059802550535
LOSS train 0.48081968156463006 valid 0.5217243380673969
LOSS train 0.48081968156463006 valid 0.5214624443289005
LOSS train 0.48081968156463006 valid 0.521389196017631
LOSS train 0.48081968156463006 valid 0.5213423373539057
LOSS train 0.48081968156463006 valid 0.5214736755247469
LOSS train 0.48081968156463006 valid 0.5214715707389748
LOSS train 0.48081968156463006 valid 0.5212289973767135
LOSS train 0.48081968156463006 valid 0.5209512634985689
LOSS train 0.48081968156463006 valid 0.5208600791667005
LOSS train 0.48081968156463006 valid 0.5208846694656781
LOSS train 0.48081968156463006 valid 0.5210468627459613
LOSS train 0.48081968156463006 valid 0.5212048546109401
LOSS train 0.48081968156463006 valid 0.5211044756265787
LOSS train 0.48081968156463006 valid 0.5211137858115964
LOSS train 0.48081968156463006 valid 0.5208316102110107
LOSS train 0.48081968156463006 valid 0.5211315463258795
LOSS train 0.48081968156463006 valid 0.5208618999743948
LOSS train 0.48081968156463006 valid 0.5212433670420904
LOSS train 0.48081968156463006 valid 0.5211535062165868
LOSS train 0.48081968156463006 valid 0.5212885795036951
LOSS train 0.48081968156463006 valid 0.5212837814889997
LOSS train 0.48081968156463006 valid 0.5210026418300051
LOSS train 0.48081968156463006 valid 0.5209603498574176
LOSS train 0.48081968156463006 valid 0.5210942364745326
LOSS train 0.48081968156463006 valid 0.5210192113153396
LOSS train 0.48081968156463006 valid 0.5214366043607394
LOSS train 0.48081968156463006 valid 0.5214228905310296
LOSS train 0.48081968156463006 valid 0.5215124931139282
LOSS train 0.48081968156463006 valid 0.5212784583838481
LOSS train 0.48081968156463006 valid 0.5212125843390822
LOSS train 0.48081968156463006 valid 0.5214149550251339
LOSS train 0.48081968156463006 valid 0.521271010607849
LOSS train 0.48081968156463006 valid 0.5211982672199881
LOSS train 0.48081968156463006 valid 0.5210431265394863
LOSS train 0.48081968156463006 valid 0.5207756273674242
LOSS train 0.48081968156463006 valid 0.5205444774354797
LOSS train 0.48081968156463006 valid 0.5207484726777334
LOSS train 0.48081968156463006 valid 0.520933939764897
LOSS train 0.48081968156463006 valid 0.5210375709999242
LOSS train 0.48081968156463006 valid 0.5210745245218277
LOSS train 0.48081968156463006 valid 0.5213435255644614
LOSS train 0.48081968156463006 valid 0.5214709627420403
LOSS train 0.48081968156463006 valid 0.5215404951848046
LOSS train 0.48081968156463006 valid 0.5215886175289921
LOSS train 0.48081968156463006 valid 0.5216747905526843
LOSS train 0.48081968156463006 valid 0.521791963245381
LOSS train 0.48081968156463006 valid 0.5219501578538431
LOSS train 0.48081968156463006 valid 0.5222107973996173
LOSS train 0.48081968156463006 valid 0.5223029523921412
LOSS train 0.48081968156463006 valid 0.5223489948444896
LOSS train 0.48081968156463006 valid 0.5223853125427309
LOSS train 0.48081968156463006 valid 0.5224292630350197
LOSS train 0.48081968156463006 valid 0.5223848179715579
LOSS train 0.48081968156463006 valid 0.5224309008082618
LOSS train 0.48081968156463006 valid 0.5223459403257112
LOSS train 0.48081968156463006 valid 0.5224132805421788
LOSS train 0.48081968156463006 valid 0.5226353035572379
LOSS train 0.48081968156463006 valid 0.522682988421714
LOSS train 0.48081968156463006 valid 0.5225187863307025
LOSS train 0.48081968156463006 valid 0.5224265818533145
LOSS train 0.48081968156463006 valid 0.5226997753400453
LOSS train 0.48081968156463006 valid 0.5228352383710444
LOSS train 0.48081968156463006 valid 0.5228872377946587
LOSS train 0.48081968156463006 valid 0.5227242078363281
LOSS train 0.48081968156463006 valid 0.5224910976030888
LOSS train 0.48081968156463006 valid 0.5224810076915488
LOSS train 0.48081968156463006 valid 0.5225428743713398
LOSS train 0.48081968156463006 valid 0.522433242864079
LOSS train 0.48081968156463006 valid 0.5225556856723287
LOSS train 0.48081968156463006 valid 0.5225677265226841
LOSS train 0.48081968156463006 valid 0.5224339933834266
LOSS train 0.48081968156463006 valid 0.5225116476269052
LOSS train 0.48081968156463006 valid 0.522423035552349
LOSS train 0.48081968156463006 valid 0.5226162623833207
LOSS train 0.48081968156463006 valid 0.5225956008201692
LOSS train 0.48081968156463006 valid 0.5228137042626594
LOSS train 0.48081968156463006 valid 0.52276864071975
LOSS train 0.48081968156463006 valid 0.5227220223213618
LOSS train 0.48081968156463006 valid 0.5224563221326856
LOSS train 0.48081968156463006 valid 0.5223676660231181
LOSS train 0.48081968156463006 valid 0.5225519559112205
LOSS train 0.48081968156463006 valid 0.5225360782922439
LOSS train 0.48081968156463006 valid 0.5225410555170176
LOSS train 0.48081968156463006 valid 0.5224862999726678
LOSS train 0.48081968156463006 valid 0.5222745568253273
LOSS train 0.48081968156463006 valid 0.5221900760575577
LOSS train 0.48081968156463006 valid 0.5223373372433922
LOSS train 0.48081968156463006 valid 0.5222776187669247
LOSS train 0.48081968156463006 valid 0.5223637068108337
LOSS train 0.48081968156463006 valid 0.5223026332530109
LOSS train 0.48081968156463006 valid 0.5224198232409102
LOSS train 0.48081968156463006 valid 0.5225982445854325
LOSS train 0.48081968156463006 valid 0.5227897274119971
LOSS train 0.48081968156463006 valid 0.5228030128138406
LOSS train 0.48081968156463006 valid 0.5227625041537814
LOSS train 0.48081968156463006 valid 0.5226970831904791
LOSS train 0.48081968156463006 valid 0.5228420225534145
LOSS train 0.48081968156463006 valid 0.5229949739418531
LOSS train 0.48081968156463006 valid 0.522959880172946
LOSS train 0.48081968156463006 valid 0.5230815729369288
LOSS train 0.48081968156463006 valid 0.5229837184860593
LOSS train 0.48081968156463006 valid 0.5230357292397269
LOSS train 0.48081968156463006 valid 0.5228173653455251
LOSS train 0.48081968156463006 valid 0.5227964538284856
LOSS train 0.48081968156463006 valid 0.5228920538374718
LOSS train 0.48081968156463006 valid 0.5228949964551602
LOSS train 0.48081968156463006 valid 0.5228579092126355
LOSS train 0.48081968156463006 valid 0.5228165518335935
LOSS train 0.48081968156463006 valid 0.5228628945151134
LOSS train 0.48081968156463006 valid 0.5228452570736408
LOSS train 0.48081968156463006 valid 0.523012799593423
LOSS train 0.48081968156463006 valid 0.5230457546297184
LOSS train 0.48081968156463006 valid 0.5230066972504918
LOSS train 0.48081968156463006 valid 0.5230126825512432
LOSS train 0.48081968156463006 valid 0.5229719074404969
LOSS train 0.48081968156463006 valid 0.5229133658292817
LOSS train 0.48081968156463006 valid 0.523104619400704
LOSS train 0.48081968156463006 valid 0.5230937285288688
LOSS train 0.48081968156463006 valid 0.5230597566409283
LOSS train 0.48081968156463006 valid 0.5232299199104309
LOSS train 0.48081968156463006 valid 0.5231902395111631
LOSS train 0.48081968156463006 valid 0.5232881884726267
LOSS train 0.48081968156463006 valid 0.5233723669655238
LOSS train 0.48081968156463006 valid 0.5233723657337699
LOSS train 0.48081968156463006 valid 0.5233512284708958
LOSS train 0.48081968156463006 valid 0.5233113407157362
LOSS train 0.48081968156463006 valid 0.5232689788833202
LOSS train 0.48081968156463006 valid 0.5232959678468778
LOSS train 0.48081968156463006 valid 0.5233574829506598
LOSS train 0.48081968156463006 valid 0.5233477759819765
LOSS train 0.48081968156463006 valid 0.5234191817342093
LOSS train 0.48081968156463006 valid 0.5234764477678837
LOSS train 0.48081968156463006 valid 0.5235287463257068
LOSS train 0.48081968156463006 valid 0.5235089106541692
LOSS train 0.48081968156463006 valid 0.5235862925367535
LOSS train 0.48081968156463006 valid 0.5235810539776221
LOSS train 0.48081968156463006 valid 0.5235069519125121
LOSS train 0.48081968156463006 valid 0.5235149924879643
LOSS train 0.48081968156463006 valid 0.5237453373834546
LOSS train 0.48081968156463006 valid 0.5238375089786671
LOSS train 0.48081968156463006 valid 0.5239371562795886
LOSS train 0.48081968156463006 valid 0.5239406534854103
LOSS train 0.48081968156463006 valid 0.5240810873744252
LOSS train 0.48081968156463006 valid 0.524063706180475
LOSS train 0.48081968156463006 valid 0.5240293303402987
LOSS train 0.48081968156463006 valid 0.5241598646709884
LOSS train 0.48081968156463006 valid 0.5242297462177621
LOSS train 0.48081968156463006 valid 0.5241945424525858
LOSS train 0.48081968156463006 valid 0.5242727836827651
LOSS train 0.48081968156463006 valid 0.5242744454315731
LOSS train 0.48081968156463006 valid 0.5240411614183853
LOSS train 0.48081968156463006 valid 0.5239159385574624
LOSS train 0.48081968156463006 valid 0.5238069955114762
LOSS train 0.48081968156463006 valid 0.5238772408223488
LOSS train 0.48081968156463006 valid 0.5239071990314282
LOSS train 0.48081968156463006 valid 0.5238501060675907
LOSS train 0.48081968156463006 valid 0.5238279442753941
LOSS train 0.48081968156463006 valid 0.523814065174924
LOSS train 0.48081968156463006 valid 0.5238122385265918
LOSS train 0.48081968156463006 valid 0.5237940901312335
LOSS train 0.48081968156463006 valid 0.5236903455658877
LOSS train 0.48081968156463006 valid 0.5236424095418355
LOSS train 0.48081968156463006 valid 0.5236447294824359
LOSS train 0.48081968156463006 valid 0.5237299872904407
LOSS train 0.48081968156463006 valid 0.5238674808356721
LOSS train 0.48081968156463006 valid 0.5239110470220849
LOSS train 0.48081968156463006 valid 0.523862509013025
LOSS train 0.48081968156463006 valid 0.5238819160317415
LOSS train 0.48081968156463006 valid 0.5240011468380191
LOSS train 0.48081968156463006 valid 0.5239178476730982
LOSS train 0.48081968156463006 valid 0.5239593943092118
LOSS train 0.48081968156463006 valid 0.5238948446630642
LOSS train 0.48081968156463006 valid 0.5239114753483939
LOSS train 0.48081968156463006 valid 0.5238689893954679
LOSS train 0.48081968156463006 valid 0.5237808938886298
LOSS train 0.48081968156463006 valid 0.5237285751922458
LOSS train 0.48081968156463006 valid 0.5236721584385303
LOSS train 0.48081968156463006 valid 0.5237023987166294
LOSS train 0.48081968156463006 valid 0.5237364988882565
LOSS train 0.48081968156463006 valid 0.523679071087991
LOSS train 0.48081968156463006 valid 0.5235959527193542
LOSS train 0.48081968156463006 valid 0.5236453098746446
LOSS train 0.48081968156463006 valid 0.5237768025824818
LOSS train 0.48081968156463006 valid 0.5238521082006442
LOSS train 0.48081968156463006 valid 0.5239240530937437
LOSS train 0.48081968156463006 valid 0.5238476825665824
LOSS train 0.48081968156463006 valid 0.5239183780522753
LOSS train 0.48081968156463006 valid 0.5238170950855099
LOSS train 0.48081968156463006 valid 0.5239231456596649
LOSS train 0.48081968156463006 valid 0.5238083030097187
LOSS train 0.48081968156463006 valid 0.5237521877355664
LOSS train 0.48081968156463006 valid 0.5237178181454262
LOSS train 0.48081968156463006 valid 0.5235945297284023
LOSS train 0.48081968156463006 valid 0.5235587830344836
LOSS train 0.48081968156463006 valid 0.5235254637094644
LOSS train 0.48081968156463006 valid 0.5236682876304615
LOSS train 0.48081968156463006 valid 0.5236919495855267
LOSS train 0.48081968156463006 valid 0.5238198755172695
LOSS train 0.48081968156463006 valid 0.5239138241778029
LOSS train 0.48081968156463006 valid 0.5239751686652502
LOSS train 0.48081968156463006 valid 0.5239209106861644
LOSS train 0.48081968156463006 valid 0.5237721150000412
LOSS train 0.48081968156463006 valid 0.5237994159127141
LOSS train 0.48081968156463006 valid 0.5239790582549786
LOSS train 0.48081968156463006 valid 0.5239896342825534
LOSS train 0.48081968156463006 valid 0.5240837593695947
LOSS train 0.48081968156463006 valid 0.5240309796453584
LOSS train 0.48081968156463006 valid 0.5240364396536844
LOSS train 0.48081968156463006 valid 0.5238830877088867
LOSS train 0.48081968156463006 valid 0.5237993382355746
LOSS train 0.48081968156463006 valid 0.5237130059524715
LOSS train 0.48081968156463006 valid 0.5237131620708265
LOSS train 0.48081968156463006 valid 0.5237364939280919
LOSS train 0.48081968156463006 valid 0.5238351503083872
LOSS train 0.48081968156463006 valid 0.5237930474073991
LOSS train 0.48081968156463006 valid 0.5238525433347404
LOSS train 0.48081968156463006 valid 0.5238490326260283
LOSS train 0.48081968156463006 valid 0.5239430876641438
LOSS train 0.48081968156463006 valid 0.5240341761392304
LOSS train 0.48081968156463006 valid 0.5240140783786774
LOSS train 0.48081968156463006 valid 0.5239330808661262
LOSS train 0.48081968156463006 valid 0.523913411423564
LOSS train 0.48081968156463006 valid 0.5240137448729604
LOSS train 0.48081968156463006 valid 0.5240688431734419
LOSS train 0.48081968156463006 valid 0.5242007712243308
LOSS train 0.48081968156463006 valid 0.5242748026097759
LOSS train 0.48081968156463006 valid 0.5242163734275753
LOSS train 0.48081968156463006 valid 0.5241329366934366
LOSS train 0.48081968156463006 valid 0.5241774782164847
LOSS train 0.48081968156463006 valid 0.5241821553972033
LOSS train 0.48081968156463006 valid 0.5242524361676456
LOSS train 0.48081968156463006 valid 0.5243485622643107
LOSS train 0.48081968156463006 valid 0.5243816865048789
LOSS train 0.48081968156463006 valid 0.5243721997344887
LOSS train 0.48081968156463006 valid 0.5244323260163608
LOSS train 0.48081968156463006 valid 0.5244349524623058
LOSS train 0.48081968156463006 valid 0.5243652816202076
LOSS train 0.48081968156463006 valid 0.5243527452744867
LOSS train 0.48081968156463006 valid 0.5243837889132461
EPOCH 7:
  batch 1 loss: 0.46113693714141846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.49524515867233276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.4911382297674815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.48770371824502945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.48738316893577577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4833768953879674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4809935135500772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.481550607830286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.479659100373586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.47581799030303956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4749111912467263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4747059990962346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.47293804242060733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.47405936249664854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4767631431420644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4772378448396921
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4756573754198411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47639788852797615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.47790250966423437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4781636863946915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4776624355997358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.47751266847957263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4785322598789049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4778962855537732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.47761563062667844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4778427183628082
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4791444650402776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.47814808040857315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4782866558124279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.478800039490064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4786336383511943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.47924101538956165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.47861180341604986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.47900617122650146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.47994069371904646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.47991709742281174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.47906484233366475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.47835097579579605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4788472782342862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.47923762574791906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4787688720517042
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4787413023767017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4801102391509123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4804542443969033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4805427961879306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.47984832590040954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.47973255083916033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.4802870744218429
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.480386701773624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.481081126332283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.48035693227076065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.48011266726713914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.47952426604504855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.47921361636232446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4783797470006076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4786808746201651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4790490018694024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4786750468714484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4781728326264074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.47843809028466544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4784545458731104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4790355293981491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4790082219101134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.47903725085780025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4795403255866124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.47898905340469244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4788573006195809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4789017377530827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4786805627138718
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4788496166467667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4789605056735831
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.47848472081952625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4787502558264014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4786168050927085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4785412871837616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.47914580020465347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4787625852343324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4783881421272571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4784702024882353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.47821263149380683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.47813982764879864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.47797436285309675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4781565892409129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4780243131376448
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.47784337085836076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4781394344429637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.47842938667056206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4787620597264983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.47867994596449176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4787183301316367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.47852295833629566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4788560744213021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.47896155426579134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4789772287328192
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.47890212410374694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4794646582255761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.47940870720086637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4793957344123295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.47941669069155296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4795803073048592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4793831048035386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4795013236648896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4797473367556785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4796889441517683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4799289970170884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.47976912192578586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4796411395072937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.47984804323426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.47982906666370706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.47992544878612864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4796957400468019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.47976710540907724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4799361495317611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.47989739843627865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.47965674918630846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.47975576489136135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4802378935691638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4801794921947738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.480291984161409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.48000319947799047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4800627768532304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.48030932418635636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4805822779492634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4804197009052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4806196839809418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.48068856601677246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.48071747243873714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4809491450432688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4808866855248
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4810038238763809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4809061320683428
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.48082670163024555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4808163965555062
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.48071810758825556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4806252170492102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4806575827738818
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.480877102291497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.48072048827357916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.48093733877586803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4809955633112362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4808956063385551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4809216325971442
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.481073476843067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4812848938422071
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.48138623422589794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4812345749711337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4814110491551509
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.48160060756915324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48151153066014285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4812677597999573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4813231857407172
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.48134435301548556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4813487728436788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4812784516192102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.48149569919032437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4817601732718639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4817140051134073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4818684581337096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4820412639177071
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4821126747876406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.48198821141112663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.48190442150757634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.48191106520547455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4818786493525272
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.48179199840083264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.48194064217877675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.48192802089417053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4816427787854558
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.48160788134710325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4817019909620285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.48159059010751065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4815148338675499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.481349669612212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4814135055432374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.481271310874394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.48113637332889164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.48105135459010884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4810252057367496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4810762656800574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.48105972127781976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.480996151326111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.48096626407497534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.480885265466294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4808611288342787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.48094267587403994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4808693194902071
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4808114749543807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.48068214255444547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4806794287666442
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4805792005438554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.48046266814176947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4802103281642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.48028718251638464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.48034004636646543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4802410501700181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4802404132728674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.48038101271929473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4805636148561131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4805672316994499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4805966682732105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.48055748708212553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.48054579018366217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4803493847987922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4803429774793924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.48029046785540697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4800378616573741
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.47996223174431474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4798152797783797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.48003956276263915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4800751152492705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4800867356395269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4802798111483736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4803036115538906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4801633493087002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4802208477674529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4801139065788852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.480191065144429
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.48042860791223857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.48068381743888333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4807596736333587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4805778635842768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4804742563146729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4805479117840395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4806183235985892
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.48044246488147313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.48032511361932334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.48031880755781603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.48012852198199224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.48004822400459557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.48015852920387103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.48009002376428417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.48021567908340484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4801103745151487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4801278102856416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4801948546095097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.48018137794935095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4801875467290355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.480104683953173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.48008321917705454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4801430977880955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4802122207598073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4801314665266305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.48025225857157766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.48027899433843424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.480361327954701
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.48054516424493093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.48058873608044766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4804841438608785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.48063105225084296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.480684415102005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4807314450047406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.48073614116698976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4808180002355764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.48072970077747434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4806537027452506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4806721081258729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4805326461791992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.48053250756374627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4807826193143042
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4808611484674307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4808659345710871
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.48078187242264053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4808017007524976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.48084647208452225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48069845482988177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.48073723038336386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.48077050219760853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4806877490299851
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.48062995463942065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4806523206057372
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.48066618389749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.480574375785449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.48052010922641547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4802725564171798
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4800765813480724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4801199194313823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.48017840630741326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4801578275162539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4801701398092359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4801857981298651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.48021691740619754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4802173674106598
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4801714805747932
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.48019693214708653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.48023926218350727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4802485005213664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.48024982598185123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4802953815087676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.48023020901482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4802843851262125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.48023970194698606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4802501577220551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.480303314358708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.48040320556990956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.48039620033765246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.48038841592701703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.48047154810693526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.48044572010536324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4803929633918813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4803603466351827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4804734062910872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.480371660941484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.480323992448278
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.48037644975671645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4804495660007977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.48042740999094025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4804050626312094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.48044824087387555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.48051507409336497
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4804980198221822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4805706322576455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.48048195758691203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4804070184406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.48029258315730244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.48025800330298285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.48034099668641633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4804025294276818
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4804265853369011
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4804450422058285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4805369351990521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4804262017535272
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.48047087272131667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.48065419859561387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.48062365814859487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.48058988075989945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4806192025450841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4806767205397288
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4807361705092395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4806715628658747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4807346555319699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4808292889523002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.48080224059073323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.48082173864046734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.48076438038292046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.48076117492433806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.48083854298151674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.48075705819738374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.48072469463715184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4806167245966143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.480681792252204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4806713408563843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.480714131255596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.48061624134594777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.48059707334221796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.48060226690941965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.48069637746824695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.48072375765107894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4807837078797406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4807296208290111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4807238758461816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.48065163190887866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4806508906185627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4807263291928991
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.48068237085800386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.48065474579032036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4805463965186912
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.48054672948786525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4806522644598391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4806146331152212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.48052070952124065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4804650545120239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4805146974423972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.48055422338900816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4804673113010742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.48048969098966415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.48043830831194184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.48040064024340556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.48041420259877393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.48037733505088787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4803852753059284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.48038783139295654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.48035174119536594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.48041322875278564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.48041239516301587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.48041101988156637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.480393667487388
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.48042608335100373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.48050023386718105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.48053976382303365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4804581797436664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4804474677000772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.48038772840774496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4804677863656385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4804858479959269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4804723067717119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.480552417008988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.48050822244442093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.48059905113018664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.48058037210859184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.48058545176799483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.48057609171513704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.48059037738308613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.48058566579988593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4805586008251016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.48048783450187005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.480535825620396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4805947200627411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.480697573054975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4807667166816262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4807535807043314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.48067580806346905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4805397481022783
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.48050472184682896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.48045328281598515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4804836448327995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4805355936729262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4804914852910897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4804847678717445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4804285103068084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.48043098820418845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4804990003723878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.480548157202966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.48048395358621354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.48062431502745345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.48069235050534626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4807826607989577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4807485038285061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4807568540413414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.48082079807727607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4807963686329978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4809143442722511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.48102054084646756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4809568008632525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4809941974872688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.48096161786247704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4808692676080784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4808618980492585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.48077379793764274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4806857154919551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4807730024637178
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4807190159357341
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4807172942630671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4806505731429569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4806798183560921
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.48058940069428807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.48068883516099475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4806767217218194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4806305600083582
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4805545339823312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4805297706614841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4805667905174956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4805542027653612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4805762952794878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.48050981484823396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.48065580591726836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.48057600688773955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4806792444697429
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.48071038350462914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.48070803410757357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4806833294365141
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4806348290913914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4806817803630787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4806429043116159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4806081533169431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4806040949873872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4805298212981015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.48048583951246815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4805093442118324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.48045326350561157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4805632055453632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.480546529277545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4805384400861088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.48055015642751114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.48056819469764317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4805398601357655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4805498639273541
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4805102585086986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.48059452847283113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.48062409984785864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4807199179492098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4807178212958536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.480765217378483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.480765217378483 valid 0.4843919575214386
LOSS train 0.480765217378483 valid 0.4992773085832596
LOSS train 0.480765217378483 valid 0.4971960683663686
LOSS train 0.480765217378483 valid 0.49306004494428635
LOSS train 0.480765217378483 valid 0.48790871500968935
LOSS train 0.480765217378483 valid 0.4934728493293126
LOSS train 0.480765217378483 valid 0.5002218101705823
LOSS train 0.480765217378483 valid 0.5026285462081432
LOSS train 0.480765217378483 valid 0.5044265555010902
LOSS train 0.480765217378483 valid 0.5085811704397202
LOSS train 0.480765217378483 valid 0.511972186240283
LOSS train 0.480765217378483 valid 0.5108947679400444
LOSS train 0.480765217378483 valid 0.51539745926857
LOSS train 0.480765217378483 valid 0.5176616417510169
LOSS train 0.480765217378483 valid 0.518993761142095
LOSS train 0.480765217378483 valid 0.5169917065650225
LOSS train 0.480765217378483 valid 0.5193603231626398
LOSS train 0.480765217378483 valid 0.5197470535834631
LOSS train 0.480765217378483 valid 0.5186820359606492
LOSS train 0.480765217378483 valid 0.5197158351540565
LOSS train 0.480765217378483 valid 0.5195016648088183
LOSS train 0.480765217378483 valid 0.5181843218478289
LOSS train 0.480765217378483 valid 0.5183099080686984
LOSS train 0.480765217378483 valid 0.5172194850941499
LOSS train 0.480765217378483 valid 0.5159996640682221
LOSS train 0.480765217378483 valid 0.5144308243806546
LOSS train 0.480765217378483 valid 0.5140444382473275
LOSS train 0.480765217378483 valid 0.514665428016867
LOSS train 0.480765217378483 valid 0.513686211972401
LOSS train 0.480765217378483 valid 0.5151194363832474
LOSS train 0.480765217378483 valid 0.5163866579532623
LOSS train 0.480765217378483 valid 0.5166955245658755
LOSS train 0.480765217378483 valid 0.5180247868552352
LOSS train 0.480765217378483 valid 0.5188574852312312
LOSS train 0.480765217378483 valid 0.5204755280699048
LOSS train 0.480765217378483 valid 0.5209034159779549
LOSS train 0.480765217378483 valid 0.5212291358290492
LOSS train 0.480765217378483 valid 0.5216764909656424
LOSS train 0.480765217378483 valid 0.5215591352719527
LOSS train 0.480765217378483 valid 0.5221569456160069
LOSS train 0.480765217378483 valid 0.5222515907229447
LOSS train 0.480765217378483 valid 0.5222012819278807
LOSS train 0.480765217378483 valid 0.5221908640029819
LOSS train 0.480765217378483 valid 0.5222808576442979
LOSS train 0.480765217378483 valid 0.5222220387723711
LOSS train 0.480765217378483 valid 0.5229465255270833
LOSS train 0.480765217378483 valid 0.52303554085975
LOSS train 0.480765217378483 valid 0.5239103529602289
LOSS train 0.480765217378483 valid 0.5250576983909218
LOSS train 0.480765217378483 valid 0.524430610537529
LOSS train 0.480765217378483 valid 0.5251552211303337
LOSS train 0.480765217378483 valid 0.5255622101517824
LOSS train 0.480765217378483 valid 0.5253855119336326
LOSS train 0.480765217378483 valid 0.5247768417552665
LOSS train 0.480765217378483 valid 0.5248139923269098
LOSS train 0.480765217378483 valid 0.524477485035147
LOSS train 0.480765217378483 valid 0.5240600642405058
LOSS train 0.480765217378483 valid 0.5242050516194311
LOSS train 0.480765217378483 valid 0.5248202843181158
LOSS train 0.480765217378483 valid 0.5242899109919866
LOSS train 0.480765217378483 valid 0.5230335407569761
LOSS train 0.480765217378483 valid 0.5231574370015052
LOSS train 0.480765217378483 valid 0.5229817647782583
LOSS train 0.480765217378483 valid 0.5234099067747593
LOSS train 0.480765217378483 valid 0.5237280744772691
LOSS train 0.480765217378483 valid 0.5230372457793264
LOSS train 0.480765217378483 valid 0.5228203232608625
LOSS train 0.480765217378483 valid 0.5227894879439298
LOSS train 0.480765217378483 valid 0.5227727622225664
LOSS train 0.480765217378483 valid 0.5220814313207354
LOSS train 0.480765217378483 valid 0.521533617671107
LOSS train 0.480765217378483 valid 0.5213254085845418
LOSS train 0.480765217378483 valid 0.521779621300632
LOSS train 0.480765217378483 valid 0.52103602201552
LOSS train 0.480765217378483 valid 0.5210279206434886
LOSS train 0.480765217378483 valid 0.521296560372177
LOSS train 0.480765217378483 valid 0.5211600750297695
LOSS train 0.480765217378483 valid 0.5212030162413915
LOSS train 0.480765217378483 valid 0.520856328780138
LOSS train 0.480765217378483 valid 0.5207335885614157
LOSS train 0.480765217378483 valid 0.5203032136699299
LOSS train 0.480765217378483 valid 0.5203949391115003
LOSS train 0.480765217378483 valid 0.5200885929257036
LOSS train 0.480765217378483 valid 0.5201621048507237
LOSS train 0.480765217378483 valid 0.5198320139856899
LOSS train 0.480765217378483 valid 0.5195400576258815
LOSS train 0.480765217378483 valid 0.5194506220433904
LOSS train 0.480765217378483 valid 0.5194933793761514
LOSS train 0.480765217378483 valid 0.5196148478583004
LOSS train 0.480765217378483 valid 0.5200881560643514
LOSS train 0.480765217378483 valid 0.5202380615276295
LOSS train 0.480765217378483 valid 0.5200878329899
LOSS train 0.480765217378483 valid 0.5198666696907371
LOSS train 0.480765217378483 valid 0.5197364148941446
LOSS train 0.480765217378483 valid 0.5195317174258985
LOSS train 0.480765217378483 valid 0.5194710536549488
LOSS train 0.480765217378483 valid 0.5195351636286863
LOSS train 0.480765217378483 valid 0.5192774847453955
LOSS train 0.480765217378483 valid 0.5197979479727118
LOSS train 0.480765217378483 valid 0.5200359430909157
LOSS train 0.480765217378483 valid 0.5199111030243411
LOSS train 0.480765217378483 valid 0.5199686618996602
LOSS train 0.480765217378483 valid 0.5202896285404279
LOSS train 0.480765217378483 valid 0.5204695104979552
LOSS train 0.480765217378483 valid 0.5206369295006706
LOSS train 0.480765217378483 valid 0.5208011508550284
LOSS train 0.480765217378483 valid 0.5206693346812347
LOSS train 0.480765217378483 valid 0.5206198463285411
LOSS train 0.480765217378483 valid 0.5208303887362874
LOSS train 0.480765217378483 valid 0.5211820615963503
LOSS train 0.480765217378483 valid 0.5210863563928518
LOSS train 0.480765217378483 valid 0.5209592886801276
LOSS train 0.480765217378483 valid 0.5211498650301875
LOSS train 0.480765217378483 valid 0.520660886377619
LOSS train 0.480765217378483 valid 0.5207044759522313
LOSS train 0.480765217378483 valid 0.5209847424050857
LOSS train 0.480765217378483 valid 0.5208455958427527
LOSS train 0.480765217378483 valid 0.5207346584332191
LOSS train 0.480765217378483 valid 0.5206384415886983
LOSS train 0.480765217378483 valid 0.5206103372077148
LOSS train 0.480765217378483 valid 0.5204259405943973
LOSS train 0.480765217378483 valid 0.520219828505985
LOSS train 0.480765217378483 valid 0.520307285272009
LOSS train 0.480765217378483 valid 0.5205064235675719
LOSS train 0.480765217378483 valid 0.520705600976944
LOSS train 0.480765217378483 valid 0.5207313008251644
LOSS train 0.480765217378483 valid 0.52093736322846
LOSS train 0.480765217378483 valid 0.5211917429696769
LOSS train 0.480765217378483 valid 0.5213216235933378
LOSS train 0.480765217378483 valid 0.5212474022920315
LOSS train 0.480765217378483 valid 0.5212693021042656
LOSS train 0.480765217378483 valid 0.5210097574374892
LOSS train 0.480765217378483 valid 0.5209366788989619
LOSS train 0.480765217378483 valid 0.5208902770458762
LOSS train 0.480765217378483 valid 0.5210185706615448
LOSS train 0.480765217378483 valid 0.5210156026570236
LOSS train 0.480765217378483 valid 0.5207717788480494
LOSS train 0.480765217378483 valid 0.5204965446306311
LOSS train 0.480765217378483 valid 0.5204078919595951
LOSS train 0.480765217378483 valid 0.5204331346920559
LOSS train 0.480765217378483 valid 0.5205986055922001
LOSS train 0.480765217378483 valid 0.5207592647680095
LOSS train 0.480765217378483 valid 0.5206591032601736
LOSS train 0.480765217378483 valid 0.5206721483005418
LOSS train 0.480765217378483 valid 0.5203909795859765
LOSS train 0.480765217378483 valid 0.5206890473627064
LOSS train 0.480765217378483 valid 0.5204176850059405
LOSS train 0.480765217378483 valid 0.5208008543059632
LOSS train 0.480765217378483 valid 0.5207103714846925
LOSS train 0.480765217378483 valid 0.5208419171969095
LOSS train 0.480765217378483 valid 0.5208361452778444
LOSS train 0.480765217378483 valid 0.5205576549235144
LOSS train 0.480765217378483 valid 0.5205145758741042
LOSS train 0.480765217378483 valid 0.5206462887974529
LOSS train 0.480765217378483 valid 0.520571901721339
LOSS train 0.480765217378483 valid 0.5209894860402132
LOSS train 0.480765217378483 valid 0.5209773034806464
LOSS train 0.480765217378483 valid 0.5210680991788453
LOSS train 0.480765217378483 valid 0.5208361735508876
LOSS train 0.480765217378483 valid 0.5207718102261424
LOSS train 0.480765217378483 valid 0.5209747406636706
LOSS train 0.480765217378483 valid 0.5208305063439004
LOSS train 0.480765217378483 valid 0.5207615653795699
LOSS train 0.480765217378483 valid 0.5206076737220694
LOSS train 0.480765217378483 valid 0.5203420185681545
LOSS train 0.480765217378483 valid 0.5201117635132319
LOSS train 0.480765217378483 valid 0.5203157707959593
LOSS train 0.480765217378483 valid 0.5205018213462262
LOSS train 0.480765217378483 valid 0.520604347865257
LOSS train 0.480765217378483 valid 0.5206430987400167
LOSS train 0.480765217378483 valid 0.5209132368453064
LOSS train 0.480765217378483 valid 0.5210397584840308
LOSS train 0.480765217378483 valid 0.5211095766869583
LOSS train 0.480765217378483 valid 0.5211561663054872
LOSS train 0.480765217378483 valid 0.52124236702919
LOSS train 0.480765217378483 valid 0.5213634133000266
LOSS train 0.480765217378483 valid 0.5215206791115345
LOSS train 0.480765217378483 valid 0.5217819426501735
LOSS train 0.480765217378483 valid 0.5218752953926278
LOSS train 0.480765217378483 valid 0.5219190761446952
LOSS train 0.480765217378483 valid 0.5219574908195939
LOSS train 0.480765217378483 valid 0.5220025058958556
LOSS train 0.480765217378483 valid 0.521958551934508
LOSS train 0.480765217378483 valid 0.5220024004254652
LOSS train 0.480765217378483 valid 0.5219171702861786
LOSS train 0.480765217378483 valid 0.5219810869424574
LOSS train 0.480765217378483 valid 0.5222034774680826
LOSS train 0.480765217378483 valid 0.5222506632513189
LOSS train 0.480765217378483 valid 0.5220852000688119
LOSS train 0.480765217378483 valid 0.5219920796783347
LOSS train 0.480765217378483 valid 0.5222688228360022
LOSS train 0.480765217378483 valid 0.5224071838892996
LOSS train 0.480765217378483 valid 0.5224569966447168
LOSS train 0.480765217378483 valid 0.5222937532306946
LOSS train 0.480765217378483 valid 0.5220596078114632
LOSS train 0.480765217378483 valid 0.5220486871442016
LOSS train 0.480765217378483 valid 0.5221103199847459
LOSS train 0.480765217378483 valid 0.5220013468554525
LOSS train 0.480765217378483 valid 0.5221231133494545
LOSS train 0.480765217378483 valid 0.522137730717659
LOSS train 0.480765217378483 valid 0.5220067931051872
LOSS train 0.480765217378483 valid 0.5220853491584854
LOSS train 0.480765217378483 valid 0.5219957065112485
LOSS train 0.480765217378483 valid 0.5221843035782084
LOSS train 0.480765217378483 valid 0.5221650937708413
LOSS train 0.480765217378483 valid 0.5223838791106511
LOSS train 0.480765217378483 valid 0.5223401635165376
LOSS train 0.480765217378483 valid 0.5222895847490201
LOSS train 0.480765217378483 valid 0.5220256021433469
LOSS train 0.480765217378483 valid 0.5219374800012225
LOSS train 0.480765217378483 valid 0.5221200199771266
LOSS train 0.480765217378483 valid 0.5221056247938354
LOSS train 0.480765217378483 valid 0.5221108845981633
LOSS train 0.480765217378483 valid 0.5220539930546395
LOSS train 0.480765217378483 valid 0.5218433703100959
LOSS train 0.480765217378483 valid 0.5217628251347277
LOSS train 0.480765217378483 valid 0.5219113847352392
LOSS train 0.480765217378483 valid 0.521848920151728
LOSS train 0.480765217378483 valid 0.5219351705078665
LOSS train 0.480765217378483 valid 0.5218757974830541
LOSS train 0.480765217378483 valid 0.5219926746452556
LOSS train 0.480765217378483 valid 0.5221729475904155
LOSS train 0.480765217378483 valid 0.5223652719114928
LOSS train 0.480765217378483 valid 0.5223768772557378
LOSS train 0.480765217378483 valid 0.5223367212878334
LOSS train 0.480765217378483 valid 0.5222712126189628
LOSS train 0.480765217378483 valid 0.5224164956729318
LOSS train 0.480765217378483 valid 0.5225684152621972
LOSS train 0.480765217378483 valid 0.5225329405615944
LOSS train 0.480765217378483 valid 0.5226556367200353
LOSS train 0.480765217378483 valid 0.5225570068988965
LOSS train 0.480765217378483 valid 0.5226122537820503
LOSS train 0.480765217378483 valid 0.5223941203094858
LOSS train 0.480765217378483 valid 0.5223709035378236
LOSS train 0.480765217378483 valid 0.5224659981879782
LOSS train 0.480765217378483 valid 0.5224680000190007
LOSS train 0.480765217378483 valid 0.5224311984289548
LOSS train 0.480765217378483 valid 0.5223897809491438
LOSS train 0.480765217378483 valid 0.5224370286803864
LOSS train 0.480765217378483 valid 0.5224185857921839
LOSS train 0.480765217378483 valid 0.522583002247751
LOSS train 0.480765217378483 valid 0.5226157567471512
LOSS train 0.480765217378483 valid 0.5225776680457739
LOSS train 0.480765217378483 valid 0.5225833357601869
LOSS train 0.480765217378483 valid 0.5225444164811348
LOSS train 0.480765217378483 valid 0.5224861860032973
LOSS train 0.480765217378483 valid 0.5226773572595496
LOSS train 0.480765217378483 valid 0.5226649193754119
LOSS train 0.480765217378483 valid 0.5226327399891543
LOSS train 0.480765217378483 valid 0.522802014708519
LOSS train 0.480765217378483 valid 0.522763451613278
LOSS train 0.480765217378483 valid 0.5228620208208523
LOSS train 0.480765217378483 valid 0.5229472858396914
LOSS train 0.480765217378483 valid 0.5229488516182411
LOSS train 0.480765217378483 valid 0.5229286328250287
LOSS train 0.480765217378483 valid 0.522888497565873
LOSS train 0.480765217378483 valid 0.5228475115410549
LOSS train 0.480765217378483 valid 0.522876459614251
LOSS train 0.480765217378483 valid 0.5229377084947461
LOSS train 0.480765217378483 valid 0.522931075669252
LOSS train 0.480765217378483 valid 0.5230033910365853
LOSS train 0.480765217378483 valid 0.5230613224606477
LOSS train 0.480765217378483 valid 0.523114816430857
LOSS train 0.480765217378483 valid 0.5230924102167288
LOSS train 0.480765217378483 valid 0.5231706123307066
LOSS train 0.480765217378483 valid 0.523165549886854
LOSS train 0.480765217378483 valid 0.523090395030011
LOSS train 0.480765217378483 valid 0.5230956803729285
LOSS train 0.480765217378483 valid 0.5233260901665598
LOSS train 0.480765217378483 valid 0.523418410508721
LOSS train 0.480765217378483 valid 0.5235179331689743
LOSS train 0.480765217378483 valid 0.5235220449154868
LOSS train 0.480765217378483 valid 0.5236635265987871
LOSS train 0.480765217378483 valid 0.5236476908852584
LOSS train 0.480765217378483 valid 0.5236103234507821
LOSS train 0.480765217378483 valid 0.5237408300888711
LOSS train 0.480765217378483 valid 0.5238124296768477
LOSS train 0.480765217378483 valid 0.5237761359635017
LOSS train 0.480765217378483 valid 0.5238547531293711
LOSS train 0.480765217378483 valid 0.5238565758935043
LOSS train 0.480765217378483 valid 0.5236248271108946
LOSS train 0.480765217378483 valid 0.5234988510397309
LOSS train 0.480765217378483 valid 0.5233902534200109
LOSS train 0.480765217378483 valid 0.5234603091654643
LOSS train 0.480765217378483 valid 0.5234912482270023
LOSS train 0.480765217378483 valid 0.5234349268924939
LOSS train 0.480765217378483 valid 0.5234127550382648
LOSS train 0.480765217378483 valid 0.5233999936737948
LOSS train 0.480765217378483 valid 0.5233956568175121
LOSS train 0.480765217378483 valid 0.5233774095773697
LOSS train 0.480765217378483 valid 0.5232737505763667
LOSS train 0.480765217378483 valid 0.5232265570188221
LOSS train 0.480765217378483 valid 0.5232296202573353
LOSS train 0.480765217378483 valid 0.5233163530526518
LOSS train 0.480765217378483 valid 0.5234539546198764
LOSS train 0.480765217378483 valid 0.5234986403705301
LOSS train 0.480765217378483 valid 0.5234496056632161
LOSS train 0.480765217378483 valid 0.5234694379888125
LOSS train 0.480765217378483 valid 0.5235883963347279
LOSS train 0.480765217378483 valid 0.5235046296318372
LOSS train 0.480765217378483 valid 0.5235463025363973
LOSS train 0.480765217378483 valid 0.523482232792488
LOSS train 0.480765217378483 valid 0.5234992666409748
LOSS train 0.480765217378483 valid 0.5234557340215695
LOSS train 0.480765217378483 valid 0.523368212238687
LOSS train 0.480765217378483 valid 0.5233162343502045
LOSS train 0.480765217378483 valid 0.5232613855542112
LOSS train 0.480765217378483 valid 0.5232900793289209
LOSS train 0.480765217378483 valid 0.5233250804317807
LOSS train 0.480765217378483 valid 0.5232669884158719
LOSS train 0.480765217378483 valid 0.5231849127643745
LOSS train 0.480765217378483 valid 0.5232349515725405
LOSS train 0.480765217378483 valid 0.5233650687403573
LOSS train 0.480765217378483 valid 0.5234404954181355
LOSS train 0.480765217378483 valid 0.5235119236840142
LOSS train 0.480765217378483 valid 0.5234339750265773
LOSS train 0.480765217378483 valid 0.5235045708316358
LOSS train 0.480765217378483 valid 0.5234037632087492
LOSS train 0.480765217378483 valid 0.5235091311430856
LOSS train 0.480765217378483 valid 0.5233928319066763
LOSS train 0.480765217378483 valid 0.5233371144514589
LOSS train 0.480765217378483 valid 0.5233036203784232
LOSS train 0.480765217378483 valid 0.5231804554307424
LOSS train 0.480765217378483 valid 0.5231418192018698
LOSS train 0.480765217378483 valid 0.5231092757445115
LOSS train 0.480765217378483 valid 0.523250737438904
LOSS train 0.480765217378483 valid 0.5232760087794849
LOSS train 0.480765217378483 valid 0.523402767210472
LOSS train 0.480765217378483 valid 0.5234962582225857
LOSS train 0.480765217378483 valid 0.5235564614787246
LOSS train 0.480765217378483 valid 0.5235016162301839
LOSS train 0.480765217378483 valid 0.5233508032488535
LOSS train 0.480765217378483 valid 0.5233767100640604
LOSS train 0.480765217378483 valid 0.523555198472417
LOSS train 0.480765217378483 valid 0.523563964331328
LOSS train 0.480765217378483 valid 0.5236586793547585
LOSS train 0.480765217378483 valid 0.5236054259167227
LOSS train 0.480765217378483 valid 0.5236119030142677
LOSS train 0.480765217378483 valid 0.523459702378529
LOSS train 0.480765217378483 valid 0.5233758880811579
LOSS train 0.480765217378483 valid 0.523288909378639
LOSS train 0.480765217378483 valid 0.5232894775288844
LOSS train 0.480765217378483 valid 0.5233127439161084
LOSS train 0.480765217378483 valid 0.5234112665923529
LOSS train 0.480765217378483 valid 0.5233675085116124
LOSS train 0.480765217378483 valid 0.5234269572992545
LOSS train 0.480765217378483 valid 0.5234249978828155
LOSS train 0.480765217378483 valid 0.5235194862745274
LOSS train 0.480765217378483 valid 0.5236099214642642
LOSS train 0.480765217378483 valid 0.5235890581778118
LOSS train 0.480765217378483 valid 0.5235082496944655
LOSS train 0.480765217378483 valid 0.5234887911514803
LOSS train 0.480765217378483 valid 0.5235894786737458
LOSS train 0.480765217378483 valid 0.5236426494215841
LOSS train 0.480765217378483 valid 0.5237741544213094
LOSS train 0.480765217378483 valid 0.5238481232624376
LOSS train 0.480765217378483 valid 0.5237902150768525
LOSS train 0.480765217378483 valid 0.523706193576312
LOSS train 0.480765217378483 valid 0.5237502468993737
LOSS train 0.480765217378483 valid 0.5237549054953787
LOSS train 0.480765217378483 valid 0.5238244802667824
LOSS train 0.480765217378483 valid 0.5239218364762996
LOSS train 0.480765217378483 valid 0.5239544886859652
LOSS train 0.480765217378483 valid 0.5239456964063121
LOSS train 0.480765217378483 valid 0.5240062066953476
LOSS train 0.480765217378483 valid 0.5240073205669069
LOSS train 0.480765217378483 valid 0.5239368574820682
LOSS train 0.480765217378483 valid 0.5239241827765236
LOSS train 0.480765217378483 valid 0.5239540970099328
EPOCH 8:
  batch 1 loss: 0.465351402759552
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.49329766631126404
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.49317113558451336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.49010763317346573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.489558607339859
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4850408285856247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4823895352227347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.48360322415828705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4809301594893138
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4769199311733246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.47595063935626636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.47530054797728855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4734692367223593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.47461873080049244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.47763428489367166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.47796793282032013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.47647279150345745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.476552782787217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.47847469386301544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4787092790007591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4781876376696995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.47796557166359643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.478988123976666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4786231443285942
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.47832384824752805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4784531398461415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4795360819057182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4786142972963197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.47863333081376963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.47898085713386535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.47900667017506016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.47944790311157703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4784702622529232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.47882264414254355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.47965135318892343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.47942772259314853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4785346404926197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.47776888938326584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4780415151363764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.47827462926507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4777255349042939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.47760745882987976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.47906703311343524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4794612316922708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4798350539472368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.47918610663517663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.47921803086361986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.47979198085765046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.47987198890471944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.48069570600986483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4800145830593857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4797097289791474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.47918583143432186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4788919869396422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4781158831986514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.47832395508885384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.47855356440209507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.47807433224957563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4776249573392383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4780818268656731
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.478119214538668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4788766113981124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4789216045349363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.47895143181085587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4793170773066007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4786412137927431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4784505981117932
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.478595293181784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.47838212225748145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.47840906594480787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.47852412411864376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4781046426958508
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4782338224045218
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4781648085729496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.47795753240585326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4785151050279015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.47823417883414726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.47799177353198713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.478085086315493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.47788289450109006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4779553137443684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.47768326539818834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.47782705167689954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4776843356944266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.47767226906383736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.47795779206031974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.47819486979780523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.47847225720232184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4784616352467055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4784076591332754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.47827076453429
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.47859840742919757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.47881944749944955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.47890138911440017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.47887709579969706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4793440445015828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4792590599084638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.47932921106718024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.47950994577070677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.47962650179862976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4794932234995436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.479639283582276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.479764903054654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4797497775692206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.47993727865673247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4797056013683103
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.47960661616280814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.47978680829207104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4797488694344092
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4798877320506356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4796905010133176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4798310250043869
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.47996558763284597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4798411235474704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4795566939789316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.47966233615217535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.48008699091071755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4800378306437347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4802054292013665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.47991261606415114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.47990573437745904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4801178388908261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.48034706251408027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.48019158792111183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4803877034187317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.48045906117038123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.48039238706348447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4806395471096039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4805292175259701
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4806773045888314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.48057174091120713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4804699113874724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.48046667504131346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4803514989899166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.48027813876116715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4802539221504155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.480454698531297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4802802218043286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4804782339994856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4805300257035664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4804558963217634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4804834305820331
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4805449566224238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.48072377654413384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.48075613667225015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4805864720311883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.48077657757973186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4810014069080353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48088212861310714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4806324541568756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.48067519305557604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.48065617406054545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.48069136360891507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4806182639939444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.480845211398217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4810304443041484
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.48097745343378395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.48108561865136595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4812555378712948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4813327187672257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.48121224297499804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.48109220225869875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.48113156224321
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.48106928987473974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.48096892996267837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4810904050806919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.48111297306186424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4808496061180319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.480829760696761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.48090957964167874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4808017609760775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4806989512817804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4805763286317704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4806683258763675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.48052888529641286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4804509458216754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.48037693695833455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4804056236583195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4804866904985971
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4804859850141737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.48041441180429406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.48038357954758865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4802563701822458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.48020553718442505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4802964645463067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4802022262286114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.48010051234520695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.479976549903129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.47994488698464854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4798444710279766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.47974417986670087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.47951242374256253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4795461808152767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.47960835034699784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4795021462134826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.47946830702071286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.47955131757682956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4796973691143171
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4797132693642947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.479732496291399
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.47971734760412527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4797213787194526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.47954696226002547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.47953414887774226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4795022702798611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.47928798806320116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4792117891104325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.47908819294892824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.47928069738680096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.47929853527318866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.47930723358104577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.479528915347918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4795435472553325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4794500691589908
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4795305423958357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.47942816962798435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.47946435103218676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.47966335618167844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.47992822895311327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.48001258942213926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.47985357032642106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4797866595489485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.47983068348046376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.47988778206386734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.47970794479052226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.479605920415009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.47962421651453696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4794601446442437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4794034508898789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.47954919688079667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4795208014709093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4796877961991162
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4795368298440532
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4795768809878928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.47966285424029576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.47965703664694803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.47967528856756314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.47960756543804617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4795970484053241
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4796798566977183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4797595104983239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4796682987823959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4797927624404185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.47980619893699394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.47992751184774907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.48009569373557237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4801371988014654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.48002276677758465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4801911751189864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.48019669008255006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.48025523951329085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4802590532908364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4803168058630977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4802375598920612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4801844072108175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.48020147474016994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.48008573901792445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4800540861464286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.48029745373026284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.48039897554195843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.48041059790443186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.4803150353085904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4803243338381836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.48034430837089365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48021755668352234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4802407711968386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.48022373405735147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4801428459251105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4801166125168144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.48013402576799746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.48015142058974264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4800242089173373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4799387676593585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.47971077132834133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.47953654365106063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4796260350208352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4796626416139224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.47957202910090524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4795980510104942
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4796165854803153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.47967714453082916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4797137287702966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4796739239574742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4797054405363513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4797361481608006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4797511570728742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.4797554646427208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.47977802478190923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.47974682328610274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4798406265932938
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.47978257559419085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.47982351624802366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4798761546204928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.47997503388090196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4799575679383035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4799395885217834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.48000848905406013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.47997012514396004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4799055207931876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.47989329079786935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4800075128228957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.47990651537251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4798705289662868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4798847993737773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.47993636658934297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.47990868313639773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4798750892912526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4799155422619411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4799853395489813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4799344043577871
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4800346005001252
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.47993832520949536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.47988007767512775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4798007729896315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.47975834068797885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4798516764105121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4798907776736311
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4799021911696068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.47991280290400345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.47998418249189856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4798566284952134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.47993845210312314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.48009131235234875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.48007269737161234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4800608427707966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4800840510181123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.48011745808685957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4801942418988158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4801264119909165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.48020865998484874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4802914406777869
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4802658707801118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4803153135039069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.48026316894028714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4802371327556781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4803028280536334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4801959576698722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4801538180141054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4800746789899899
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.48013223751502876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.48012234012751986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.48015663350186155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.48006034236260126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.480035308401945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4800547684448353
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.48010554832185626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.48017703396099104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.48022030508038643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4801720996470028
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.48014532114778247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4800663366276994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4800786337899891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.48015336367293726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4801156903054081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4801024533493418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4800215825605928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4800356239163909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4801283235656483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4801039089731519
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.47999630578690106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4799321741278482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4799785944967639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4800134993289128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.47992323085174454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4799578611164877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.47990703965471093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.479865782186186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.47988515169076296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.47986553443802726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.479890059860977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4799040204913147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.47988686654516444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.47993598834439194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4799235402581526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4799240294297536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.47990443993439064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.47989856730405467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4799909073682058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4800142807035773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4799522462644075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.47994079653985233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4798517096885212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.47993488917151567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.47996994845258695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4799524171785875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.48005773435911364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.48002386208652525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4801032898813179
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4800745270246099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.480090587414228
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.48008651219670423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4800989710706837
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.48008812345924573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.48009236988984993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.48001775251159184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4800820539545531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.480125235970735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.4802237841951188
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4802911696876201
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.48027210861444475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.48019518058496224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.48006171329104486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.48004506021812005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4800192869388231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4800345751238458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.48008311433451517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4800385849628167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4800264432880224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4799664963428432
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.47995555022867714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.48002613460930593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.480075002729314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4800135496164927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4801409962960487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.48024524622652903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4803196739118833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4802784964049177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.48027295337624526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.48031298833985886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.48029349481775646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.48042906909260785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4805433957073926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.48045411269151855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.48048314501373274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.48044263145502875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.48033179139867077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.48033898315050005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.48027069163378155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4801721766695276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4802728302950083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4802292399367711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4802628929416339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4801859468841112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4802180819797076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.48012728403354515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4802487425574469
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.48025200139194113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.48019497287055674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4801141482550897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4801041159440171
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.48013946251804324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.48012769458250765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.48015355290193323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.48006710202038827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4802059042989538
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4800987661953999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.48020550375283433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4802632338500449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.48028024559828114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.48024417016241283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4801974926317346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4802417393147418
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4801903696644385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4801338884142527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4801386169024876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4800693641106288
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4800266011799451
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.48002959970043213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.47998230071628795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.48010571579570355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.48007075886147144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.480067278077076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.48009241470507874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4801086911225113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.48007984808696214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.48010821570142653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.48008266199834854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4801491481116694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4801774246097882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4802726390513968
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.48026678143286655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.48032456731139606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.48032456731139606 valid 0.487754225730896
LOSS train 0.48032456731139606 valid 0.5027230679988861
LOSS train 0.48032456731139606 valid 0.5007365544637045
LOSS train 0.48032456731139606 valid 0.4964461326599121
LOSS train 0.48032456731139606 valid 0.4913199424743652
LOSS train 0.48032456731139606 valid 0.49688543876012164
LOSS train 0.48032456731139606 valid 0.5036264487675258
LOSS train 0.48032456731139606 valid 0.50605658441782
LOSS train 0.48032456731139606 valid 0.5078644818729825
LOSS train 0.48032456731139606 valid 0.512032550573349
LOSS train 0.48032456731139606 valid 0.5153363455425609
LOSS train 0.48032456731139606 valid 0.5142875462770462
LOSS train 0.48032456731139606 valid 0.5187822167689984
LOSS train 0.48032456731139606 valid 0.5210227923733848
LOSS train 0.48032456731139606 valid 0.5223667661348979
LOSS train 0.48032456731139606 valid 0.5203438717871904
LOSS train 0.48032456731139606 valid 0.5227582402089063
LOSS train 0.48032456731139606 valid 0.523176704843839
LOSS train 0.48032456731139606 valid 0.5220681726932526
LOSS train 0.48032456731139606 valid 0.523080651462078
LOSS train 0.48032456731139606 valid 0.5228695401123592
LOSS train 0.48032456731139606 valid 0.5215575681491331
LOSS train 0.48032456731139606 valid 0.5216982662677765
LOSS train 0.48032456731139606 valid 0.5206033115585645
LOSS train 0.48032456731139606 valid 0.5193738639354706
LOSS train 0.48032456731139606 valid 0.5178126062338169
LOSS train 0.48032456731139606 valid 0.5174282270449179
LOSS train 0.48032456731139606 valid 0.5180397086909839
LOSS train 0.48032456731139606 valid 0.517059109334288
LOSS train 0.48032456731139606 valid 0.5184807608524958
LOSS train 0.48032456731139606 valid 0.5197472235848827
LOSS train 0.48032456731139606 valid 0.5200356850400567
LOSS train 0.48032456731139606 valid 0.5213611225287119
LOSS train 0.48032456731139606 valid 0.5221640178385902
LOSS train 0.48032456731139606 valid 0.5238041119916098
LOSS train 0.48032456731139606 valid 0.5242409764064683
LOSS train 0.48032456731139606 valid 0.524558495025377
LOSS train 0.48032456731139606 valid 0.5250335139663596
LOSS train 0.48032456731139606 valid 0.5249099586254511
LOSS train 0.48032456731139606 valid 0.5255107216536998
LOSS train 0.48032456731139606 valid 0.5256018020757814
LOSS train 0.48032456731139606 valid 0.5255650615408307
LOSS train 0.48032456731139606 valid 0.5255543818307478
LOSS train 0.48032456731139606 valid 0.5256449099291455
LOSS train 0.48032456731139606 valid 0.5255999015437232
LOSS train 0.48032456731139606 valid 0.5263181698063145
LOSS train 0.48032456731139606 valid 0.5263908752735625
LOSS train 0.48032456731139606 valid 0.527259316916267
LOSS train 0.48032456731139606 valid 0.5284164091762231
LOSS train 0.48032456731139606 valid 0.5277839422225952
LOSS train 0.48032456731139606 valid 0.5285048835417804
LOSS train 0.48032456731139606 valid 0.5289119115242591
LOSS train 0.48032456731139606 valid 0.5287334266698586
LOSS train 0.48032456731139606 valid 0.5281230122954758
LOSS train 0.48032456731139606 valid 0.5281499862670899
LOSS train 0.48032456731139606 valid 0.5278056710958481
LOSS train 0.48032456731139606 valid 0.5273891833790562
LOSS train 0.48032456731139606 valid 0.5275289580739778
LOSS train 0.48032456731139606 valid 0.5281463356341346
LOSS train 0.48032456731139606 valid 0.5276134277383486
LOSS train 0.48032456731139606 valid 0.5263608615906512
LOSS train 0.48032456731139606 valid 0.5264756660307607
LOSS train 0.48032456731139606 valid 0.5263014388462853
LOSS train 0.48032456731139606 valid 0.5267331898212433
LOSS train 0.48032456731139606 valid 0.5270440285022442
LOSS train 0.48032456731139606 valid 0.5263470474517706
LOSS train 0.48032456731139606 valid 0.5261321308007881
LOSS train 0.48032456731139606 valid 0.5260988342411378
LOSS train 0.48032456731139606 valid 0.526073808255403
LOSS train 0.48032456731139606 valid 0.5253744057246617
LOSS train 0.48032456731139606 valid 0.5248244681828459
LOSS train 0.48032456731139606 valid 0.5246164078513781
LOSS train 0.48032456731139606 valid 0.5250707301374984
LOSS train 0.48032456731139606 valid 0.5243234586071324
LOSS train 0.48032456731139606 valid 0.5243149741490682
LOSS train 0.48032456731139606 valid 0.5245867199019382
LOSS train 0.48032456731139606 valid 0.5244504538449374
LOSS train 0.48032456731139606 valid 0.5244894623756409
LOSS train 0.48032456731139606 valid 0.5241400418402273
LOSS train 0.48032456731139606 valid 0.5240213699638844
LOSS train 0.48032456731139606 valid 0.5235902063640547
LOSS train 0.48032456731139606 valid 0.5236809101046586
LOSS train 0.48032456731139606 valid 0.5233767334237156
LOSS train 0.48032456731139606 valid 0.5234410897606895
LOSS train 0.48032456731139606 valid 0.5231137885766871
LOSS train 0.48032456731139606 valid 0.5228145372035892
LOSS train 0.48032456731139606 valid 0.5227202231856598
LOSS train 0.48032456731139606 valid 0.5227579013867811
LOSS train 0.48032456731139606 valid 0.5228750504804461
LOSS train 0.48032456731139606 valid 0.523356290658315
LOSS train 0.48032456731139606 valid 0.5235029825797448
LOSS train 0.48032456731139606 valid 0.523348956004433
LOSS train 0.48032456731139606 valid 0.5231258035987936
LOSS train 0.48032456731139606 valid 0.5229875299524753
LOSS train 0.48032456731139606 valid 0.5227793084947686
LOSS train 0.48032456731139606 valid 0.522720747316877
LOSS train 0.48032456731139606 valid 0.5227891778208545
LOSS train 0.48032456731139606 valid 0.5225321614012426
LOSS train 0.48032456731139606 valid 0.5230491498504022
LOSS train 0.48032456731139606 valid 0.5232949584722519
LOSS train 0.48032456731139606 valid 0.5231704446348814
LOSS train 0.48032456731139606 valid 0.5232286283782884
LOSS train 0.48032456731139606 valid 0.5235470782205897
LOSS train 0.48032456731139606 valid 0.5237250322332749
LOSS train 0.48032456731139606 valid 0.5238980185417902
LOSS train 0.48032456731139606 valid 0.5240707335607061
LOSS train 0.48032456731139606 valid 0.5239386224301061
LOSS train 0.48032456731139606 valid 0.5238851805528005
LOSS train 0.48032456731139606 valid 0.5240902135131555
LOSS train 0.48032456731139606 valid 0.5244379791346463
LOSS train 0.48032456731139606 valid 0.5243367767548776
LOSS train 0.48032456731139606 valid 0.5242056846618652
LOSS train 0.48032456731139606 valid 0.5243921617491055
LOSS train 0.48032456731139606 valid 0.5239013956304182
LOSS train 0.48032456731139606 valid 0.5239438927691916
LOSS train 0.48032456731139606 valid 0.5242258413084622
LOSS train 0.48032456731139606 valid 0.5240817528504592
LOSS train 0.48032456731139606 valid 0.5239648132000939
LOSS train 0.48032456731139606 valid 0.5238653842140647
LOSS train 0.48032456731139606 valid 0.5238363246122996
LOSS train 0.48032456731139606 valid 0.5236529446830435
LOSS train 0.48032456731139606 valid 0.5234460950386329
LOSS train 0.48032456731139606 valid 0.5235342894627796
LOSS train 0.48032456731139606 valid 0.5237391872271415
LOSS train 0.48032456731139606 valid 0.5239349806308746
LOSS train 0.48032456731139606 valid 0.5239640845665856
LOSS train 0.48032456731139606 valid 0.5241699671651435
LOSS train 0.48032456731139606 valid 0.5244231198448688
LOSS train 0.48032456731139606 valid 0.5245471714540969
LOSS train 0.48032456731139606 valid 0.5244696298470863
LOSS train 0.48032456731139606 valid 0.5244889043214667
LOSS train 0.48032456731139606 valid 0.5242283635518767
LOSS train 0.48032456731139606 valid 0.5241537616217047
LOSS train 0.48032456731139606 valid 0.5241049241218994
LOSS train 0.48032456731139606 valid 0.5242356461507303
LOSS train 0.48032456731139606 valid 0.52423371045905
LOSS train 0.48032456731139606 valid 0.5239927727375587
LOSS train 0.48032456731139606 valid 0.5237134662659272
LOSS train 0.48032456731139606 valid 0.5236213809723477
LOSS train 0.48032456731139606 valid 0.5236445199166025
LOSS train 0.48032456731139606 valid 0.5238105885103239
LOSS train 0.48032456731139606 valid 0.5239697079843199
LOSS train 0.48032456731139606 valid 0.5238695317631835
LOSS train 0.48032456731139606 valid 0.5238768017540375
LOSS train 0.48032456731139606 valid 0.5235960341733078
LOSS train 0.48032456731139606 valid 0.5238959640264511
LOSS train 0.48032456731139606 valid 0.5236273036927593
LOSS train 0.48032456731139606 valid 0.5240124518404136
LOSS train 0.48032456731139606 valid 0.5239188621108164
LOSS train 0.48032456731139606 valid 0.5240588329235712
LOSS train 0.48032456731139606 valid 0.5240548033982713
LOSS train 0.48032456731139606 valid 0.5237702621441138
LOSS train 0.48032456731139606 valid 0.5237284926028033
LOSS train 0.48032456731139606 valid 0.5238606500161158
LOSS train 0.48032456731139606 valid 0.5237856322719204
LOSS train 0.48032456731139606 valid 0.524202653612846
LOSS train 0.48032456731139606 valid 0.5241914744589738
LOSS train 0.48032456731139606 valid 0.524280082198638
LOSS train 0.48032456731139606 valid 0.5240475784682628
LOSS train 0.48032456731139606 valid 0.5239852702245116
LOSS train 0.48032456731139606 valid 0.5241908610607526
LOSS train 0.48032456731139606 valid 0.5240457729424959
LOSS train 0.48032456731139606 valid 0.5239722745184519
LOSS train 0.48032456731139606 valid 0.523816683852091
LOSS train 0.48032456731139606 valid 0.5235474783362765
LOSS train 0.48032456731139606 valid 0.5233158492539303
LOSS train 0.48032456731139606 valid 0.5235202228594683
LOSS train 0.48032456731139606 valid 0.523707262994278
LOSS train 0.48032456731139606 valid 0.5238166999887433
LOSS train 0.48032456731139606 valid 0.5238533400437411
LOSS train 0.48032456731139606 valid 0.52412318468791
LOSS train 0.48032456731139606 valid 0.5242461726762527
LOSS train 0.48032456731139606 valid 0.524316481599918
LOSS train 0.48032456731139606 valid 0.5243605829175861
LOSS train 0.48032456731139606 valid 0.5244438561371395
LOSS train 0.48032456731139606 valid 0.5245634302158247
LOSS train 0.48032456731139606 valid 0.524721480863916
LOSS train 0.48032456731139606 valid 0.524983934639545
LOSS train 0.48032456731139606 valid 0.5250757271684082
LOSS train 0.48032456731139606 valid 0.5251177964939011
LOSS train 0.48032456731139606 valid 0.5251554216139883
LOSS train 0.48032456731139606 valid 0.5251981352384274
LOSS train 0.48032456731139606 valid 0.5251547181215442
LOSS train 0.48032456731139606 valid 0.5251985721937988
LOSS train 0.48032456731139606 valid 0.5251130453638129
LOSS train 0.48032456731139606 valid 0.525178480693089
LOSS train 0.48032456731139606 valid 0.5254004299640656
LOSS train 0.48032456731139606 valid 0.5254473966803956
LOSS train 0.48032456731139606 valid 0.5252815469232186
LOSS train 0.48032456731139606 valid 0.5251898470677827
LOSS train 0.48032456731139606 valid 0.5254663753259868
LOSS train 0.48032456731139606 valid 0.5256012513612708
LOSS train 0.48032456731139606 valid 0.5256510997683274
LOSS train 0.48032456731139606 valid 0.5254888536082101
LOSS train 0.48032456731139606 valid 0.5252555659184089
LOSS train 0.48032456731139606 valid 0.52524555261646
LOSS train 0.48032456731139606 valid 0.5253111830520146
LOSS train 0.48032456731139606 valid 0.5252012347031121
LOSS train 0.48032456731139606 valid 0.5253233617574127
LOSS train 0.48032456731139606 valid 0.5253350283205509
LOSS train 0.48032456731139606 valid 0.5252006893134236
LOSS train 0.48032456731139606 valid 0.5252779613036921
LOSS train 0.48032456731139606 valid 0.5251867427614522
LOSS train 0.48032456731139606 valid 0.5253775283402088
LOSS train 0.48032456731139606 valid 0.5253584210465594
LOSS train 0.48032456731139606 valid 0.5255760836948469
LOSS train 0.48032456731139606 valid 0.5255315228936753
LOSS train 0.48032456731139606 valid 0.5254836618327178
LOSS train 0.48032456731139606 valid 0.5252187052411896
LOSS train 0.48032456731139606 valid 0.5251327500456855
LOSS train 0.48032456731139606 valid 0.5253163756917438
LOSS train 0.48032456731139606 valid 0.5253006579740992
LOSS train 0.48032456731139606 valid 0.5253033330183075
LOSS train 0.48032456731139606 valid 0.5252480671227535
LOSS train 0.48032456731139606 valid 0.525038866941319
LOSS train 0.48032456731139606 valid 0.5249567288491461
LOSS train 0.48032456731139606 valid 0.5251054252896991
LOSS train 0.48032456731139606 valid 0.5250454359098312
LOSS train 0.48032456731139606 valid 0.5251302449670556
LOSS train 0.48032456731139606 valid 0.5250707011331212
LOSS train 0.48032456731139606 valid 0.5251858404319211
LOSS train 0.48032456731139606 valid 0.5253656654207556
LOSS train 0.48032456731139606 valid 0.5255612586645803
LOSS train 0.48032456731139606 valid 0.5255734696984291
LOSS train 0.48032456731139606 valid 0.525533987681071
LOSS train 0.48032456731139606 valid 0.5254692551309028
LOSS train 0.48032456731139606 valid 0.525614021633165
LOSS train 0.48032456731139606 valid 0.5257663653607954
LOSS train 0.48032456731139606 valid 0.525730259293552
LOSS train 0.48032456731139606 valid 0.5258526068666707
LOSS train 0.48032456731139606 valid 0.5257553711081996
LOSS train 0.48032456731139606 valid 0.5258076733042454
LOSS train 0.48032456731139606 valid 0.5255882207927786
LOSS train 0.48032456731139606 valid 0.5255676650593424
LOSS train 0.48032456731139606 valid 0.5256635856121145
LOSS train 0.48032456731139606 valid 0.5256636301844807
LOSS train 0.48032456731139606 valid 0.5256268377042521
LOSS train 0.48032456731139606 valid 0.5255865053970272
LOSS train 0.48032456731139606 valid 0.5256339533558451
LOSS train 0.48032456731139606 valid 0.5256154524783293
LOSS train 0.48032456731139606 valid 0.5257812543034059
LOSS train 0.48032456731139606 valid 0.525811537238192
LOSS train 0.48032456731139606 valid 0.5257737494299932
LOSS train 0.48032456731139606 valid 0.5257807764850679
LOSS train 0.48032456731139606 valid 0.5257387715943006
LOSS train 0.48032456731139606 valid 0.5256825157297336
LOSS train 0.48032456731139606 valid 0.5258761159321557
LOSS train 0.48032456731139606 valid 0.5258650933542559
LOSS train 0.48032456731139606 valid 0.5258309812430876
LOSS train 0.48032456731139606 valid 0.5260015835762024
LOSS train 0.48032456731139606 valid 0.5259625892715151
LOSS train 0.48032456731139606 valid 0.5260598962269132
LOSS train 0.48032456731139606 valid 0.5261454808382178
LOSS train 0.48032456731139606 valid 0.5261445392773846
LOSS train 0.48032456731139606 valid 0.5261231032072329
LOSS train 0.48032456731139606 valid 0.5260820211842656
LOSS train 0.48032456731139606 valid 0.5260409629298555
LOSS train 0.48032456731139606 valid 0.5260682718236317
LOSS train 0.48032456731139606 valid 0.5261300565193059
LOSS train 0.48032456731139606 valid 0.5261210553921186
LOSS train 0.48032456731139606 valid 0.5261943689708052
LOSS train 0.48032456731139606 valid 0.5262516762009104
LOSS train 0.48032456731139606 valid 0.5263041418768154
LOSS train 0.48032456731139606 valid 0.5262818641283296
LOSS train 0.48032456731139606 valid 0.5263587854943186
LOSS train 0.48032456731139606 valid 0.5263531765991584
LOSS train 0.48032456731139606 valid 0.5262769284319788
LOSS train 0.48032456731139606 valid 0.5262863286840382
LOSS train 0.48032456731139606 valid 0.5265152593970742
LOSS train 0.48032456731139606 valid 0.5266082757049136
LOSS train 0.48032456731139606 valid 0.5267049377694781
LOSS train 0.48032456731139606 valid 0.5267090679091566
LOSS train 0.48032456731139606 valid 0.5268511776522402
LOSS train 0.48032456731139606 valid 0.5268342625485719
LOSS train 0.48032456731139606 valid 0.5267993322285739
LOSS train 0.48032456731139606 valid 0.5269303980512895
LOSS train 0.48032456731139606 valid 0.5269991824342886
LOSS train 0.48032456731139606 valid 0.5269634076159635
LOSS train 0.48032456731139606 valid 0.5270403860717692
LOSS train 0.48032456731139606 valid 0.5270407259464264
LOSS train 0.48032456731139606 valid 0.5268067476800328
LOSS train 0.48032456731139606 valid 0.5266800806032005
LOSS train 0.48032456731139606 valid 0.5265700183150626
LOSS train 0.48032456731139606 valid 0.5266407071284844
LOSS train 0.48032456731139606 valid 0.5266710164254171
LOSS train 0.48032456731139606 valid 0.5266150146514386
LOSS train 0.48032456731139606 valid 0.5265930124691555
LOSS train 0.48032456731139606 valid 0.5265798531472683
LOSS train 0.48032456731139606 valid 0.5265762682192053
LOSS train 0.48032456731139606 valid 0.5265584102992353
LOSS train 0.48032456731139606 valid 0.5264560498322818
LOSS train 0.48032456731139606 valid 0.5264078121479243
LOSS train 0.48032456731139606 valid 0.526409686628869
LOSS train 0.48032456731139606 valid 0.5264952178715038
LOSS train 0.48032456731139606 valid 0.5266320408400843
LOSS train 0.48032456731139606 valid 0.5266761310599946
LOSS train 0.48032456731139606 valid 0.5266267041164616
LOSS train 0.48032456731139606 valid 0.5266464052584348
LOSS train 0.48032456731139606 valid 0.5267668492020572
LOSS train 0.48032456731139606 valid 0.5266832359631857
LOSS train 0.48032456731139606 valid 0.5267233470349613
LOSS train 0.48032456731139606 valid 0.526659167562889
LOSS train 0.48032456731139606 valid 0.5266751924363693
LOSS train 0.48032456731139606 valid 0.5266305400352729
LOSS train 0.48032456731139606 valid 0.5265427120396349
LOSS train 0.48032456731139606 valid 0.5264913069656472
LOSS train 0.48032456731139606 valid 0.5264361821090748
LOSS train 0.48032456731139606 valid 0.5264639039705326
LOSS train 0.48032456731139606 valid 0.5264982449969813
LOSS train 0.48032456731139606 valid 0.5264415604452933
LOSS train 0.48032456731139606 valid 0.5263582113471446
LOSS train 0.48032456731139606 valid 0.5264085368850292
LOSS train 0.48032456731139606 valid 0.5265377917990517
LOSS train 0.48032456731139606 valid 0.5266134634519078
LOSS train 0.48032456731139606 valid 0.526683757607899
LOSS train 0.48032456731139606 valid 0.5266058841083623
LOSS train 0.48032456731139606 valid 0.5266765797927928
LOSS train 0.48032456731139606 valid 0.5265754028311316
LOSS train 0.48032456731139606 valid 0.5266813661984889
LOSS train 0.48032456731139606 valid 0.5265681562945247
LOSS train 0.48032456731139606 valid 0.5265114190422486
LOSS train 0.48032456731139606 valid 0.5264775941830985
LOSS train 0.48032456731139606 valid 0.5263525149770566
LOSS train 0.48032456731139606 valid 0.5263181735336044
LOSS train 0.48032456731139606 valid 0.52628489952821
LOSS train 0.48032456731139606 valid 0.5264267524692909
LOSS train 0.48032456731139606 valid 0.5264517903692496
LOSS train 0.48032456731139606 valid 0.5265775170268082
LOSS train 0.48032456731139606 valid 0.5266730846967378
LOSS train 0.48032456731139606 valid 0.5267357353008155
LOSS train 0.48032456731139606 valid 0.5266813783487164
LOSS train 0.48032456731139606 valid 0.5265315204679247
LOSS train 0.48032456731139606 valid 0.5265582571695516
LOSS train 0.48032456731139606 valid 0.5267375637135819
LOSS train 0.48032456731139606 valid 0.5267484121358217
LOSS train 0.48032456731139606 valid 0.5268448042195468
LOSS train 0.48032456731139606 valid 0.5267922274259856
LOSS train 0.48032456731139606 valid 0.5267988227351883
LOSS train 0.48032456731139606 valid 0.5266468646252049
LOSS train 0.48032456731139606 valid 0.5265634523595081
LOSS train 0.48032456731139606 valid 0.5264759175588658
LOSS train 0.48032456731139606 valid 0.5264758519959032
LOSS train 0.48032456731139606 valid 0.526500640040584
LOSS train 0.48032456731139606 valid 0.5266001844821975
LOSS train 0.48032456731139606 valid 0.5265562465225441
LOSS train 0.48032456731139606 valid 0.526617553192756
LOSS train 0.48032456731139606 valid 0.5266152450261954
LOSS train 0.48032456731139606 valid 0.5267085862913351
LOSS train 0.48032456731139606 valid 0.5268002856085157
LOSS train 0.48032456731139606 valid 0.5267803876740592
LOSS train 0.48032456731139606 valid 0.5266975255263837
LOSS train 0.48032456731139606 valid 0.5266771898181601
LOSS train 0.48032456731139606 valid 0.526778317629109
LOSS train 0.48032456731139606 valid 0.5268328458407504
LOSS train 0.48032456731139606 valid 0.5269663620163018
LOSS train 0.48032456731139606 valid 0.5270417423897915
LOSS train 0.48032456731139606 valid 0.5269822737916845
LOSS train 0.48032456731139606 valid 0.5268982851138994
LOSS train 0.48032456731139606 valid 0.526942240245495
LOSS train 0.48032456731139606 valid 0.5269458624223868
LOSS train 0.48032456731139606 valid 0.5270140677112621
LOSS train 0.48032456731139606 valid 0.527110908983162
LOSS train 0.48032456731139606 valid 0.5271437081916273
LOSS train 0.48032456731139606 valid 0.5271338225229756
LOSS train 0.48032456731139606 valid 0.527194492376014
LOSS train 0.48032456731139606 valid 0.5271977410127556
LOSS train 0.48032456731139606 valid 0.5271270792393333
LOSS train 0.48032456731139606 valid 0.5271138293749612
LOSS train 0.48032456731139606 valid 0.5271455920970214
EPOCH 9:
  batch 1 loss: 0.4618401825428009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.4946594387292862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.49224016070365906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.490172915160656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4897147476673126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4870752841234207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.484970999615533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4856017045676708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.48216335309876335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4773291975259781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.47641588612036273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4762953147292137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.47456069405262286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.47485791572502684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4774914642175039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.47841992415487766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4771472496144912
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47749732269181144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.47889581793232966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.479290309548378
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4786345192364284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.47833558917045593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4792949039003123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4790922502676646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.47868030905723574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.47900745616509366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.48043720700122694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.47956525321517673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.47961267212341574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.48013742367426554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.48023089478092806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.48075490817427635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4798307436885256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.48003010188832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.48089749472481863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4805273935198784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.47962964708740646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.47885157246338694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4791113520279909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.47916834279894827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4786492651555596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.47862575451533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4799578827480937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4804025827483697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.48051618801222906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.47970521255679754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.47958234713432635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.48013781445721787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4802153432855801
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.48105217158794406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.48028092290840896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.48006769441641295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4796778329138486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4793932691768364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4785694631663236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.47876232649598804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.478982478903051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4783103671567193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4776949761277538
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.47798654685417813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4779785050720465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4785569339029251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4786818538393293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4786908240057528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.47923610164568975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.47866862018903095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4785035724070535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4787331468918744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.47851624091466266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.478516377721514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.47858874814611085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.47807809213797253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.47833072241038493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4781508711544243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.47793054699897763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.47834110063941854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4780024576496768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.47766821201031023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4778202798547624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4775898210704327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.47745222809873983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.47719438410386805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4773659189063382
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4771681938852583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4771590211812188
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.47742930331895517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.47769564253160324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.47795558111234143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.477926763590802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4779329445627001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.47781536801830754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.47810534355433093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.47828598849235043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.47833722417658947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.47831699158016006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.47891820160051185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.47879231283345175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4788973954867344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4790495095228908
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.47915853321552276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4790968381532348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4792344225387947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.47940468498804034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4793459475040436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4795533833049592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4793199865885501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4791208898352685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4793085116479132
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.47927221765211964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.47933358468792653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4791243454894504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.47919014495398315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4793100523210205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4792275815679316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.478961007491402
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4790058192507974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.47938131623797947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4792912385221255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4795113957228781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.47923663109540937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.47922724436137304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4794965801668949
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4797256104345244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4796040524398127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.47973211836814883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.479890765651824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4798751966221126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.48015756998211145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4800579672635988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4801416736382704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.480080129308555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.47994809236490366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.47992615592210813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.47986613547624046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.47979658400570907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.47987744234064045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.48001088038848266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4798452819603077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4799723629471209
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.480004979457174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4798623572850058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4799414810160516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.47999627690215213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.48021166440513396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4802538886152465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.48016729583478956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.480326940413235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.48058914050862594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4804288058872991
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4802668803930283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.480356321034842
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4804100219748522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.480441602032169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4802998610131152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4805279258758791
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4807558399744523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.48068497894675866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4808088548575776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.48098258852208936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.48107636347413063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.48090894529538125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.48078940330464165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.48081457048106047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4807527435988915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.48068783536101833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.48080673562474996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4807814288282109
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4805159976794606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.48052281564509375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.480643748886445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.48060133791806403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.48050602768049683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4803990273806401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4804710581384856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4803223024095808
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.48023133081468666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.48014136391170953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.48016097505440875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4802912720088852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.48028917610645294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4801916068430105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.48010951378843286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.479990835561127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.47994843465478526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4800332878087018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.47995039724534555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.47988552492570113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.47976701437158786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4797687007005883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4796587959716195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4795508161577255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4793228209018707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4793642933813401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.47938590443011414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.47930927887941016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.47932037178959164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.47936502386470736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.47952334206513686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.47951922075233266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4795483000576496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.47952459033448896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4795095619588795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4792739261547333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4792572391383788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.47921123824468476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4790003194102963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.478938934451716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.4788496810942888
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.479091587962146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.47913449647880735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.47913993125278237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.47929236391242946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.47932269245805875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4792285295568894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.47926168538803277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.47919832156212244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4792628237454023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4794654653433266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4797161968603526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4797937879508192
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4796300016647011
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.47952737504834525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4796362119672544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4796902570607407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.47952898131476507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4794320880839255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.47944679160475207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4792943025628726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4792880362558573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.47941130723642267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4793692709821643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.47952456913631536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4794149796594366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.479424201652535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.47950756993699584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.47953396391565517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4795310616744721
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.47944778479447886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4794857857366985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.47959304936230185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4796559203462482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4795545055107637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4796725188999019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.47969479504667345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4797881443889774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4799499774609155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.47996723989726076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4798396292232698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.48005010899769734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4801076372861862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.48016693428218127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4801614027884271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.48024468730560876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4801160099468832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.48003555068782733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.48006226459983736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4799082155125614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.47988431894964023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.48013039134644175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4802280743534748
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4802184106061285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.4801279150575172
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4801806366715594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4801870741401658
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48005117402886444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.48009300668884936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4801023130336504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.48002657327634185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4799628305390865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.48001167321646654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4800472013184945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.47994706001790133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4798708715281644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.47962373864911767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4794653875177557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.47957001842450403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4796161025439789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4795416202262151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4795348989279894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.47954030452030044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4796022434463705
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4796223680601052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.47956635021068184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4796049900248017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.47962233298703244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.47965338357261844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.4796802624800479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.47971286873022717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4796560522181765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4797353890435449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4796824297544473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4797359563104094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.47978703306396664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4798555425843414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4798141809843354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.47980424248286196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.47990059019740583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4798572400472308
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4798341649631194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4798034908374151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4799088384225915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4797873408194409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4797373115032813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4797715223149249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4798798877684796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4798525836732652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.47985752698652906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.47991110800535647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.47997335583260914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.47994763783870203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.48003176793791474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4799154467689685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.47983348102996143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.47974791116775223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4797117235168578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.47978207865093325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4798329286394811
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.47985630102877347
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4798893691230343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.47998784445226195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.47984578546333906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.479906753168343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.48007579706032577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4800134152173996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.47998729999248796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4800027043907189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4800404725818459
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.48013373555206673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4800754403270849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.48017885450160863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4802576885122547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.48021882557007206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.48022599925508014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4801826369976569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4801763614611839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4802482747251079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.480162299970491
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4801337816835155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4800789841508443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.48011495751493116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.480105095682256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4801538845426158
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.4800458308037794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.48004010077132736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4800517823385156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.48013317912300196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.48016946786418774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4802420901498575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.48018145740544554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4801478385073798
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4801003939745433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4800993502140045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4801559367193379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.48009152230569874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.48005299710891614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4799491212274251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.47996145954319075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.48005376531425137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.48002512043233037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.47991385236382483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4798546384741395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.47988387818823863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.47990500902341415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.47982097875613433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.47982329505763643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.47978596438149934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.47975492038908707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4797620876975682
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.47974635818140293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4797618689569267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.47978877081382626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4797600436434951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.47978155294947583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.47977978134537763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.47978015677134195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4797552596539893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4797513504717647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4798269070803173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.479859174084223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4797986123122667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4797731449441334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.47971250694147577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.47978385473667173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4798039401260515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4798062070623621
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.47986983357315854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.47985545255109013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4799485598335561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.47993450483503564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.47992006693130884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.479924521482814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4799234153208684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.47990588749031377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4799191990328319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.47986356004883973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4799198998947336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.47997562275725586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.48008662956443865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4801458904617711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4801257296651602
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4800834254433687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4799329975795983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4799152248106878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4798735417794473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4799001553176362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4799501221315027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.47990009027558406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4798891477871175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4798187485242531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.47980585592549024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.4798643806554975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.47991342249425867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4798433962514845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.47999029415817074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4800637862768518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.48016644082963467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.480132578945846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.48013908177186426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4801963996631149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4801603824609802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.48028538452191477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.48037821245136986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.48030896100873927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4803437040240135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4803141790277818
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4802240786697943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.48022606829290365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4801744277649951
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4800819737927897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.48018612612125483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4801410812789492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4801638710691973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4800855809216136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.48009865418557196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4800076588131916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.48010378522337027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.48008908075653445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.48005008010287264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.47997160476541195
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.47995899814096366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.47997995575809693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4799894304162237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4800193338711698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.47994400856194197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4800815221968662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4799897820425675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4800769630694549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4801136466807553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4801290746786547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4800909897353914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.48005198460989146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4801146868715244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4800898411021327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4800468797463152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.48004611815725057
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.47997712703389034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4799406415654481
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.479966495299964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4798879587702242
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.47999271445948144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.47996603065612775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4799486983777125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.47997893248212004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4799794691518463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4799374000359607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.47993989921946384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4798975722820396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.47997594624757767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4800084660937791
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4800852691239499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4800666537760676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.480099898273662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.480099898273662 valid 0.4814140200614929
LOSS train 0.480099898273662 valid 0.4964695870876312
LOSS train 0.480099898273662 valid 0.4945337971051534
LOSS train 0.480099898273662 valid 0.4904274493455887
LOSS train 0.480099898273662 valid 0.4852611064910889
LOSS train 0.480099898273662 valid 0.49088242650032043
LOSS train 0.480099898273662 valid 0.49762432064328876
LOSS train 0.480099898273662 valid 0.49998316913843155
LOSS train 0.480099898273662 valid 0.5018004708819919
LOSS train 0.480099898273662 valid 0.5060320734977722
LOSS train 0.480099898273662 valid 0.5094283494082364
LOSS train 0.480099898273662 valid 0.5083843171596527
LOSS train 0.480099898273662 valid 0.5129020443329444
LOSS train 0.480099898273662 valid 0.5151697610105787
LOSS train 0.480099898273662 valid 0.5165078123410543
LOSS train 0.480099898273662 valid 0.5144926235079765
LOSS train 0.480099898273662 valid 0.5168800143634572
LOSS train 0.480099898273662 valid 0.5172335571712918
LOSS train 0.480099898273662 valid 0.5161541167058443
LOSS train 0.480099898273662 valid 0.5171932101249694
LOSS train 0.480099898273662 valid 0.516998637290228
LOSS train 0.480099898273662 valid 0.515678577802398
LOSS train 0.480099898273662 valid 0.5158202401969744
LOSS train 0.480099898273662 valid 0.5147370596726736
LOSS train 0.480099898273662 valid 0.5134984123706817
LOSS train 0.480099898273662 valid 0.5119248364980404
LOSS train 0.480099898273662 valid 0.5114926861392127
LOSS train 0.480099898273662 valid 0.5120831568326268
LOSS train 0.480099898273662 valid 0.5111107466549709
LOSS train 0.480099898273662 valid 0.5125646044810613
LOSS train 0.480099898273662 valid 0.5138472866627478
LOSS train 0.480099898273662 valid 0.5141533659771085
LOSS train 0.480099898273662 valid 0.5155124456593485
LOSS train 0.480099898273662 valid 0.5163495970122954
LOSS train 0.480099898273662 valid 0.5179816254547664
LOSS train 0.480099898273662 valid 0.5184093937277794
LOSS train 0.480099898273662 valid 0.5187412927279601
LOSS train 0.480099898273662 valid 0.5192122028062218
LOSS train 0.480099898273662 valid 0.5190981068672278
LOSS train 0.480099898273662 valid 0.5196989707648754
LOSS train 0.480099898273662 valid 0.5197984220051184
LOSS train 0.480099898273662 valid 0.5197435113645735
LOSS train 0.480099898273662 valid 0.5197251737117767
LOSS train 0.480099898273662 valid 0.5197991938753561
LOSS train 0.480099898273662 valid 0.5197325236267514
LOSS train 0.480099898273662 valid 0.5204606930846754
LOSS train 0.480099898273662 valid 0.5205387618947537
LOSS train 0.480099898273662 valid 0.5214354389657577
LOSS train 0.480099898273662 valid 0.5225894603194022
LOSS train 0.480099898273662 valid 0.5219540923833847
LOSS train 0.480099898273662 valid 0.5226899309485566
LOSS train 0.480099898273662 valid 0.5230955980145015
LOSS train 0.480099898273662 valid 0.5229141009303758
LOSS train 0.480099898273662 valid 0.5222920974095663
LOSS train 0.480099898273662 valid 0.5223298593000932
LOSS train 0.480099898273662 valid 0.5220025990690503
LOSS train 0.480099898273662 valid 0.5215814129302376
LOSS train 0.480099898273662 valid 0.5217290782722933
LOSS train 0.480099898273662 valid 0.5223603445594593
LOSS train 0.480099898273662 valid 0.5218333199620246
LOSS train 0.480099898273662 valid 0.5205670746623493
LOSS train 0.480099898273662 valid 0.5206981219591633
LOSS train 0.480099898273662 valid 0.5205153184277671
LOSS train 0.480099898273662 valid 0.520951981190592
LOSS train 0.480099898273662 valid 0.5212763295723841
LOSS train 0.480099898273662 valid 0.5205853161486712
LOSS train 0.480099898273662 valid 0.5203446928244918
LOSS train 0.480099898273662 valid 0.5203207832048921
LOSS train 0.480099898273662 valid 0.5203043062617814
LOSS train 0.480099898273662 valid 0.5195981532335281
LOSS train 0.480099898273662 valid 0.5190473375186114
LOSS train 0.480099898273662 valid 0.5188517570495605
LOSS train 0.480099898273662 valid 0.5193164626212969
LOSS train 0.480099898273662 valid 0.5185632834563384
LOSS train 0.480099898273662 valid 0.5185534723599752
LOSS train 0.480099898273662 valid 0.5188312099168175
LOSS train 0.480099898273662 valid 0.5186934029901182
LOSS train 0.480099898273662 valid 0.5187250085366077
LOSS train 0.480099898273662 valid 0.518377570411827
LOSS train 0.480099898273662 valid 0.5182572163641452
LOSS train 0.480099898273662 valid 0.5178300583804095
LOSS train 0.480099898273662 valid 0.5179263077131132
LOSS train 0.480099898273662 valid 0.5176118806184057
LOSS train 0.480099898273662 valid 0.5176764435711361
LOSS train 0.480099898273662 valid 0.5173443352474886
LOSS train 0.480099898273662 valid 0.5170453863088474
LOSS train 0.480099898273662 valid 0.5169571699767277
LOSS train 0.480099898273662 valid 0.5169994946230542
LOSS train 0.480099898273662 valid 0.517125007141842
LOSS train 0.480099898273662 valid 0.5176065974765354
LOSS train 0.480099898273662 valid 0.5177626721151583
LOSS train 0.480099898273662 valid 0.5176119921000107
LOSS train 0.480099898273662 valid 0.5173892141670309
LOSS train 0.480099898273662 valid 0.5172587557041899
LOSS train 0.480099898273662 valid 0.5170530200004577
LOSS train 0.480099898273662 valid 0.516986774901549
LOSS train 0.480099898273662 valid 0.5170551489308938
LOSS train 0.480099898273662 valid 0.5167983831191549
LOSS train 0.480099898273662 valid 0.5173226612986941
LOSS train 0.480099898273662 valid 0.5175653576850892
LOSS train 0.480099898273662 valid 0.5174402866033044
LOSS train 0.480099898273662 valid 0.5174982331547082
LOSS train 0.480099898273662 valid 0.5178218235089941
LOSS train 0.480099898273662 valid 0.5179996461822436
LOSS train 0.480099898273662 valid 0.5181701609066555
LOSS train 0.480099898273662 valid 0.5183300876392508
LOSS train 0.480099898273662 valid 0.5181960664062857
LOSS train 0.480099898273662 valid 0.5181434877492763
LOSS train 0.480099898273662 valid 0.5183574010472779
LOSS train 0.480099898273662 valid 0.5187115154483102
LOSS train 0.480099898273662 valid 0.5186122177957414
LOSS train 0.480099898273662 valid 0.5184864971254554
LOSS train 0.480099898273662 valid 0.5186783407641723
LOSS train 0.480099898273662 valid 0.5181808288682971
LOSS train 0.480099898273662 valid 0.5182234458301378
LOSS train 0.480099898273662 valid 0.5185072560762537
LOSS train 0.480099898273662 valid 0.518367749503535
LOSS train 0.480099898273662 valid 0.518252432851468
LOSS train 0.480099898273662 valid 0.5181537861583614
LOSS train 0.480099898273662 valid 0.5181228200594584
LOSS train 0.480099898273662 valid 0.5179321204335237
LOSS train 0.480099898273662 valid 0.5177239905126759
LOSS train 0.480099898273662 valid 0.5178146926852746
LOSS train 0.480099898273662 valid 0.5180142053192661
LOSS train 0.480099898273662 valid 0.5182133343219757
LOSS train 0.480099898273662 valid 0.51824052111497
LOSS train 0.480099898273662 valid 0.5184528257433824
LOSS train 0.480099898273662 valid 0.5187098809983581
LOSS train 0.480099898273662 valid 0.5188414761724398
LOSS train 0.480099898273662 valid 0.5187679416858233
LOSS train 0.480099898273662 valid 0.5187896487822059
LOSS train 0.480099898273662 valid 0.5185274610465224
LOSS train 0.480099898273662 valid 0.5184493102973565
LOSS train 0.480099898273662 valid 0.5184025192883477
LOSS train 0.480099898273662 valid 0.5185322282490907
LOSS train 0.480099898273662 valid 0.51852831397863
LOSS train 0.480099898273662 valid 0.5182859247183278
LOSS train 0.480099898273662 valid 0.5180071348297424
LOSS train 0.480099898273662 valid 0.5179174201522799
LOSS train 0.480099898273662 valid 0.517944999890668
LOSS train 0.480099898273662 valid 0.5181125019881743
LOSS train 0.480099898273662 valid 0.5182743431396888
LOSS train 0.480099898273662 valid 0.5181743875666932
LOSS train 0.480099898273662 valid 0.5181892963333262
LOSS train 0.480099898273662 valid 0.5179089026204471
LOSS train 0.480099898273662 valid 0.5182096633600862
LOSS train 0.480099898273662 valid 0.5179382546418378
LOSS train 0.480099898273662 valid 0.5183290331750303
LOSS train 0.480099898273662 valid 0.5182382152384559
LOSS train 0.480099898273662 valid 0.5183707245190938
LOSS train 0.480099898273662 valid 0.5183645080256936
LOSS train 0.480099898273662 valid 0.5180824148027521
LOSS train 0.480099898273662 valid 0.5180394793647567
LOSS train 0.480099898273662 valid 0.5181695350578853
LOSS train 0.480099898273662 valid 0.5180938639948445
LOSS train 0.480099898273662 valid 0.5185173734640464
LOSS train 0.480099898273662 valid 0.5185083185031916
LOSS train 0.480099898273662 valid 0.5186076677298244
LOSS train 0.480099898273662 valid 0.5183766291201489
LOSS train 0.480099898273662 valid 0.5183101860806346
LOSS train 0.480099898273662 valid 0.5185140991433067
LOSS train 0.480099898273662 valid 0.5183676926442135
LOSS train 0.480099898273662 valid 0.5183004034808808
LOSS train 0.480099898273662 valid 0.5181433652959219
LOSS train 0.480099898273662 valid 0.5178757606130657
LOSS train 0.480099898273662 valid 0.517643584185336
LOSS train 0.480099898273662 valid 0.5178475740427029
LOSS train 0.480099898273662 valid 0.5180346022049586
LOSS train 0.480099898273662 valid 0.5181432913040974
LOSS train 0.480099898273662 valid 0.5181789622587316
LOSS train 0.480099898273662 valid 0.5184526168114958
LOSS train 0.480099898273662 valid 0.5185758273961932
LOSS train 0.480099898273662 valid 0.5186501028220778
LOSS train 0.480099898273662 valid 0.5186959436570091
LOSS train 0.480099898273662 valid 0.5187818254743304
LOSS train 0.480099898273662 valid 0.5188998065211556
LOSS train 0.480099898273662 valid 0.5190568805414405
LOSS train 0.480099898273662 valid 0.5193230978558573
LOSS train 0.480099898273662 valid 0.5194197526857174
LOSS train 0.480099898273662 valid 0.5194640490743849
LOSS train 0.480099898273662 valid 0.5195041348262387
LOSS train 0.480099898273662 valid 0.5195489964642368
LOSS train 0.480099898273662 valid 0.5195054929764544
LOSS train 0.480099898273662 valid 0.5195490316204403
LOSS train 0.480099898273662 valid 0.5194643059292355
LOSS train 0.480099898273662 valid 0.5195289741280258
LOSS train 0.480099898273662 valid 0.5197541656341145
LOSS train 0.480099898273662 valid 0.5198007153069719
LOSS train 0.480099898273662 valid 0.5196343455365096
LOSS train 0.480099898273662 valid 0.519539978943373
LOSS train 0.480099898273662 valid 0.5198235053042467
LOSS train 0.480099898273662 valid 0.5199622564638654
LOSS train 0.480099898273662 valid 0.5200114874024465
LOSS train 0.480099898273662 valid 0.5198478514386207
LOSS train 0.480099898273662 valid 0.5196060133286011
LOSS train 0.480099898273662 valid 0.5195921016286831
LOSS train 0.480099898273662 valid 0.519653730132253
LOSS train 0.480099898273662 valid 0.519546222807181
LOSS train 0.480099898273662 valid 0.5196689849522844
LOSS train 0.480099898273662 valid 0.5196816709637642
LOSS train 0.480099898273662 valid 0.5195492679503426
LOSS train 0.480099898273662 valid 0.519626177035936
LOSS train 0.480099898273662 valid 0.5195370778955263
LOSS train 0.480099898273662 valid 0.5197263641976843
LOSS train 0.480099898273662 valid 0.5197097140114482
LOSS train 0.480099898273662 valid 0.5199299971166166
LOSS train 0.480099898273662 valid 0.5198832204664386
LOSS train 0.480099898273662 valid 0.5198300674271125
LOSS train 0.480099898273662 valid 0.5195633235730623
LOSS train 0.480099898273662 valid 0.5194745015530359
LOSS train 0.480099898273662 valid 0.5196571039362541
LOSS train 0.480099898273662 valid 0.5196408747502093
LOSS train 0.480099898273662 valid 0.5196454088452837
LOSS train 0.480099898273662 valid 0.5195899391285727
LOSS train 0.480099898273662 valid 0.5193764913913815
LOSS train 0.480099898273662 valid 0.5192963453354659
LOSS train 0.480099898273662 valid 0.519447053083077
LOSS train 0.480099898273662 valid 0.5193843562668616
LOSS train 0.480099898273662 valid 0.519474352875801
LOSS train 0.480099898273662 valid 0.519415441697294
LOSS train 0.480099898273662 valid 0.5195315776906941
LOSS train 0.480099898273662 valid 0.5197155840762027
LOSS train 0.480099898273662 valid 0.5199116687603595
LOSS train 0.480099898273662 valid 0.5199219100177288
LOSS train 0.480099898273662 valid 0.5198833131790161
LOSS train 0.480099898273662 valid 0.5198181382322733
LOSS train 0.480099898273662 valid 0.5199640994555099
LOSS train 0.480099898273662 valid 0.5201176052030764
LOSS train 0.480099898273662 valid 0.5200821957733954
LOSS train 0.480099898273662 valid 0.5202073843582816
LOSS train 0.480099898273662 valid 0.5201079977023138
LOSS train 0.480099898273662 valid 0.520163956130373
LOSS train 0.480099898273662 valid 0.5199427125024182
LOSS train 0.480099898273662 valid 0.5199199391481204
LOSS train 0.480099898273662 valid 0.5200163837443007
LOSS train 0.480099898273662 valid 0.5200194136823638
LOSS train 0.480099898273662 valid 0.5199795904793317
LOSS train 0.480099898273662 valid 0.5199368399481813
LOSS train 0.480099898273662 valid 0.5199846097864367
LOSS train 0.480099898273662 valid 0.5199652561297019
LOSS train 0.480099898273662 valid 0.5201291044965325
LOSS train 0.480099898273662 valid 0.5201592535273103
LOSS train 0.480099898273662 valid 0.5201182965143227
LOSS train 0.480099898273662 valid 0.5201238561116281
LOSS train 0.480099898273662 valid 0.520082931250942
LOSS train 0.480099898273662 valid 0.5200257002095866
LOSS train 0.480099898273662 valid 0.5202199989243558
LOSS train 0.480099898273662 valid 0.5202065673806975
LOSS train 0.480099898273662 valid 0.520175762803679
LOSS train 0.480099898273662 valid 0.5203480328321457
LOSS train 0.480099898273662 valid 0.520310000713128
LOSS train 0.480099898273662 valid 0.5204074296449858
LOSS train 0.480099898273662 valid 0.5204953168456262
LOSS train 0.480099898273662 valid 0.5204951499156126
LOSS train 0.480099898273662 valid 0.5204738258146773
LOSS train 0.480099898273662 valid 0.5204342376673594
LOSS train 0.480099898273662 valid 0.5203911159984796
LOSS train 0.480099898273662 valid 0.5204192826221156
LOSS train 0.480099898273662 valid 0.5204816945041009
LOSS train 0.480099898273662 valid 0.5204750903523885
LOSS train 0.480099898273662 valid 0.5205498501030421
LOSS train 0.480099898273662 valid 0.5206077377532274
LOSS train 0.480099898273662 valid 0.5206621881900179
LOSS train 0.480099898273662 valid 0.5206386312616594
LOSS train 0.480099898273662 valid 0.5207160599951474
LOSS train 0.480099898273662 valid 0.5207115627993318
LOSS train 0.480099898273662 valid 0.5206344604268949
LOSS train 0.480099898273662 valid 0.5206366874166389
LOSS train 0.480099898273662 valid 0.5208711202038265
LOSS train 0.480099898273662 valid 0.5209661506944232
LOSS train 0.480099898273662 valid 0.5210662703012628
LOSS train 0.480099898273662 valid 0.5210714330348898
LOSS train 0.480099898273662 valid 0.5212124602480249
LOSS train 0.480099898273662 valid 0.5211970156779254
LOSS train 0.480099898273662 valid 0.5211580815098502
LOSS train 0.480099898273662 valid 0.5212894096106723
LOSS train 0.480099898273662 valid 0.5213598037669805
LOSS train 0.480099898273662 valid 0.5213242219292002
LOSS train 0.480099898273662 valid 0.5214022837018454
LOSS train 0.480099898273662 valid 0.5214036804224763
LOSS train 0.480099898273662 valid 0.5211698646222993
LOSS train 0.480099898273662 valid 0.5210422103075271
LOSS train 0.480099898273662 valid 0.5209310830903138
LOSS train 0.480099898273662 valid 0.5210000688970928
LOSS train 0.480099898273662 valid 0.5210301565496545
LOSS train 0.480099898273662 valid 0.5209754475138404
LOSS train 0.480099898273662 valid 0.5209511604666295
LOSS train 0.480099898273662 valid 0.5209391561026374
LOSS train 0.480099898273662 valid 0.5209321890116563
LOSS train 0.480099898273662 valid 0.5209152623497206
LOSS train 0.480099898273662 valid 0.5208129804978257
LOSS train 0.480099898273662 valid 0.5207634329387586
LOSS train 0.480099898273662 valid 0.520765846296382
LOSS train 0.480099898273662 valid 0.5208534454407335
LOSS train 0.480099898273662 valid 0.5209924602912644
LOSS train 0.480099898273662 valid 0.5210362932569271
LOSS train 0.480099898273662 valid 0.5209880264519843
LOSS train 0.480099898273662 valid 0.5210087113332429
LOSS train 0.480099898273662 valid 0.5211274765406962
LOSS train 0.480099898273662 valid 0.5210450633366903
LOSS train 0.480099898273662 valid 0.5210867844942796
LOSS train 0.480099898273662 valid 0.5210236757006866
LOSS train 0.480099898273662 valid 0.5210411300753602
LOSS train 0.480099898273662 valid 0.5209954157471657
LOSS train 0.480099898273662 valid 0.5209077560510792
LOSS train 0.480099898273662 valid 0.5208545725524815
LOSS train 0.480099898273662 valid 0.5207992649427843
LOSS train 0.480099898273662 valid 0.520828487133825
LOSS train 0.480099898273662 valid 0.5208653565556486
LOSS train 0.480099898273662 valid 0.5208048142733113
LOSS train 0.480099898273662 valid 0.5207214073736185
LOSS train 0.480099898273662 valid 0.5207724601794512
LOSS train 0.480099898273662 valid 0.5209025222653398
LOSS train 0.480099898273662 valid 0.5209785208200953
LOSS train 0.480099898273662 valid 0.5210504813799782
LOSS train 0.480099898273662 valid 0.5209694593390332
LOSS train 0.480099898273662 valid 0.5210401705386887
LOSS train 0.480099898273662 valid 0.5209385305643082
LOSS train 0.480099898273662 valid 0.5210447138566582
LOSS train 0.480099898273662 valid 0.5209273641929031
LOSS train 0.480099898273662 valid 0.5208707934599428
LOSS train 0.480099898273662 valid 0.5208380242682392
LOSS train 0.480099898273662 valid 0.5207133826456571
LOSS train 0.480099898273662 valid 0.5206737448403864
LOSS train 0.480099898273662 valid 0.5206412271352915
LOSS train 0.480099898273662 valid 0.5207824096357896
LOSS train 0.480099898273662 valid 0.5208081608518548
LOSS train 0.480099898273662 valid 0.5209354634692029
LOSS train 0.480099898273662 valid 0.5210308912677243
LOSS train 0.480099898273662 valid 0.5210912923018137
LOSS train 0.480099898273662 valid 0.5210368271320608
LOSS train 0.480099898273662 valid 0.5208834610789655
LOSS train 0.480099898273662 valid 0.5209086642966972
LOSS train 0.480099898273662 valid 0.5210897390713949
LOSS train 0.480099898273662 valid 0.5210990411132129
LOSS train 0.480099898273662 valid 0.5211954235675789
LOSS train 0.480099898273662 valid 0.521140856099058
LOSS train 0.480099898273662 valid 0.5211456938255468
LOSS train 0.480099898273662 valid 0.5209931667927092
LOSS train 0.480099898273662 valid 0.5209088380722439
LOSS train 0.480099898273662 valid 0.5208187628526492
LOSS train 0.480099898273662 valid 0.5208190065204051
LOSS train 0.480099898273662 valid 0.5208425481013584
LOSS train 0.480099898273662 valid 0.5209438413554845
LOSS train 0.480099898273662 valid 0.5208985056566156
LOSS train 0.480099898273662 valid 0.5209595758274111
LOSS train 0.480099898273662 valid 0.5209585463451034
LOSS train 0.480099898273662 valid 0.5210535316460434
LOSS train 0.480099898273662 valid 0.5211459434988847
LOSS train 0.480099898273662 valid 0.5211250018221991
LOSS train 0.480099898273662 valid 0.5210404490303789
LOSS train 0.480099898273662 valid 0.5210195877165957
LOSS train 0.480099898273662 valid 0.5211209304440798
LOSS train 0.480099898273662 valid 0.5211729052881736
LOSS train 0.480099898273662 valid 0.5213069545551086
LOSS train 0.480099898273662 valid 0.5213821834225333
LOSS train 0.480099898273662 valid 0.5213233465407076
LOSS train 0.480099898273662 valid 0.5212385983273969
LOSS train 0.480099898273662 valid 0.5212815275265313
LOSS train 0.480099898273662 valid 0.5212873024245103
LOSS train 0.480099898273662 valid 0.521356708372729
LOSS train 0.480099898273662 valid 0.5214560926783809
LOSS train 0.480099898273662 valid 0.5214895409821807
LOSS train 0.480099898273662 valid 0.5214792926396642
LOSS train 0.480099898273662 valid 0.5215415819867016
LOSS train 0.480099898273662 valid 0.5215441020297222
LOSS train 0.480099898273662 valid 0.521472492968354
LOSS train 0.480099898273662 valid 0.5214591725203006
LOSS train 0.480099898273662 valid 0.5214883419394816
EPOCH 10:
  batch 1 loss: 0.4655741751194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.49383117258548737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.4924512803554535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.49098842591047287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.48950234055519104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.48614072799682617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4833318293094635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.48335687816143036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.48031913571887547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.47662968933582306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.47501572695645417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4746853659550349
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4738362248127277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.474730521440506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4772557973861694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4783509876579046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4768364622312434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47760112086931866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.47891273937727274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4790529727935791
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4786809569313413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.47824436155232514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.47951717739519867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.47905399898688
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4784693193435669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.47841811180114746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4792648642151444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.47822270542383194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4781525546106799
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4786353091398875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.47857794934703457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4790168246254325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.47810007135073346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4782649734440972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.47910423278808595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.479033918844329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.47807389175569687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4773738760697214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4777142711174794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.47809799909591677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4776573471906709
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.47766834852241336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.47937272939571113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.47985779494047165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.47997335261768764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.47924278676509857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4792579120778023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.479863657305638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4800076849606572
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4808700752258301
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.48023008073077483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4799247601857552
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4794546950538203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.47910896054020635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4783456260507757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.47866676481706755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.47883383851302297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.47826328359801196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4777050038515511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4780711978673935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.4779024163230521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.47850522783494764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.47871106011526926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4788626478984952
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4793934941291809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4788248159668662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.47872197049767223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.47891730333075805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.47884066381316254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.47901934470449176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.47917261048102044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4786527322398292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4788781702518463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.47878455068614034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.47854714075724286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4791028523131421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.47883639862011007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4785412916770348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4786286603046369
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.47834212258458136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4783761942828143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4781955095326028
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4783406839313277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.47813479141110465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4780028991839465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4782461160144141
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.47848364779318886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4786919223313982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.47864513685194293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4785980711380641
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.47839461709116843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4787857338138249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.47896220543051277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4790109896913488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.47888876325205754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4794983994215727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4794440478393712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.47940805645621554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4795699679490292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4797625529766083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4796968686698687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.47978417516923416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4800044439950036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.48002417414234233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4801412562529246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4799331215754995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4798251646701421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4800029844045639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4799434444226256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4799880092794245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4798288444677989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4798256776162556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.480007264993887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4799252894886753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4796276657477669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4797444001867853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4801656575793894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4800731415970851
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4802103380696112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4799238299330076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4799428311261264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4802612217723346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4804380366472694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4802668705101936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.48040990352630614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4805766041316683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.48049489015669333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4807372004725039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.480642975762833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.4807101520208212
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4806477281883473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4805370221535365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4805051592507757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.48040488384552854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4803695950243208
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.4803938622422078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.48061832307028945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4804732119259627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4806480577094949
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4807228942002569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4805957021865439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4806570446407291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.480738991415584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4810155491448111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.48109490912536096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4809466984174023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4811073468655956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4812890871151074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.4811677724723048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4809643582503001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.48101786114522166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4810687758420643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.48107612133026123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.48097009240806876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.48121868910328036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.481446915330031
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4813979000422605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4814958219664006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4816891489163885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4817652780562639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4816245721734088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4814853322358779
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.481531194931159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.48143297561058185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.48134255860791064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4815060275505824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.48150239715319193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4812208053966363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.48117953274377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.4812421704039854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.48118280057321516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4810650849411654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4809345787315699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4810432956136506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4808943852356502
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.48075888627632096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4806759128462797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4806706473398744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.48073847516954943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.48073239210579133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.480648923315396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.48063875620181745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4804875849048948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4803997415887273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.48045359253883363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.48040230476087137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.480329663995753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.48022524964936236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.48021267756583197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4801375473800458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4800360845645685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.47978506113092106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4797979255105547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4798569934269817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4797823630846464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.47980411806885076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.47991134914649924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4801172042133832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.48011413246542967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4801782739162445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4801927011701005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.48018305092164787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.47993153128130683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4799022394068101
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4798603854528288
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.47968498132761245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.47964386030095785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.47954523434432655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4797547053207051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.47978632875851224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.479766291747161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4799526218535765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.47999836343554825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.47986274177783006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4798978467320287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.47983027194385175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.47990018266686646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.48014494694701026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.48039668118028334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.48044187020171775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.48027475252410406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4801921935768815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.48025027371842766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.48032256521816763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4801415365272098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4800228749492527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4800440995966285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4799126899033262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.47985979276973606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4799875539282094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.47994091397240046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.48006364805945034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4799613432055379
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4800081761219563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4800661651377982
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4800525925169557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4800397719763502
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4799691338499053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.47997797233789036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.48004236072301865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4800796873589274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4799695612231562
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4800405501092903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.48005306879516507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4801881694063848
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.48032020759291766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4803745615096227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.48026572276026974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4804240224591221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4804541670084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.48048552253331794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.48045440290182356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4805424723464981
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.480453063535878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4804189673825806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.48041166889015585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.48025970943706975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.48026884260565733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4804928349942314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.480606732574793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4806081665201662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.48053749178657096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4805418183821689
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.48054717684333975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.48042419991403257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.48047331972677904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4804755181409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4804177547791111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4803571412997618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.48036150137583417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.48042305182266937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.48034085914054336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.48029061409579965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4800739384045566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.47990962852131236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.479973791734032
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.48001815330250597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.47995353452593303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4799805605069711
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4800092237336295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4800707015914849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4800856503400397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.48005020544722726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.48009092066909226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.48012697414348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.48014120153197043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.4801599948248381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4801834477111697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4801326626106117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.48019293556953296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.48013294613648116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4801504627278406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.48020068075469735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.48026590322961615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4802401918475911
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.48021917286756877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4803146320561367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4802822175641988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4802503971551174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.48024433533350624
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.48035644296791863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.48028413408639414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.48021833652710366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4802399213965002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4802951702328979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.48027291806305156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.48023461188866184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4802883956339452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.48035172206684223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.48028340464638125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.48033752395409096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.48025960370134085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.48015572459172134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.48005303446274655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4800139562478141
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.48008178334824647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.48012098519583984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.48014134965227834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4801531020189901
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.48021114794537423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4800997273387196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.4801792507030949
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.48034730885789123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4803253756261166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4802887454399696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4802999554053406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4803661499001564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.48046024498052714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.48038432835445577
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4804806618076382
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.48055381798312025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4805186675435089
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4805356961291832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.48048239402071447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.48046518466365873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4805175799521662
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4804357462714617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.48042442266052293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.48033457590063766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.48041126517688526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4804155407063772
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4804173233041986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.48029786461296303
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.480267021805048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4802686294783717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4803523794247236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.48041647646887503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4804789041136873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.48041756882366954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4804108669076647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.48033063092462697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4803485200655731
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.48042871737615245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.48036934401692644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.48035521431708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.48026913379350405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.48026199609625575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.48036004952545275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.48032842032756645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.48024760824110774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4801900092089275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4802176087106789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4802223451373991
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.48012276509633434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.480138447513319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4800656384131948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4800099190476805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.48001027576949284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.47999067818569296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4800055258177422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.48001659004836067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.47998585447829256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.48001536519214233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.48000910089296456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4799885987440745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.47996760825527474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4799868013087255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.48009569643351135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4801383363697334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.48004242856251567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4800071842244917
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4799400815320889
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.48003887141964763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4800630411288391
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.48003893223675814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.48011113448464193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4800973399819022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.48017676182321667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4801798117344667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4801770304258053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.48017927638405117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4802120993179934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.48020138737506235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4801926956261475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4801502909841417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4802130069395508
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4802569066847602
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.4803657979521919
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4804187225817439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4803771363943815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.48028186528462724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.480139091314368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4801152108177062
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4800843378104786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4800824732692153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.48013666514399017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.48009682031169865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4800807542222388
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4800207712539542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.48001699055113445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.48009549512770344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.48013954616866067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.48007271833916265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.48021535215458433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4803064777908555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.48039746348961043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.48038114653788594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.48039036226329623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4804613290794709
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4804600687254043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.48056629123144085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.48067737953357786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.48062449813452734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4806210846411732
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.4805847900054034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4804796831848476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4804884155544799
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4804244256604498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4803318288915363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4804270358279694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4803823198077297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.48041381645533776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.48032116862422597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.48032657115415495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4802083690276091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.48032217007984807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4803083320776985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.48028161631871574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4802066364701082
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.48019852875308555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4802458136935894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.48022243562596956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.48024530691971357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4801703041066995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4803207517339942
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4802339697766197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.48031579614752357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.48035115249721066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4803572546002063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.480340005490515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4803030393736854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.48036294918408434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.48032799942077653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4802791639702961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.48028254083224703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4802209072860709
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4801712009395499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.480178867365075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.48011389017624534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.48023331994595736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.48019881187705826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4801876481090273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.48019306017307173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.48019097327929117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.48015016644231734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4801734836828044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4801503460718682
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4802393998600479
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4802577261731569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.48032986914857906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4803013276395777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.48036041742159147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.48036041742159147 valid 0.4880025386810303
LOSS train 0.48036041742159147 valid 0.5031897127628326
LOSS train 0.48036041742159147 valid 0.5013146102428436
LOSS train 0.48036041742159147 valid 0.49698014557361603
LOSS train 0.48036041742159147 valid 0.49187723398208616
LOSS train 0.48036041742159147 valid 0.4974750379721324
LOSS train 0.48036041742159147 valid 0.5041789838245937
LOSS train 0.48036041742159147 valid 0.5065950900316238
LOSS train 0.48036041742159147 valid 0.5083941221237183
LOSS train 0.48036041742159147 valid 0.5126228272914887
LOSS train 0.48036041742159147 valid 0.5159224163402211
LOSS train 0.48036041742159147 valid 0.5149017572402954
LOSS train 0.48036041742159147 valid 0.5193930039039025
LOSS train 0.48036041742159147 valid 0.5216248418603625
LOSS train 0.48036041742159147 valid 0.5229784329732259
LOSS train 0.48036041742159147 valid 0.5209415201097727
LOSS train 0.48036041742159147 valid 0.5233490554725423
LOSS train 0.48036041742159147 valid 0.5237427635325326
LOSS train 0.48036041742159147 valid 0.5226395020359441
LOSS train 0.48036041742159147 valid 0.5236643806099892
LOSS train 0.48036041742159147 valid 0.5234687399296534
LOSS train 0.48036041742159147 valid 0.5221503905274651
LOSS train 0.48036041742159147 valid 0.5223082602024078
LOSS train 0.48036041742159147 valid 0.5212240802745024
LOSS train 0.48036041742159147 valid 0.5199868440628052
LOSS train 0.48036041742159147 valid 0.5184252605988429
LOSS train 0.48036041742159147 valid 0.5180137047061214
LOSS train 0.48036041742159147 valid 0.5186089766877038
LOSS train 0.48036041742159147 valid 0.5176357637191641
LOSS train 0.48036041742159147 valid 0.5190754403670629
LOSS train 0.48036041742159147 valid 0.5203488824828979
LOSS train 0.48036041742159147 valid 0.5206309473142028
LOSS train 0.48036041742159147 valid 0.5219681091380842
LOSS train 0.48036041742159147 valid 0.5227770568693385
LOSS train 0.48036041742159147 valid 0.5244241382394518
LOSS train 0.48036041742159147 valid 0.5248621412449412
LOSS train 0.48036041742159147 valid 0.5251798138425157
LOSS train 0.48036041742159147 valid 0.5256700554960653
LOSS train 0.48036041742159147 valid 0.5255475051892109
LOSS train 0.48036041742159147 valid 0.5261469163000584
LOSS train 0.48036041742159147 valid 0.526239779664249
LOSS train 0.48036041742159147 valid 0.5262001504500707
LOSS train 0.48036041742159147 valid 0.5261812106121418
LOSS train 0.48036041742159147 valid 0.5262640856883742
LOSS train 0.48036041742159147 valid 0.5262135869926876
LOSS train 0.48036041742159147 valid 0.526931956410408
LOSS train 0.48036041742159147 valid 0.5269993106101422
LOSS train 0.48036041742159147 valid 0.5278866657366356
LOSS train 0.48036041742159147 valid 0.5290462137485037
LOSS train 0.48036041742159147 valid 0.528409224152565
LOSS train 0.48036041742159147 valid 0.5291363217082679
LOSS train 0.48036041742159147 valid 0.5295376279033147
LOSS train 0.48036041742159147 valid 0.5293547370523777
LOSS train 0.48036041742159147 valid 0.5287373965537107
LOSS train 0.48036041742159147 valid 0.5287628320130435
LOSS train 0.48036041742159147 valid 0.528424513659307
LOSS train 0.48036041742159147 valid 0.5280057155249411
LOSS train 0.48036041742159147 valid 0.5281455172546978
LOSS train 0.48036041742159147 valid 0.5287759046433336
LOSS train 0.48036041742159147 valid 0.5282498036821683
LOSS train 0.48036041742159147 valid 0.5269946978717553
LOSS train 0.48036041742159147 valid 0.5271174556786015
LOSS train 0.48036041742159147 valid 0.5269399214358557
LOSS train 0.48036041742159147 valid 0.5273791174404323
LOSS train 0.48036041742159147 valid 0.5276909713561718
LOSS train 0.48036041742159147 valid 0.526994784673055
LOSS train 0.48036041742159147 valid 0.5267653020460215
LOSS train 0.48036041742159147 valid 0.5267361560288597
LOSS train 0.48036041742159147 valid 0.5267086357310198
LOSS train 0.48036041742159147 valid 0.5260011655943734
LOSS train 0.48036041742159147 valid 0.5254516786252948
LOSS train 0.48036041742159147 valid 0.5252522569563653
LOSS train 0.48036041742159147 valid 0.5257128060680546
LOSS train 0.48036041742159147 valid 0.524959604482393
LOSS train 0.48036041742159147 valid 0.5249483871459961
LOSS train 0.48036041742159147 valid 0.5252272972935125
LOSS train 0.48036041742159147 valid 0.5250924810186609
LOSS train 0.48036041742159147 valid 0.5251249136068882
LOSS train 0.48036041742159147 valid 0.5247772094569628
LOSS train 0.48036041742159147 valid 0.5246606700122356
LOSS train 0.48036041742159147 valid 0.5242311608644179
LOSS train 0.48036041742159147 valid 0.5243241518009
LOSS train 0.48036041742159147 valid 0.5240203835159899
LOSS train 0.48036041742159147 valid 0.5240821458754086
LOSS train 0.48036041742159147 valid 0.5237543309436125
LOSS train 0.48036041742159147 valid 0.5234509113916131
LOSS train 0.48036041742159147 valid 0.5233572409755882
LOSS train 0.48036041742159147 valid 0.5233920578929511
LOSS train 0.48036041742159147 valid 0.5235140467627665
LOSS train 0.48036041742159147 valid 0.5239961501624849
LOSS train 0.48036041742159147 valid 0.5241451744849865
LOSS train 0.48036041742159147 valid 0.5239934399724007
LOSS train 0.48036041742159147 valid 0.5237695962511083
LOSS train 0.48036041742159147 valid 0.5236307575981668
LOSS train 0.48036041742159147 valid 0.5234238828483381
LOSS train 0.48036041742159147 valid 0.523361693136394
LOSS train 0.48036041742159147 valid 0.5234334090935815
LOSS train 0.48036041742159147 valid 0.5231780643974032
LOSS train 0.48036041742159147 valid 0.5236951163922897
LOSS train 0.48036041742159147 valid 0.5239425411820412
LOSS train 0.48036041742159147 valid 0.5238175973443702
LOSS train 0.48036041742159147 valid 0.523875991211218
LOSS train 0.48036041742159147 valid 0.5241956499595086
LOSS train 0.48036041742159147 valid 0.5243722529938588
LOSS train 0.48036041742159147 valid 0.5245467449937548
LOSS train 0.48036041742159147 valid 0.524715541949812
LOSS train 0.48036041742159147 valid 0.5245809307165235
LOSS train 0.48036041742159147 valid 0.5245265240470568
LOSS train 0.48036041742159147 valid 0.5247335245303058
LOSS train 0.48036041742159147 valid 0.5250834375619888
LOSS train 0.48036041742159147 valid 0.5249800067227166
LOSS train 0.48036041742159147 valid 0.5248530451208353
LOSS train 0.48036041742159147 valid 0.5250389895080465
LOSS train 0.48036041742159147 valid 0.5245452648714969
LOSS train 0.48036041742159147 valid 0.5245883594388547
LOSS train 0.48036041742159147 valid 0.5248687303271787
LOSS train 0.48036041742159147 valid 0.5247247096819755
LOSS train 0.48036041742159147 valid 0.5246051373118061
LOSS train 0.48036041742159147 valid 0.5245055105505871
LOSS train 0.48036041742159147 valid 0.524474872648716
LOSS train 0.48036041742159147 valid 0.5242863524058634
LOSS train 0.48036041742159147 valid 0.5240780750259024
LOSS train 0.48036041742159147 valid 0.5241692366638804
LOSS train 0.48036041742159147 valid 0.5243751570101707
LOSS train 0.48036041742159147 valid 0.5245703916549682
LOSS train 0.48036041742159147 valid 0.5246002664641728
LOSS train 0.48036041742159147 valid 0.524809776798008
LOSS train 0.48036041742159147 valid 0.5250658034346998
LOSS train 0.48036041742159147 valid 0.5251933257709178
LOSS train 0.48036041742159147 valid 0.5251155940385965
LOSS train 0.48036041742159147 valid 0.5251364093700438
LOSS train 0.48036041742159147 valid 0.5248754308982329
LOSS train 0.48036041742159147 valid 0.5247980284511595
LOSS train 0.48036041742159147 valid 0.5247484943759975
LOSS train 0.48036041742159147 valid 0.5248790034541377
LOSS train 0.48036041742159147 valid 0.5248762377921272
LOSS train 0.48036041742159147 valid 0.5246363371393107
LOSS train 0.48036041742159147 valid 0.5243552795786789
LOSS train 0.48036041742159147 valid 0.524263080718706
LOSS train 0.48036041742159147 valid 0.5242864334157535
LOSS train 0.48036041742159147 valid 0.5244544683196021
LOSS train 0.48036041742159147 valid 0.5246152334230046
LOSS train 0.48036041742159147 valid 0.5245155431590713
LOSS train 0.48036041742159147 valid 0.524524695550402
LOSS train 0.48036041742159147 valid 0.5242448070953633
LOSS train 0.48036041742159147 valid 0.5245452935565008
LOSS train 0.48036041742159147 valid 0.5242764828156452
LOSS train 0.48036041742159147 valid 0.5246672098701065
LOSS train 0.48036041742159147 valid 0.5245732373039195
LOSS train 0.48036041742159147 valid 0.5247136823336284
LOSS train 0.48036041742159147 valid 0.5247093912781469
LOSS train 0.48036041742159147 valid 0.5244230953486342
LOSS train 0.48036041742159147 valid 0.5243809562103421
LOSS train 0.48036041742159147 valid 0.5245116236922028
LOSS train 0.48036041742159147 valid 0.5244360500766385
LOSS train 0.48036041742159147 valid 0.5248562200711324
LOSS train 0.48036041742159147 valid 0.5248471422559896
LOSS train 0.48036041742159147 valid 0.5249392254443108
LOSS train 0.48036041742159147 valid 0.5247077692604665
LOSS train 0.48036041742159147 valid 0.5246463095769286
LOSS train 0.48036041742159147 valid 0.5248525836823149
LOSS train 0.48036041742159147 valid 0.5247051956844918
LOSS train 0.48036041742159147 valid 0.524632595250943
LOSS train 0.48036041742159147 valid 0.5244757138737818
LOSS train 0.48036041742159147 valid 0.5242056637099295
LOSS train 0.48036041742159147 valid 0.5239735048219382
LOSS train 0.48036041742159147 valid 0.5241775958837863
LOSS train 0.48036041742159147 valid 0.5243654882624036
LOSS train 0.48036041742159147 valid 0.5244793733196146
LOSS train 0.48036041742159147 valid 0.5245146348195917
LOSS train 0.48036041742159147 valid 0.5247870408303557
LOSS train 0.48036041742159147 valid 0.5249068445937578
LOSS train 0.48036041742159147 valid 0.5249794321942192
LOSS train 0.48036041742159147 valid 0.5250211481390328
LOSS train 0.48036041742159147 valid 0.5251039041791643
LOSS train 0.48036041742159147 valid 0.5252235850149934
LOSS train 0.48036041742159147 valid 0.5253810788278526
LOSS train 0.48036041742159147 valid 0.5256466383344671
LOSS train 0.48036041742159147 valid 0.5257403377714104
LOSS train 0.48036041742159147 valid 0.5257809774743186
LOSS train 0.48036041742159147 valid 0.5258204472657725
LOSS train 0.48036041742159147 valid 0.525863630431039
LOSS train 0.48036041742159147 valid 0.5258202858961345
LOSS train 0.48036041742159147 valid 0.525863411957803
LOSS train 0.48036041742159147 valid 0.5257776521347665
LOSS train 0.48036041742159147 valid 0.525841728333504
LOSS train 0.48036041742159147 valid 0.5260655468797939
LOSS train 0.48036041742159147 valid 0.5261116725333194
LOSS train 0.48036041742159147 valid 0.5259448952145047
LOSS train 0.48036041742159147 valid 0.5258522996776982
LOSS train 0.48036041742159147 valid 0.5261339195735791
LOSS train 0.48036041742159147 valid 0.5262698394556841
LOSS train 0.48036041742159147 valid 0.5263188104555396
LOSS train 0.48036041742159147 valid 0.5261563188636426
LOSS train 0.48036041742159147 valid 0.5259189300048046
LOSS train 0.48036041742159147 valid 0.5259070189631715
LOSS train 0.48036041742159147 valid 0.5259738709720864
LOSS train 0.48036041742159147 valid 0.5258646351520462
LOSS train 0.48036041742159147 valid 0.5259864512999454
LOSS train 0.48036041742159147 valid 0.5259971621632576
LOSS train 0.48036041742159147 valid 0.5258628737867175
LOSS train 0.48036041742159147 valid 0.5259397997714506
LOSS train 0.48036041742159147 valid 0.5258481857811876
LOSS train 0.48036041742159147 valid 0.526037260890007
LOSS train 0.48036041742159147 valid 0.5260204355891158
LOSS train 0.48036041742159147 valid 0.5262392475767043
LOSS train 0.48036041742159147 valid 0.5261941675978582
LOSS train 0.48036041742159147 valid 0.5261429857749206
LOSS train 0.48036041742159147 valid 0.525877116114329
LOSS train 0.48036041742159147 valid 0.5257921318213145
LOSS train 0.48036041742159147 valid 0.5259746948689646
LOSS train 0.48036041742159147 valid 0.5259587236170499
LOSS train 0.48036041742159147 valid 0.525960431412352
LOSS train 0.48036041742159147 valid 0.5259053779539661
LOSS train 0.48036041742159147 valid 0.5256958398708077
LOSS train 0.48036041742159147 valid 0.5256161206850299
LOSS train 0.48036041742159147 valid 0.525766204853761
LOSS train 0.48036041742159147 valid 0.5257056486715964
LOSS train 0.48036041742159147 valid 0.5257915702040337
LOSS train 0.48036041742159147 valid 0.525733172622594
LOSS train 0.48036041742159147 valid 0.5258470129103682
LOSS train 0.48036041742159147 valid 0.5260295277243262
LOSS train 0.48036041742159147 valid 0.526228496312026
LOSS train 0.48036041742159147 valid 0.5262396301009825
LOSS train 0.48036041742159147 valid 0.526200708548228
LOSS train 0.48036041742159147 valid 0.5261363975242176
LOSS train 0.48036041742159147 valid 0.5262816679635237
LOSS train 0.48036041742159147 valid 0.5264340602515036
LOSS train 0.48036041742159147 valid 0.5263978248079791
LOSS train 0.48036041742159147 valid 0.5265217065811157
LOSS train 0.48036041742159147 valid 0.5264236426456667
LOSS train 0.48036041742159147 valid 0.5264771616664427
LOSS train 0.48036041742159147 valid 0.5262562491863071
LOSS train 0.48036041742159147 valid 0.5262358168251494
LOSS train 0.48036041742159147 valid 0.5263328273245629
LOSS train 0.48036041742159147 valid 0.5263322124541816
LOSS train 0.48036041742159147 valid 0.5262944388993179
LOSS train 0.48036041742159147 valid 0.5262535868071708
LOSS train 0.48036041742159147 valid 0.5263018134248806
LOSS train 0.48036041742159147 valid 0.5262821167707443
LOSS train 0.48036041742159147 valid 0.5264464067720279
LOSS train 0.48036041742159147 valid 0.5264748950635106
LOSS train 0.48036041742159147 valid 0.5264370186338699
LOSS train 0.48036041742159147 valid 0.5264443256815926
LOSS train 0.48036041742159147 valid 0.5264014166228626
LOSS train 0.48036041742159147 valid 0.5263461538446628
LOSS train 0.48036041742159147 valid 0.5265415226399657
LOSS train 0.48036041742159147 valid 0.5265294933511365
LOSS train 0.48036041742159147 valid 0.5264961097135122
LOSS train 0.48036041742159147 valid 0.5266675958633423
LOSS train 0.48036041742159147 valid 0.526629418015955
LOSS train 0.48036041742159147 valid 0.5267261328205229
LOSS train 0.48036041742159147 valid 0.5268138517504153
LOSS train 0.48036041742159147 valid 0.5268123863250251
LOSS train 0.48036041742159147 valid 0.5267905160492542
LOSS train 0.48036041742159147 valid 0.526749515440315
LOSS train 0.48036041742159147 valid 0.5267084090162344
LOSS train 0.48036041742159147 valid 0.5267357537450716
LOSS train 0.48036041742159147 valid 0.5267979751222382
LOSS train 0.48036041742159147 valid 0.526789760360351
LOSS train 0.48036041742159147 valid 0.5268649276188964
LOSS train 0.48036041742159147 valid 0.5269223947561424
LOSS train 0.48036041742159147 valid 0.5269756212887202
LOSS train 0.48036041742159147 valid 0.5269514642881624
LOSS train 0.48036041742159147 valid 0.5270279403002757
LOSS train 0.48036041742159147 valid 0.5270225239875621
LOSS train 0.48036041742159147 valid 0.526944237255425
LOSS train 0.48036041742159147 valid 0.5269513232494468
LOSS train 0.48036041742159147 valid 0.527181975460407
LOSS train 0.48036041742159147 valid 0.5272767049294931
LOSS train 0.48036041742159147 valid 0.5273726848658601
LOSS train 0.48036041742159147 valid 0.5273779008318397
LOSS train 0.48036041742159147 valid 0.5275209557005774
LOSS train 0.48036041742159147 valid 0.5275042298501426
LOSS train 0.48036041742159147 valid 0.5274674968285994
LOSS train 0.48036041742159147 valid 0.5275988220304683
LOSS train 0.48036041742159147 valid 0.527667190624058
LOSS train 0.48036041742159147 valid 0.5276317626452275
LOSS train 0.48036041742159147 valid 0.5277082994847315
LOSS train 0.48036041742159147 valid 0.5277085212724549
LOSS train 0.48036041742159147 valid 0.527474172811067
LOSS train 0.48036041742159147 valid 0.5273461111471163
LOSS train 0.48036041742159147 valid 0.5272347487956812
LOSS train 0.48036041742159147 valid 0.5273049443330563
LOSS train 0.48036041742159147 valid 0.5273352544558676
LOSS train 0.48036041742159147 valid 0.5272806858891373
LOSS train 0.48036041742159147 valid 0.5272575993778814
LOSS train 0.48036041742159147 valid 0.5272450375681123
LOSS train 0.48036041742159147 valid 0.5272391171397635
LOSS train 0.48036041742159147 valid 0.5272220137818107
LOSS train 0.48036041742159147 valid 0.5271208627322286
LOSS train 0.48036041742159147 valid 0.5270715756979707
LOSS train 0.48036041742159147 valid 0.5270736981374005
LOSS train 0.48036041742159147 valid 0.5271599561381503
LOSS train 0.48036041742159147 valid 0.5272975104340052
LOSS train 0.48036041742159147 valid 0.5273417706626493
LOSS train 0.48036041742159147 valid 0.5272924804727638
LOSS train 0.48036041742159147 valid 0.5273131547158196
LOSS train 0.48036041742159147 valid 0.5274337269988746
LOSS train 0.48036041742159147 valid 0.5273505517840386
LOSS train 0.48036041742159147 valid 0.5273906446968598
LOSS train 0.48036041742159147 valid 0.5273271304684759
LOSS train 0.48036041742159147 valid 0.5273435653829732
LOSS train 0.48036041742159147 valid 0.5272968108520696
LOSS train 0.48036041742159147 valid 0.5272088487617305
LOSS train 0.48036041742159147 valid 0.527157152302904
LOSS train 0.48036041742159147 valid 0.527102768712401
LOSS train 0.48036041742159147 valid 0.5271296718871439
LOSS train 0.48036041742159147 valid 0.5271653645825618
LOSS train 0.48036041742159147 valid 0.5271076882077802
LOSS train 0.48036041742159147 valid 0.5270239274793116
LOSS train 0.48036041742159147 valid 0.5270755859330679
LOSS train 0.48036041742159147 valid 0.5272039040780296
LOSS train 0.48036041742159147 valid 0.5272800902462309
LOSS train 0.48036041742159147 valid 0.5273497652439844
LOSS train 0.48036041742159147 valid 0.5272694330992578
LOSS train 0.48036041742159147 valid 0.5273402023954722
LOSS train 0.48036041742159147 valid 0.5272389488212718
LOSS train 0.48036041742159147 valid 0.5273451609858151
LOSS train 0.48036041742159147 valid 0.527231413219124
LOSS train 0.48036041742159147 valid 0.5271745891400216
LOSS train 0.48036041742159147 valid 0.5271413878809591
LOSS train 0.48036041742159147 valid 0.5270150768867587
LOSS train 0.48036041742159147 valid 0.5269793763204857
LOSS train 0.48036041742159147 valid 0.5269462007742661
LOSS train 0.48036041742159147 valid 0.5270871042839589
LOSS train 0.48036041742159147 valid 0.5271134327311034
LOSS train 0.48036041742159147 valid 0.5272385458030352
LOSS train 0.48036041742159147 valid 0.5273349995308734
LOSS train 0.48036041742159147 valid 0.5273981509786664
LOSS train 0.48036041742159147 valid 0.5273436938167699
LOSS train 0.48036041742159147 valid 0.5271919091422874
LOSS train 0.48036041742159147 valid 0.5272176822384557
LOSS train 0.48036041742159147 valid 0.5273979393664948
LOSS train 0.48036041742159147 valid 0.5274082897314385
LOSS train 0.48036041742159147 valid 0.5275060875075204
LOSS train 0.48036041742159147 valid 0.5274525663265489
LOSS train 0.48036041742159147 valid 0.5274591525278148
LOSS train 0.48036041742159147 valid 0.5273079938944814
LOSS train 0.48036041742159147 valid 0.5272246808690183
LOSS train 0.48036041742159147 valid 0.5271351721978956
LOSS train 0.48036041742159147 valid 0.5271350833756184
LOSS train 0.48036041742159147 valid 0.527160521151373
LOSS train 0.48036041742159147 valid 0.5272616225966188
LOSS train 0.48036041742159147 valid 0.5272160132726034
LOSS train 0.48036041742159147 valid 0.5272783578475776
LOSS train 0.48036041742159147 valid 0.5272769883317975
LOSS train 0.48036041742159147 valid 0.5273704787437943
LOSS train 0.48036041742159147 valid 0.5274625468390719
LOSS train 0.48036041742159147 valid 0.5274419585296086
LOSS train 0.48036041742159147 valid 0.5273571009309883
LOSS train 0.48036041742159147 valid 0.5273362274535678
LOSS train 0.48036041742159147 valid 0.5274377294707906
LOSS train 0.48036041742159147 valid 0.5274906229164641
LOSS train 0.48036041742159147 valid 0.5276254610276558
LOSS train 0.48036041742159147 valid 0.5277020716935061
LOSS train 0.48036041742159147 valid 0.5276419949464771
LOSS train 0.48036041742159147 valid 0.527557292797046
LOSS train 0.48036041742159147 valid 0.5276004054420174
LOSS train 0.48036041742159147 valid 0.5276042915052838
LOSS train 0.48036041742159147 valid 0.5276716828676472
LOSS train 0.48036041742159147 valid 0.5277696775468015
LOSS train 0.48036041742159147 valid 0.5278028115096499
LOSS train 0.48036041742159147 valid 0.5277922724956995
LOSS train 0.48036041742159147 valid 0.5278541625362553
LOSS train 0.48036041742159147 valid 0.5278575285210636
LOSS train 0.48036041742159147 valid 0.5277857946115229
LOSS train 0.48036041742159147 valid 0.5277720864700235
LOSS train 0.48036041742159147 valid 0.5278035264997302
EPOCH 11:
  batch 1 loss: 0.45471563935279846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.4905046969652176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.4908687472343445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.49085550010204315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.49023978114128114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.48607918123404187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4837494364806584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4845554642379284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4817390541235606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.47726791203022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.475751055912538
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4759546642502149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4742610431634463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.47490084384168896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4772706051667531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.47789674438536167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.47615912030724916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47683536012967426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4788625899114107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4788942039012909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.4786834716796875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.47852392901073804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4795561951139699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.47929443667332333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.47886516332626344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4791909685501686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.48039130369822186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.47934895221676144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4794601438374355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4795457094907761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4792046691140821
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.47963674273341894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4790078347379511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4794598011409535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4804568018232073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4799569182925754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4790022340980736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4780655126822622
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4782288448932843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.47865634933114054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.47812204462725943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.47800296048323315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.47955953451090083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.47979951243508945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4798672589990828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4792166637337726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.47943042313798945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.47985167304674786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4799543144751568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.48096813678741457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.48031583720562504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.48000239294308883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.4795844329977935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.47945918087606076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.47848149754784325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4788140867437635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4791531573262131
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.47862982852705593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4780048010712963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4782875115672747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.47822145409271366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4788012345952372
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4789268057497721
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4788900506682694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4793298377440526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4787321456454017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.47845862249829874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.47868334677289515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.478405624628067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.47849715777805873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4785667191928541
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.47810619862543213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4784421434957687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.478313857236424
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4780881635348002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.47861873240847336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.47839942613205355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.47811710299589694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4780903258655645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.4778807289898396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.47786764340636173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4776419535642717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4778014626129564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.47751474912677494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.47738069997114296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4776026876859887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4778777840493739
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.47819034484299744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4781490581089191
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.47817056410842473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.47801295872573013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4782913988051207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.47846771920880965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4785328250616155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4785620457247684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.47911259656151134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.47898786399782317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.47895842334445643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.47913820003018237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4792274481058121
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.47899934472423966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4791763676147835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4794084510756928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4793476009598145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.479486240091778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.47924727848115956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.47907258667678476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4792699253669492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.4792444222017166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.47928015129132706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.479073860623815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4790881063256945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4793112910954298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.47922104884657946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.47891938712285914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4790000941219001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.47946271886173475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.47934145669815903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4794762157091573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4792102692027887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.47924854292357266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.47948621140151726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4796265460611359
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.47949182194086815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.47966652274131777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.47977360941114877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.47968911467574715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4799622241407633
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.479871145283529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.479968848824501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.47994345722307685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4798176602432222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.4798105213427006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.47970449702063606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4795682017449979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.47960135537911863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.47975806532985105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.47957512110039807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4797664921489551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.47978212875979287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4796788252837269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.47973598707729664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4798130182536332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4800285053335958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4800967294594337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4798833337956912
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4800898219857897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.48029070468367757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48019082074197345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.47997015396753945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4800521344538556
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4799905489934118
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4800058790281707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4799465806066216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4801666988480476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4803768894993342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.48032790631245653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.48047894861879226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4806820111079786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4807753162458539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.48062197632671144
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.48051689749146687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.48052494529566153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.48041694647655253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4803317904472351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4804900852312525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4804701373248757
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4801904316104594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4801584520988916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.48028126429109014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4801620891568256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.48006303729706035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4799408740390932
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.48003705222716275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4799038311413356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4797831778837876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.47968384488827764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.47968088810363513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.47974634303726965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.47976424164242215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4797063249250802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.47966662704289614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.47958208123842877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.47950261215800827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.47962267463271685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.47950687235401523
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4794466258051561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4793068952065833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.47928407614824003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.47920695496232885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.47908633994182365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.47881462005898356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.47886471041125955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4789217670553738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.47881259612548044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.47882468846379495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.47896185199621366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.47909772335880935
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4791051857735044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4791602352261543
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.47916529190481005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4791465726229224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4789304696574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.47895850518754884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4788986259844245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4787028757403198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.47864378448845685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.47851583619530386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.47876812367918387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.47878966402439843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4787932577856344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.4789956307636117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.47898041068668096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.47886006715141727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4788785138795542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.4787792143998323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4788393879541054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.47906832068885136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4793322084973392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4794327046383511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.47925868819202233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.4791977829761333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4792274864799773
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.47928668478769915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.47911130759451126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.47901204281148657
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4790212554028381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.47886850358101357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.47882794800283607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.47894483895405476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4789021622824979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.47905740206097736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.47894172057061746
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.47898408541312587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.47908823008232926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4790604425183797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.479035419628087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.47899381853953127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4790116259243698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4790931098163128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.479167038227018
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4790884963244446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.47920322565384854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4791958373589594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4792949428363722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4794680073978455
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4794927232178599
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4793547488028003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.47953387915369977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4795681009292603
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4796212073341309
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4795695917000846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.47961287524389185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4795086023610408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.479435961152993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4794582651229575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4793401315286466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4793342535578927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.4795664382026923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4796952512401801
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4797029489530001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.47964577956964044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.47967159328805176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.47966007177125325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4795185198199074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.47954221226667104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4795470199781411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.47945089827277765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4794295825701221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4794467955827713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4794770299948449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4793666323975605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4793011801583426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.47905584832612613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4788646177812056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.47893160203660745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.47894440187874254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.47888793319249323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.478894822913686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.47894557639956475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.47898970390554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.47900396574896276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.47894960968317496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.47897628212059046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4790122948194805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4790244964244482
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.47902744998084545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4790525712693731
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4790353596622969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4791095352378385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.47904174342188227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.47906405152115106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.47911884465315235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.47922137247867325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4791938184681585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4791845068134166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.479285258937765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4792427701638049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4791998137598452
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.47920632243156436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.47931277355878454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4792171222287298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4791728479437309
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4792103287028639
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.479283878256063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.47924228723532236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.47922777974256087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.47926384249290865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4793277419500752
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.47932879770955733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4794041721383858
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.47930097828308743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4792291324930831
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4791687521015763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.4791470311936878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.47922979446151587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.47927866203927844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.47931779433721267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4793055394787026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.47938732327893374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.47926045680343177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.479331919217702
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4794984521696073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4794438331399435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.479404489168754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.47941432033945447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4794493137149636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.47956120350011966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4795048365477008
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.47957833752487644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4796581819338381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.47962113748113794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4796716927050112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.479616941270714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4796249394986167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4796849039516279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4795860259929114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4795691464426955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4794765682698703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4795610985335182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.47955478950679475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4796050210096683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.47950239327489114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4794937768128029
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.47948485103206356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.47956838833458854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.4796045004290875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4796862308492606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.479653440693388
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4796184983423778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4795367798404476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4795314466411417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4795826293591399
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4795357476351625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.47951506754042394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4794219714704524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.47944056754018743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4795251475366134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4794980771528313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.47940712595979373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.47936334991389035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4793892752235107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.47942235031403785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4793570735133611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.47938126668538134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.47933101312058873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4792978010807765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4793253127161575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.47931852807520525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4793278923711261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4793551291898897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4793298482414215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.47936452114230504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.47935870313708157
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4793543197313945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4793570690015529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.47936840659743596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.47944589321890835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.47949919812282976
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.47941735222151405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.47941907434638714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.47936501443698143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.47946913575379096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.47947489377111197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4794591296028781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4795305210846076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4795050663387437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.47957874319909777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.47956443384557884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.47957101471913166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.47956365301176107
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.47958302345811105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.47958537405380464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.4795769602060318
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4795111479638498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.47957404364239087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4796396354283734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.4797414947095229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4798185728247602
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4798140665143728
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.47974763450182584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4795932425047035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.47956492091822567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.47951199888887974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4795361704296536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.47959302754824973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4795837536344364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.4795728333878751
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.47952437932741965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.47952304242587673
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.47958288988927855
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.47962096239467267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.47955765042986187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4796885247679724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4797686035374561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.47984157860852206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.47981851742707854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.47982362504495957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4798857897591193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.47987487074874696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.47999021573757616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4800680788207393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4799860704593343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.48001920213958005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.47999081576571745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4798879650696902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4798893382035597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.47980888584785375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4797157204095578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4798319009154342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4797872381669463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4798126248297868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.47973998864858863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.47976241133729436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.47964887749189616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4797522441372959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4797527673451797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4797159320415427
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4796461101816564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4796333090825514
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4796391993152852
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.47965025881566614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.47968441402669953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.47962756253577565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4797706029388342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4796872089529251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.47977709863543244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.47982010218713966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.47985256016918176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.47981662730375924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.47977062425433664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.47982097654479794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4797735367521282
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4797327520432451
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.47973323870491197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.479668654697506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.4796223141562756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.47963421163860886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.47958203345082684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4796739483009214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4796542200116429
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4796397744061111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4796769562987993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4796723535862462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4796426541061812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.47965231134911973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.47961510867837664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.47968068674334097
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.47971999384701125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.47979594285183763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4797924686769012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.47987133586558245
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.47987133586558245 valid 0.49122828245162964
LOSS train 0.47987133586558245 valid 0.5065734386444092
LOSS train 0.47987133586558245 valid 0.5047774116198221
LOSS train 0.47987133586558245 valid 0.5003253594040871
LOSS train 0.47987133586558245 valid 0.49527462124824523
LOSS train 0.47987133586558245 valid 0.5008749614159266
LOSS train 0.47987133586558245 valid 0.5075610067163195
LOSS train 0.47987133586558245 valid 0.5100219137966633
LOSS train 0.47987133586558245 valid 0.5118009282482995
LOSS train 0.47987133586558245 valid 0.5160382717847825
LOSS train 0.47987133586558245 valid 0.5192972069436853
LOSS train 0.47987133586558245 valid 0.5182881032427152
LOSS train 0.47987133586558245 valid 0.5227844692193545
LOSS train 0.47987133586558245 valid 0.5249980453933988
LOSS train 0.47987133586558245 valid 0.5263597468535105
LOSS train 0.47987133586558245 valid 0.524309741333127
LOSS train 0.47987133586558245 valid 0.526719810331569
LOSS train 0.47987133586558245 valid 0.527128333846728
LOSS train 0.47987133586558245 valid 0.5260205943333475
LOSS train 0.47987133586558245 valid 0.5270482882857322
LOSS train 0.47987133586558245 valid 0.5268526261761075
LOSS train 0.47987133586558245 valid 0.5255348777229135
LOSS train 0.47987133586558245 valid 0.5257014282371687
LOSS train 0.47987133586558245 valid 0.5246222106118997
LOSS train 0.47987133586558245 valid 0.5233873450756072
LOSS train 0.47987133586558245 valid 0.5218299455367602
LOSS train 0.47987133586558245 valid 0.5214273101753659
LOSS train 0.47987133586558245 valid 0.5220268251640456
LOSS train 0.47987133586558245 valid 0.5210574156251447
LOSS train 0.47987133586558245 valid 0.5224957138299942
LOSS train 0.47987133586558245 valid 0.5237668281601321
LOSS train 0.47987133586558245 valid 0.5240343688055873
LOSS train 0.47987133586558245 valid 0.5253631228750403
LOSS train 0.47987133586558245 valid 0.5261615050189635
LOSS train 0.47987133586558245 valid 0.5278165604387011
LOSS train 0.47987133586558245 valid 0.5282589520017306
LOSS train 0.47987133586558245 valid 0.5285708187399684
LOSS train 0.47987133586558245 valid 0.5290687264580476
LOSS train 0.47987133586558245 valid 0.5289438053583487
LOSS train 0.47987133586558245 valid 0.5295424170792102
LOSS train 0.47987133586558245 valid 0.5296327028332687
LOSS train 0.47987133586558245 valid 0.5295975243761426
LOSS train 0.47987133586558245 valid 0.529577874167021
LOSS train 0.47987133586558245 valid 0.5296642489053986
LOSS train 0.47987133586558245 valid 0.5296231885751088
LOSS train 0.47987133586558245 valid 0.5303381908199062
LOSS train 0.47987133586558245 valid 0.5304018176616506
LOSS train 0.47987133586558245 valid 0.5312911986062924
LOSS train 0.47987133586558245 valid 0.5324529123549558
LOSS train 0.47987133586558245 valid 0.531815772652626
LOSS train 0.47987133586558245 valid 0.5325401279271818
LOSS train 0.47987133586558245 valid 0.532937741623475
LOSS train 0.47987133586558245 valid 0.5327526842648128
LOSS train 0.47987133586558245 valid 0.532134058298888
LOSS train 0.47987133586558245 valid 0.5321520870382136
LOSS train 0.47987133586558245 valid 0.5318088105746678
LOSS train 0.47987133586558245 valid 0.5313904484113058
LOSS train 0.47987133586558245 valid 0.5315261133785906
LOSS train 0.47987133586558245 valid 0.5321599780502966
LOSS train 0.47987133586558245 valid 0.5316363662481308
LOSS train 0.47987133586558245 valid 0.5303862182820429
LOSS train 0.47987133586558245 valid 0.5305073165124462
LOSS train 0.47987133586558245 valid 0.530333277725038
LOSS train 0.47987133586558245 valid 0.5307747181504965
LOSS train 0.47987133586558245 valid 0.5310815847837008
LOSS train 0.47987133586558245 valid 0.5303840248873739
LOSS train 0.47987133586558245 valid 0.5301589894650588
LOSS train 0.47987133586558245 valid 0.5301268705550362
LOSS train 0.47987133586558245 valid 0.5300920242848604
LOSS train 0.47987133586558245 valid 0.529384559392929
LOSS train 0.47987133586558245 valid 0.5288358918378051
LOSS train 0.47987133586558245 valid 0.528636522591114
LOSS train 0.47987133586558245 valid 0.5290958301661766
LOSS train 0.47987133586558245 valid 0.5283413706599055
LOSS train 0.47987133586558245 valid 0.5283287731806438
LOSS train 0.47987133586558245 valid 0.5286081245071009
LOSS train 0.47987133586558245 valid 0.5284755787292084
LOSS train 0.47987133586558245 valid 0.5285083636259421
LOSS train 0.47987133586558245 valid 0.5281617098216769
LOSS train 0.47987133586558245 valid 0.5280461549758911
LOSS train 0.47987133586558245 valid 0.5276153286298116
LOSS train 0.47987133586558245 valid 0.527705752994956
LOSS train 0.47987133586558245 valid 0.5274083090115742
LOSS train 0.47987133586558245 valid 0.5274705056633268
LOSS train 0.47987133586558245 valid 0.5271436971776625
LOSS train 0.47987133586558245 valid 0.5268379851829174
LOSS train 0.47987133586558245 valid 0.5267414916520832
LOSS train 0.47987133586558245 valid 0.5267708850177851
LOSS train 0.47987133586558245 valid 0.5268932085358695
LOSS train 0.47987133586558245 valid 0.527373175488578
LOSS train 0.47987133586558245 valid 0.5275180922759758
LOSS train 0.47987133586558245 valid 0.5273671687945075
LOSS train 0.47987133586558245 valid 0.5271421779868424
LOSS train 0.47987133586558245 valid 0.5269997316472074
LOSS train 0.47987133586558245 valid 0.5267937120638395
LOSS train 0.47987133586558245 valid 0.5267322057237228
LOSS train 0.47987133586558245 valid 0.5268057996464759
LOSS train 0.47987133586558245 valid 0.526550757641695
LOSS train 0.47987133586558245 valid 0.5270648387947467
LOSS train 0.47987133586558245 valid 0.527313517332077
LOSS train 0.47987133586558245 valid 0.5271888829693936
LOSS train 0.47987133586558245 valid 0.5272476684813406
LOSS train 0.47987133586558245 valid 0.5275668478706508
LOSS train 0.47987133586558245 valid 0.5277425847374476
LOSS train 0.47987133586558245 valid 0.5279176592826843
LOSS train 0.47987133586558245 valid 0.5280892196691261
LOSS train 0.47987133586558245 valid 0.527954021903956
LOSS train 0.47987133586558245 valid 0.5279002195155179
LOSS train 0.47987133586558245 valid 0.528103990839162
LOSS train 0.47987133586558245 valid 0.5284528022462671
LOSS train 0.47987133586558245 valid 0.5283477735948993
LOSS train 0.47987133586558245 valid 0.5282215507967132
LOSS train 0.47987133586558245 valid 0.5284046588745792
LOSS train 0.47987133586558245 valid 0.5279134010013781
LOSS train 0.47987133586558245 valid 0.5279583516328231
LOSS train 0.47987133586558245 valid 0.5282365705432563
LOSS train 0.47987133586558245 valid 0.5280899670388963
LOSS train 0.47987133586558245 valid 0.5279698508270716
LOSS train 0.47987133586558245 valid 0.5278695441093766
LOSS train 0.47987133586558245 valid 0.5278389344612757
LOSS train 0.47987133586558245 valid 0.52765008388472
LOSS train 0.47987133586558245 valid 0.5274408826085387
LOSS train 0.47987133586558245 valid 0.5275326283966623
LOSS train 0.47987133586558245 valid 0.5277421873423361
LOSS train 0.47987133586558245 valid 0.5279349412918091
LOSS train 0.47987133586558245 valid 0.5279662013053894
LOSS train 0.47987133586558245 valid 0.5281754628879818
LOSS train 0.47987133586558245 valid 0.5284317005425692
LOSS train 0.47987133586558245 valid 0.528558893721233
LOSS train 0.47987133586558245 valid 0.5284788535191463
LOSS train 0.47987133586558245 valid 0.5285003153422406
LOSS train 0.47987133586558245 valid 0.5282397048942971
LOSS train 0.47987133586558245 valid 0.5281628670549035
LOSS train 0.47987133586558245 valid 0.5281118488133844
LOSS train 0.47987133586558245 valid 0.5282420056837577
LOSS train 0.47987133586558245 valid 0.5282396178911714
LOSS train 0.47987133586558245 valid 0.5280006356047888
LOSS train 0.47987133586558245 valid 0.5277183787978214
LOSS train 0.47987133586558245 valid 0.5276260463882694
LOSS train 0.47987133586558245 valid 0.5276474673833166
LOSS train 0.47987133586558245 valid 0.5278168462269696
LOSS train 0.47987133586558245 valid 0.5279783885663664
LOSS train 0.47987133586558245 valid 0.5278789665732351
LOSS train 0.47987133586558245 valid 0.5278860841774278
LOSS train 0.47987133586558245 valid 0.5276064110213312
LOSS train 0.47987133586558245 valid 0.5279066923954715
LOSS train 0.47987133586558245 valid 0.5276385799151699
LOSS train 0.47987133586558245 valid 0.5280299812958047
LOSS train 0.47987133586558245 valid 0.5279344482309867
LOSS train 0.47987133586558245 valid 0.528078245917956
LOSS train 0.47987133586558245 valid 0.5280757208928367
LOSS train 0.47987133586558245 valid 0.5277875428529162
LOSS train 0.47987133586558245 valid 0.5277456588604871
LOSS train 0.47987133586558245 valid 0.5278761891962646
LOSS train 0.47987133586558245 valid 0.5278005786480442
LOSS train 0.47987133586558245 valid 0.5282192916060106
LOSS train 0.47987133586558245 valid 0.5282102100029114
LOSS train 0.47987133586558245 valid 0.5282988885912714
LOSS train 0.47987133586558245 valid 0.5280675726866572
LOSS train 0.47987133586558245 valid 0.5280089974403381
LOSS train 0.47987133586558245 valid 0.5282167933002022
LOSS train 0.47987133586558245 valid 0.5280686296798565
LOSS train 0.47987133586558245 valid 0.5279943500559754
LOSS train 0.47987133586558245 valid 0.527837493434185
LOSS train 0.47987133586558245 valid 0.5275662900823536
LOSS train 0.47987133586558245 valid 0.527334133185536
LOSS train 0.47987133586558245 valid 0.5275390490800321
LOSS train 0.47987133586558245 valid 0.5277278870344162
LOSS train 0.47987133586558245 valid 0.5278450426970713
LOSS train 0.47987133586558245 valid 0.5278806609265945
LOSS train 0.47987133586558245 valid 0.528152596880818
LOSS train 0.47987133586558245 valid 0.5282705128192902
LOSS train 0.47987133586558245 valid 0.5283423924032663
LOSS train 0.47987133586558245 valid 0.5283818950598267
LOSS train 0.47987133586558245 valid 0.5284634828567505
LOSS train 0.47987133586558245 valid 0.5285850251940164
LOSS train 0.47987133586558245 valid 0.5287431451560414
LOSS train 0.47987133586558245 valid 0.5290089939417464
LOSS train 0.47987133586558245 valid 0.5291015259380447
LOSS train 0.47987133586558245 valid 0.5291394654247495
LOSS train 0.47987133586558245 valid 0.5291793007218377
LOSS train 0.47987133586558245 valid 0.5292214702118884
LOSS train 0.47987133586558245 valid 0.5291777262922193
LOSS train 0.47987133586558245 valid 0.5292208246562792
LOSS train 0.47987133586558245 valid 0.5291344230239455
LOSS train 0.47987133586558245 valid 0.52919713303607
LOSS train 0.47987133586558245 valid 0.5294205976680001
LOSS train 0.47987133586558245 valid 0.5294661322172652
LOSS train 0.47987133586558245 valid 0.5292982952619987
LOSS train 0.47987133586558245 valid 0.5292057089115444
LOSS train 0.47987133586558245 valid 0.5294881505179779
LOSS train 0.47987133586558245 valid 0.5296235828039547
LOSS train 0.47987133586558245 valid 0.5296722256766699
LOSS train 0.47987133586558245 valid 0.5295100556206458
LOSS train 0.47987133586558245 valid 0.5292743147947849
LOSS train 0.47987133586558245 valid 0.5292633069413049
LOSS train 0.47987133586558245 valid 0.529333104639489
LOSS train 0.47987133586558245 valid 0.5292230438102375
LOSS train 0.47987133586558245 valid 0.5293437919425006
LOSS train 0.47987133586558245 valid 0.5293538847565651
LOSS train 0.47987133586558245 valid 0.5292191013174864
LOSS train 0.47987133586558245 valid 0.5292966587118583
LOSS train 0.47987133586558245 valid 0.5292031101405327
LOSS train 0.47987133586558245 valid 0.5293909834296096
LOSS train 0.47987133586558245 valid 0.5293742028678335
LOSS train 0.47987133586558245 valid 0.5295923751534768
LOSS train 0.47987133586558245 valid 0.5295486329258352
LOSS train 0.47987133586558245 valid 0.5294970199465752
LOSS train 0.47987133586558245 valid 0.5292317446624263
LOSS train 0.47987133586558245 valid 0.529149175115994
LOSS train 0.47987133586558245 valid 0.5293312689986839
LOSS train 0.47987133586558245 valid 0.5293155479824768
LOSS train 0.47987133586558245 valid 0.5293161959995126
LOSS train 0.47987133586558245 valid 0.5292606889923043
LOSS train 0.47987133586558245 valid 0.5290528822776883
LOSS train 0.47987133586558245 valid 0.5289740905993514
LOSS train 0.47987133586558245 valid 0.5291241941638806
LOSS train 0.47987133586558245 valid 0.529063714890305
LOSS train 0.47987133586558245 valid 0.529147547810045
LOSS train 0.47987133586558245 valid 0.5290896891192957
LOSS train 0.47987133586558245 valid 0.5292022243074702
LOSS train 0.47987133586558245 valid 0.5293847138548756
LOSS train 0.47987133586558245 valid 0.5295854725377976
LOSS train 0.47987133586558245 valid 0.5295967067192707
LOSS train 0.47987133586558245 valid 0.5295577201578352
LOSS train 0.47987133586558245 valid 0.5294937703725511
LOSS train 0.47987133586558245 valid 0.5296389044381449
LOSS train 0.47987133586558245 valid 0.5297907649686462
LOSS train 0.47987133586558245 valid 0.5297543308880652
LOSS train 0.47987133586558245 valid 0.5298775806375172
LOSS train 0.47987133586558245 valid 0.529780039926628
LOSS train 0.47987133586558245 valid 0.529832893276009
LOSS train 0.47987133586558245 valid 0.5296121572220275
LOSS train 0.47987133586558245 valid 0.5295924725186112
LOSS train 0.47987133586558245 valid 0.5296899242604033
LOSS train 0.47987133586558245 valid 0.5296871157015784
LOSS train 0.47987133586558245 valid 0.5296501977534234
LOSS train 0.47987133586558245 valid 0.5296101615208537
LOSS train 0.47987133586558245 valid 0.5296590023958533
LOSS train 0.47987133586558245 valid 0.529639033228159
LOSS train 0.47987133586558245 valid 0.5298026278305845
LOSS train 0.47987133586558245 valid 0.5298302471637726
LOSS train 0.47987133586558245 valid 0.5297939176422087
LOSS train 0.47987133586558245 valid 0.529802138443853
LOSS train 0.47987133586558245 valid 0.5297585302469682
LOSS train 0.47987133586558245 valid 0.5297039727854534
LOSS train 0.47987133586558245 valid 0.5299001835618424
LOSS train 0.47987133586558245 valid 0.5298885919394032
LOSS train 0.47987133586558245 valid 0.5298541394103483
LOSS train 0.47987133586558245 valid 0.5300253763198852
LOSS train 0.47987133586558245 valid 0.5299872573153431
LOSS train 0.47987133586558245 valid 0.5300837788316939
LOSS train 0.47987133586558245 valid 0.5301717760063442
LOSS train 0.47987133586558245 valid 0.5301701245814796
LOSS train 0.47987133586558245 valid 0.5301484178094303
LOSS train 0.47987133586558245 valid 0.530106692109257
LOSS train 0.47987133586558245 valid 0.5300674206551874
LOSS train 0.47987133586558245 valid 0.5300948587498924
LOSS train 0.47987133586558245 valid 0.5301567081318859
LOSS train 0.47987133586558245 valid 0.5301484355559716
LOSS train 0.47987133586558245 valid 0.5302240122323749
LOSS train 0.47987133586558245 valid 0.5302816183512448
LOSS train 0.47987133586558245 valid 0.5303346539631543
LOSS train 0.47987133586558245 valid 0.53030962587306
LOSS train 0.47987133586558245 valid 0.5303861397617268
LOSS train 0.47987133586558245 valid 0.5303803832459271
LOSS train 0.47987133586558245 valid 0.5303012331326803
LOSS train 0.47987133586558245 valid 0.5303098477089583
LOSS train 0.47987133586558245 valid 0.5305393105545895
LOSS train 0.47987133586558245 valid 0.5306341915218918
LOSS train 0.47987133586558245 valid 0.5307278542940906
LOSS train 0.47987133586558245 valid 0.5307338126003742
LOSS train 0.47987133586558245 valid 0.5308788154588078
LOSS train 0.47987133586558245 valid 0.5308618236632243
LOSS train 0.47987133586558245 valid 0.5308253277431835
LOSS train 0.47987133586558245 valid 0.5309565268132997
LOSS train 0.47987133586558245 valid 0.5310241461660887
LOSS train 0.47987133586558245 valid 0.5309885062759728
LOSS train 0.47987133586558245 valid 0.5310640403446758
LOSS train 0.47987133586558245 valid 0.5310638453279223
LOSS train 0.47987133586558245 valid 0.5308295280483694
LOSS train 0.47987133586558245 valid 0.5307010467170824
LOSS train 0.47987133586558245 valid 0.5305894014060286
LOSS train 0.47987133586558245 valid 0.5306603873909359
LOSS train 0.47987133586558245 valid 0.5306909995120869
LOSS train 0.47987133586558245 valid 0.5306363744543983
LOSS train 0.47987133586558245 valid 0.5306136517782245
LOSS train 0.47987133586558245 valid 0.5306012426606483
LOSS train 0.47987133586558245 valid 0.5305950723098636
LOSS train 0.47987133586558245 valid 0.5305779020334113
LOSS train 0.47987133586558245 valid 0.5304772863068532
LOSS train 0.47987133586558245 valid 0.5304284592809743
LOSS train 0.47987133586558245 valid 0.530430905139487
LOSS train 0.47987133586558245 valid 0.5305172023521799
LOSS train 0.47987133586558245 valid 0.5306542797613952
LOSS train 0.47987133586558245 valid 0.530699188342771
LOSS train 0.47987133586558245 valid 0.5306489027108408
LOSS train 0.47987133586558245 valid 0.5306696756774147
LOSS train 0.47987133586558245 valid 0.5307913044822654
LOSS train 0.47987133586558245 valid 0.5307075795531273
LOSS train 0.47987133586558245 valid 0.5307472345242865
LOSS train 0.47987133586558245 valid 0.5306837916966306
LOSS train 0.47987133586558245 valid 0.530699758344751
LOSS train 0.47987133586558245 valid 0.5306520078723368
LOSS train 0.47987133586558245 valid 0.5305639682246036
LOSS train 0.47987133586558245 valid 0.5305129925604739
LOSS train 0.47987133586558245 valid 0.5304593811788466
LOSS train 0.47987133586558245 valid 0.5304842967685167
LOSS train 0.47987133586558245 valid 0.5305193787060895
LOSS train 0.47987133586558245 valid 0.5304630568911952
LOSS train 0.47987133586558245 valid 0.530378946633201
LOSS train 0.47987133586558245 valid 0.5304311740283782
LOSS train 0.47987133586558245 valid 0.5305582681974284
LOSS train 0.47987133586558245 valid 0.5306347379828714
LOSS train 0.47987133586558245 valid 0.5307032701515016
LOSS train 0.47987133586558245 valid 0.5306227160971376
LOSS train 0.47987133586558245 valid 0.5306936430066166
LOSS train 0.47987133586558245 valid 0.5305928186800495
LOSS train 0.47987133586558245 valid 0.5306989459034791
LOSS train 0.47987133586558245 valid 0.5305865256115794
LOSS train 0.47987133586558245 valid 0.5305298433125576
LOSS train 0.47987133586558245 valid 0.5304968068318338
LOSS train 0.47987133586558245 valid 0.5303698440454324
LOSS train 0.47987133586558245 valid 0.5303352259927325
LOSS train 0.47987133586558245 valid 0.5303018546104431
LOSS train 0.47987133586558245 valid 0.5304422380368402
LOSS train 0.47987133586558245 valid 0.5304694363465732
LOSS train 0.47987133586558245 valid 0.5305933661577178
LOSS train 0.47987133586558245 valid 0.5306902612958636
LOSS train 0.47987133586558245 valid 0.5307547612623735
LOSS train 0.47987133586558245 valid 0.5306998646151263
LOSS train 0.47987133586558245 valid 0.5305480333157333
LOSS train 0.47987133586558245 valid 0.5305739020979082
LOSS train 0.47987133586558245 valid 0.5307535024995576
LOSS train 0.47987133586558245 valid 0.5307636872156343
LOSS train 0.47987133586558245 valid 0.5308625095834335
LOSS train 0.47987133586558245 valid 0.5308092599983385
LOSS train 0.47987133586558245 valid 0.530817254496044
LOSS train 0.47987133586558245 valid 0.5306669750572306
LOSS train 0.47987133586558245 valid 0.5305842384696007
LOSS train 0.47987133586558245 valid 0.5304949924218689
LOSS train 0.47987133586558245 valid 0.5304948538541794
LOSS train 0.47987133586558245 valid 0.5305214015978766
LOSS train 0.47987133586558245 valid 0.530622448772192
LOSS train 0.47987133586558245 valid 0.5305759347867275
LOSS train 0.47987133586558245 valid 0.5306388281845633
LOSS train 0.47987133586558245 valid 0.5306378167541295
LOSS train 0.47987133586558245 valid 0.5307308939852934
LOSS train 0.47987133586558245 valid 0.5308227287151752
LOSS train 0.47987133586558245 valid 0.530801847066198
LOSS train 0.47987133586558245 valid 0.5307167388944545
LOSS train 0.47987133586558245 valid 0.5306956950067119
LOSS train 0.47987133586558245 valid 0.5307976469270906
LOSS train 0.47987133586558245 valid 0.5308504974269598
LOSS train 0.47987133586558245 valid 0.5309856734645199
LOSS train 0.47987133586558245 valid 0.5310630894611391
LOSS train 0.47987133586558245 valid 0.5310023735050394
LOSS train 0.47987133586558245 valid 0.5309173487251697
LOSS train 0.47987133586558245 valid 0.5309606162120373
LOSS train 0.47987133586558245 valid 0.5309634378386868
LOSS train 0.47987133586558245 valid 0.5310296993341472
LOSS train 0.47987133586558245 valid 0.531127277741116
LOSS train 0.47987133586558245 valid 0.5311601064257714
LOSS train 0.47987133586558245 valid 0.5311496582823795
LOSS train 0.47987133586558245 valid 0.5312115660268967
LOSS train 0.47987133586558245 valid 0.5312150300689082
LOSS train 0.47987133586558245 valid 0.5311428203732181
LOSS train 0.47987133586558245 valid 0.5311286257498938
LOSS train 0.47987133586558245 valid 0.5311606892240726
EPOCH 12:
  batch 1 loss: 0.46103376150131226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.4920697510242462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.4905788103739421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4875922203063965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.48685005903244016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4834034691254298
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.48153436183929443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.4821595698595047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4809349344836341
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4765362083911896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4751621132547205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4744463140765826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.47379323840141296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.4752022304705211
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4783326804637909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4791261460632086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.47747132532736836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47757308681805927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.47903576336408915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.4791879549622536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.47857321869759334
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.47798674350435083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4790121200292007
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.47883261864384014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4782027304172516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4789486493055637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4799559502689927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.47891672062022345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.47883061191131326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.47941462298234305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4791117791206606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.47946059983223677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.47889747854435083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.47935519937206716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.48036157148224967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.48002903080648845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.47914920545913076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.47824651630301224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4786318013301262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.47914610877633096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.47883486238921563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.47874141661893754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4801819137362547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4804939824071797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4807271361351013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.4800574947958407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.4798666004170763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.480399605507652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4804367125034332
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4812216228246689
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4804626568859699
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.4801381482527806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.47970075033745674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4794244666894277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.47855040485208683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.478826818721635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.47907151726254243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.47861082440820235
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.478001780934253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4783284241954486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.478301501664959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4789105894104127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4791227967020065
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.47912378143519163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4796223878860474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4789647496107853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4788194779139846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.47896916243959875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.47872112065121747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4787926495075226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.47885307459764076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4783301084405846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.47853876997346745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4783767248327668
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4780950164794922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4786097924960287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.47836777529159147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4779317103899442
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4779420940181877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.477717649564147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.47773256382824464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.47749908086730214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.47772092345249223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.47757421682278317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.47750117848901186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.47776002003703005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4779475547116378
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4782424518330531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4782495418291413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4782272345489926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.4779649760041918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4782605394721031
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.47842549540663276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.478502834096868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.47840247530686225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4789728174606959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4788859130180988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.47884155718647703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4790229977983417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.47912042021751405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.47906879770873795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4791327539612265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.47933585319704225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.4792981199347056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4794911299433027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4792689855368632
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4791235873632342
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4793412823368002
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.479235505292175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4792990660125559
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.47908116165582126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4791020027228764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.47926611077469006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4791518125617713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4788115838299627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4788462781700595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.47932147113685936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.47924305877443085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4793812462261745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4791324605544408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.47914465793893357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.47935822801511796
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.47954258589240595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.479399950033234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4795834758281708
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.479752679429357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.47971074811116915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.4799791753757745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.47992679430532825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.479989525446525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.47989762329873237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4798065746823947
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.47982569856751234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4796272400599807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.47955695479004473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.47959135363207145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.47976823161988363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.4796516107044358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4798065721988678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.47986082370792116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4797303868946454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.47970602986678273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.479798143768644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.4800573229375813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4800716870817645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4799136076479742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.48009580799511503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4802877699603906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48020080892031625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.48001171012719474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.48004892665818827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4800427616818955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4800378277021296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.47999403577346306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.4802474706403671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4803989048187549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.480327725030814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4804549356804618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.48063167948392954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.48074879553169014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4806112123202093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4805313453630165
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.480526323150272
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.48048514018698435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4804457409815355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4806554078696722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.48066884047256975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.48044077218288467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.48040823841236047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.480510710793383
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.48043421085117854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.48035106218831486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4802289014262271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4803331254542559
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4801690377507891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4800302430310033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4799251889778396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.479906721898679
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4800061801625364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.4799896768397755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4799596145337458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.47990401760562434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.47974598163464033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4797277552602084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.4798207709918151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.479719024031393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.47968434251565983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.479555219253327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4795505570040809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4794299720149291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4793095989689153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.47907095790530246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4791470809304035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4792018028878674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4790995784294911
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.47910564803347294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4791985750198364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4793711437119378
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.47933897331132364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4793704617023468
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4793751091506351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4793866623451214
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4791358070714133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.47914495333737017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.479119574151388
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.47893296601702867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.47884571537879356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.47870645199257594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4789352620902814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4789430091778437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4789556730979992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.47910543573352526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4791134919079257
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.47902529289789286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4790517788986827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.47898849637971985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.47905955597552285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4792897040964267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4795314945858907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.47960850257765164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.47944620116803444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.47936850464021835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4794531245402691
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4795324970036745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4793906407886081
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4792883402742116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.47929796523984836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.47913403456148346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4791051925009515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.4792028976523358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.47913452970001086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4792815963255948
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.47917099981348915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4792052469192407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.47928169851607466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.47925341621798984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4792520483083363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4791744515425017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.47917218986415466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.47921959112087886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.47929124626875913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.47921603228435045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4793219041431882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4793449278737678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4794577909975636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4795942078760969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.47961484999791815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4795119072641096
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.4796916990873804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.479719279050827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4797756246836537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4797845897930009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.47982223172904004
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.47972609196591565
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.47967499658173207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.4796569312456995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.4795323457235492
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.47952192663684373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.47976135574712714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4798262855181327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4798473652980337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.47976322085347795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.47978839221562725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4797733527692882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.47965591977227406
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.47967453312156794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.4796890357460422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.47959309549474005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.4795501108063198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.47957127944186884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4795907998656875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.47946007155320225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4793888094661
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.47915172054819816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4789477294141596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.47903230613556463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.47908291317495627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.47901237675611924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4790348820788886
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.47904720710856574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.47909273498847393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4791012350337725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.47902637772762313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.47906470896912295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4791088149212954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.47912005017270576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.47912911224448307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.47915943267030847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.47908268719395963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.47916626961066805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.47911845838900696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4791289351574362
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.4791792533503458
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4792483218875872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4792034294645665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.47919083910213933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4792702115746058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.47920377462502295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4791277237361091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.4791068735718727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4792088728608483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.47913197196082563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.4790850009265119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4791219966780198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4791856580093259
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.47916513116531123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.4791253475102229
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4791564264080741
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.47922202877242204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4791937219519769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4792744938008655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.47918098324384445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.4791308761404726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.4790264846412999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.47897453364871795
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4790455912110172
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.47909408431699974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4791005806727979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.47911267323553747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.47918276460841297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.4790488692273232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.479130804446173
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.47930068414277704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.47929611305395764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.47927122317827664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.47928294045793496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4793539823742088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4794472246998694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4793898226823488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4794743863922177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.47953748171783284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.47949566054775056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4795449194428441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.47948995411039114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4794872593523851
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.4795301877671764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.47944254222538774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.47942616468703253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4793389557385515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4794276651214151
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.47941370251591253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.47945425620204524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.47935082370268706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.47933622596915376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4793414831161499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4794205957754499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.47945186418483854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.47951983001040316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.4794725618594697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.47945108481815885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.47939284778388475
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4793824785473672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4794357112548169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4793625361165084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4793495906910426
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4792601854613658
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.47925743402219284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.47937075951911884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.47935152950393123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.47926836642954085
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.47922313147304463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4792633560480992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.47928894272192124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4792003566092187
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4792141630224986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.47916651382798053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.4791066463864142
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4791150720709044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4790797471838592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.47911365539640993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4791387058493262
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4791060883992462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.47914885891346765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.47914545285829246
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4791428786913554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4791188159204544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.47915114450517954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4792374866822409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.47928228589035277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.47921006773647506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4792092710029422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4791451790882031
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4792260927568839
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4792479633664091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.47923365413368524
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.47932012649397776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.47930958374218113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4793967404162761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.47938341859986666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4794082964077974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4794139647117966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4794281023953642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.4794053642349389
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.47938616952012636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4793261060986338
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.47938954115214977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4794350475898618
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.47954799923765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.4796206660587387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.47960956528782844
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4795288225064551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.47938481640459885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.47936117981858645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4793189255760448
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.47934173154242243
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.47937608543287946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4793259223204573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.47934452064481436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.4792942611687341
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.47928710303655486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.47934450676841456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.4793871508061307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.47932687091481024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4794894475579838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4795716992343765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.47966089529486805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.47962537157735663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.47963307961892854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.47968303417533564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.4796455386139098
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4797671935620614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4798613547996322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.479790745474768
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4798235141865487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.47979255199432375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4796895516310499
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.47968537376133563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.4796067391322038
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.47953023207493317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4796285717986351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.47958043708602127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4795896461992352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4795080428861305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4795357396800397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.47943905715284674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.47953921173690656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4795493767927113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4795121892810412
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.47943363530489197
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4794248112223365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.47944375527959293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.47944158726957586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.47945348464339366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4793641100729908
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.479489989294095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.47939912239799587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.4795137936503562
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4795636624496962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.4795787280014735
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.47954239428043366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.47950057939785284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.47954600647223733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4795199617513231
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4794760664129047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.479469463458428
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.47941689461208226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.47936089079280914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.47939352157594856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.47932852502741846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4794382667411929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4794183821455775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.47939338428633554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.479430431616744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.4794420176667386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.4793891385678322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4794203339088628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4793760154308548
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.4794432895942631
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4794843245162638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4795652465617403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.479547534525521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4795846226230516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4795846226230516 valid 0.48789387941360474
LOSS train 0.4795846226230516 valid 0.503298431634903
LOSS train 0.4795846226230516 valid 0.5015614231427511
LOSS train 0.4795846226230516 valid 0.497164785861969
LOSS train 0.4795846226230516 valid 0.4920981407165527
LOSS train 0.4795846226230516 valid 0.497749129931132
LOSS train 0.4795846226230516 valid 0.504423303263528
LOSS train 0.4795846226230516 valid 0.5068624019622803
LOSS train 0.4795846226230516 valid 0.5086526605818007
LOSS train 0.4795846226230516 valid 0.5129157543182373
LOSS train 0.4795846226230516 valid 0.5161988951943137
LOSS train 0.4795846226230516 valid 0.5151998996734619
LOSS train 0.4795846226230516 valid 0.5197158134900607
LOSS train 0.4795846226230516 valid 0.5219339728355408
LOSS train 0.4795846226230516 valid 0.5232940475145976
LOSS train 0.4795846226230516 valid 0.5212482772767544
LOSS train 0.4795846226230516 valid 0.5236520065980799
LOSS train 0.4795846226230516 valid 0.5240428845087687
LOSS train 0.4795846226230516 valid 0.5229376491747404
LOSS train 0.4795846226230516 valid 0.523980438709259
LOSS train 0.4795846226230516 valid 0.523793705872127
LOSS train 0.4795846226230516 valid 0.5224694867025722
LOSS train 0.4795846226230516 valid 0.5226377909598143
LOSS train 0.4795846226230516 valid 0.521566657970349
LOSS train 0.4795846226230516 valid 0.5203290140628815
LOSS train 0.4795846226230516 valid 0.5187691014546615
LOSS train 0.4795846226230516 valid 0.5183486187899554
LOSS train 0.4795846226230516 valid 0.5189346436943326
LOSS train 0.4795846226230516 valid 0.5179720377099926
LOSS train 0.4795846226230516 valid 0.5194190780321757
LOSS train 0.4795846226230516 valid 0.5206960439682007
LOSS train 0.4795846226230516 valid 0.5209634471684694
LOSS train 0.4795846226230516 valid 0.5223093412139199
LOSS train 0.4795846226230516 valid 0.5231121445403379
LOSS train 0.4795846226230516 valid 0.524770040171487
LOSS train 0.4795846226230516 valid 0.5252107580502828
LOSS train 0.4795846226230516 valid 0.5255293395068195
LOSS train 0.4795846226230516 valid 0.5260325027139563
LOSS train 0.4795846226230516 valid 0.5259139308562646
LOSS train 0.4795846226230516 valid 0.526513746380806
LOSS train 0.4795846226230516 valid 0.5266086081179177
LOSS train 0.4795846226230516 valid 0.526568516379311
LOSS train 0.4795846226230516 valid 0.526547254518021
LOSS train 0.4795846226230516 valid 0.5266235132109035
LOSS train 0.4795846226230516 valid 0.5265768700175815
LOSS train 0.4795846226230516 valid 0.5272970134797303
LOSS train 0.4795846226230516 valid 0.527359221843963
LOSS train 0.4795846226230516 valid 0.5282599305113157
LOSS train 0.4795846226230516 valid 0.5294218744550433
LOSS train 0.4795846226230516 valid 0.5287832194566726
LOSS train 0.4795846226230516 valid 0.5295134683450063
LOSS train 0.4795846226230516 valid 0.5299101191071364
LOSS train 0.4795846226230516 valid 0.5297229835447276
LOSS train 0.4795846226230516 valid 0.5290964014000363
LOSS train 0.4795846226230516 valid 0.5291162100705233
LOSS train 0.4795846226230516 valid 0.5287794917821884
LOSS train 0.4795846226230516 valid 0.5283589321270323
LOSS train 0.4795846226230516 valid 0.5284969292837998
LOSS train 0.4795846226230516 valid 0.5291381205542612
LOSS train 0.4795846226230516 valid 0.5286175911625226
LOSS train 0.4795846226230516 valid 0.5273617012578933
LOSS train 0.4795846226230516 valid 0.5274890137295569
LOSS train 0.4795846226230516 valid 0.5273112470195407
LOSS train 0.4795846226230516 valid 0.5277572055347264
LOSS train 0.4795846226230516 valid 0.528067022562027
LOSS train 0.4795846226230516 valid 0.5273727982333212
LOSS train 0.4795846226230516 valid 0.5271370846833756
LOSS train 0.4795846226230516 valid 0.5271090032423243
LOSS train 0.4795846226230516 valid 0.5270762037539828
LOSS train 0.4795846226230516 valid 0.5263643758637565
LOSS train 0.4795846226230516 valid 0.5258141143221251
LOSS train 0.4795846226230516 valid 0.5256212651729584
LOSS train 0.4795846226230516 valid 0.5260853587764583
LOSS train 0.4795846226230516 valid 0.5253282422954971
LOSS train 0.4795846226230516 valid 0.5253140600522359
LOSS train 0.4795846226230516 valid 0.5255980907302154
LOSS train 0.4795846226230516 valid 0.5254658460617065
LOSS train 0.4795846226230516 valid 0.5254930838560447
LOSS train 0.4795846226230516 valid 0.5251471373853804
LOSS train 0.4795846226230516 valid 0.525031204149127
LOSS train 0.4795846226230516 valid 0.5246023627710931
LOSS train 0.4795846226230516 valid 0.5246954222277898
LOSS train 0.4795846226230516 valid 0.5243931057223354
LOSS train 0.4795846226230516 valid 0.5244529186969712
LOSS train 0.4795846226230516 valid 0.5241248449858498
LOSS train 0.4795846226230516 valid 0.5238174096096394
LOSS train 0.4795846226230516 valid 0.5237223396356079
LOSS train 0.4795846226230516 valid 0.5237534398382361
LOSS train 0.4795846226230516 valid 0.5238805701223652
LOSS train 0.4795846226230516 valid 0.5243619792991214
LOSS train 0.4795846226230516 valid 0.5245092733875736
LOSS train 0.4795846226230516 valid 0.5243586424900137
LOSS train 0.4795846226230516 valid 0.5241344814659447
LOSS train 0.4795846226230516 valid 0.523992749604773
LOSS train 0.4795846226230516 valid 0.5237885104982476
LOSS train 0.4795846226230516 valid 0.5237249465038379
LOSS train 0.4795846226230516 valid 0.5237996264831307
LOSS train 0.4795846226230516 valid 0.5235442069112038
LOSS train 0.4795846226230516 valid 0.5240604516231653
LOSS train 0.4795846226230516 valid 0.5243097108602524
LOSS train 0.4795846226230516 valid 0.5241846843521194
LOSS train 0.4795846226230516 valid 0.5242443879445394
LOSS train 0.4795846226230516 valid 0.5245658356009177
LOSS train 0.4795846226230516 valid 0.5247406317637517
LOSS train 0.4795846226230516 valid 0.5249157332238696
LOSS train 0.4795846226230516 valid 0.5250835008216355
LOSS train 0.4795846226230516 valid 0.5249466957332932
LOSS train 0.4795846226230516 valid 0.5248928003840976
LOSS train 0.4795846226230516 valid 0.5250987645682939
LOSS train 0.4795846226230516 valid 0.5254503044215115
LOSS train 0.4795846226230516 valid 0.5253433558317993
LOSS train 0.4795846226230516 valid 0.5252180732786655
LOSS train 0.4795846226230516 valid 0.5254022922136087
LOSS train 0.4795846226230516 valid 0.5249080156025133
LOSS train 0.4795846226230516 valid 0.5249523162841797
LOSS train 0.4795846226230516 valid 0.5252317431671866
LOSS train 0.4795846226230516 valid 0.525086413591336
LOSS train 0.4795846226230516 valid 0.524965049351676
LOSS train 0.4795846226230516 valid 0.5248643425332398
LOSS train 0.4795846226230516 valid 0.5248334780335426
LOSS train 0.4795846226230516 valid 0.5246409990570762
LOSS train 0.4795846226230516 valid 0.5244314035431283
LOSS train 0.4795846226230516 valid 0.5245246363849174
LOSS train 0.4795846226230516 valid 0.5247327550765006
LOSS train 0.4795846226230516 valid 0.5249254250526428
LOSS train 0.4795846226230516 valid 0.5249566776411874
LOSS train 0.4795846226230516 valid 0.5251704257304274
LOSS train 0.4795846226230516 valid 0.5254278723150492
LOSS train 0.4795846226230516 valid 0.5255571492882662
LOSS train 0.4795846226230516 valid 0.5254783722070547
LOSS train 0.4795846226230516 valid 0.5255005286850092
LOSS train 0.4795846226230516 valid 0.5252391777255319
LOSS train 0.4795846226230516 valid 0.5251606236723133
LOSS train 0.4795846226230516 valid 0.52510952994005
LOSS train 0.4795846226230516 valid 0.5252398680757593
LOSS train 0.4795846226230516 valid 0.5252359290333355
LOSS train 0.4795846226230516 valid 0.5249968580085865
LOSS train 0.4795846226230516 valid 0.5247134333071501
LOSS train 0.4795846226230516 valid 0.5246224321907372
LOSS train 0.4795846226230516 valid 0.5246453681162425
LOSS train 0.4795846226230516 valid 0.5248150664863857
LOSS train 0.4795846226230516 valid 0.5249768277289162
LOSS train 0.4795846226230516 valid 0.5248777516238339
LOSS train 0.4795846226230516 valid 0.5248868602017561
LOSS train 0.4795846226230516 valid 0.5246069086009059
LOSS train 0.4795846226230516 valid 0.5249085005832045
LOSS train 0.4795846226230516 valid 0.524639934909587
LOSS train 0.4795846226230516 valid 0.525034286685892
LOSS train 0.4795846226230516 valid 0.524939741064238
LOSS train 0.4795846226230516 valid 0.5250823918978373
LOSS train 0.4795846226230516 valid 0.5250792116518842
LOSS train 0.4795846226230516 valid 0.5247902621171976
LOSS train 0.4795846226230516 valid 0.5247481938670663
LOSS train 0.4795846226230516 valid 0.52487784411226
LOSS train 0.4795846226230516 valid 0.5248012736920388
LOSS train 0.4795846226230516 valid 0.5252222160880382
LOSS train 0.4795846226230516 valid 0.5252138883065266
LOSS train 0.4795846226230516 valid 0.5253069557343857
LOSS train 0.4795846226230516 valid 0.5250764339225097
LOSS train 0.4795846226230516 valid 0.5250169333070517
LOSS train 0.4795846226230516 valid 0.5252241951338252
LOSS train 0.4795846226230516 valid 0.5250752277580308
LOSS train 0.4795846226230516 valid 0.5250020498878385
LOSS train 0.4795846226230516 valid 0.524844246303163
LOSS train 0.4795846226230516 valid 0.5245729749852961
LOSS train 0.4795846226230516 valid 0.5243401513042221
LOSS train 0.4795846226230516 valid 0.5245448051098578
LOSS train 0.4795846226230516 valid 0.5247342593613125
LOSS train 0.4795846226230516 valid 0.5248533628396028
LOSS train 0.4795846226230516 valid 0.524888575778288
LOSS train 0.4795846226230516 valid 0.5251619536974277
LOSS train 0.4795846226230516 valid 0.5252785530201224
LOSS train 0.4795846226230516 valid 0.5253519360729725
LOSS train 0.4795846226230516 valid 0.5253914180158199
LOSS train 0.4795846226230516 valid 0.5254730452810015
LOSS train 0.4795846226230516 valid 0.5255931057035923
LOSS train 0.4795846226230516 valid 0.52575110345237
LOSS train 0.4795846226230516 valid 0.526019780823354
LOSS train 0.4795846226230516 valid 0.5261143752316523
LOSS train 0.4795846226230516 valid 0.5261525577969022
LOSS train 0.4795846226230516 valid 0.5261932051642824
LOSS train 0.4795846226230516 valid 0.5262355254246638
LOSS train 0.4795846226230516 valid 0.5261913746432528
LOSS train 0.4795846226230516 valid 0.5262352082392444
LOSS train 0.4795846226230516 valid 0.5261492545540268
LOSS train 0.4795846226230516 valid 0.5262124355762235
LOSS train 0.4795846226230516 valid 0.5264374285458243
LOSS train 0.4795846226230516 valid 0.5264820440652522
LOSS train 0.4795846226230516 valid 0.5263134837150574
LOSS train 0.4795846226230516 valid 0.5262194699362704
LOSS train 0.4795846226230516 valid 0.5265056996445381
LOSS train 0.4795846226230516 valid 0.5266421154762307
LOSS train 0.4795846226230516 valid 0.5266906588188724
LOSS train 0.4795846226230516 valid 0.5265281509185574
LOSS train 0.4795846226230516 valid 0.5262890215103443
LOSS train 0.4795846226230516 valid 0.5262760883387254
LOSS train 0.4795846226230516 valid 0.5263445914396779
LOSS train 0.4795846226230516 valid 0.5262357323157667
LOSS train 0.4795846226230516 valid 0.5263563455948278
LOSS train 0.4795846226230516 valid 0.5263650827109814
LOSS train 0.4795846226230516 valid 0.5262302928303012
LOSS train 0.4795846226230516 valid 0.5263074822355025
LOSS train 0.4795846226230516 valid 0.5262144918512242
LOSS train 0.4795846226230516 valid 0.526402055925014
LOSS train 0.4795846226230516 valid 0.5263865997151631
LOSS train 0.4795846226230516 valid 0.5266049469558938
LOSS train 0.4795846226230516 valid 0.5265602210293645
LOSS train 0.4795846226230516 valid 0.5265068030701234
LOSS train 0.4795846226230516 valid 0.526239887379003
LOSS train 0.4795846226230516 valid 0.5261567351363954
LOSS train 0.4795846226230516 valid 0.526338420490518
LOSS train 0.4795846226230516 valid 0.5263225557106845
LOSS train 0.4795846226230516 valid 0.5263234052299893
LOSS train 0.4795846226230516 valid 0.5262677583181969
LOSS train 0.4795846226230516 valid 0.5260579519493636
LOSS train 0.4795846226230516 valid 0.5259795354472266
LOSS train 0.4795846226230516 valid 0.526130555412187
LOSS train 0.4795846226230516 valid 0.52606968157882
LOSS train 0.4795846226230516 valid 0.5261555256908887
LOSS train 0.4795846226230516 valid 0.5260980969125574
LOSS train 0.4795846226230516 valid 0.5262099844298211
LOSS train 0.4795846226230516 valid 0.5263941698783153
LOSS train 0.4795846226230516 valid 0.5265956422138641
LOSS train 0.4795846226230516 valid 0.5266061042036329
LOSS train 0.4795846226230516 valid 0.5265675841437446
LOSS train 0.4795846226230516 valid 0.5265038024007747
LOSS train 0.4795846226230516 valid 0.5266494690584191
LOSS train 0.4795846226230516 valid 0.5268019116238544
LOSS train 0.4795846226230516 valid 0.5267656666743182
LOSS train 0.4795846226230516 valid 0.5268899026124374
LOSS train 0.4795846226230516 valid 0.5267921541676377
LOSS train 0.4795846226230516 valid 0.5268456031536234
LOSS train 0.4795846226230516 valid 0.5266241364724646
LOSS train 0.4795846226230516 valid 0.526604246125262
LOSS train 0.4795846226230516 valid 0.5267024854396252
LOSS train 0.4795846226230516 valid 0.5267005307694613
LOSS train 0.4795846226230516 valid 0.5266628021429359
LOSS train 0.4795846226230516 valid 0.5266215079972724
LOSS train 0.4795846226230516 valid 0.5266710053427948
LOSS train 0.4795846226230516 valid 0.5266508104900519
LOSS train 0.4795846226230516 valid 0.5268140187896634
LOSS train 0.4795846226230516 valid 0.5268411215179223
LOSS train 0.4795846226230516 valid 0.5268034959526219
LOSS train 0.4795846226230516 valid 0.5268114331315775
LOSS train 0.4795846226230516 valid 0.5267673716253164
LOSS train 0.4795846226230516 valid 0.5267123790775857
LOSS train 0.4795846226230516 valid 0.5269099206094318
LOSS train 0.4795846226230516 valid 0.5268973650470856
LOSS train 0.4795846226230516 valid 0.5268636901215856
LOSS train 0.4795846226230516 valid 0.5270362384319306
LOSS train 0.4795846226230516 valid 0.5269982216367683
LOSS train 0.4795846226230516 valid 0.5270944166751135
LOSS train 0.4795846226230516 valid 0.5271834785288031
LOSS train 0.4795846226230516 valid 0.5271812602290957
LOSS train 0.4795846226230516 valid 0.5271594762802124
LOSS train 0.4795846226230516 valid 0.5271179457195103
LOSS train 0.4795846226230516 valid 0.5270779281274818
LOSS train 0.4795846226230516 valid 0.5271056516225948
LOSS train 0.4795846226230516 valid 0.5271674640850671
LOSS train 0.4795846226230516 valid 0.5271594237822753
LOSS train 0.4795846226230516 valid 0.5272357895456511
LOSS train 0.4795846226230516 valid 0.5272934207024466
LOSS train 0.4795846226230516 valid 0.5273472301860272
LOSS train 0.4795846226230516 valid 0.5273216624151577
LOSS train 0.4795846226230516 valid 0.5273984931549935
LOSS train 0.4795846226230516 valid 0.5273930439375397
LOSS train 0.4795846226230516 valid 0.527313092451417
LOSS train 0.4795846226230516 valid 0.5273192451516194
LOSS train 0.4795846226230516 valid 0.5275514101450328
LOSS train 0.4795846226230516 valid 0.5276478879981571
LOSS train 0.4795846226230516 valid 0.5277425193698644
LOSS train 0.4795846226230516 valid 0.5277495143168113
LOSS train 0.4795846226230516 valid 0.5278945973504594
LOSS train 0.4795846226230516 valid 0.5278780547371746
LOSS train 0.4795846226230516 valid 0.527840546911413
LOSS train 0.4795846226230516 valid 0.5279720306828402
LOSS train 0.4795846226230516 valid 0.5280392154889847
LOSS train 0.4795846226230516 valid 0.5280035972166405
LOSS train 0.4795846226230516 valid 0.528079069643465
LOSS train 0.4795846226230516 valid 0.5280797249504499
LOSS train 0.4795846226230516 valid 0.5278455241719174
LOSS train 0.4795846226230516 valid 0.5277160290919297
LOSS train 0.4795846226230516 valid 0.5276034430143268
LOSS train 0.4795846226230516 valid 0.527673816596958
LOSS train 0.4795846226230516 valid 0.5277042685893544
LOSS train 0.4795846226230516 valid 0.5276503035655389
LOSS train 0.4795846226230516 valid 0.5276265914847211
LOSS train 0.4795846226230516 valid 0.5276148120562235
LOSS train 0.4795846226230516 valid 0.5276069839107949
LOSS train 0.4795846226230516 valid 0.5275906684069798
LOSS train 0.4795846226230516 valid 0.5274907297285152
LOSS train 0.4795846226230516 valid 0.5274409288412905
LOSS train 0.4795846226230516 valid 0.5274436750509633
LOSS train 0.4795846226230516 valid 0.527531119836431
LOSS train 0.4795846226230516 valid 0.5276690472990779
LOSS train 0.4795846226230516 valid 0.5277136417256819
LOSS train 0.4795846226230516 valid 0.5276634618890808
LOSS train 0.4795846226230516 valid 0.5276849039849019
LOSS train 0.4795846226230516 valid 0.5278062062917346
LOSS train 0.4795846226230516 valid 0.5277233131726583
LOSS train 0.4795846226230516 valid 0.5277631611523043
LOSS train 0.4795846226230516 valid 0.5277005070882128
LOSS train 0.4795846226230516 valid 0.5277165847249551
LOSS train 0.4795846226230516 valid 0.527668038873296
LOSS train 0.4795846226230516 valid 0.5275798576777099
LOSS train 0.4795846226230516 valid 0.5275282261807934
LOSS train 0.4795846226230516 valid 0.5274745123005845
LOSS train 0.4795846226230516 valid 0.5275001878088171
LOSS train 0.4795846226230516 valid 0.5275358661864568
LOSS train 0.4795846226230516 valid 0.5274785097568265
LOSS train 0.4795846226230516 valid 0.5273936831682825
LOSS train 0.4795846226230516 valid 0.5274458376642985
LOSS train 0.4795846226230516 valid 0.5275728426421412
LOSS train 0.4795846226230516 valid 0.5276493331429305
LOSS train 0.4795846226230516 valid 0.5277183623540969
LOSS train 0.4795846226230516 valid 0.5276363492012024
LOSS train 0.4795846226230516 valid 0.5277073887244385
LOSS train 0.4795846226230516 valid 0.5276064584090275
LOSS train 0.4795846226230516 valid 0.5277130562683632
LOSS train 0.4795846226230516 valid 0.5275992656126618
LOSS train 0.4795846226230516 valid 0.5275425571147526
LOSS train 0.4795846226230516 valid 0.5275099779137914
LOSS train 0.4795846226230516 valid 0.527382900563556
LOSS train 0.4795846226230516 valid 0.5273468559722841
LOSS train 0.4795846226230516 valid 0.5273137647372026
LOSS train 0.4795846226230516 valid 0.5274538954525637
LOSS train 0.4795846226230516 valid 0.5274813216213786
LOSS train 0.4795846226230516 valid 0.5276055773038689
LOSS train 0.4795846226230516 valid 0.5277030932685887
LOSS train 0.4795846226230516 valid 0.5277672725193429
LOSS train 0.4795846226230516 valid 0.5277124316490669
LOSS train 0.4795846226230516 valid 0.5275592502341213
LOSS train 0.4795846226230516 valid 0.5275844849265732
LOSS train 0.4795846226230516 valid 0.5277652278274834
LOSS train 0.4795846226230516 valid 0.5277748316081602
LOSS train 0.4795846226230516 valid 0.5278742077449957
LOSS train 0.4795846226230516 valid 0.5278197001632667
LOSS train 0.4795846226230516 valid 0.5278270327480588
LOSS train 0.4795846226230516 valid 0.5276765378527234
LOSS train 0.4795846226230516 valid 0.5275935027529212
LOSS train 0.4795846226230516 valid 0.5275033443204818
LOSS train 0.4795846226230516 valid 0.5275031436256498
LOSS train 0.4795846226230516 valid 0.5275296099679463
LOSS train 0.4795846226230516 valid 0.5276317102617996
LOSS train 0.4795846226230516 valid 0.5275843480358953
LOSS train 0.4795846226230516 valid 0.5276474820051579
LOSS train 0.4795846226230516 valid 0.5276471841919319
LOSS train 0.4795846226230516 valid 0.5277406508210062
LOSS train 0.4795846226230516 valid 0.5278328407801325
LOSS train 0.4795846226230516 valid 0.5278114894458226
LOSS train 0.4795846226230516 valid 0.5277246836243872
LOSS train 0.4795846226230516 valid 0.5277032747187398
LOSS train 0.4795846226230516 valid 0.5278057825801731
LOSS train 0.4795846226230516 valid 0.5278576959324421
LOSS train 0.4795846226230516 valid 0.5279936434517444
LOSS train 0.4795846226230516 valid 0.5280715357721522
LOSS train 0.4795846226230516 valid 0.5280109567134654
LOSS train 0.4795846226230516 valid 0.5279258601159357
LOSS train 0.4795846226230516 valid 0.5279686648533537
LOSS train 0.4795846226230516 valid 0.5279721811413765
LOSS train 0.4795846226230516 valid 0.5280384702035265
LOSS train 0.4795846226230516 valid 0.5281372882055314
LOSS train 0.4795846226230516 valid 0.5281702672482851
LOSS train 0.4795846226230516 valid 0.528159716790849
LOSS train 0.4795846226230516 valid 0.5282223115228627
LOSS train 0.4795846226230516 valid 0.5282257766020103
LOSS train 0.4795846226230516 valid 0.5281532695897594
LOSS train 0.4795846226230516 valid 0.5281387616110884
LOSS train 0.4795846226230516 valid 0.5281697934882105
EPOCH 13:
  batch 1 loss: 0.4654277563095093
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.4956100285053253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.49345727761586505
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.49128488451242447
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.4904311716556549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4858935624361038
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4843545045171465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.48495914041996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.48244545194837785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.47813619375228883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4765498854897239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4756304348508517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.47445844457699704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.4754870129483087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4783229132493337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.4786194730550051
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4769640512326184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.47757674422529006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4787641277438716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.479080767929554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.47866858329091755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4786050698973916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.4795769997265028
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4791509533921878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.47870697498321535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.47904404539328355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.480060875415802
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4791988411120006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4791403001752393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4796273330847422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.47936214746967437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4798789946362376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4792068302631378
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.47956497178358193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.4806672198431832
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4804697185754776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4795537993714616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.47878639713714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.47901900074420833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4794718436896801
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4789102869789775
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.4787791122992833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.4801047770089881
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.4803483479402282
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.48050514856974286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.47971952998119854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.47962891421419507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.48037491366267204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4803781618877333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.48117725729942323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4804446720609478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.48018228205350727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.47974858981258467
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.4794799597175033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.478650855476206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.4788166896573135
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4791176742629001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.4785589344542602
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4779874455120604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4784627839922905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.478311051599315
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.4790903334656069
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4790879540027134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.47910268139094114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4796482535508963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4789544190421249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4788078576771181
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4789692614884937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4787795608458312
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.47892610473292213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4790811899682166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.47863059118390083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.47879800363762737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.47862860278503316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.4784911167621613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.47903450107888174
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4786751587669571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4782496683108501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.478226116940945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.477923009544611
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.47793706552481946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.47763723898224714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.47777017915105247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.47756643167563845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4774798056658576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4777612817841907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.47801919024566125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4782776480371302
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4781833441739672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.47820876472526125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.47799288080288815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4782529761609824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4783687351211425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.47842781055480876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.4782863205985019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.47891855395088595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4789026296630348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4789703403200422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.4791051203554327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.47914791852235794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.47894872680749045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.47906411249263614
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.47921006627453183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.479092553544503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.47924772415842326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.4790433468121403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.478913081862102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4790279870783841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.47895871061797535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4790700218894265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4788710611897546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.4789113117648022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.4791100048913365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4790278691471669
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.4788195807000865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.478917491333238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.4793264667193095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.47928537251585623
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.479411249150749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4791144736111164
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4791339835352149
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.479402413866559
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.47959429679847343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4794419996680752
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.4795321362018585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4796605287563233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4795984205767864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.47980531328357756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.47969252032827037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.47975447109112374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.47961531272371305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.47955913999767014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.47952911078481747
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.4794303318902628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4793524742126465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.47938760983593326
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.47955004620726094
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.47939341655675916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4795475769386017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4795186868735722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4794533041352076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.47950667394718655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.47960079091412205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.47985123718778294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4798847108051695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.47974286789763465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.4798912369475073
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4801373852265848
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48002365171509304
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.4798420405387878
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.47985959270142564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4799210346843067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.4799586665007024
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4799199946127929
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.48013683192191586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.48032557372099316
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.48026001927958933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.480454874755461
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.4806716732633939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.4807661730796099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.48058237755520744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4804970066488525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4805360878903442
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4804430611249877
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4803747762333263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4805630948170122
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.48061412787009145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.4803450953747545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.4803033677431253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.48040966549340414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.48033197563991215
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4802609016728956
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4801388680934906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.48025540973263225
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.4800711877005441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.47996601699428126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.47988365093866986
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4799296653337693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.48002225110650726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.47999906688928606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4799022430873049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4798347769857763
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.47966772936732394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4795950923276984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.47970278150326495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.47962425841439155
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4795730912430401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4794515810431318
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4794477364688954
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.4793634698579186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.4792141900324697
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.47900950458521646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.47905437578809074
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.47909974898259666
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4789902381407909
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4789785837032357
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4791184439876963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.47930488712859876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4793229531403163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4793404397368431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.47934594350074655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.4793382915529874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.4790830949844398
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.4790518733800626
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.47903411969905946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4788276049697283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.47879198078372054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.47863672501765764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4788545763663698
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4789455256291798
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.47893124211455973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.47915916664982744
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.47918508072414306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.47907133177619116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.47913271382797595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.47905709511703914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4791058639776872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.47931102273661064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4795505238450281
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4796108293262395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.4794338702885813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.47934279825773324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.4793995604119493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.4794410900878055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.47925341698858476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4791539681959996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4791368165992955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.47896659073599596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.47894537930405295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.47905249453109244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4790134885352411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.47917601633174667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4790473408965082
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.47909692604827064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4791732282080549
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.47914115819385494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.47913837885554833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4790661760738918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.4790901793595637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4792073672016462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.47925919108865667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4791587668755823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4792791069044498
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.47931996439812613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4794745392945348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4796340835045993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.47967748156925927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.479561356887702
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.47969157880089847
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4797377930879593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.4797604904469266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.47975355197512914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4797920405629124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.4796950669269862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4796075989218319
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.47964877740014344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.47955443063598663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4795469009830046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.47980875777922083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4799328053226838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.4799311061700185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.4798573974434656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.47990705010555545
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.47990155513539456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.47977446733780627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4798075221759036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.47979990674761797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.4797069171248977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.47965844180504186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.4796592115252106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.47971587064521337
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4795963689684868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.47952086530325616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4792826184391105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.47910201462832364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.47916909469210583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4792005783384027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4791264094465928
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4791415814430483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.47915363418204443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4792056287310726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4792106474967713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.47919557477897134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.479216970608268
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4792289067778671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.479218025724371
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.47921232043243034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4792558503233724
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.4791891329428729
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.4792241641159715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4791377041348067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4791759971069963
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.47926099247493026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.4793719801367546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4793293568037324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.47931793483125196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4793966832987789
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.47934448208984914
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.4793114461827039
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.479295155107975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.47940457411778725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4792881671166578
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.479240355908674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.479303083137462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.4793692817453478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.479320200342758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.47928924504242815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4793237929607367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.4794149470174968
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.4794021055583031
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4794931345622256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.479381590986099
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.479335086985518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.47926253678312725
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.47921452484433613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.4792912383622761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4793003974276762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4793288170729043
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.47934977303851733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.4794383496977389
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.47931077203646627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.47938580681448395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4795352930070446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4795235205947617
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4795081437551058
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.47952920490978684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.47957497935411764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.47968746294699066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.479620510955712
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4797283404704296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.47981613325208333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.47977261433759366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4798248420069526
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4797819346903327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4797731339931488
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.47982495961089927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4797331396302413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4797161894260779
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4796169709666992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.47965459394104343
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.47963896516131516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.47968194167516387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.47955622947598336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4795200670527857
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.47953298022781593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.4796110086702887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.47967262072247113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.479732577314322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.479694056135194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.47965472613062177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.47958393976559327
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.47959428805519233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4796305145994462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4795624466434037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.47955941373193767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4794811440652676
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4794989431939539
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4796048814025005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.4795570755403354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.47947133680184684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.47938931120399625
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4794433948414102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4794696659752817
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4793855138532408
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4794088990720984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.47937684094970995
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.47932418604312865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.47933719096624333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.47932577504698176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4793380547214199
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4793711250040409
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.47936676234327336
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.4794088074732722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4794047404738033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4793929540316264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4793696935348054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.479405709618915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.47952536797081985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4795675554501979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.4794844933246311
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4794639219918589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.4793926008552781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4794701319917375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.479498890771841
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.47947725963282894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4795356185170653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4795139240202054
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.47958525516015965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.47956503678716544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4795674026012421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4795525509225743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.47957470017124193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.47957260485823827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.479580647827405
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4795237193379221
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4795821771928758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4796261686822329
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.47972626527350154
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.47978751417389487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.47974553003907205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.47966154614588863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.479507174657945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4794850861907893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.47944054073921527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.4794498645964964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.47952763295819606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.47947414472003536
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.47947075225266755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.47943289683617124
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.47944036591343764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.47949971813355047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.47954547607782977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4794875452651239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.47960606044617254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4796811435596052
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4797674769965502
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.47973133033985715
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.47972682168324027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.4797706327318861
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.47973974219390325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.4798795474679906
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4799803986933559
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4799049304309466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4799341863759284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.47991746145136216
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4798285050990996
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.47983842383223896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.47977495207407767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.47969546316664813
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4798041184974271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4797829286543233
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.47980510884964905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4797193251085612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4797345170502289
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.4796173997309016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4797352520971123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.47971190781560585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.47968339049108494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.47960734475989547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.4795887444506992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4796218335493352
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.479632586780177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4796449058346501
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4795817369007849
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.4797421188836687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.47965365360937845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.47974207237262856
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.47978474479168653
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.47978586854541755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4797646768225564
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.47972480559560515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4797757516524433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4797334659836413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.47969201994887534
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.47971190895353044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4796388398921281
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.47959884688160354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4796110699400631
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.47954163663008115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.47963024727676223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4796241713190803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4795995852647922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.47962365442681776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.47963063804240064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.47960300810875434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4796046385053913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.47957671154489867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.47964239050435203
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.47966044346915127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4797417731361186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.47971195507707615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4797508119273994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4797508119273994 valid 0.48816606402397156
LOSS train 0.4797508119273994 valid 0.5036776512861252
LOSS train 0.4797508119273994 valid 0.5020720859368643
LOSS train 0.4797508119273994 valid 0.4977112337946892
LOSS train 0.4797508119273994 valid 0.4926378905773163
LOSS train 0.4797508119273994 valid 0.498312845826149
LOSS train 0.4797508119273994 valid 0.5050008084092822
LOSS train 0.4797508119273994 valid 0.5074522159993649
LOSS train 0.4797508119273994 valid 0.509255074792438
LOSS train 0.4797508119273994 valid 0.5135494560003281
LOSS train 0.4797508119273994 valid 0.5168634463440288
LOSS train 0.4797508119273994 valid 0.5158624822894732
LOSS train 0.4797508119273994 valid 0.520401649750196
LOSS train 0.4797508119273994 valid 0.5226353045020785
LOSS train 0.4797508119273994 valid 0.5239992837111155
LOSS train 0.4797508119273994 valid 0.5219466332346201
LOSS train 0.4797508119273994 valid 0.5243524681119358
LOSS train 0.4797508119273994 valid 0.5247394922706816
LOSS train 0.4797508119273994 valid 0.5236363614860334
LOSS train 0.4797508119273994 valid 0.5246915116906166
LOSS train 0.4797508119273994 valid 0.5245073423499153
LOSS train 0.4797508119273994 valid 0.5231728052551096
LOSS train 0.4797508119273994 valid 0.523344883452291
LOSS train 0.4797508119273994 valid 0.522275485098362
LOSS train 0.4797508119273994 valid 0.5210390281677246
LOSS train 0.4797508119273994 valid 0.5194747207256464
LOSS train 0.4797508119273994 valid 0.5190408527851105
LOSS train 0.4797508119273994 valid 0.5196258989827973
LOSS train 0.4797508119273994 valid 0.518663064159196
LOSS train 0.4797508119273994 valid 0.5201224873463313
LOSS train 0.4797508119273994 valid 0.5214033424854279
LOSS train 0.4797508119273994 valid 0.5216733990237117
LOSS train 0.4797508119273994 valid 0.5230340352564147
LOSS train 0.4797508119273994 valid 0.523846290567342
LOSS train 0.4797508119273994 valid 0.5255098862307412
LOSS train 0.4797508119273994 valid 0.525951339966721
LOSS train 0.4797508119273994 valid 0.5262748011060663
LOSS train 0.4797508119273994 valid 0.5267807927570844
LOSS train 0.4797508119273994 valid 0.5266660230282025
LOSS train 0.4797508119273994 valid 0.5272698335349559
LOSS train 0.4797508119273994 valid 0.5273686581995429
LOSS train 0.4797508119273994 valid 0.5273249099651972
LOSS train 0.4797508119273994 valid 0.5273037407287332
LOSS train 0.4797508119273994 valid 0.5273748886856165
LOSS train 0.4797508119273994 valid 0.5273251566621993
LOSS train 0.4797508119273994 valid 0.5280482023954391
LOSS train 0.4797508119273994 valid 0.5281099658063118
LOSS train 0.4797508119273994 valid 0.5290219914168119
LOSS train 0.4797508119273994 valid 0.530185630735086
LOSS train 0.4797508119273994 valid 0.5295438992977143
LOSS train 0.4797508119273994 valid 0.5302808518503227
LOSS train 0.4797508119273994 valid 0.5306785507844045
LOSS train 0.4797508119273994 valid 0.5304915601352476
LOSS train 0.4797508119273994 valid 0.5298584837604452
LOSS train 0.4797508119273994 valid 0.5298821606419303
LOSS train 0.4797508119273994 valid 0.5295485114412648
LOSS train 0.4797508119273994 valid 0.5291245699974528
LOSS train 0.4797508119273994 valid 0.5292657978575805
LOSS train 0.4797508119273994 valid 0.5299136007236223
LOSS train 0.4797508119273994 valid 0.5293938423196475
LOSS train 0.4797508119273994 valid 0.5281318421246576
LOSS train 0.4797508119273994 valid 0.5282635299428817
LOSS train 0.4797508119273994 valid 0.5280834327614496
LOSS train 0.4797508119273994 valid 0.5285328053869307
LOSS train 0.4797508119273994 valid 0.5288457003923562
LOSS train 0.4797508119273994 valid 0.5281496476946455
LOSS train 0.4797508119273994 valid 0.5279084777654107
LOSS train 0.4797508119273994 valid 0.5278821653302979
LOSS train 0.4797508119273994 valid 0.5278506836165553
LOSS train 0.4797508119273994 valid 0.527133384346962
LOSS train 0.4797508119273994 valid 0.5265812206436211
LOSS train 0.4797508119273994 valid 0.5263903153439363
LOSS train 0.4797508119273994 valid 0.526858678827547
LOSS train 0.4797508119273994 valid 0.5260976178420557
LOSS train 0.4797508119273994 valid 0.5260843718051911
LOSS train 0.4797508119273994 valid 0.5263718503870463
LOSS train 0.4797508119273994 valid 0.5262401262661079
LOSS train 0.4797508119273994 valid 0.5262647076294973
LOSS train 0.4797508119273994 valid 0.5259170898153812
LOSS train 0.4797508119273994 valid 0.5257989209145307
LOSS train 0.4797508119273994 valid 0.525369190139535
LOSS train 0.4797508119273994 valid 0.5254642171103779
LOSS train 0.4797508119273994 valid 0.5251590674182018
LOSS train 0.4797508119273994 valid 0.5252201720362618
LOSS train 0.4797508119273994 valid 0.52489073416766
LOSS train 0.4797508119273994 valid 0.5245824178983999
LOSS train 0.4797508119273994 valid 0.5244876728660759
LOSS train 0.4797508119273994 valid 0.5245189246806231
LOSS train 0.4797508119273994 valid 0.5246479511260986
LOSS train 0.4797508119273994 valid 0.52513214747111
LOSS train 0.4797508119273994 valid 0.5252811712223094
LOSS train 0.4797508119273994 valid 0.5251304274019988
LOSS train 0.4797508119273994 valid 0.5249054265278642
LOSS train 0.4797508119273994 valid 0.5247641833538704
LOSS train 0.4797508119273994 valid 0.5245605311895671
LOSS train 0.4797508119273994 valid 0.5244954967250427
LOSS train 0.4797508119273994 valid 0.5245714587034639
LOSS train 0.4797508119273994 valid 0.5243159112881641
LOSS train 0.4797508119273994 valid 0.5248347815841136
LOSS train 0.4797508119273994 valid 0.5250847536325455
LOSS train 0.4797508119273994 valid 0.5249599613765679
LOSS train 0.4797508119273994 valid 0.5250200962319094
LOSS train 0.4797508119273994 valid 0.5253445054720907
LOSS train 0.4797508119273994 valid 0.5255196174749961
LOSS train 0.4797508119273994 valid 0.525694781825656
LOSS train 0.4797508119273994 valid 0.5258606694779306
LOSS train 0.4797508119273994 valid 0.5257229381632582
LOSS train 0.4797508119273994 valid 0.5256700521266019
LOSS train 0.4797508119273994 valid 0.5258782724721716
LOSS train 0.4797508119273994 valid 0.5262322425842285
LOSS train 0.4797508119273994 valid 0.5261235849277394
LOSS train 0.4797508119273994 valid 0.5260002932378224
LOSS train 0.4797508119273994 valid 0.5261856992687799
LOSS train 0.4797508119273994 valid 0.5256897127419188
LOSS train 0.4797508119273994 valid 0.5257346780403801
LOSS train 0.4797508119273994 valid 0.5260138876479248
LOSS train 0.4797508119273994 valid 0.5258684856259924
LOSS train 0.4797508119273994 valid 0.5257464157322705
LOSS train 0.4797508119273994 valid 0.525646066966177
LOSS train 0.4797508119273994 valid 0.5256144454081854
LOSS train 0.4797508119273994 valid 0.5254192514853044
LOSS train 0.4797508119273994 valid 0.5252087573047544
LOSS train 0.4797508119273994 valid 0.5253027626653997
LOSS train 0.4797508119273994 valid 0.525510405100161
LOSS train 0.4797508119273994 valid 0.5257039754390717
LOSS train 0.4797508119273994 valid 0.5257354177652843
LOSS train 0.4797508119273994 valid 0.5259517053450187
LOSS train 0.4797508119273994 valid 0.5262110659386963
LOSS train 0.4797508119273994 valid 0.5263422720654066
LOSS train 0.4797508119273994 valid 0.5262645567838963
LOSS train 0.4797508119273994 valid 0.5262884581817016
LOSS train 0.4797508119273994 valid 0.5260261353669744
LOSS train 0.4797508119273994 valid 0.5259467302856589
LOSS train 0.4797508119273994 valid 0.52589618025431
LOSS train 0.4797508119273994 valid 0.5260274800989363
LOSS train 0.4797508119273994 valid 0.5260233188814977
LOSS train 0.4797508119273994 valid 0.5257830382698644
LOSS train 0.4797508119273994 valid 0.5254985947107923
LOSS train 0.4797508119273994 valid 0.5254082737637938
LOSS train 0.4797508119273994 valid 0.5254308826157025
LOSS train 0.4797508119273994 valid 0.5256019025406939
LOSS train 0.4797508119273994 valid 0.5257646821334329
LOSS train 0.4797508119273994 valid 0.5256660120053724
LOSS train 0.4797508119273994 valid 0.5256765900800625
LOSS train 0.4797508119273994 valid 0.5253955353950632
LOSS train 0.4797508119273994 valid 0.5256983137702289
LOSS train 0.4797508119273994 valid 0.5254274965549002
LOSS train 0.4797508119273994 valid 0.5258244390825968
LOSS train 0.4797508119273994 valid 0.5257294984071846
LOSS train 0.4797508119273994 valid 0.5258711844682693
LOSS train 0.4797508119273994 valid 0.5258674627503023
LOSS train 0.4797508119273994 valid 0.5255773214525298
LOSS train 0.4797508119273994 valid 0.5255352069739423
LOSS train 0.4797508119273994 valid 0.5256653952521163
LOSS train 0.4797508119273994 valid 0.5255881922860299
LOSS train 0.4797508119273994 valid 0.5260112948524647
LOSS train 0.4797508119273994 valid 0.5260039102879299
LOSS train 0.4797508119273994 valid 0.5260991610680954
LOSS train 0.4797508119273994 valid 0.5258686356949356
LOSS train 0.4797508119273994 valid 0.5258080197498203
LOSS train 0.4797508119273994 valid 0.5260156220901087
LOSS train 0.4797508119273994 valid 0.5258653886892177
LOSS train 0.4797508119273994 valid 0.5257937939254784
LOSS train 0.4797508119273994 valid 0.5256352255620608
LOSS train 0.4797508119273994 valid 0.5253632977153315
LOSS train 0.4797508119273994 valid 0.525129554321967
LOSS train 0.4797508119273994 valid 0.5253346585584971
LOSS train 0.4797508119273994 valid 0.5255253710562274
LOSS train 0.4797508119273994 valid 0.5256442119031263
LOSS train 0.4797508119273994 valid 0.5256791369003408
LOSS train 0.4797508119273994 valid 0.525954119120425
LOSS train 0.4797508119273994 valid 0.5260700869352318
LOSS train 0.4797508119273994 valid 0.5261434938521744
LOSS train 0.4797508119273994 valid 0.5261834762219725
LOSS train 0.4797508119273994 valid 0.5262658451284681
LOSS train 0.4797508119273994 valid 0.5263860576193441
LOSS train 0.4797508119273994 valid 0.5265443195394204
LOSS train 0.4797508119273994 valid 0.526815090119169
LOSS train 0.4797508119273994 valid 0.526911206585069
LOSS train 0.4797508119273994 valid 0.5269494697451591
LOSS train 0.4797508119273994 valid 0.5269906753005243
LOSS train 0.4797508119273994 valid 0.5270336330919475
LOSS train 0.4797508119273994 valid 0.5269890653956784
LOSS train 0.4797508119273994 valid 0.5270331620198229
LOSS train 0.4797508119273994 valid 0.5269468476643433
LOSS train 0.4797508119273994 valid 0.5270096356830289
LOSS train 0.4797508119273994 valid 0.5272362718288911
LOSS train 0.4797508119273994 valid 0.5272803764711035
LOSS train 0.4797508119273994 valid 0.5271105468273163
LOSS train 0.4797508119273994 valid 0.5270145342538232
LOSS train 0.4797508119273994 valid 0.5273036640039913
LOSS train 0.4797508119273994 valid 0.5274415073605875
LOSS train 0.4797508119273994 valid 0.52749053045258
LOSS train 0.4797508119273994 valid 0.5273278317193395
LOSS train 0.4797508119273994 valid 0.5270858646967472
LOSS train 0.4797508119273994 valid 0.5270715202299916
LOSS train 0.4797508119273994 valid 0.527139180656617
LOSS train 0.4797508119273994 valid 0.5270304883068259
LOSS train 0.4797508119273994 valid 0.5271512567996979
LOSS train 0.4797508119273994 valid 0.5271595804393292
LOSS train 0.4797508119273994 valid 0.52702504055417
LOSS train 0.4797508119273994 valid 0.5271029597756887
LOSS train 0.4797508119273994 valid 0.5270095959379169
LOSS train 0.4797508119273994 valid 0.5271970870740273
LOSS train 0.4797508119273994 valid 0.5271819430153545
LOSS train 0.4797508119273994 valid 0.5274016057113999
LOSS train 0.4797508119273994 valid 0.5273569268017
LOSS train 0.4797508119273994 valid 0.5273020652910838
LOSS train 0.4797508119273994 valid 0.5270334660436549
LOSS train 0.4797508119273994 valid 0.5269500362021583
LOSS train 0.4797508119273994 valid 0.52713188896247
LOSS train 0.4797508119273994 valid 0.5271155163645744
LOSS train 0.4797508119273994 valid 0.5271164401316307
LOSS train 0.4797508119273994 valid 0.527060345372307
LOSS train 0.4797508119273994 valid 0.526848463402238
LOSS train 0.4797508119273994 valid 0.5267709741989771
LOSS train 0.4797508119273994 valid 0.5269227508575686
LOSS train 0.4797508119273994 valid 0.526860922574997
LOSS train 0.4797508119273994 valid 0.5269478243779918
LOSS train 0.4797508119273994 valid 0.52689074521715
LOSS train 0.4797508119273994 valid 0.5270028559330902
LOSS train 0.4797508119273994 valid 0.5271889371377928
LOSS train 0.4797508119273994 valid 0.5273913265343739
LOSS train 0.4797508119273994 valid 0.5274014800254788
LOSS train 0.4797508119273994 valid 0.5273625853326586
LOSS train 0.4797508119273994 valid 0.5272988357902628
LOSS train 0.4797508119273994 valid 0.5274449904584675
LOSS train 0.4797508119273994 valid 0.5275979499545014
LOSS train 0.4797508119273994 valid 0.5275620149212633
LOSS train 0.4797508119273994 valid 0.5276873837346616
LOSS train 0.4797508119273994 valid 0.5275892416636149
LOSS train 0.4797508119273994 valid 0.5276434927664954
LOSS train 0.4797508119273994 valid 0.5274213927242377
LOSS train 0.4797508119273994 valid 0.5274011814950877
LOSS train 0.4797508119273994 valid 0.5274997707377089
LOSS train 0.4797508119273994 valid 0.5274983883156614
LOSS train 0.4797508119273994 valid 0.5274601343563338
LOSS train 0.4797508119273994 valid 0.5274179376223508
LOSS train 0.4797508119273994 valid 0.5274682879198546
LOSS train 0.4797508119273994 valid 0.5274479328344266
LOSS train 0.4797508119273994 valid 0.5276107883304976
LOSS train 0.4797508119273994 valid 0.5276378049584459
LOSS train 0.4797508119273994 valid 0.5275996169190348
LOSS train 0.4797508119273994 valid 0.527607897143872
LOSS train 0.4797508119273994 valid 0.527563993663204
LOSS train 0.4797508119273994 valid 0.5275086502476436
LOSS train 0.4797508119273994 valid 0.5277075336770973
LOSS train 0.4797508119273994 valid 0.5276941523676918
LOSS train 0.4797508119273994 valid 0.5276613274970686
LOSS train 0.4797508119273994 valid 0.5278350473642349
LOSS train 0.4797508119273994 valid 0.527797088561305
LOSS train 0.4797508119273994 valid 0.5278938700045858
LOSS train 0.4797508119273994 valid 0.5279838220168479
LOSS train 0.4797508119273994 valid 0.5279815193471007
LOSS train 0.4797508119273994 valid 0.5279598933808943
LOSS train 0.4797508119273994 valid 0.5279184348182753
LOSS train 0.4797508119273994 valid 0.5278786885831143
LOSS train 0.4797508119273994 valid 0.5279066342022992
LOSS train 0.4797508119273994 valid 0.5279683676695731
LOSS train 0.4797508119273994 valid 0.5279607769388419
LOSS train 0.4797508119273994 valid 0.5280376080123858
LOSS train 0.4797508119273994 valid 0.5280958433415144
LOSS train 0.4797508119273994 valid 0.5281504912748083
LOSS train 0.4797508119273994 valid 0.5281242607443621
LOSS train 0.4797508119273994 valid 0.5282013505134943
LOSS train 0.4797508119273994 valid 0.5281962464402493
LOSS train 0.4797508119273994 valid 0.5281154601538226
LOSS train 0.4797508119273994 valid 0.5281198159305017
LOSS train 0.4797508119273994 valid 0.5283544038086576
LOSS train 0.4797508119273994 valid 0.5284520741966036
LOSS train 0.4797508119273994 valid 0.5285473546198813
LOSS train 0.4797508119273994 valid 0.5285550676943624
LOSS train 0.4797508119273994 valid 0.5287003751857814
LOSS train 0.4797508119273994 valid 0.5286844741471493
LOSS train 0.4797508119273994 valid 0.5286459858850999
LOSS train 0.4797508119273994 valid 0.5287778585933257
LOSS train 0.4797508119273994 valid 0.5288452205890353
LOSS train 0.4797508119273994 valid 0.5288094013071746
LOSS train 0.4797508119273994 valid 0.5288851625389523
LOSS train 0.4797508119273994 valid 0.5288861595094204
LOSS train 0.4797508119273994 valid 0.5286517320366516
LOSS train 0.4797508119273994 valid 0.5285212834042015
LOSS train 0.4797508119273994 valid 0.5284080933976931
LOSS train 0.4797508119273994 valid 0.5284781534696968
LOSS train 0.4797508119273994 valid 0.5285089132032896
LOSS train 0.4797508119273994 valid 0.5284551072579163
LOSS train 0.4797508119273994 valid 0.5284310653026927
LOSS train 0.4797508119273994 valid 0.5284195501978198
LOSS train 0.4797508119273994 valid 0.5284109170255364
LOSS train 0.4797508119273994 valid 0.5283949306298946
LOSS train 0.4797508119273994 valid 0.5282948524067083
LOSS train 0.4797508119273994 valid 0.5282444981475399
LOSS train 0.4797508119273994 valid 0.5282476020550972
LOSS train 0.4797508119273994 valid 0.5283361672341418
LOSS train 0.4797508119273994 valid 0.5284751701152931
LOSS train 0.4797508119273994 valid 0.5285200362874044
LOSS train 0.4797508119273994 valid 0.5284696956876954
LOSS train 0.4797508119273994 valid 0.5284911069093935
LOSS train 0.4797508119273994 valid 0.5286126327155825
LOSS train 0.4797508119273994 valid 0.5285289298494656
LOSS train 0.4797508119273994 valid 0.5285688558488193
LOSS train 0.4797508119273994 valid 0.5285064782330532
LOSS train 0.4797508119273994 valid 0.528523174351198
LOSS train 0.4797508119273994 valid 0.5284742500240865
LOSS train 0.4797508119273994 valid 0.5283857053420583
LOSS train 0.4797508119273994 valid 0.528333868173992
LOSS train 0.4797508119273994 valid 0.5282801802267081
LOSS train 0.4797508119273994 valid 0.5283057946082833
LOSS train 0.4797508119273994 valid 0.5283422035113893
LOSS train 0.4797508119273994 valid 0.5282842062173351
LOSS train 0.4797508119273994 valid 0.5281991411443692
LOSS train 0.4797508119273994 valid 0.5282517164372481
LOSS train 0.4797508119273994 valid 0.5283793272873083
LOSS train 0.4797508119273994 valid 0.5284563045782648
LOSS train 0.4797508119273994 valid 0.5285255455781543
LOSS train 0.4797508119273994 valid 0.5284422821825063
LOSS train 0.4797508119273994 valid 0.5285138644818628
LOSS train 0.4797508119273994 valid 0.5284127862011112
LOSS train 0.4797508119273994 valid 0.5285198100868811
LOSS train 0.4797508119273994 valid 0.5284048598259687
LOSS train 0.4797508119273994 valid 0.5283477506904959
LOSS train 0.4797508119273994 valid 0.5283157427488647
LOSS train 0.4797508119273994 valid 0.5281885401014204
LOSS train 0.4797508119273994 valid 0.5281508443532167
LOSS train 0.4797508119273994 valid 0.5281176908199604
LOSS train 0.4797508119273994 valid 0.5282582583968625
LOSS train 0.4797508119273994 valid 0.5282860146750004
LOSS train 0.4797508119273994 valid 0.5284109520839482
LOSS train 0.4797508119273994 valid 0.5285086611846298
LOSS train 0.4797508119273994 valid 0.5285728680365014
LOSS train 0.4797508119273994 valid 0.528517693011062
LOSS train 0.4797508119273994 valid 0.5283633779330426
LOSS train 0.4797508119273994 valid 0.5283882281443736
LOSS train 0.4797508119273994 valid 0.5285700015322177
LOSS train 0.4797508119273994 valid 0.5285795007179033
LOSS train 0.4797508119273994 valid 0.5286793939414478
LOSS train 0.4797508119273994 valid 0.5286240429128313
LOSS train 0.4797508119273994 valid 0.5286310509111755
LOSS train 0.4797508119273994 valid 0.5284801565967829
LOSS train 0.4797508119273994 valid 0.5283969154252726
LOSS train 0.4797508119273994 valid 0.5283059607153414
LOSS train 0.4797508119273994 valid 0.5283057046564001
LOSS train 0.4797508119273994 valid 0.5283322647083605
LOSS train 0.4797508119273994 valid 0.5284351243875748
LOSS train 0.4797508119273994 valid 0.5283871479656386
LOSS train 0.4797508119273994 valid 0.528450803777386
LOSS train 0.4797508119273994 valid 0.5284511544862467
LOSS train 0.4797508119273994 valid 0.5285452520367743
LOSS train 0.4797508119273994 valid 0.5286379323306262
LOSS train 0.4797508119273994 valid 0.5286163701329912
LOSS train 0.4797508119273994 valid 0.5285286865173242
LOSS train 0.4797508119273994 valid 0.5285072049803354
LOSS train 0.4797508119273994 valid 0.5286099670122433
LOSS train 0.4797508119273994 valid 0.5286610937219555
LOSS train 0.4797508119273994 valid 0.5287979798417696
LOSS train 0.4797508119273994 valid 0.5288763499159491
LOSS train 0.4797508119273994 valid 0.5288155991323188
LOSS train 0.4797508119273994 valid 0.5287298184699852
LOSS train 0.4797508119273994 valid 0.5287721456757495
LOSS train 0.4797508119273994 valid 0.5287762414250109
LOSS train 0.4797508119273994 valid 0.5288426916520022
LOSS train 0.4797508119273994 valid 0.5289423657550337
LOSS train 0.4797508119273994 valid 0.528975679608416
LOSS train 0.4797508119273994 valid 0.5289652548157252
LOSS train 0.4797508119273994 valid 0.5290283416232018
LOSS train 0.4797508119273994 valid 0.5290313220577814
LOSS train 0.4797508119273994 valid 0.528958429838721
LOSS train 0.4797508119273994 valid 0.5289440102389326
LOSS train 0.4797508119273994 valid 0.5289744627346514
EPOCH 14:
  batch 1 loss: 0.45961859822273254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.49270792305469513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.48876141508420307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.4862957075238228
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.48643234372138977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.48474864661693573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4826070027691977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.48388535901904106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.4813408719168769
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4770175516605377
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.47616959701884876
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4751211851835251
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.47372414057071394
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.4744821680443628
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.4770123143990835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.47804026305675507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.4767650611260358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4771347939968109
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.4786135930764048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.47871062606573106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.478233338821502
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4781723049553958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.47898465654124384
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.47843799243370694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.4782900035381317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.4783461896272806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4793440169758267
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4781678020954132
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.47825126812375823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.4785635242859522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4784660964242874
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4787149280309677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4779185571453788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.47831688821315765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.47924013393265863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.47898797111378777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.4781505747421368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.47737336943024083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.4775221378375322
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4778439477086067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.47744508850865247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.47723804130440667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.47865150487700175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.47915544496341184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.47940165400505064
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.47863542709661566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.478526049471916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.47900160153706867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.479112121523643
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4800187921524048
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.47923651512931376
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.47892862214491916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.47842746410729753
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.47822374215832464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.4774109211834994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.47765327457870754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.4780182922095583
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.477509671244128
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4770804512298713
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4774902274211248
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.47734490672095875
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.47817029010865
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4782926619998992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.478384374640882
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4789524564376244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.47832290602452826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4782024617515393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4784055759801584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4781271815299988
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.4781287329537528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.47802891026080496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.4776380583643913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.4778100909435586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.4776218279793456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.47743295311927797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.47798273163406474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4777695474686561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4773665311244818
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.4774877221523961
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.47733763642609117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.47736436238995306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.4771941725800677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.47740786477743863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.4772635002930959
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.47729230628294106
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.47752605240012325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.4777282315424119
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4780749709091403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4780043266462476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4780379934443368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.47784978740817896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.47811767847641656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4782073920772922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.47825999938427133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.478285950422287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4788121360664566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4787351473705056
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.47876805492809843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.47893506499251937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.4790535718202591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.478936502248934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.4791343872453652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.47929233023263873
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.47923936408299667
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.4793876239231655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.47916097967129834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.47896309823633354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.47920559015538955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.47919032497143527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.47923397665674033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.47904040711420076
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.47910858504474163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.47922220219553047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.4791491679977952
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.47899865248928897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.4790690841859785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.47953173874789834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4794144632957749
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.4795340883130787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.4792612890402476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4792947123858554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4794806711009291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.4797273893666461
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.4796091918983767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.47973447942733766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4798778314439077
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4798336564086554
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.48015181766822934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.4800945806872937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.48012719796254083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.48004332412290207
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.4799002334475517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.47984935690585834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.47977627013156665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.479722989709289
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.47981330511324544
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4800316436882437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.47979952222195227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.47997787723438345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.4800557262131146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4799250311462592
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4799870342855722
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4800698646715471
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.48034253530204296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.4804006089424265
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.48019610059587925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.48034998247412597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4805825584240862
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48047958124403983
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.48023403545220694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4802877362200756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.4802812837848538
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.48027267272955454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.48017547598906923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.48042721690670137
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.4806232622418648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4805918273272788
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.4807969122370587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.48095953708174843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.48101145420223473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.48083541426599397
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4807325253883998
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.4807951013369063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.48071165092107726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4806275293682561
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.4807984687118645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.4808215481078553
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.48055974677914665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.48053802646828825
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.480683976762435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4806084916954152
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.480470078802386
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.480396522951953
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4804642378598794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.48026785271508354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.4801652472127568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4800959010582186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.4800724169511474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.4801471398196407
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.48014710661437776
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.48003411507079613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.48003454211649005
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4799225211469202
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4799211206643478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.47995294332504274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4799033401794331
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.479848493866742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.4796849934661642
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.4796433847732645
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.47950970969702067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.47937342992627807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.47910983053346473
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.47918014081648597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.4791898054560435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.4790631723709596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4790788501196978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4791721911902355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4793523683993503
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4793453885981785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4793479697406292
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4793634838725797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.479346104482613
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.479143353812213
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.47914374049972086
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4790523870689113
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.4788061679856291
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.4787319060684978
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.47861449907605463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.4788269722860966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.47884160933040437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4788347686071531
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.47901330297847966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.4790316702614368
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4789104914275285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.478988936196926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.47887362319010274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.4789101827529169
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4791595290560241
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.47937942258843547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4794558798724955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.47928959953838884
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.479188492303496
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.47926948409978587
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.47934011715863434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4792243667443593
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.4791213164551068
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.4791509058769579
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.4789998940469926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.4789805951076824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.47909559141034663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.47902135312299193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4791771987902707
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.47905569258165975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4790859731853518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.47916194783880356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4791738784919351
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.47918053405194344
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.4790920140613027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.47908788532891533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4791675001382828
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4792657252169249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4791747196154161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.47929059306289923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4793095017065767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4794403397307104
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.47961187677654793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.47964184607571436
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4795454137267605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.47972676241732987
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.47976423943042756
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.47979272919822025
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4798051292697589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.4798857874785487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.479789562347367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.4797166541510937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.479696836322546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.479575139191364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.4795257728691249
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.47978050460226285
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.4798679182162652
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.47989096472546516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.47980511939252607
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.47982005248051635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4798247963190079
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.4797130452012116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.4797346714071761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.47972851400071764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.47962077384564417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.47959358763074345
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.47961870663695866
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.4796528256467348
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.47949429393252907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.47945594012518944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4792244190717266
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.4790444883433255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4791115363654883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.4791202531179366
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4790707366715232
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4791066545098486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4791171532656465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.4791715028447189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.4791852831840515
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.4791378810633198
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4791853593688616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4792613485403228
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.4792689708146182
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.47929043242324937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.4793322721703185
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.47928813502037815
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.47934899761759003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4792991096211463
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.4793212158630972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.47942201961022596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.47951636792851143
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.4794830732426401
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4794632291068902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.4795537603021872
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.4795283253160899
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.47948179795191836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.47943366318941116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4795406626110457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.47945116736636256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.47940337215319717
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4794228285747139
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.47950140794769663
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.47947122409842374
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.47946174709727013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.4794796924892958
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.47954052696336047
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.47948813678756835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.4795731019552114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4794819418054361
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.47942355113288465
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.47932311550826784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.47925944063398573
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.47933215506469146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4793878378176163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.4793899654404922
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.4793902431909567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.47949370127171276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.47935622930526733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.47941706028784287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.4795676257588177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.47953247168549784
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.4795127816383655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.4795402450247045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4795878514055083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.47969491607168824
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4796328150573835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.47970466875668727
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4798019803002522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4797494564968419
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.4797846935353838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.4797067746609271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4796843485156102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.47973220680086387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.4796477749899516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.4796382702842972
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.4795548137837807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.47961196136825224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4796099959056049
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.47965044088182396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.47954603847192256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.47954368885866433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.4795399544895559
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.47962274647861547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.47965412060877777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4796981772129563
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.47965216790365967
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.47964048641068596
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.4795625068862893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4795759850266305
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.47961485444992863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.4795406965044259
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.47951554798744095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.4794095204619879
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4794123435721678
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4794982334588493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.479464545804478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4793675962421629
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.4792970720255474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.4793306529027981
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.47934900770174244
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.47925846188605487
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.47928057606906105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.4792242801743127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.47919312834090044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.4792030537096055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.47917605746729264
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.4791754563917985
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.4791976068058425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.4791737915847891
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.47922533438928006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4792299186960261
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.47922170790036517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.47921626333226547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4792218334794993
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.47930013313495295
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.4793274039328885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.47923870086669923
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4792275724448557
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.47916946673268423
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.4792438641229435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4792778721700112
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4792657735285821
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.47936112792689567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4793429815954016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.47943333997247145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.4794340718221542
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.4794349634494537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4794361128679017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.4794642013706723
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.47945714702133
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.47945433756724226
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4793752618982822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4794415563645989
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.4794966976348339
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.4795997964976421
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.47966532420395014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.4796388229727745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.47958023835001445
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.47944116006739695
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.4794287433843163
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4793869923837114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.47940453776606806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4794613416559003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.4794232124778504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.47941937867332907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.47938562357629716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.4793840887343011
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.47946923572361616
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.47951143611114
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.4794490022030061
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4795849892684227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.47965925077357924
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.4797480400794974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.47972753172298127
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.4797403500125739
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.479771337531916
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.47975064516067506
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.47987813281333364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.4799844255379591
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4799140484620493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4799429436899581
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.47990345695439507
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4798112646654738
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.4798092142061551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.47971265066728414
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.47963855462474425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.479724724417509
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.4796824097080186
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.479690709185821
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.4796009970179331
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4796329491561459
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.47952345602813806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.4796359416678411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4796187263877223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4795769945671569
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.47949949626498994
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.47948806726119736
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.479522566946726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.4795073354406055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4795387923448403
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.47945543499411764
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.479619498802035
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4795156998618301
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.47960765856491105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.4796490163010146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.47965663379444046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.47962920043203566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4795887207244822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.47963386589446955
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.47958974543523053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.4795482476377277
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.4795504581797254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.4794895763982806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.47945333198854123
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4794645331572237
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.4793927926643222
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.4795080252315687
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.479474264473822
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.47945451362308483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4794628555779838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.47948357719799567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.47945839615278346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.47947462766467247
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.47943798683950684
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.47950007823797375
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4795322790583059
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.47962221744212696
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.47959193327877425
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4796736606601941
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4796736606601941 valid 0.48839807510375977
LOSS train 0.4796736606601941 valid 0.503938615322113
LOSS train 0.4796736606601941 valid 0.5024016896883646
LOSS train 0.4796736606601941 valid 0.49793750047683716
LOSS train 0.4796736606601941 valid 0.4929226875305176
LOSS train 0.4796736606601941 valid 0.4985606869061788
LOSS train 0.4796736606601941 valid 0.505170396396092
LOSS train 0.4796736606601941 valid 0.5076279640197754
LOSS train 0.4796736606601941 valid 0.5094229380289713
LOSS train 0.4796736606601941 valid 0.5136797547340393
LOSS train 0.4796736606601941 valid 0.5168978355147622
LOSS train 0.4796736606601941 valid 0.5159291476011276
LOSS train 0.4796736606601941 valid 0.5204163927298325
LOSS train 0.4796736606601941 valid 0.5226126866681235
LOSS train 0.4796736606601941 valid 0.5239742477734883
LOSS train 0.4796736606601941 valid 0.5219344180077314
LOSS train 0.4796736606601941 valid 0.5243381033925449
LOSS train 0.4796736606601941 valid 0.5247489793433083
LOSS train 0.4796736606601941 valid 0.5236284842616633
LOSS train 0.4796736606601941 valid 0.5246666476130486
LOSS train 0.4796736606601941 valid 0.5244860549767812
LOSS train 0.4796736606601941 valid 0.5231613855470311
LOSS train 0.4796736606601941 valid 0.5233387908209925
LOSS train 0.4796736606601941 valid 0.5222820279498895
LOSS train 0.4796736606601941 valid 0.5210552632808685
LOSS train 0.4796736606601941 valid 0.519512170782456
LOSS train 0.4796736606601941 valid 0.519091569715076
LOSS train 0.4796736606601941 valid 0.5196656105773789
LOSS train 0.4796736606601941 valid 0.5187084582345239
LOSS train 0.4796736606601941 valid 0.5201411853233974
LOSS train 0.4796736606601941 valid 0.5214069418368801
LOSS train 0.4796736606601941 valid 0.5216565718874335
LOSS train 0.4796736606601941 valid 0.523000152725162
LOSS train 0.4796736606601941 valid 0.5237814003930372
LOSS train 0.4796736606601941 valid 0.5254457771778107
LOSS train 0.4796736606601941 valid 0.5258921244078212
LOSS train 0.4796736606601941 valid 0.5262052698715313
LOSS train 0.4796736606601941 valid 0.526726160394518
LOSS train 0.4796736606601941 valid 0.5266082554291456
LOSS train 0.4796736606601941 valid 0.5272053144872189
LOSS train 0.4796736606601941 valid 0.5273015361006667
LOSS train 0.4796736606601941 valid 0.527268383474577
LOSS train 0.4796736606601941 valid 0.527249216340309
LOSS train 0.4796736606601941 valid 0.5273184864358469
LOSS train 0.4796736606601941 valid 0.5272791498237186
LOSS train 0.4796736606601941 valid 0.5279916570238445
LOSS train 0.4796736606601941 valid 0.5280430614948273
LOSS train 0.4796736606601941 valid 0.5289402498553196
LOSS train 0.4796736606601941 valid 0.5300952895563475
LOSS train 0.4796736606601941 valid 0.5294563549757004
LOSS train 0.4796736606601941 valid 0.5301826952719221
LOSS train 0.4796736606601941 valid 0.5305753665474745
LOSS train 0.4796736606601941 valid 0.5303890407085419
LOSS train 0.4796736606601941 valid 0.5297626218310109
LOSS train 0.4796736606601941 valid 0.5297795973040841
LOSS train 0.4796736606601941 valid 0.5294430420867035
LOSS train 0.4796736606601941 valid 0.5290246318306839
LOSS train 0.4796736606601941 valid 0.5291616490174984
LOSS train 0.4796736606601941 valid 0.5298031038146908
LOSS train 0.4796736606601941 valid 0.5292877157529196
LOSS train 0.4796736606601941 valid 0.5280416705569283
LOSS train 0.4796736606601941 valid 0.5281660104951551
LOSS train 0.4796736606601941 valid 0.5279900251872955
LOSS train 0.4796736606601941 valid 0.5284394426271319
LOSS train 0.4796736606601941 valid 0.5287402886610765
LOSS train 0.4796736606601941 valid 0.5280498984185132
LOSS train 0.4796736606601941 valid 0.527816677716241
LOSS train 0.4796736606601941 valid 0.5277874623151386
LOSS train 0.4796736606601941 valid 0.5277506333330403
LOSS train 0.4796736606601941 valid 0.5270370487655912
LOSS train 0.4796736606601941 valid 0.526489149096986
LOSS train 0.4796736606601941 valid 0.5262984637584951
LOSS train 0.4796736606601941 valid 0.5267615616321564
LOSS train 0.4796736606601941 valid 0.5260050316920152
LOSS train 0.4796736606601941 valid 0.5259903037548065
LOSS train 0.4796736606601941 valid 0.5262780240491817
LOSS train 0.4796736606601941 valid 0.5261494621828005
LOSS train 0.4796736606601941 valid 0.5261726933412063
LOSS train 0.4796736606601941 valid 0.5258257543738885
LOSS train 0.4796736606601941 valid 0.5257108870893716
LOSS train 0.4796736606601941 valid 0.5252825025423074
LOSS train 0.4796736606601941 valid 0.5253752001175066
LOSS train 0.4796736606601941 valid 0.5250765713582556
LOSS train 0.4796736606601941 valid 0.5251312529047331
LOSS train 0.4796736606601941 valid 0.5248078321709352
LOSS train 0.4796736606601941 valid 0.5244976257862046
LOSS train 0.4796736606601941 valid 0.5243999755930626
LOSS train 0.4796736606601941 valid 0.524426992982626
LOSS train 0.4796736606601941 valid 0.5245534117971913
LOSS train 0.4796736606601941 valid 0.5250361697541343
LOSS train 0.4796736606601941 valid 0.5251789148692246
LOSS train 0.4796736606601941 valid 0.5250267817274384
LOSS train 0.4796736606601941 valid 0.5248024011811903
LOSS train 0.4796736606601941 valid 0.5246552948621993
LOSS train 0.4796736606601941 valid 0.5244531126398789
LOSS train 0.4796736606601941 valid 0.5243912807976207
LOSS train 0.4796736606601941 valid 0.5244695977451875
LOSS train 0.4796736606601941 valid 0.5242160595193202
LOSS train 0.4796736606601941 valid 0.5247256545105365
LOSS train 0.4796736606601941 valid 0.5249779170751572
LOSS train 0.4796736606601941 valid 0.5248555304980514
LOSS train 0.4796736606601941 valid 0.5249151979006973
LOSS train 0.4796736606601941 valid 0.5252348936877205
LOSS train 0.4796736606601941 valid 0.5254069841825045
LOSS train 0.4796736606601941 valid 0.5255850036938985
LOSS train 0.4796736606601941 valid 0.5257553857452465
LOSS train 0.4796736606601941 valid 0.5256177961269272
LOSS train 0.4796736606601941 valid 0.5255628647627654
LOSS train 0.4796736606601941 valid 0.5257652866730996
LOSS train 0.4796736606601941 valid 0.5261141316457228
LOSS train 0.4796736606601941 valid 0.526002612736848
LOSS train 0.4796736606601941 valid 0.5258790541972432
LOSS train 0.4796736606601941 valid 0.5260582624283512
LOSS train 0.4796736606601941 valid 0.5255679890774844
LOSS train 0.4796736606601941 valid 0.5256126538566921
LOSS train 0.4796736606601941 valid 0.5258882241002445
LOSS train 0.4796736606601941 valid 0.5257412174828032
LOSS train 0.4796736606601941 valid 0.5256151769120815
LOSS train 0.4796736606601941 valid 0.5255147088475588
LOSS train 0.4796736606601941 valid 0.5254843334356943
LOSS train 0.4796736606601941 valid 0.5252910586428051
LOSS train 0.4796736606601941 valid 0.5250826927482105
LOSS train 0.4796736606601941 valid 0.5251761481044738
LOSS train 0.4796736606601941 valid 0.5253864584430572
LOSS train 0.4796736606601941 valid 0.5255751485824585
LOSS train 0.4796736606601941 valid 0.525608808275253
LOSS train 0.4796736606601941 valid 0.5258233345399691
LOSS train 0.4796736606601941 valid 0.5260794810019433
LOSS train 0.4796736606601941 valid 0.5262054948843726
LOSS train 0.4796736606601941 valid 0.5261256098747253
LOSS train 0.4796736606601941 valid 0.5261474688544528
LOSS train 0.4796736606601941 valid 0.5258878392703605
LOSS train 0.4796736606601941 valid 0.5258081479180128
LOSS train 0.4796736606601941 valid 0.5257559085070197
LOSS train 0.4796736606601941 valid 0.5258870919545492
LOSS train 0.4796736606601941 valid 0.5258832906975466
LOSS train 0.4796736606601941 valid 0.5256473319808932
LOSS train 0.4796736606601941 valid 0.5253623907548793
LOSS train 0.4796736606601941 valid 0.5252709060692958
LOSS train 0.4796736606601941 valid 0.5252905000533377
LOSS train 0.4796736606601941 valid 0.5254595429762036
LOSS train 0.4796736606601941 valid 0.5256188795180388
LOSS train 0.4796736606601941 valid 0.5255211885575648
LOSS train 0.4796736606601941 valid 0.5255274323539602
LOSS train 0.4796736606601941 valid 0.5252486537242758
LOSS train 0.4796736606601941 valid 0.5255499265781821
LOSS train 0.4796736606601941 valid 0.525283217024641
LOSS train 0.4796736606601941 valid 0.5256774767830565
LOSS train 0.4796736606601941 valid 0.5255810114361296
LOSS train 0.4796736606601941 valid 0.5257276169459025
LOSS train 0.4796736606601941 valid 0.5257255975773792
LOSS train 0.4796736606601941 valid 0.5254334674069756
LOSS train 0.4796736606601941 valid 0.5253922689973919
LOSS train 0.4796736606601941 valid 0.5255214479062464
LOSS train 0.4796736606601941 valid 0.5254440669090518
LOSS train 0.4796736606601941 valid 0.5258611822739626
LOSS train 0.4796736606601941 valid 0.5258542268898836
LOSS train 0.4796736606601941 valid 0.5259455125543135
LOSS train 0.4796736606601941 valid 0.5257174556360305
LOSS train 0.4796736606601941 valid 0.5256595633924007
LOSS train 0.4796736606601941 valid 0.5258668438988443
LOSS train 0.4796736606601941 valid 0.5257164066956367
LOSS train 0.4796736606601941 valid 0.5256416026068611
LOSS train 0.4796736606601941 valid 0.525483943703698
LOSS train 0.4796736606601941 valid 0.5252124172268492
LOSS train 0.4796736606601941 valid 0.5249808717922992
LOSS train 0.4796736606601941 valid 0.52518475269843
LOSS train 0.4796736606601941 valid 0.5253749635247957
LOSS train 0.4796736606601941 valid 0.5254981570695278
LOSS train 0.4796736606601941 valid 0.5255318859044243
LOSS train 0.4796736606601941 valid 0.5258036618344268
LOSS train 0.4796736606601941 valid 0.5259160091017567
LOSS train 0.4796736606601941 valid 0.5259881622529443
LOSS train 0.4796736606601941 valid 0.5260250160748932
LOSS train 0.4796736606601941 valid 0.526104565007346
LOSS train 0.4796736606601941 valid 0.5262234461578456
LOSS train 0.4796736606601941 valid 0.5263799644459439
LOSS train 0.4796736606601941 valid 0.526649184106441
LOSS train 0.4796736606601941 valid 0.5267425012988085
LOSS train 0.4796736606601941 valid 0.5267784936560524
LOSS train 0.4796736606601941 valid 0.5268185444958302
LOSS train 0.4796736606601941 valid 0.5268597851742755
LOSS train 0.4796736606601941 valid 0.5268149506198904
LOSS train 0.4796736606601941 valid 0.5268588143846263
LOSS train 0.4796736606601941 valid 0.5267726511568637
LOSS train 0.4796736606601941 valid 0.5268355011940002
LOSS train 0.4796736606601941 valid 0.5270595034176015
LOSS train 0.4796736606601941 valid 0.5271024317183393
LOSS train 0.4796736606601941 valid 0.526933593409402
LOSS train 0.4796736606601941 valid 0.5268399018990366
LOSS train 0.4796736606601941 valid 0.5271262432892285
LOSS train 0.4796736606601941 valid 0.5272604944184422
LOSS train 0.4796736606601941 valid 0.527309322913076
LOSS train 0.4796736606601941 valid 0.5271486371141119
LOSS train 0.4796736606601941 valid 0.5269106209278107
LOSS train 0.4796736606601941 valid 0.5268972721330973
LOSS train 0.4796736606601941 valid 0.5269679570863695
LOSS train 0.4796736606601941 valid 0.526859696615826
LOSS train 0.4796736606601941 valid 0.5269783284496422
LOSS train 0.4796736606601941 valid 0.5269837437570095
LOSS train 0.4796736606601941 valid 0.52684797087119
LOSS train 0.4796736606601941 valid 0.52692479500086
LOSS train 0.4796736606601941 valid 0.5268309208853491
LOSS train 0.4796736606601941 valid 0.5270175280816415
LOSS train 0.4796736606601941 valid 0.5270029191563769
LOSS train 0.4796736606601941 valid 0.527219802864547
LOSS train 0.4796736606601941 valid 0.5271759227566097
LOSS train 0.4796736606601941 valid 0.527123376297263
LOSS train 0.4796736606601941 valid 0.526856416435333
LOSS train 0.4796736606601941 valid 0.5267759184042613
LOSS train 0.4796736606601941 valid 0.5269567280019064
LOSS train 0.4796736606601941 valid 0.526940551006569
LOSS train 0.4796736606601941 valid 0.5269389468739291
LOSS train 0.4796736606601941 valid 0.5268838319265954
LOSS train 0.4796736606601941 valid 0.5266755713972935
LOSS train 0.4796736606601941 valid 0.5265985600374363
LOSS train 0.4796736606601941 valid 0.526748896469169
LOSS train 0.4796736606601941 valid 0.5266903947799577
LOSS train 0.4796736606601941 valid 0.5267746342371588
LOSS train 0.4796736606601941 valid 0.5267183628949252
LOSS train 0.4796736606601941 valid 0.5268267069467053
LOSS train 0.4796736606601941 valid 0.52701030685021
LOSS train 0.4796736606601941 valid 0.5272128325406746
LOSS train 0.4796736606601941 valid 0.527223465698106
LOSS train 0.4796736606601941 valid 0.5271848183208042
LOSS train 0.4796736606601941 valid 0.5271221151394127
LOSS train 0.4796736606601941 valid 0.5272663366952132
LOSS train 0.4796736606601941 valid 0.5274173264440737
LOSS train 0.4796736606601941 valid 0.5273814823429658
LOSS train 0.4796736606601941 valid 0.5275046952392743
LOSS train 0.4796736606601941 valid 0.5274092704702765
LOSS train 0.4796736606601941 valid 0.5274608692732351
LOSS train 0.4796736606601941 valid 0.527240743069178
LOSS train 0.4796736606601941 valid 0.5272230532688972
LOSS train 0.4796736606601941 valid 0.5273215386461705
LOSS train 0.4796736606601941 valid 0.5273178837309449
LOSS train 0.4796736606601941 valid 0.5272812381826876
LOSS train 0.4796736606601941 valid 0.527240023517809
LOSS train 0.4796736606601941 valid 0.5272903478544626
LOSS train 0.4796736606601941 valid 0.5272698120524486
LOSS train 0.4796736606601941 valid 0.5274319788479707
LOSS train 0.4796736606601941 valid 0.5274572536226146
LOSS train 0.4796736606601941 valid 0.5274208137773192
LOSS train 0.4796736606601941 valid 0.5274303959774189
LOSS train 0.4796736606601941 valid 0.5273849150355981
LOSS train 0.4796736606601941 valid 0.5273312532562551
LOSS train 0.4796736606601941 valid 0.5275299465849332
LOSS train 0.4796736606601941 valid 0.5275174202697892
LOSS train 0.4796736606601941 valid 0.5274828977613564
LOSS train 0.4796736606601941 valid 0.5276554526090622
LOSS train 0.4796736606601941 valid 0.5276174299507977
LOSS train 0.4796736606601941 valid 0.5277129228389452
LOSS train 0.4796736606601941 valid 0.5278022643841302
LOSS train 0.4796736606601941 valid 0.5277982247392023
LOSS train 0.4796736606601941 valid 0.527776354083828
LOSS train 0.4796736606601941 valid 0.5277342280605808
LOSS train 0.4796736606601941 valid 0.5276959906060408
LOSS train 0.4796736606601941 valid 0.5277229948330295
LOSS train 0.4796736606601941 valid 0.527784392065063
LOSS train 0.4796736606601941 valid 0.5277751371264457
LOSS train 0.4796736606601941 valid 0.527851530304357
LOSS train 0.4796736606601941 valid 0.5279089056581031
LOSS train 0.4796736606601941 valid 0.5279625707479484
LOSS train 0.4796736606601941 valid 0.527936310817798
LOSS train 0.4796736606601941 valid 0.5280123821969303
LOSS train 0.4796736606601941 valid 0.5280067301110217
LOSS train 0.4796736606601941 valid 0.5279256206996432
LOSS train 0.4796736606601941 valid 0.527932544141563
LOSS train 0.4796736606601941 valid 0.5281634664225312
LOSS train 0.4796736606601941 valid 0.5282605181137721
LOSS train 0.4796736606601941 valid 0.5283526104094798
LOSS train 0.4796736606601941 valid 0.5283607644412447
LOSS train 0.4796736606601941 valid 0.5285063175273029
LOSS train 0.4796736606601941 valid 0.5284893265823378
LOSS train 0.4796736606601941 valid 0.5284529752081091
LOSS train 0.4796736606601941 valid 0.5285837595229563
LOSS train 0.4796736606601941 valid 0.5286481859236418
LOSS train 0.4796736606601941 valid 0.5286130608200169
LOSS train 0.4796736606601941 valid 0.5286868999722183
LOSS train 0.4796736606601941 valid 0.5286872096359729
LOSS train 0.4796736606601941 valid 0.5284541905774764
LOSS train 0.4796736606601941 valid 0.5283240768926364
LOSS train 0.4796736606601941 valid 0.5282109481917674
LOSS train 0.4796736606601941 valid 0.5282809330334126
LOSS train 0.4796736606601941 valid 0.5283116523633924
LOSS train 0.4796736606601941 valid 0.5282586345097402
LOSS train 0.4796736606601941 valid 0.5282349768208294
LOSS train 0.4796736606601941 valid 0.5282231317833066
LOSS train 0.4796736606601941 valid 0.5282149854209597
LOSS train 0.4796736606601941 valid 0.5281994993316717
LOSS train 0.4796736606601941 valid 0.52810139641729
LOSS train 0.4796736606601941 valid 0.5280510547430548
LOSS train 0.4796736606601941 valid 0.5280536674598785
LOSS train 0.4796736606601941 valid 0.5281406293312708
LOSS train 0.4796736606601941 valid 0.528277866011959
LOSS train 0.4796736606601941 valid 0.5283221659829488
LOSS train 0.4796736606601941 valid 0.5282712826624463
LOSS train 0.4796736606601941 valid 0.5282927456518147
LOSS train 0.4796736606601941 valid 0.5284144889351516
LOSS train 0.4796736606601941 valid 0.5283311687906583
LOSS train 0.4796736606601941 valid 0.5283695387087787
LOSS train 0.4796736606601941 valid 0.5283077604920658
LOSS train 0.4796736606601941 valid 0.5283233974829759
LOSS train 0.4796736606601941 valid 0.5282743309477442
LOSS train 0.4796736606601941 valid 0.5281860166885813
LOSS train 0.4796736606601941 valid 0.5281352039450914
LOSS train 0.4796736606601941 valid 0.5280823337721126
LOSS train 0.4796736606601941 valid 0.5281070241486872
LOSS train 0.4796736606601941 valid 0.5281420096417461
LOSS train 0.4796736606601941 valid 0.5280863780167795
LOSS train 0.4796736606601941 valid 0.5280009936481427
LOSS train 0.4796736606601941 valid 0.528053344346774
LOSS train 0.4796736606601941 valid 0.5281787142395592
LOSS train 0.4796736606601941 valid 0.528255100937406
LOSS train 0.4796736606601941 valid 0.5283227225144704
LOSS train 0.4796736606601941 valid 0.5282405227234092
LOSS train 0.4796736606601941 valid 0.5283114602701146
LOSS train 0.4796736606601941 valid 0.5282114223114349
LOSS train 0.4796736606601941 valid 0.5283184524240165
LOSS train 0.4796736606601941 valid 0.5282067860476672
LOSS train 0.4796736606601941 valid 0.5281496082325219
LOSS train 0.4796736606601941 valid 0.5281176481002606
LOSS train 0.4796736606601941 valid 0.5279901888532904
LOSS train 0.4796736606601941 valid 0.5279558883221062
LOSS train 0.4796736606601941 valid 0.5279225313663483
LOSS train 0.4796736606601941 valid 0.5280617529446362
LOSS train 0.4796736606601941 valid 0.5280892337680957
LOSS train 0.4796736606601941 valid 0.528212006044824
LOSS train 0.4796736606601941 valid 0.5283098904738672
LOSS train 0.4796736606601941 valid 0.5283754701867248
LOSS train 0.4796736606601941 valid 0.5283210296465191
LOSS train 0.4796736606601941 valid 0.52816928222955
LOSS train 0.4796736606601941 valid 0.5281944024312245
LOSS train 0.4796736606601941 valid 0.5283747194056025
LOSS train 0.4796736606601941 valid 0.528384731954603
LOSS train 0.4796736606601941 valid 0.528484986119327
LOSS train 0.4796736606601941 valid 0.5284304454347853
LOSS train 0.4796736606601941 valid 0.5284381323664852
LOSS train 0.4796736606601941 valid 0.5282890234021662
LOSS train 0.4796736606601941 valid 0.5282071658793618
LOSS train 0.4796736606601941 valid 0.5281174133949615
LOSS train 0.4796736606601941 valid 0.5281169825827169
LOSS train 0.4796736606601941 valid 0.5281443724479342
LOSS train 0.4796736606601941 valid 0.528246691753698
LOSS train 0.4796736606601941 valid 0.5281987050305242
LOSS train 0.4796736606601941 valid 0.5282630711966168
LOSS train 0.4796736606601941 valid 0.5282632296298354
LOSS train 0.4796736606601941 valid 0.5283556075274259
LOSS train 0.4796736606601941 valid 0.5284472340157517
LOSS train 0.4796736606601941 valid 0.5284262747423989
LOSS train 0.4796736606601941 valid 0.5283382105351853
LOSS train 0.4796736606601941 valid 0.5283168300308965
LOSS train 0.4796736606601941 valid 0.5284192221022868
LOSS train 0.4796736606601941 valid 0.5284704523908217
LOSS train 0.4796736606601941 valid 0.5286071587616289
LOSS train 0.4796736606601941 valid 0.5286860784118095
LOSS train 0.4796736606601941 valid 0.5286248054157118
LOSS train 0.4796736606601941 valid 0.5285396412764182
LOSS train 0.4796736606601941 valid 0.5285814263362406
LOSS train 0.4796736606601941 valid 0.528584617541896
LOSS train 0.4796736606601941 valid 0.5286490691005358
LOSS train 0.4796736606601941 valid 0.5287476098010553
LOSS train 0.4796736606601941 valid 0.52878062537879
LOSS train 0.4796736606601941 valid 0.5287698056999144
LOSS train 0.4796736606601941 valid 0.5288321896775128
LOSS train 0.4796736606601941 valid 0.5288360464116915
LOSS train 0.4796736606601941 valid 0.5287638511254937
LOSS train 0.4796736606601941 valid 0.5287494891039703
LOSS train 0.4796736606601941 valid 0.5287809974455898
EPOCH 15:
  batch 1 loss: 0.4635810852050781
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 2 loss: 0.49561432003974915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 3 loss: 0.49270668625831604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 4 loss: 0.49006419628858566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 5 loss: 0.48812697529792787
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 6 loss: 0.4851755201816559
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 7 loss: 0.4825687663895743
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 8 loss: 0.48272551223635674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 9 loss: 0.48010939028528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 10 loss: 0.4760501891374588
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 11 loss: 0.4750674935904416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 12 loss: 0.4744763895869255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 13 loss: 0.4738227495780358
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 14 loss: 0.475244260260037
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 15 loss: 0.47807188232739767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 16 loss: 0.47880454175174236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 17 loss: 0.47721557932741504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 18 loss: 0.4775910559627745
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 19 loss: 0.47905752376506205
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 20 loss: 0.47909671664237974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 21 loss: 0.478713884240105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 22 loss: 0.4782587533647364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 23 loss: 0.47941386181375256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 24 loss: 0.4791939618686835
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 25 loss: 0.47882035970687864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 26 loss: 0.47881208474819476
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 27 loss: 0.4797964360978868
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 28 loss: 0.4787145448582513
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 29 loss: 0.4787792018775282
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 30 loss: 0.47913181483745576
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 31 loss: 0.4787666682274111
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 32 loss: 0.4791080616414547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 33 loss: 0.4781877046281641
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 34 loss: 0.4785662985899869
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 35 loss: 0.47938468711716786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 36 loss: 0.4789924845099449
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 37 loss: 0.478249056919201
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 38 loss: 0.4775113996706511
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 39 loss: 0.47791103827647674
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 40 loss: 0.4783217698335648
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 41 loss: 0.4780887699708706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 42 loss: 0.47790696081661044
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 43 loss: 0.47922175290972685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 44 loss: 0.47957064617763867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 45 loss: 0.4796826011604733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 46 loss: 0.47895012277623883
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 47 loss: 0.47885827498233063
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 48 loss: 0.47957541855672997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 49 loss: 0.4795174288506411
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 50 loss: 0.4802848345041275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 51 loss: 0.4794346076600692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 52 loss: 0.47897149049318755
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 53 loss: 0.478550449857172
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 54 loss: 0.47820113433731926
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 55 loss: 0.47731888185847887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 56 loss: 0.47756236685173853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 57 loss: 0.47781708470562045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 58 loss: 0.47720428222212297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 59 loss: 0.4767416028653161
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 60 loss: 0.4772382080554962
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 61 loss: 0.47722121535754597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 62 loss: 0.47791309606644417
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 63 loss: 0.4780713367083716
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 64 loss: 0.4781191744841635
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 65 loss: 0.4788066538480612
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 66 loss: 0.4781947293967912
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 67 loss: 0.4780378083684551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 68 loss: 0.4781924407271778
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 69 loss: 0.4778959785682568
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 70 loss: 0.47802654249327525
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 71 loss: 0.4780876804405535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 72 loss: 0.47771216928958893
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 73 loss: 0.47798241695312604
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 74 loss: 0.47780267652627584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 75 loss: 0.47767457445462547
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 76 loss: 0.4781529954389522
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 77 loss: 0.4778049735279826
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 78 loss: 0.4773727563711313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 79 loss: 0.47744662889951395
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 80 loss: 0.47722234167158606
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 81 loss: 0.4771705645102042
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 82 loss: 0.47689035353137227
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 83 loss: 0.4769651458924075
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 84 loss: 0.47675107703322456
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 85 loss: 0.4767172813415527
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 86 loss: 0.4770582318305969
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 87 loss: 0.47727042607877446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 88 loss: 0.4774888049472462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 89 loss: 0.4773824586627189
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 90 loss: 0.4774009754260381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 91 loss: 0.47728749487426253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 92 loss: 0.4776502258103827
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 93 loss: 0.4777793810572675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 94 loss: 0.4777773504561566
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 95 loss: 0.47772387360271656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 96 loss: 0.4782259014124672
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 97 loss: 0.4781738436713661
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 98 loss: 0.4781841060944966
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 99 loss: 0.47821929358472726
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 100 loss: 0.47829886645078656
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 101 loss: 0.4781084683271918
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 102 loss: 0.47827158430043387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 103 loss: 0.4784917003900102
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 104 loss: 0.478516776401263
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 105 loss: 0.47860294580459595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 106 loss: 0.47845360861634306
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 107 loss: 0.4782354656223939
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 108 loss: 0.4783951778102804
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 109 loss: 0.47834997439603194
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 110 loss: 0.4784652769565582
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 111 loss: 0.4783142488282006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 112 loss: 0.47831256155456814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 113 loss: 0.47851895231061276
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 114 loss: 0.47841368406488183
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 115 loss: 0.47817453068235644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 116 loss: 0.47825383703256474
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 117 loss: 0.47878044206871945
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 118 loss: 0.4787218045380156
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 119 loss: 0.47896493783518046
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 120 loss: 0.47868896697958313
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 121 loss: 0.4787456117385675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 122 loss: 0.4790645930610719
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 123 loss: 0.479285887586392
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 124 loss: 0.47913612040781206
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 125 loss: 0.47925541090965273
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 126 loss: 0.4794054241880538
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 127 loss: 0.4793590731977478
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 128 loss: 0.47971810796298087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 129 loss: 0.47969627680704574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 130 loss: 0.47980044048566084
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 131 loss: 0.4796887556560167
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 132 loss: 0.47954490487322665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 133 loss: 0.47949555247349845
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 134 loss: 0.47937772411908675
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 135 loss: 0.4792807673966443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 136 loss: 0.47938307550023584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 137 loss: 0.4795609664742964
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 138 loss: 0.47942766028901806
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 139 loss: 0.4795598220482147
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 140 loss: 0.47959487012454444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 141 loss: 0.4794607162475586
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 142 loss: 0.4795368181567797
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 143 loss: 0.4796183970007863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 144 loss: 0.47988770591715973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 145 loss: 0.47994858458124356
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 146 loss: 0.4797758041587594
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 147 loss: 0.47999048456042803
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 148 loss: 0.4801815432068464
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 149 loss: 0.48002658394359105
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 150 loss: 0.47979910572369894
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 151 loss: 0.4799246503817325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 152 loss: 0.47995530931573166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 153 loss: 0.47992417430566026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 154 loss: 0.4798343529948941
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 155 loss: 0.48006150376412177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 156 loss: 0.48026891358387774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 157 loss: 0.4801753391126159
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 158 loss: 0.48031359043302413
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 159 loss: 0.48047725322111595
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 160 loss: 0.48059024214744567
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 161 loss: 0.4804103087564433
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 162 loss: 0.4802973579477381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 163 loss: 0.48035943873820863
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 164 loss: 0.4802587840978692
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 165 loss: 0.4801972069523551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 166 loss: 0.48034922670887176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 167 loss: 0.48033842212425737
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 168 loss: 0.48007834596293314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 169 loss: 0.47998935742491095
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 170 loss: 0.480115607380867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 171 loss: 0.4800831952638793
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 172 loss: 0.4800036473329677
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 173 loss: 0.4799065016253146
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 174 loss: 0.4800090644208864
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 175 loss: 0.47983133469309125
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 176 loss: 0.47971221652220597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 177 loss: 0.4796042832951088
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 178 loss: 0.47960479105456494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 179 loss: 0.47967154486885283
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 180 loss: 0.47963894373840754
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 181 loss: 0.4795418292777973
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 182 loss: 0.4794848702111087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 183 loss: 0.4793714296296646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 184 loss: 0.4792938143338846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 185 loss: 0.47933825190002854
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 186 loss: 0.4793280699560719
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 187 loss: 0.4792720508129201
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 188 loss: 0.47910163995433364
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 189 loss: 0.47908191438074466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 190 loss: 0.47893987250955483
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 191 loss: 0.478815903370293
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 192 loss: 0.4785549573910733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 193 loss: 0.4785738256928834
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 194 loss: 0.47861625561394644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 195 loss: 0.47853066416887136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 196 loss: 0.4785335555064435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 197 loss: 0.4787017934515997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 198 loss: 0.4788374408628001
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 199 loss: 0.4788334748553271
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 200 loss: 0.4788812102377415
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 201 loss: 0.4788716006931381
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 202 loss: 0.47889716775700597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 203 loss: 0.47866222570682393
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 204 loss: 0.47868092387330297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 205 loss: 0.4786456227302551
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 206 loss: 0.47841209954428443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 207 loss: 0.47833790828064443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 208 loss: 0.47822069147458446
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 209 loss: 0.47846743649843204
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 210 loss: 0.4784926177490325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 211 loss: 0.4785292405652774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 212 loss: 0.478693129600219
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 213 loss: 0.47873033604151766
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 214 loss: 0.4786253273487091
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 215 loss: 0.4786735283773999
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 216 loss: 0.478598742849297
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 217 loss: 0.47865241903313843
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 218 loss: 0.4788860115436239
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 219 loss: 0.4791114586129036
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 220 loss: 0.4791759125211022
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 221 loss: 0.47902326454404254
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 222 loss: 0.478929905472575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 223 loss: 0.47903829786275
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 224 loss: 0.47909182496368885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 225 loss: 0.4789484596252441
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 226 loss: 0.47887692435652807
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 227 loss: 0.47887251949520365
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 228 loss: 0.47869603309715003
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 229 loss: 0.47867075038268575
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 230 loss: 0.47882066654122396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 231 loss: 0.4787498397744579
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 232 loss: 0.4789140072876009
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 233 loss: 0.4788087158755683
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 234 loss: 0.4788723526856838
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 235 loss: 0.4789556447495805
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 236 loss: 0.4789905245021238
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 237 loss: 0.4789630937928389
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 238 loss: 0.47888905123001385
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 239 loss: 0.47886624458444665
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 240 loss: 0.4789525477836529
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 241 loss: 0.4790213944011704
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 242 loss: 0.4789385125656758
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 243 loss: 0.4790494628403903
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 244 loss: 0.4790719897776354
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 245 loss: 0.4791974407069537
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 246 loss: 0.4793385365387289
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 247 loss: 0.4793770304816937
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 248 loss: 0.4792894293223658
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 249 loss: 0.47948687502658033
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 250 loss: 0.4795191116333008
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 251 loss: 0.47958664091459785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 252 loss: 0.4795726114322269
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 253 loss: 0.47966981428885175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 254 loss: 0.47956329889184846
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 255 loss: 0.47951243180854647
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 256 loss: 0.47953390167094767
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 257 loss: 0.47940014981110274
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 258 loss: 0.47937409071497217
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 259 loss: 0.47960317215403997
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 260 loss: 0.47971203751288927
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 261 loss: 0.47972077873474794
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 262 loss: 0.47964045303013486
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 263 loss: 0.4796429592620284
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 264 loss: 0.4796537964633017
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 265 loss: 0.47953095717250177
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 266 loss: 0.47955215201342016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 267 loss: 0.47957522994123597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 268 loss: 0.47948318853307126
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 269 loss: 0.47944964462939693
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 270 loss: 0.47948976788255904
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 271 loss: 0.47951640051229416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 272 loss: 0.4794392994440654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 273 loss: 0.4793668765943129
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 274 loss: 0.4791384603637848
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 275 loss: 0.47897801583463495
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 276 loss: 0.4790672453633253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 277 loss: 0.479092198266019
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 278 loss: 0.4790240488678431
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 279 loss: 0.4790319545081012
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 280 loss: 0.4790695666202477
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 281 loss: 0.47912088375923045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 282 loss: 0.47915228239610685
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 283 loss: 0.47909064311863253
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 284 loss: 0.4790930612616136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 285 loss: 0.4791345801269799
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 286 loss: 0.47914946485649457
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 287 loss: 0.4791818048272814
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 288 loss: 0.47918593500637346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 289 loss: 0.479133142525762
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 290 loss: 0.47919822088603314
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 291 loss: 0.4791489199469589
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 292 loss: 0.47919731036032714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 293 loss: 0.47925187611742637
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 294 loss: 0.47935465089723367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 295 loss: 0.47932231486853905
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 296 loss: 0.4792831203824765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 297 loss: 0.47937745779050317
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 298 loss: 0.47933975402140777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 299 loss: 0.47929784286779703
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 300 loss: 0.47929283519585925
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 301 loss: 0.4793944810316016
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 302 loss: 0.4793214679553809
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 303 loss: 0.47929094884261836
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 304 loss: 0.4793119160948615
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 305 loss: 0.47937014552413443
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 306 loss: 0.4793515020336201
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 307 loss: 0.47931528499149734
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 308 loss: 0.47935751815894984
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 309 loss: 0.47943317465797597
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 310 loss: 0.47939343990818145
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 311 loss: 0.47948177067796516
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 312 loss: 0.4793708994984627
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 313 loss: 0.47929657876681975
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 314 loss: 0.47920289170590175
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 315 loss: 0.47915734440561325
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 316 loss: 0.47922383220512654
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 317 loss: 0.4792823329896957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 318 loss: 0.47929700909170714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 319 loss: 0.47931595263436294
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 320 loss: 0.47938838582485915
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 321 loss: 0.47928595134402363
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 322 loss: 0.47934787502940396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 323 loss: 0.47952935385630224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 324 loss: 0.4794751681663372
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 325 loss: 0.47944537107761087
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 326 loss: 0.47946505403957485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 327 loss: 0.4794844546631571
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 328 loss: 0.4795836367439933
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 329 loss: 0.4795241034320785
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 330 loss: 0.4795970343279116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 331 loss: 0.4796870751503371
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 332 loss: 0.4796364125178521
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 333 loss: 0.47969013676271066
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 334 loss: 0.47965048146462014
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 335 loss: 0.4796522623567439
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 336 loss: 0.47970114799127694
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 337 loss: 0.47962855921301006
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 338 loss: 0.47960847228236453
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 339 loss: 0.47951911323893387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 340 loss: 0.4795994216028382
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 341 loss: 0.4795848685275774
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 342 loss: 0.4796339283909714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 343 loss: 0.47951754927635193
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 344 loss: 0.4794738596781742
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 345 loss: 0.47947164765302686
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 346 loss: 0.47955041219388816
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 347 loss: 0.47958663913289823
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 348 loss: 0.4796256670492819
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 349 loss: 0.47956297979997015
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 350 loss: 0.4795222135952541
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 351 loss: 0.479443448731023
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 352 loss: 0.4794298252090812
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 353 loss: 0.4795047959085902
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 354 loss: 0.47946527406657485
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 355 loss: 0.4794569849967957
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 356 loss: 0.47937038934297777
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 357 loss: 0.4793795499147153
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 358 loss: 0.4794783041130897
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 359 loss: 0.47945626507562517
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 360 loss: 0.4793763922320472
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 361 loss: 0.47929934558775944
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 362 loss: 0.47934996703053045
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 363 loss: 0.4793768310842435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 364 loss: 0.4792985754844907
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 365 loss: 0.4793237363638943
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 366 loss: 0.47927215377815435
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 367 loss: 0.47923387030814585
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 368 loss: 0.479268966242671
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 369 loss: 0.4792470832665761
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 370 loss: 0.47927352826337555
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 371 loss: 0.47929206827901444
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 372 loss: 0.47924984222458256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 373 loss: 0.479265247209462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 374 loss: 0.4792483763739387
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 375 loss: 0.4792198402881622
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 376 loss: 0.4791640140750307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 377 loss: 0.4792069667846518
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 378 loss: 0.4793009243944965
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 379 loss: 0.47931232081239644
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 380 loss: 0.47922630482598355
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 381 loss: 0.4792127594390879
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 382 loss: 0.47915826730079053
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 383 loss: 0.47924155603812196
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 384 loss: 0.4792801335764428
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 385 loss: 0.4792720888342176
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 386 loss: 0.4793321779818115
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 387 loss: 0.4793107904667078
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 388 loss: 0.4793929335536416
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 389 loss: 0.47935674107779574
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 390 loss: 0.47936594043022546
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 391 loss: 0.4793459800503138
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 392 loss: 0.47937719904038373
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 393 loss: 0.47935208564496223
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 394 loss: 0.47934900307413286
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 395 loss: 0.4792783678332462
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 396 loss: 0.4793391205144651
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 397 loss: 0.47939631200257116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 398 loss: 0.47950801462983367
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 399 loss: 0.47956444789891256
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 400 loss: 0.47954225324094296
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 401 loss: 0.4794711382163136
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 402 loss: 0.4793232389498706
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 403 loss: 0.47929290129292396
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 404 loss: 0.4792375858910013
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 405 loss: 0.47923858607256853
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 406 loss: 0.4793137104934072
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 407 loss: 0.47927867092137255
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 408 loss: 0.47925524457412605
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 409 loss: 0.47919644987379134
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 410 loss: 0.47918027108762323
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 411 loss: 0.47926274957157977
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 412 loss: 0.47931600579069655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 413 loss: 0.47926502041608887
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 414 loss: 0.4794126028455974
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 415 loss: 0.4795021533247936
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 416 loss: 0.47959359412869584
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 417 loss: 0.4795790557666934
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 418 loss: 0.47957435663807335
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 419 loss: 0.47963217676112646
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 420 loss: 0.47961178649039493
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 421 loss: 0.47973916564588026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 422 loss: 0.47981536925121504
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 423 loss: 0.4797404546546034
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 424 loss: 0.4797749581202021
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 425 loss: 0.47974462859770833
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 426 loss: 0.4796526653106224
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 427 loss: 0.479662512727867
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 428 loss: 0.47961388249820636
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 429 loss: 0.4795314217364038
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 430 loss: 0.4796166076909664
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 431 loss: 0.47956695101653896
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 432 loss: 0.4795693860699733
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 433 loss: 0.47947835364738184
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 434 loss: 0.4794923611637634
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 435 loss: 0.47939363423435166
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 436 loss: 0.479502377911992
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 437 loss: 0.4794848568788655
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 438 loss: 0.4794535621252234
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 439 loss: 0.4793835075270885
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 440 loss: 0.47936719649217346
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 441 loss: 0.4793896110825528
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 442 loss: 0.47938729249514067
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 443 loss: 0.4794225494963859
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 444 loss: 0.4793606321285437
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 445 loss: 0.47949934126286026
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 446 loss: 0.4793982533863307
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 447 loss: 0.47951231333500055
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 448 loss: 0.47954847291111946
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 449 loss: 0.47958837399769466
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 450 loss: 0.4795534623331494
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 451 loss: 0.4795224887304454
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 452 loss: 0.4795917054984422
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 453 loss: 0.4795534788378027
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 454 loss: 0.47949767651011765
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 455 loss: 0.47948594499420333
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 456 loss: 0.47943194230136116
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 457 loss: 0.47939535095081287
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 458 loss: 0.4794082820545638
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 459 loss: 0.47935330244450786
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 460 loss: 0.47946869407011117
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 461 loss: 0.4794405321883535
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 462 loss: 0.4794151729448533
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 463 loss: 0.4794448522074434
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 464 loss: 0.479464676744979
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 465 loss: 0.47944039183278236
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 466 loss: 0.4794558535445913
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 467 loss: 0.4794301851403279
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 468 loss: 0.47950577315611714
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 469 loss: 0.4795499010635083
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 470 loss: 0.4796203875795324
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 471 loss: 0.4795918174230369
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
  batch 472 loss: 0.4796169198796911
####################
Base Model Weight Norm = tensor(0., device='mps:0')
Model Weight Norm = tensor(0., device='mps:0')
####################
LOSS train 0.4796169198796911 valid 0.49101415276527405
LOSS train 0.4796169198796911 valid 0.506797268986702
LOSS train 0.4796169198796911 valid 0.5053828060626984
LOSS train 0.4796169198796911 valid 0.5007774457335472
LOSS train 0.4796169198796911 valid 0.4957453191280365
LOSS train 0.4796169198796911 valid 0.5013919423023859
LOSS train 0.4796169198796911 valid 0.5080409092562539
LOSS train 0.4796169198796911 valid 0.5105516351759434
LOSS train 0.4796169198796911 valid 0.5123411383893755
LOSS train 0.4796169198796911 valid 0.5166225522756577
LOSS train 0.4796169198796911 valid 0.5198890864849091
LOSS train 0.4796169198796911 valid 0.5189003472526869
LOSS train 0.4796169198796911 valid 0.5234343340763679
LOSS train 0.4796169198796911 valid 0.5256336735827583
LOSS train 0.4796169198796911 valid 0.5270188232262929
LOSS train 0.4796169198796911 valid 0.5249435864388943
LOSS train 0.4796169198796911 valid 0.5273517545531777
LOSS train 0.4796169198796911 valid 0.5277709431118436
LOSS train 0.4796169198796911 valid 0.5266573742816323
LOSS train 0.4796169198796911 valid 0.5277157545089721
LOSS train 0.4796169198796911 valid 0.5275318736121768
LOSS train 0.4796169198796911 valid 0.5261847945776853
LOSS train 0.4796169198796911 valid 0.5263804689697598
LOSS train 0.4796169198796911 valid 0.5253127987186114
LOSS train 0.4796169198796911 valid 0.5240828633308411
LOSS train 0.4796169198796911 valid 0.5225265369965479
LOSS train 0.4796169198796911 valid 0.5221043847225331
LOSS train 0.4796169198796911 valid 0.5226932742765972
LOSS train 0.4796169198796911 valid 0.521741985247053
LOSS train 0.4796169198796911 valid 0.5231990704933802
LOSS train 0.4796169198796911 valid 0.5244740872613846
LOSS train 0.4796169198796911 valid 0.5247295619919896
LOSS train 0.4796169198796911 valid 0.5260812179608778
LOSS train 0.4796169198796911 valid 0.5268783823532217
LOSS train 0.4796169198796911 valid 0.5285497043813978
LOSS train 0.4796169198796911 valid 0.5290024934543504
LOSS train 0.4796169198796911 valid 0.5293143270788966
LOSS train 0.4796169198796911 valid 0.5298279092500084
LOSS train 0.4796169198796911 valid 0.5297148586847843
LOSS train 0.4796169198796911 valid 0.5303166024386883
LOSS train 0.4796169198796911 valid 0.5304123475784208
LOSS train 0.4796169198796911 valid 0.5303741700592495
LOSS train 0.4796169198796911 valid 0.5303527830645095
LOSS train 0.4796169198796911 valid 0.5304303744977171
LOSS train 0.4796169198796911 valid 0.5303937508000268
LOSS train 0.4796169198796911 valid 0.5311120742041132
LOSS train 0.4796169198796911 valid 0.5311694151543557
LOSS train 0.4796169198796911 valid 0.5320809986442327
LOSS train 0.4796169198796911 valid 0.5332457173843773
LOSS train 0.4796169198796911 valid 0.5326028209924698
LOSS train 0.4796169198796911 valid 0.5333302774850059
LOSS train 0.4796169198796911 valid 0.5337189281216035
LOSS train 0.4796169198796911 valid 0.5335336175729644
LOSS train 0.4796169198796911 valid 0.5329025398801874
LOSS train 0.4796169198796911 valid 0.5329187859188427
LOSS train 0.4796169198796911 valid 0.5325771187032972
LOSS train 0.4796169198796911 valid 0.5321527761325502
LOSS train 0.4796169198796911 valid 0.532290898520371
LOSS train 0.4796169198796911 valid 0.5329400078725006
LOSS train 0.4796169198796911 valid 0.5324257761240005
LOSS train 0.4796169198796911 valid 0.5311757257727326
LOSS train 0.4796169198796911 valid 0.5313036586007764
LOSS train 0.4796169198796911 valid 0.5311277480352492
LOSS train 0.4796169198796911 valid 0.5315799992531538
LOSS train 0.4796169198796911 valid 0.5318825483322144
LOSS train 0.4796169198796911 valid 0.531189063281724
LOSS train 0.4796169198796911 valid 0.5309567033354916
LOSS train 0.4796169198796911 valid 0.5309260697925792
LOSS train 0.4796169198796911 valid 0.5308848325757013
LOSS train 0.4796169198796911 valid 0.5301671573093959
LOSS train 0.4796169198796911 valid 0.5296143045727636
LOSS train 0.4796169198796911 valid 0.5294213448133733
LOSS train 0.4796169198796911 valid 0.5298867964581268
LOSS train 0.4796169198796911 valid 0.5291271745353132
LOSS train 0.4796169198796911 valid 0.52911448041598
LOSS train 0.4796169198796911 valid 0.5294016697689107
LOSS train 0.4796169198796911 valid 0.5292752567049744
LOSS train 0.4796169198796911 valid 0.5292996653379538
LOSS train 0.4796169198796911 valid 0.5289516535740865
LOSS train 0.4796169198796911 valid 0.5288381922990084
LOSS train 0.4796169198796911 valid 0.528410452015606
LOSS train 0.4796169198796911 valid 0.5285054783268672
LOSS train 0.4796169198796911 valid 0.528212050716561
LOSS train 0.4796169198796911 valid 0.5282755738922528
LOSS train 0.4796169198796911 valid 0.5279517906553605
LOSS train 0.4796169198796911 valid 0.5276398911725643
LOSS train 0.4796169198796911 valid 0.527539486515111
LOSS train 0.4796169198796911 valid 0.5275659131055529
LOSS train 0.4796169198796911 valid 0.5276948190137242
LOSS train 0.4796169198796911 valid 0.5281758868032032
LOSS train 0.4796169198796911 valid 0.5283167679886241
LOSS train 0.4796169198796911 valid 0.5281641130214152
LOSS train 0.4796169198796911 valid 0.5279401082505462
LOSS train 0.4796169198796911 valid 0.5277920825050232
LOSS train 0.4796169198796911 valid 0.5275882987599624
LOSS train 0.4796169198796911 valid 0.527525955500702
LOSS train 0.4796169198796911 valid 0.5276055320636514
LOSS train 0.4796169198796911 valid 0.5273522378838792
LOSS train 0.4796169198796911 valid 0.5278653963045641
LOSS train 0.4796169198796911 valid 0.5281181320548057
LOSS train 0.4796169198796911 valid 0.5279930006749559
LOSS train 0.4796169198796911 valid 0.5280543165464028
LOSS train 0.4796169198796911 valid 0.5283783601904378
LOSS train 0.4796169198796911 valid 0.5285532953074346
LOSS train 0.4796169198796911 valid 0.5287280170690446
LOSS train 0.4796169198796911 valid 0.528898040922183
LOSS train 0.4796169198796911 valid 0.5287573524167605
LOSS train 0.4796169198796911 valid 0.5287070304707244
LOSS train 0.4796169198796911 valid 0.5289119096524125
LOSS train 0.4796169198796911 valid 0.5292632186954672
LOSS train 0.4796169198796911 valid 0.5291524456964957
LOSS train 0.4796169198796911 valid 0.5290310050227812
LOSS train 0.4796169198796911 valid 0.5292115683576702
LOSS train 0.4796169198796911 valid 0.5287211511218757
LOSS train 0.4796169198796911 valid 0.528768109238666
LOSS train 0.4796169198796911 valid 0.5290420317444308
LOSS train 0.4796169198796911 valid 0.5288929282090603
LOSS train 0.4796169198796911 valid 0.5287686293408022
LOSS train 0.4796169198796911 valid 0.5286690116930408
LOSS train 0.4796169198796911 valid 0.5286384254693985
LOSS train 0.4796169198796911 valid 0.5284425246814066
LOSS train 0.4796169198796911 valid 0.5282326643584204
LOSS train 0.4796169198796911 valid 0.5283263960504919
LOSS train 0.4796169198796911 valid 0.5285381501720797
LOSS train 0.4796169198796911 valid 0.5287270727157592
LOSS train 0.4796169198796911 valid 0.5287592344813876
LOSS train 0.4796169198796911 valid 0.5289730349863608
LOSS train 0.4796169198796911 valid 0.5292296931147575
LOSS train 0.4796169198796911 valid 0.5293628481007362
LOSS train 0.4796169198796911 valid 0.5292818825978499
LOSS train 0.4796169198796911 valid 0.5293064576978902
LOSS train 0.4796169198796911 valid 0.5290466379938703
LOSS train 0.4796169198796911 valid 0.5289671479311204
LOSS train 0.4796169198796911 valid 0.5289154986837017
LOSS train 0.4796169198796911 valid 0.5290463858180576
LOSS train 0.4796169198796911 valid 0.5290424766785958
LOSS train 0.4796169198796911 valid 0.5288039828739027
LOSS train 0.4796169198796911 valid 0.5285199420607608
LOSS train 0.4796169198796911 valid 0.5284292455628622
LOSS train 0.4796169198796911 valid 0.5284484294908387
LOSS train 0.4796169198796911 valid 0.5286196819011201
LOSS train 0.4796169198796911 valid 0.5287828216670265
LOSS train 0.4796169198796911 valid 0.5286852544421082
LOSS train 0.4796169198796911 valid 0.5286928777479463
LOSS train 0.4796169198796911 valid 0.528409815040128
LOSS train 0.4796169198796911 valid 0.5287130550570684
LOSS train 0.4796169198796911 valid 0.5284437350675363
LOSS train 0.4796169198796911 valid 0.5288390609863642
LOSS train 0.4796169198796911 valid 0.528740040807916
LOSS train 0.4796169198796911 valid 0.5288861346244812
LOSS train 0.4796169198796911 valid 0.5288829254788279
LOSS train 0.4796169198796911 valid 0.5285909989554631
LOSS train 0.4796169198796911 valid 0.5285493071172752
LOSS train 0.4796169198796911 valid 0.5286795332447275
LOSS train 0.4796169198796911 valid 0.5286033663057512
LOSS train 0.4796169198796911 valid 0.5290218112178338
LOSS train 0.4796169198796911 valid 0.5290154596422888
LOSS train 0.4796169198796911 valid 0.5291044381977636
LOSS train 0.4796169198796911 valid 0.5288752557346655
LOSS train 0.4796169198796911 valid 0.5288189612329006
LOSS train 0.4796169198796911 valid 0.5290289506408739
LOSS train 0.4796169198796911 valid 0.5288782767307612
LOSS train 0.4796169198796911 valid 0.5288043183051735
LOSS train 0.4796169198796911 valid 0.528647441689561
LOSS train 0.4796169198796911 valid 0.5283748462344661
LOSS train 0.4796169198796911 valid 0.5281421838395567
LOSS train 0.4796169198796911 valid 0.5283475569979159
LOSS train 0.4796169198796911 valid 0.5285393686166832
LOSS train 0.4796169198796911 valid 0.528661381034456
LOSS train 0.4796169198796911 valid 0.528697637775365
LOSS train 0.4796169198796911 valid 0.5289701643394448
LOSS train 0.4796169198796911 valid 0.5290823414228684
LOSS train 0.4796169198796911 valid 0.529151825029726
LOSS train 0.4796169198796911 valid 0.52918817034398
LOSS train 0.4796169198796911 valid 0.5292690799917493
LOSS train 0.4796169198796911 valid 0.5293919936838475
LOSS train 0.4796169198796911 valid 0.5295512425360707
LOSS train 0.4796169198796911 valid 0.5298230857326743
LOSS train 0.4796169198796911 valid 0.5299166935449205
LOSS train 0.4796169198796911 valid 0.5299498556388749
LOSS train 0.4796169198796911 valid 0.5299902240545051
LOSS train 0.4796169198796911 valid 0.5300318154987398
LOSS train 0.4796169198796911 valid 0.5299871435256603
LOSS train 0.4796169198796911 valid 0.5300314204524392
LOSS train 0.4796169198796911 valid 0.5299442863142169
LOSS train 0.4796169198796911 valid 0.5300050183970441
LOSS train 0.4796169198796911 valid 0.5302295664096262
LOSS train 0.4796169198796911 valid 0.5302722186167189
LOSS train 0.4796169198796911 valid 0.5301017654005182
LOSS train 0.4796169198796911 valid 0.530006238033897
LOSS train 0.4796169198796911 valid 0.5302951844574894
LOSS train 0.4796169198796911 valid 0.5304341480756799
LOSS train 0.4796169198796911 valid 0.5304825889631875
LOSS train 0.4796169198796911 valid 0.5303216797789347
LOSS train 0.4796169198796911 valid 0.5300832412181756
LOSS train 0.4796169198796911 valid 0.5300691468375069
LOSS train 0.4796169198796911 valid 0.5301392798496382
LOSS train 0.4796169198796911 valid 0.5300296888206945
LOSS train 0.4796169198796911 valid 0.5301482557651386
LOSS train 0.4796169198796911 valid 0.5301553797721863
LOSS train 0.4796169198796911 valid 0.530020311400665
LOSS train 0.4796169198796911 valid 0.5300991549940393
LOSS train 0.4796169198796911 valid 0.5300027405099915
LOSS train 0.4796169198796911 valid 0.5301882049032286
LOSS train 0.4796169198796911 valid 0.530173381944982
LOSS train 0.4796169198796911 valid 0.5303915611748556
LOSS train 0.4796169198796911 valid 0.5303495523434331
LOSS train 0.4796169198796911 valid 0.5302944524356952
LOSS train 0.4796169198796911 valid 0.5300263477284373
LOSS train 0.4796169198796911 valid 0.5299470640364148
LOSS train 0.4796169198796911 valid 0.5301284818287709
LOSS train 0.4796169198796911 valid 0.530112586212608
LOSS train 0.4796169198796911 valid 0.530111034431368
LOSS train 0.4796169198796911 valid 0.5300541236021808
LOSS train 0.4796169198796911 valid 0.5298452746036441
LOSS train 0.4796169198796911 valid 0.5297700787583987
LOSS train 0.4796169198796911 valid 0.5299214426822926
LOSS train 0.4796169198796911 valid 0.5298599764841412
LOSS train 0.4796169198796911 valid 0.5299430650118824
LOSS train 0.4796169198796911 valid 0.5298873847181147
LOSS train 0.4796169198796911 valid 0.529996988460489
LOSS train 0.4796169198796911 valid 0.5301821827888489
LOSS train 0.4796169198796911 valid 0.5303858029468177
LOSS train 0.4796169198796911 valid 0.530395619571209
LOSS train 0.4796169198796911 valid 0.5303564023971558
LOSS train 0.4796169198796911 valid 0.5302933475612539
LOSS train 0.4796169198796911 valid 0.530439170971841
LOSS train 0.4796169198796911 valid 0.5305898707163962
LOSS train 0.4796169198796911 valid 0.5305531542894621
LOSS train 0.4796169198796911 valid 0.5306756486063419
LOSS train 0.4796169198796911 valid 0.5305791561737722
LOSS train 0.4796169198796911 valid 0.5306327312157072
LOSS train 0.4796169198796911 valid 0.5304118394851685
LOSS train 0.4796169198796911 valid 0.530392111876072
LOSS train 0.4796169198796911 valid 0.5304909612270112
LOSS train 0.4796169198796911 valid 0.5304860545922134
LOSS train 0.4796169198796911 valid 0.5304507457254305
LOSS train 0.4796169198796911 valid 0.5304092276497048
LOSS train 0.4796169198796911 valid 0.5304608484691157
LOSS train 0.4796169198796911 valid 0.5304397746920586
LOSS train 0.4796169198796911 valid 0.5306006709569717
LOSS train 0.4796169198796911 valid 0.5306268033902507
LOSS train 0.4796169198796911 valid 0.5305911690119363
LOSS train 0.4796169198796911 valid 0.5306015566724246
LOSS train 0.4796169198796911 valid 0.5305581988120566
LOSS train 0.4796169198796911 valid 0.5305038433733994
LOSS train 0.4796169198796911 valid 0.5307039261346886
LOSS train 0.4796169198796911 valid 0.5306905774820235
LOSS train 0.4796169198796911 valid 0.5306572916517296
LOSS train 0.4796169198796911 valid 0.5308299787044525
LOSS train 0.4796169198796911 valid 0.530792290945927
LOSS train 0.4796169198796911 valid 0.5308895983866283
LOSS train 0.4796169198796911 valid 0.5309795840926792
LOSS train 0.4796169198796911 valid 0.5309762896045925
LOSS train 0.4796169198796911 valid 0.5309551012282278
LOSS train 0.4796169198796911 valid 0.5309125240892172
LOSS train 0.4796169198796911 valid 0.5308758609489708
LOSS train 0.4796169198796911 valid 0.5309038762898408
LOSS train 0.4796169198796911 valid 0.5309644861571117
LOSS train 0.4796169198796911 valid 0.5309568698589618
LOSS train 0.4796169198796911 valid 0.5310330582761217
LOSS train 0.4796169198796911 valid 0.5310918600049638
LOSS train 0.4796169198796911 valid 0.5311464812365775
LOSS train 0.4796169198796911 valid 0.5311187530557314
LOSS train 0.4796169198796911 valid 0.5311965530773379
LOSS train 0.4796169198796911 valid 0.5311907809927947
LOSS train 0.4796169198796911 valid 0.5311089921533392
LOSS train 0.4796169198796911 valid 0.5311161622182646
LOSS train 0.4796169198796911 valid 0.5313479439476608
LOSS train 0.4796169198796911 valid 0.5314457498214863
LOSS train 0.4796169198796911 valid 0.5315378145538133
LOSS train 0.4796169198796911 valid 0.5315472639220602
LOSS train 0.4796169198796911 valid 0.5316948050107712
LOSS train 0.4796169198796911 valid 0.5316790231387981
LOSS train 0.4796169198796911 valid 0.5316417709263889
LOSS train 0.4796169198796911 valid 0.5317733592313268
LOSS train 0.4796169198796911 valid 0.5318389289645942
LOSS train 0.4796169198796911 valid 0.5318024169198043
LOSS train 0.4796169198796911 valid 0.5318765990623009
LOSS train 0.4796169198796911 valid 0.5318778949124473
LOSS train 0.4796169198796911 valid 0.5316452946102916
LOSS train 0.4796169198796911 valid 0.5315134455548957
LOSS train 0.4796169198796911 valid 0.5313998882003892
LOSS train 0.4796169198796911 valid 0.5314708490606764
LOSS train 0.4796169198796911 valid 0.5315026312543635
LOSS train 0.4796169198796911 valid 0.5314492401960013
LOSS train 0.4796169198796911 valid 0.5314266874815113
LOSS train 0.4796169198796911 valid 0.5314153865393665
LOSS train 0.4796169198796911 valid 0.5314064652862021
LOSS train 0.4796169198796911 valid 0.5313904762268067
LOSS train 0.4796169198796911 valid 0.5312915573415068
LOSS train 0.4796169198796911 valid 0.5312422246557392
LOSS train 0.4796169198796911 valid 0.5312454256995139
LOSS train 0.4796169198796911 valid 0.5313343523310966
LOSS train 0.4796169198796911 valid 0.531471917588832
LOSS train 0.4796169198796911 valid 0.531517981274708
LOSS train 0.4796169198796911 valid 0.5314664752395065
LOSS train 0.4796169198796911 valid 0.5314872984918172
LOSS train 0.4796169198796911 valid 0.5316095140865416
LOSS train 0.4796169198796911 valid 0.5315246162811915
LOSS train 0.4796169198796911 valid 0.5315628628002053
LOSS train 0.4796169198796911 valid 0.5315004107573175
LOSS train 0.4796169198796911 valid 0.5315162779474416
LOSS train 0.4796169198796911 valid 0.5314669752199399
LOSS train 0.4796169198796911 valid 0.5313784245584832
LOSS train 0.4796169198796911 valid 0.5313275836262048
LOSS train 0.4796169198796911 valid 0.5312752873190839
LOSS train 0.4796169198796911 valid 0.5312975736020448
LOSS train 0.4796169198796911 valid 0.5313327515009537
LOSS train 0.4796169198796911 valid 0.5312778155649862
LOSS train 0.4796169198796911 valid 0.531192830712849
LOSS train 0.4796169198796911 valid 0.5312453067073455
LOSS train 0.4796169198796911 valid 0.531370761295477
LOSS train 0.4796169198796911 valid 0.531447763465772
LOSS train 0.4796169198796911 valid 0.5315147239064414
LOSS train 0.4796169198796911 valid 0.5314319867499268
LOSS train 0.4796169198796911 valid 0.5315037710057449
LOSS train 0.4796169198796911 valid 0.5314031601327021
LOSS train 0.4796169198796911 valid 0.5315097385439379
LOSS train 0.4796169198796911 valid 0.5313970888033509
LOSS train 0.4796169198796911 valid 0.5313398793478993
LOSS train 0.4796169198796911 valid 0.5313084732671702
LOSS train 0.4796169198796911 valid 0.53118035566327
LOSS train 0.4796169198796911 valid 0.5311446080421224
LOSS train 0.4796169198796911 valid 0.5311117099798642
LOSS train 0.4796169198796911 valid 0.5312519465670263
LOSS train 0.4796169198796911 valid 0.531279830301938
LOSS train 0.4796169198796911 valid 0.5314023753673565
LOSS train 0.4796169198796911 valid 0.531500968255533
LOSS train 0.4796169198796911 valid 0.5315666862509467
LOSS train 0.4796169198796911 valid 0.5315110988667364
LOSS train 0.4796169198796911 valid 0.5313582302755621
LOSS train 0.4796169198796911 valid 0.531382713142458
LOSS train 0.4796169198796911 valid 0.5315634098773945
LOSS train 0.4796169198796911 valid 0.5315738707336027
LOSS train 0.4796169198796911 valid 0.5316751231217668
LOSS train 0.4796169198796911 valid 0.5316204993767272
LOSS train 0.4796169198796911 valid 0.5316288052402305
LOSS train 0.4796169198796911 valid 0.5314802018414556
LOSS train 0.4796169198796911 valid 0.5313979593269965
LOSS train 0.4796169198796911 valid 0.5313082250856584
LOSS train 0.4796169198796911 valid 0.5313079351047326
LOSS train 0.4796169198796911 valid 0.5313355108565562
LOSS train 0.4796169198796911 valid 0.5314382868277472
LOSS train 0.4796169198796911 valid 0.5313894924046336
LOSS train 0.4796169198796911 valid 0.5314543136110196
LOSS train 0.4796169198796911 valid 0.5314554294694741
LOSS train 0.4796169198796911 valid 0.5315489764699991
LOSS train 0.4796169198796911 valid 0.53163988465566
LOSS train 0.4796169198796911 valid 0.531618303997176
LOSS train 0.4796169198796911 valid 0.531530245501771
LOSS train 0.4796169198796911 valid 0.5315092945132743
LOSS train 0.4796169198796911 valid 0.5316122690104897
LOSS train 0.4796169198796911 valid 0.5316623372715071
LOSS train 0.4796169198796911 valid 0.5318000408125595
LOSS train 0.4796169198796911 valid 0.5318795406583989
LOSS train 0.4796169198796911 valid 0.5318180836048447
LOSS train 0.4796169198796911 valid 0.5317321328976967
LOSS train 0.4796169198796911 valid 0.5317746067943679
LOSS train 0.4796169198796911 valid 0.5317774169147015
LOSS train 0.4796169198796911 valid 0.5318422006272874
LOSS train 0.4796169198796911 valid 0.5319413168160296
LOSS train 0.4796169198796911 valid 0.5319741500474862
LOSS train 0.4796169198796911 valid 0.5319643687907156
LOSS train 0.4796169198796911 valid 0.5320270250104878
LOSS train 0.4796169198796911 valid 0.532029087019097
LOSS train 0.4796169198796911 valid 0.5319560641976079
LOSS train 0.4796169198796911 valid 0.5319417438915243
LOSS train 0.4796169198796911 valid 0.5319731921199861
bichrom_seq(
  (conv1d): Conv1d(4, 256, kernel_size=(24,), stride=(1,))
  (relu): ReLU()
  (batchNorm1d): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (maxPool1d): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=True)
  (lstm): LSTM(256, 32, batch_first=True)
  (tanh): Tanh()
  (model_dense_repeat): Sequential(
    (0): Linear(in_features=32, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=512, out_features=512, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=512, out_features=512, bias=True)
    (7): ReLU()
    (8): Dropout(p=0.5, inplace=False)
  )
  (linear): Linear(in_features=512, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
bimodal_network(
  (base_model): bichrom_seq(
    (conv1d): Conv1d(4, 256, kernel_size=(24,), stride=(1,))
    (relu): ReLU()
    (batchNorm1d): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (maxPool1d): MaxPool1d(kernel_size=15, stride=15, padding=0, dilation=1, ceil_mode=True)
    (lstm): LSTM(256, 32, batch_first=True)
    (tanh): Tanh()
    (model_dense_repeat): Sequential(
      (0): Linear(in_features=32, out_features=512, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=512, out_features=512, bias=True)
      (4): ReLU()
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=512, out_features=512, bias=True)
      (7): ReLU()
      (8): Dropout(p=0.5, inplace=False)
    )
    (linear): Linear(in_features=512, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
  (linear): Linear(in_features=512, out_features=1, bias=True)
  (tanh): Tanh()
  (model): bichrom_chrom(
    (_reshape): _reshape()
    (conv1d): Conv1d(12, 15, kernel_size=(1,), stride=(1,), padding=valid)
    (relu): ReLU()
    (lstm): LSTM(15, 5, batch_first=True)
    (relu2): ReLU()
    (linear): Linear(in_features=5, out_features=1, bias=True)
    (tanh): Tanh()
  )
  (linear2): Linear(in_features=2, out_features=1, bias=True)
  (sigmoid): Sigmoid()
)
0.17940199335548174
0.17940199335548174
    17923.41 real     17299.95 user      2758.61 sys
